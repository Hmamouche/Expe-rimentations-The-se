# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP260
# number_predictions; 40;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=13, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.7070386401876072
0.7306156525656228
0.7760470767772709
0.7261337114741024
0.9247202127543357
0.9872894416369947
0.7391146100781016
0.7679288732810763
0.7950849597016756
0.6510886986183304
0.6347731828407743
0.4792077495383559
0.12436688924939754
0.14710175449713891
0.2860314240111242
0.6958615417932751
0.236400831996601
0.39961890337302325
0.3644550594498024
0.4308566132936123
0.5585489344309491
0.9336442346719216
0.9156514005384698
0.5629806327776335
0.6318183482786341
0.8124498616572782
0.7085939612526785
0.8653466614220667
0.7576534992653595
0.6620657850393791
0.7829726981841634
0.618524943268097
0.7359469393916088
0.6040330501290678
0.45932453296705894
0.44011134425081533
0.6037399173421308
0.2383233442076983
0.3357752385281717
0.5367746681711933
