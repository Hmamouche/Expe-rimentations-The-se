# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP272A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=8, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.006127227696468306
0.006866260144804173
0.008048780336646357
0.006751182174988554
0.005527372852481111
0.0035745424931402036
0.007401658654015857
0.003895555781429776
0.0033198033879267373
0.00496780086798102
0.003379415851516584
0.003087572869419644
0.0054791090504335005
0.004782603470311912
0.004972443563058685
0.00486902151569918
0.006828934975696231
0.005799074525629957
0.0051974417770908055
0.006498302901242247
0.007615602380400374
0.008189982778268606
0.007520709981754605
0.007810289529673474
0.005158516195807861
0.005888905536733083
0.007714836939305051
0.008399054658854608
0.007309061322363479
0.007128637000594925
0.008761585064996486
0.004576992193544585
0.007278790519894085
0.0058061375002797415
0.0053388688082785015
0.005267931761705113
0.0024941887460288494
0.004517405440153338
0.006442165906833932
0.0033366828713369007
0.004943009421029691
0.004615564493903601
0.004676781772531774
0.005412951479546893
0.005909272115940378
0.005067395237812454
0.004329600507101298
0.0038662049742175467
0.004028428392199878
0.005080756308401915
0.0035705179008453077
0.004153529055242677
0.003833952583231129
0.0039545029998102514
0.004743137488624304
0.003689351829770547
0.003591209375203034
0.0038784012300014828
0.0016728942415871954
0.0022514261075020953
0.002807891442703354
0.003042932393100634
0.0025087684212541047
0.004126138928927862
0.0037625207385260703
0.005178909720637497
0.006561817637037264
0.004571985212619534
0.004850690173900027
0.006468324541351577
0.005004471793502196
0.0069728961337303655
0.0048561724887583625
0.0052026583541607855
0.006511505478174325
0.0020267519176022613
0.003376782856354386
0.0054127442173864965
0.006738598594545069
0.002768370028100619
0.006467713195937263
0.006971242972552579
0.0061229696008302725
0.009304223426715025
0.007710730504544791
0.00929135154117687
0.009585809555779973
0.006265297008266106
0.009576306809546324
0.010038778778121297
0.00900568380163326
0.010258996885149713
0.007662405696718698
0.007818798608221541
0.00887388878176391
0.007049353788630873
0.0070237945883838675
0.00849725403387663
0.005095692000320852
0.0037608935429416348
