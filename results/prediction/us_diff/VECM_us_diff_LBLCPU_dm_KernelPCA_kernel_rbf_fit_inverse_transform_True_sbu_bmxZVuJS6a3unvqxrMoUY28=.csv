# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; LBLCPU
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=1, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
4.70178114638127e-05
0.0016694799656178847
0.009703233972401703
0.0045805720676428555
0.007419764516746936
0.005968800878685697
0.004746317097581276
0.004723516988467235
0.0019507166130875724
0.004352764345475176
0.005418978500397954
0.00325228715150778
0.002723597865236159
0.00774572030646865
0.005667666761884879
0.00587931333281395
0.00899569714368824
0.007626331772792046
0.008919923238468904
0.0065796581778997144
0.007958610221072185
0.006134742449585753
0.005590078992186066
0.004964023887086019
0.0016538732214524347
0.0020902611334588875
0.00435418178710697
0.007768102419915518
0.010104410947776582
0.012096325787062562
0.009527999004411826
0.005311514079406445
0.004819459066041327
0.007161075241228522
0.003538145708645561
0.002910684630237018
0.0056002034940686824
0.0003125848050944419
0.0024382361232428533
0.006773012225751397
0.003967843852708817
0.0009943628580310411
0.004165222043989849
0.0017795093535536808
0.0034126052761890967
0.002143640570338393
0.004425589592420218
0.005780957057009194
0.0020146089135388632
0.002281208700746164
0.0012827959585397395
-0.0013686391906058012
0.00198138403909692
0.0029615712792644025
0.0046273960329560725
0.004344696757997452
0.002133053563166309
0.006251742422202958
0.007838657102621778
0.008675066056637796
0.008950206962172254
0.006232913322886594
0.006320479982493852
0.005304212308944792
0.0038941516132481955
0.004141495449494344
0.016974564832374375
0.0165884141828762
0.0063528649465725215
0.022836247378390972
-0.0003962157779612138
0.012716803182786911
-0.003283702336246093
0.0032101217788983744
-0.008843700053163457
-0.004054518080021464
0.0030609219460468948
-0.001832917768104293
0.002226896301766911
9.234089532316305e-05
-5.180667132974478e-05
-0.0028690206476712095
0.004946381449074196
-5.3903078928165004e-05
0.00488466931082357
0.0055829099272934075
0.007831687921171927
0.0065830497553983685
0.006468756845174564
0.0029170744344500063
0.009160006451800554
0.010069849183795051
0.007443585914918897
0.007000079146486192
0.00913618493918474
0.012163583254387213
0.013052845608533195
0.008668387227967443
-0.0013874660214286448
-0.005387986020084014
