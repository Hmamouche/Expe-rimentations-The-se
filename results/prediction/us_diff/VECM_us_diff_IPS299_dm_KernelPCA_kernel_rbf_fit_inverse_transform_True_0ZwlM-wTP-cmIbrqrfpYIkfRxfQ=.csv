# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; IPS299
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=13, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0025722147809271456
-0.007052698275102905
0.028153550349154448
-0.01828190161017259
0.004400956205387258
0.0051286856321037955
0.006588328357275188
0.013298208982750201
0.012472595659692602
0.013034022117251302
0.015021274933204825
-0.008479639416510977
-0.006745961703361811
-1.4727474414700202e-05
0.004957808116744511
0.01487567875193164
0.011823599698064655
0.007981945408505315
0.004812740722888456
0.010707602061920417
0.019716443406376447
0.016167698041837333
-0.006412933012746754
0.0006706752476369864
-0.006512249509145541
-0.0011405232025396297
0.0011856126764749645
0.009598267879240823
0.0005980253734557575
-0.0020343901324520746
-0.004740005308603576
0.0008828634465216573
0.007858956286747112
-0.00017754439378820947
-0.006581380162764783
0.005202333593746916
0.0006557423002253656
0.017114117217342364
0.010482669789460749
0.008830800399410043
0.011433078563820444
0.005943967188077419
0.015960211956087718
0.004408258352306084
0.008861594821848383
0.012880285335948365
0.003207072644524075
0.005995069844552476
0.0038692452675168415
0.0012897799694817646
0.005729799673561729
0.01389381996688784
0.013425555507030725
0.017028515711188286
0.012655304330509726
0.013468166307409263
0.018518784899728784
0.014933553928481499
0.01634754878122193
0.017525666292030298
0.0136609355367292
0.004441304328181124
0.013856582185122712
0.00910601556146562
0.014368809972249505
0.015317983084987495
-0.0006310735260274748
0.010591859597880775
0.0013920031199575358
0.0033018306603751946
-0.0022166777575799664
0.0011579133657436112
-0.012241578341731424
-0.014175952700719108
5.43430712563785e-05
0.004521932628140938
0.002366918090643276
-0.00795003230998385
-0.00602672856068758
0.021666707065936344
0.0007150001346234577
0.01541471340979292
0.009162155095307553
0.005406038370830368
0.010512206712403084
0.0036106974749576357
0.0005177331475831404
0.005374694687107786
0.011708196821655926
0.011190662518229597
0.009645240897789821
0.008325641118009649
0.008279826758089975
0.008858943167290799
0.01188361735857113
0.0002882581358286356
0.0029007508735077597
-0.01238439564928423
-0.0030140899490197054
-0.0016231222466636835
