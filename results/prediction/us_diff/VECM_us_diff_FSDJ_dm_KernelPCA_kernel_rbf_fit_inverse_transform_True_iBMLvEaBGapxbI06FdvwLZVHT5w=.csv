# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; FSDJ
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=15, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.0023006324350705416
-0.009467510425817366
-0.003680460949456393
-0.016730235995072583
0.005707882239251798
-0.0003992795522533808
0.005401776614183401
-0.004782392483500755
0.0009676090653743051
0.015470430092323005
0.016153307118091653
0.010806303827059813
0.003067195562285855
0.006882623806304689
0.011547971713190032
-0.0009748916317627492
0.01241755965690804
-0.00048046482766164137
0.00447406826441521
0.06007761075072879
0.02701277560123143
-0.0317439389117169
-0.004398424208077483
-0.0033704543489257205
0.01264161431640197
0.016996054381902177
0.011239171536472387
0.0016460708460094755
0.0030418571910362227
0.000978245045711765
0.017864108502426028
-0.005276324662414558
0.004623499544746679
0.004396550578824871
0.011013989029929873
-0.0025767184479875585
0.006622004344817809
0.010515040199699146
-0.0011708829066606353
0.006620560380339504
0.00966743516899268
3.520626781125676e-05
0.0017599412701871072
-0.0054525227415067245
0.011422319120295508
0.004138246729152414
-0.002791151620679078
0.008348115012133131
0.030719753423070414
0.025146329974385595
0.01839917457628733
0.008789668068852473
0.022185030992895535
0.013687603241780786
0.024866497125944284
0.021599304436873856
0.04424511959113178
0.04004102201607753
0.04759940509792869
0.025787703650326343
0.054514993771895046
0.025957660451244553
-0.021152079572884838
0.014184626473824742
0.0077196316882779704
0.054065293572419834
0.04015456746198015
0.04796304754111117
0.01831413530355401
-0.0021439171956577395
0.001445835381210893
-0.0017751226769704784
-0.008641358154610894
-0.016554697594212704
-0.00693727576842584
-0.014037093006998838
-0.0372617849561151
0.022875461426601247
-0.04905438946797062
-0.01245707855925154
-0.045411629218869806
-0.008199022733141525
0.01995883355798737
0.023180172968438502
0.019063843134253473
0.027654290929693577
0.051527775259837386
0.003638042188561923
-0.007051511963092817
0.0007663115687119443
0.017432279603662854
0.001366069088158589
0.01963533468673238
0.046222614194364485
0.006473974696104235
0.0369558646373819
0.04544577599864982
0.03061805084263589
-0.019583427877243754
0.002546280872945993
