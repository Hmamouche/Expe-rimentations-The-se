# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP265
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=8, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.008845721860683019
0.005057309163921404
0.0035752919916683034
0.010858392383478018
0.006326375439915008
0.006053189380193757
0.032948160229688245
0.007573129318979975
0.025871199242932862
0.009297800539575705
0.010533778933681005
0.015932908881402464
0.016090484756618326
0.008600577789558358
0.004541022481372342
0.015748288504898466
0.008013344446796002
0.0012580598880610294
0.016204419457773723
-0.001896057166061871
0.009472184259296364
-0.0010275978036745348
0.011074299351042646
-0.00023758540257123005
0.012696346999138592
0.0025424632389087366
0.011205783757251647
0.0035873543679146233
0.002910846634351826
0.004501610718660664
0.005643040666508299
0.0034334542383702565
0.0032011577332394345
-0.003773634381012068
-0.004389865929701881
0.0035142309472695186
-0.0020654701143750656
-0.002749175748401466
0.008534269139665965
0.002783481383728283
-0.0018926787809787334
0.006560125689880245
-0.004706446219304385
0.0023030684265299747
0.005047390927323425
-0.007270420209792645
0.02036007261144633
-0.0002970018223449056
0.00235868389776749
0.0034899085816164936
-0.0008439267220491592
0.007992805701959198
-0.0005556318270689628
-0.0006276359913258756
0.010167108128560658
0.003366782106329931
0.004629080769624725
0.007286602959540978
0.004544348355745307
0.0002187735026554596
0.00556148127243139
0.0035526908272014764
0.012645454990555785
0.01492194100566251
0.010460582132816594
0.004880427582999107
0.012634968207222728
0.012656152489044501
0.011903221704440874
6.528340608848789e-05
0.008992976815483545
0.004228216819617316
0.00958309557270185
0.014804430189750774
0.018460359598792452
0.014855070156314095
0.016772777487079074
0.005366576842101413
0.018058074844549143
0.005361658823366324
0.0045819949418960965
0.0077919250824620995
0.012074462179501044
0.010256290814286478
-0.0021288764505851586
-0.0010664312470764193
0.009824887876282943
0.004447276051979321
0.0013551334621002577
0.00044256554286573394
0.005899920794773181
0.005196511324797747
0.004871913322425051
0.00019811628534936298
0.009144031126256981
0.003574766712799084
0.011598920251255836
0.014290641717739465
0.018610501995314853
0.00899143977185598
