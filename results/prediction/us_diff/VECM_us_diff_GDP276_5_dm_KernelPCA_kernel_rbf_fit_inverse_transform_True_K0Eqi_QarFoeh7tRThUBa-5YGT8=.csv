# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP276_5
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=6, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0012934898545889915
-0.004495697627379339
-0.00796424126060474
0.0014162856139466676
0.01709560319749763
-0.0028126361295831067
0.027819162263587188
-0.0012311467754431273
0.00013462658520209956
0.007673032122023533
-0.0019244943048251323
-0.004619391155775979
-0.004404089296383382
0.005986543166228249
0.013971675265311876
-0.00389873613019497
0.01143604674220497
-0.0024353184299828125
0.022296934660833982
-0.0029565270419674794
0.017306182011412458
0.0010921355342061422
0.009466305735269485
0.008956988134884679
0.010682850969820128
0.011037077836312852
0.0008467146349398673
0.003913800690013364
0.0016748006065339192
0.01158887852466651
0.009290798464374812
0.013401412131612934
-0.0013350043054421116
0.004573395048336059
0.00685855021426829
0.005734945207199144
0.006332743412571781
0.007031017460079814
0.012242629163176299
0.004092598740468474
0.017179485978430865
0.0030968903228105384
0.007709723999984559
0.004689581122143761
0.01211598191881258
-0.003638525927588694
0.008141708248693948
0.0029443225056129375
0.008959326590903628
0.012334092592864734
0.000731040186553259
0.0017749024976301433
0.00273783060628651
0.0037943300464276983
0.004746861220099115
0.00920811706945026
0.004115522753434476
0.0006772838565446485
0.009165867678639516
-0.0004093540698056027
0.007513295221795716
0.002907610034468169
0.00469737868861789
0.0005242776137838862
0.00514386977699555
0.008131949009225663
0.004130218883047585
0.005368662408337033
0.005012668537054283
0.009672781308388858
0.006294431717833839
-9.235666832102855e-05
0.007179204319501088
-0.00046958676379820765
0.010633969197353803
-0.0017573201677884669
-0.0014631039274437506
0.0037475083827945488
0.003612349758987131
0.0014191899455815067
0.011107116244128067
0.005756881525718809
0.007178445408693698
0.0051548596903529115
0.01094424083923094
0.002674479892605707
0.0068374023673178855
0.008127796829039769
0.006859883163110824
0.008542517678981128
0.01383772003884427
0.008249223526369531
0.005850229130493413
0.013259543095682344
0.010749841517545789
-0.0009384225258590561
0.005033012800735411
0.0038157809151260465
0.011090112639476261
0.010611920588125639
