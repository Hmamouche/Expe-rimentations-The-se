# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP276_7
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=1, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.002781265221655867
0.006475128625636888
0.005189165245047968
0.007702866718942721
0.005723298505771358
0.005938229286029015
0.005388930445196202
0.005540926034700154
0.004719334307672951
0.004544743692327371
0.006533347500171637
0.0055751178029720015
0.005166358618967655
0.004130781971007608
0.005744428061723622
0.0055790869600694315
0.005623597348847161
0.0057576167324587145
0.0056757349545856995
0.006249917635159347
0.005790841574390774
0.007250478793808478
0.0075408188644290695
0.007368019572482163
0.006430768548746267
0.0068097974014918825
0.008383761065746533
0.007932004675315482
0.010270021840223558
0.008252259476085124
0.009381169841830071
0.009287360718224605
0.009633039335988797
0.006307451833112391
0.00412551896048653
0.00689670611500565
0.006388295722593299
0.005339753965270788
0.004903040878514584
0.006312567316090485
0.005595041025099147
0.006048122387371157
0.005268030787952681
0.003412259052944451
0.0027427716664458817
0.003540205265013806
0.004665700463752182
0.004864386617680317
0.005329396583227925
0.005819104248564669
0.005728368050511865
0.0070376045475778
0.007261061423988253
0.006704196751322914
0.00679845249192457
0.006587589007488234
0.0070714184279387846
0.0058106832113968415
0.005854508631523266
0.005840653180698733
0.005136198880891611
0.005041233006200851
0.00642294205798891
0.00731705856103303
0.006755302094729367
0.007376943890315089
0.00855077148005295
0.008578059333478187
0.009181387181594915
0.008478822357065919
0.007862112831024646
0.008034596081936926
0.009077225941019108
0.00636667173738293
0.006065190665205721
0.008256997127053831
0.007306528846196092
0.007384926096115154
0.007674939386440146
0.007385414780630671
0.006350770677559297
0.005745189921936242
0.00675639922761556
0.0068293755985080265
0.00731392010439502
0.00701474108473169
0.007556738149542079
0.005974852058238454
0.0073253766084076756
0.009891901709950792
0.007930354192511771
0.008123380383921389
0.009687749694963292
0.005386826299507275
0.002076914693655677
0.005065673046439629
0.004267639578657458
0.006606959790537145
0.007104312814932511
0.009962374579292492
