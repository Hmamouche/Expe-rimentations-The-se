# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; PMI
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=10, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.24286560586704037
-0.04474172780280189
0.025781327289121483
-0.27911713574535885
-0.1672994129904185
0.004839323103292315
0.07867614166631579
0.08921110658896274
0.022608808622852514
0.0673194725288225
0.14562189404776754
-0.00045977170780551677
-0.05694161582121234
-0.031179317803833914
0.07822880049200547
0.0045204164019291004
-0.02442235058344964
-0.14241905889116935
0.06605445844803545
0.02648481644673848
-0.02356174206543757
0.08203046197193548
-0.18620278220521438
-0.05536517352950378
-0.015360050586595907
0.000596962828468859
-0.004554041059638712
-0.0010723817785992691
0.015621797646147425
-0.0020047166306531652
0.11040292176371601
0.07576620560640897
0.03599840827636655
-0.026228147059603125
0.10192836853628778
0.046794196441880036
0.0037505750632347203
0.06374537743779746
-0.11491237394054762
-0.1705756613306915
0.017239936365430877
0.07953479207679834
0.07043479874356277
-0.017905704996224424
0.05569961515544711
-0.028752084077566915
-0.12284228552309974
0.09592808132384442
-0.06852819001516344
-0.07100841667850945
-0.05672400645929065
0.0052287617632412395
-0.00425602575206048
0.16227896644224277
0.07713893441804007
-0.01528118115937242
0.02213846422963369
-0.03386405057105844
0.030946795666271457
-0.0416108149433031
-0.1261709451766408
-0.08838402291142765
0.12936746710948754
0.04907267251612295
0.0808997605861593
0.06460700926930305
-0.06647185869189089
-0.1390545684217414
-0.05662536371037837
-0.08745955839389694
-0.036467093152102704
-0.015763278651426703
0.001739238456315309
0.11461058139080368
0.2518604424058667
0.02038719798939141
-0.052498383928118585
0.006873743887238319
-0.1840463435090422
0.08397141281748897
0.04055847475728863
-0.017538964676671952
0.03474835667651858
0.041634704895473724
0.009135431390370909
-0.08465370439218645
-0.11152484891114142
-0.045434330208791535
0.017300307535187593
-0.07239545204439014
0.12344333794214032
-0.03108684266086353
-0.04915145887288787
0.08660550999986052
0.047507521345542064
-0.06268542236159938
0.029175336698943823
0.0016216991348272872
-0.07592315626338433
0.04864293004898052
