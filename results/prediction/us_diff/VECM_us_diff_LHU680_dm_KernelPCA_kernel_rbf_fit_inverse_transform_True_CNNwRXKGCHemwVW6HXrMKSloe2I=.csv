# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; LHU680
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=8, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0012728624303719634
-0.11767401628458021
-0.07155059094467486
-0.052558114391154445
-0.01155146062059996
0.0049877427098494985
-0.005563126919025933
0.0015353544954844287
0.011926900678756455
0.013482506824998224
-0.035218477018473054
-0.015313987845866071
0.016671295787108204
-0.01741556620222938
-0.01633253023990695
-0.014068056716209892
-0.03831170596244688
-0.04607020155828581
-0.011023631551753933
-0.04074495599432205
-0.009394550942735667
-0.018267877671515605
-0.03346809468950669
-0.014155946162669408
0.004966344652092887
0.0027378334838620063
-0.0021026684797746716
0.005378746393820715
0.08037786436000746
0.02977505167781693
0.0754484738828214
0.07852589127230171
-0.01605290678811973
0.019467131291721493
0.06226821383913804
0.044810574314293444
0.05136500788085376
0.05779397034941888
-0.013704192057189432
-0.023736423046892767
-0.007669936187010674
0.0038912245760913855
0.01853085080938101
-0.005251185936372011
0.01342454807699445
-0.019252909568258425
-0.0693600406785002
0.034269979224983135
-0.03622322480948684
0.01712835209902995
0.02392700099240125
0.024563475140335366
-0.03728241973602632
-0.03819052237144477
-0.037219662283346326
-0.03484943639153415
0.01839134339944594
-0.04083859305835451
-0.003164183224534184
-0.019188918925853476
0.0070949359500597844
0.013848131174883505
-0.04729497192276037
-0.0013228372792782033
-0.07205891007367307
-0.01167911765705542
-0.06283513307672273
-0.019682601619464064
0.014108927792576262
-0.0041510639265847655
0.07434470135853374
0.049429569945182765
0.09478265769639294
0.07371740529622899
0.02727224487229864
0.03238878562462563
-0.009040528123643327
0.0700090635227084
0.010899399788169211
0.06597333114068896
0.06390262632799924
0.017201598923734435
0.01653091238884083
-0.011346544422357878
-0.04996150352906208
0.010877040294104974
0.006259752940097819
-0.026938031783460388
-0.031830808576912825
-0.02514672949715606
-0.05236105418515462
-0.02341858711827967
-0.012135338416614364
-0.03160265561170372
-0.01355313080166315
0.019781535273455997
0.04778821933766614
0.033271026241417596
0.006977518009128314
0.028313491886970226
