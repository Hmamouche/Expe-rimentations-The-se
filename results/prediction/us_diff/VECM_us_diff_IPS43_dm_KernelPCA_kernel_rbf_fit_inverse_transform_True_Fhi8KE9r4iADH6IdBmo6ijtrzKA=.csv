# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; IPS43
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=12, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.000172378875028272
0.012330039292325424
0.006158041185804946
-0.014513236594974577
-0.0027806853399065666
0.0033923063190463214
0.014186290574241468
0.010494437779068541
0.004268871955874802
0.008244801717389214
0.011552263454891715
-0.006617359879278107
-0.004956427459885056
0.0009511589960139728
0.005683885265555912
0.014436207221038444
0.013645930338233947
0.002907801253485511
0.011521853121415768
0.015802195687510383
0.013657995560522834
0.013293317674006232
-0.005484716728330362
-0.0008224105465072466
-0.009060661160430077
-0.00016567226667386177
0.003177261066448647
0.004645046101872748
-0.003948454329196087
-0.003381197324237425
-0.005287997306244293
0.006012328739976478
0.008080512985173517
-0.00332453155647338
-0.00022397817366056233
0.005651944996686478
0.001355761530263128
0.018177794851461707
0.008486532022045214
0.0004042499333101828
0.015105155990931134
0.00865381787776174
0.015784449342157024
0.006991272745324184
0.01176899457332832
0.0129064633694607
0.008395354142202292
0.008631911409550882
0.0024880147651936842
0.0016805890076715918
0.0041825916587818
0.019069222141823206
0.015954119281273615
0.01909051404975648
0.01806891160729608
0.01501539112308877
0.022322935481672843
0.018568283640905313
0.01835595348412172
0.01405336345523663
0.011245897275041267
0.008540611944596477
0.018183693974514012
0.016235377068559657
0.02057940061802867
0.02344554589051687
0.0075750640152393665
0.011055301526984609
0.0036302289830025623
0.0040882554967166945
-0.0071825214513417494
-0.0066919906902733264
-0.020096527301451065
-0.020780682791771414
0.015257799944627838
0.007875084721153162
0.0052403308051841785
-0.004563348965843319
-0.008674491434516866
0.018544242463462215
0.004292523426390686
0.012313400983555723
0.004436906308907718
0.006289035117209091
0.0017855169835369901
0.0037055309026912623
0.005150706552197713
0.006916482879167275
0.012674956508446867
0.014107464521282828
0.013053713600877119
0.0020726438765263687
0.0009035532532598802
0.00071803624723596
0.016049892649243697
-0.00258323109738855
0.00436933755861743
-0.0052099501857087145
-0.009057767551446817
-0.0024713460317422565
