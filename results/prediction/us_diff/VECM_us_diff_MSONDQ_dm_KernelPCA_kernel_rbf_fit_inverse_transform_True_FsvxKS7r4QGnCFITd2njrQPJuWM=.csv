# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; MSONDQ
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=2, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.034736887544524864
0.03322867317431035
0.02458440106661484
0.031199910081090618
-0.008354806088622557
0.005590031476455253
-0.014845202968326855
0.020811102628429376
-0.004914064285969133
-0.0005481158065868581
0.008387089970549719
0.02210107453987353
-0.023684758839363808
-0.03377270791321024
0.006353929697475792
0.016280116502130126
0.03940283769647037
0.021135999021041543
-0.0019662772574678307
0.03196095980111408
0.0082978512417375
0.042110131185140606
0.008523774127149804
-0.006047755493898738
-0.014859898887469067
-0.012853899893520454
0.02008168459291989
0.014441179681514081
-0.045595091252057296
-0.06264913552225752
-0.007293282445249955
0.04831384509849127
-0.011924114391014148
-0.019556285790584462
-0.015153636072644593
-0.008620327349600627
0.016399070732210766
0.007333224498659705
-0.016333323591623504
-0.02749753120640567
-0.0025480009483898752
0.03705953335068511
0.05503995710397863
0.04638065708603548
0.023182216515220306
0.01627486900998051
-0.0054959185427154375
-0.020650021612829528
0.001572727751845306
0.0034179767002359054
0.058731575064575575
0.05936495966164408
0.016917188794272293
0.012935501826838523
-0.003776418112016674
0.018592731316012426
0.027565282656492697
0.04324006823291761
0.05677030276751314
0.007800999140940896
-0.005681866236585172
1.6037918859849315e-06
-0.0012057737562938772
0.01176851198642806
0.007471730438743135
0.0390219976196376
0.03227989038473278
-0.019590405634826186
-0.0046141988956092915
0.002842888827707057
-0.003177072929017013
-0.003912400298857161
-0.04564994557058291
-0.07222822003516463
-0.05102308961137455
-0.050077543117134964
-0.05172414398099438
-0.016659138210283583
-0.031298831479753916
0.0034597166115461204
0.033388491264957736
0.05147937800778347
0.037757888219994505
0.006935080270299379
-0.02252507955223487
0.008347751860728147
0.015057762144275563
-0.011843178615840635
0.0520152769499226
0.026679219552376645
0.0819489353334808
0.022594668067172995
-0.022816042303907005
0.00514797862681517
0.01478537529286768
0.0052423554053317445
0.0008383910120760736
-0.0008818566378588524
-0.01540154115136805
-0.01658318219074527
