# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; LHEL
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=12, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.024806347305212785
0.06909967071887599
-0.018603635199032464
-0.019484764676716268
0.005637690292759616
0.0261011476632157
0.05028862365012629
0.02657903747636186
0.016489391835064277
0.008279601716720307
0.031434756170888395
0.001900154866717671
-0.022562612022683094
-0.013931059373110871
0.01401835085140919
0.028845207158790704
0.019212338935519716
0.031381093466488694
0.007445423364016438
-0.04432070545784438
0.03813741483340616
0.056389854989203334
-0.08714602230521568
-0.0422390140769056
-0.01117687916130818
0.010771853417808971
-0.035738244293803734
-0.09808478298162426
-0.061951435089795004
-0.09553679210450064
-0.07406998149422422
-0.004888035079028607
-0.024597994144447938
-0.002071377090008295
0.07472935776413095
0.01694936556399545
-0.013507624456273308
0.016459563372141595
-0.0058135331185591764
-0.025918467725690897
0.05770483316859002
0.05344704623195289
0.09638868017415445
-0.031516724779372084
0.036026561944586304
-0.005568212498495692
-0.002892006655837706
0.011046770663754375
0.025685070607885083
-0.003458640217706612
-0.02227811992552569
-0.03650929207882924
-0.0024742522736659056
-0.004021810287593438
0.07730266630934157
0.017327093443359136
0.01897657017083244
-0.015181534501826058
0.029826550005365132
-0.013320819025494781
-0.025108137998757135
-0.017375672319398728
0.002900560352522826
-0.05573027840810972
-0.0002437234204976371
0.012958764146153138
-0.028706007796865732
-0.022782274037907307
-0.04521171006021884
-0.03524866107451915
-0.0758006057123338
-0.06673440099600655
-0.12098144669613606
-0.09549578371092547
-0.010530768141439661
0.0141016252446102
-0.010581688948465052
-0.009638897080780248
-0.06930859513592558
-0.018502458816000395
0.02290824677591726
0.04526393494058558
-0.0368901752401439
-0.06562079290513023
-0.019873028067878953
-0.024076160724393152
-0.023215036648733256
0.0036021069479162515
0.009366710044581443
-0.011693026256552032
0.007641990721462535
-0.06202159351583972
-0.04541571871097752
0.0013661340544378255
-0.009699835215021503
-0.00440195477293368
-0.01989095218979165
-0.08938627416146533
-0.017915054208639047
-0.05950308476633639
