# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP285A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=6, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.007223342099580029
-0.015401343901520002
0.009434755217464725
0.01453034842995795
-0.019734418085715164
-0.005632130075054677
-0.013390819950748886
-0.0027919521213383316
-0.00156820330983099
0.01768292546642628
0.01345104605660465
-0.02790672533275306
0.00801990256760804
0.00101566148121689
0.01824927614287822
0.02363020905961207
-0.0008669472846375634
0.018562095834856508
0.015392126294784921
0.0148687204573786
-0.002574985943869489
-0.0028320018029916348
0.010662647636297241
0.012269747138986192
-0.013486324437905563
0.009849495404562966
0.008583393780182698
-0.018132345114505177
0.021828396561870748
0.04129474321865003
-0.005678624969949133
0.00554788403985957
-0.021318753088631348
0.00442691240762882
-0.019934079073287536
0.010629665352809544
0.00890025071365464
-0.007342118481547639
0.00046818985865474923
0.002638516346433999
-0.015575087188451364
0.003637969739478516
-0.005869113019588246
0.009821061012415819
0.009303079129686991
0.01029452731741341
0.007300993403717724
0.009679190224311273
-0.01066301012083629
0.002298667431745108
-0.006135813514535188
-0.0034394101080627917
-0.003461363287340337
0.0020866110021556692
-0.007500675087028318
-0.010631593325400137
-0.004821590697583152
-0.01091803209719643
-0.019266522883307487
-0.010517988979225464
-0.016996537710339238
-0.0062132871757202635
-0.0022274546612344806
0.008992744434791677
0.007440604320313135
0.01350905420644888
0.013058374185678633
8.811542612194388e-05
0.009461887216228659
0.0002259510891791292
-0.002389303643525799
-0.00972484244673764
-0.008617723691408589
-0.018520168007311953
-0.006050683727099878
0.007335749312264059
0.0025661270625573843
0.0064488890648972605
0.013699110278642837
-0.007644207522117512
0.0100082688834865
0.006077418583980835
0.01882368509271322
0.011715690805293416
0.009776566681295605
0.015712508332577105
0.002435623277465977
0.018611025745504294
0.01504474277960038
0.019543261001365327
0.013897776426136025
0.015274513346720992
0.015057215877871375
-0.011778959021169709
0.008929097932435256
0.00655813458034782
0.008497030551395718
0.02958332467024346
0.027678196062596038
0.05423883265033823
