# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; MSONDQ
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=9, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.035140665856951664
-0.0011714578049564286
0.0319239421478853
0.05911019403358607
-0.008203531090555272
-0.013830585169736908
-0.004028284479499142
0.04858551399915698
0.023566930885946705
-0.01459677012558687
0.04617965972415328
-0.011734898764202827
-0.041385266946351196
-0.03561179672799146
0.006021514603542801
0.015603127685573285
0.0045292725485880266
-0.007114838519501697
-0.010926538718964547
0.08396099841464764
-0.017646906451005872
0.03833777179994927
-0.01693305700718129
0.004202261309198787
0.013334485955058113
-0.016458219827983504
0.04256645577067687
0.011008765902790289
-0.03821033009643096
-0.033843089631558576
-0.03818857832874123
0.041209215521410124
-0.006766535361739424
-0.03270237312616058
0.016184327431736888
-0.012811759428188792
-0.005488733636960966
0.008238062892496173
0.034763243722540874
0.01708017962939137
0.02366384780335212
0.025949938955971256
0.01700121572254272
0.01202822646148571
-0.006198638140782711
0.016139426572728165
-0.010715882227525893
-0.02055273261071669
-0.011430114430308735
-0.01294968175300695
0.0516394742170527
0.07730395168307841
0.014976605906607023
0.007978094502054929
0.017483112372168107
0.002353289727389317
0.012718636634135716
0.044553415097448645
0.06668672955418078
0.033163848608993185
-0.013550484052482784
-0.00207300030873505
-0.01808415599799055
0.00769565801035125
0.011693446255670304
0.028824567816301258
0.010371788186597392
-0.018972768637377985
-0.005630108137398381
0.04095957648706125
0.02881363568611116
-0.0295556717979652
-0.05145881135279115
-0.08758760694808668
-0.07610778996881357
-0.0541090817936787
-0.033959191106251146
-0.009071617806842631
0.01676558754204349
0.008274356107180301
0.017030015814140268
0.014558068662079258
0.04946375808910539
0.033929358367128175
-0.020241347162628612
-0.010068650654701736
-0.01640590320431275
-0.01787835657397819
0.061344597164288195
0.05037089381735807
0.09255487195557788
0.048546553980675394
-0.044285551871392666
-0.011206296130534567
0.057431331302428786
0.015061701726232569
-0.032159936304597805
0.0057589844131054006
0.003335108011144866
0.017567294384526394
