# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP261
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=6, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.007085151536139005
-0.011904009257732572
0.05225091579654108
-0.01194004832548624
-0.003880403498157395
0.02101518465642388
0.04048324613349187
0.03581193828186039
-0.00470766246765548
-0.0046438253899175296
0.01595359359669074
0.03403444084526974
-0.004916173672467265
0.005666994913089489
0.012590386640483892
-0.02789070550312325
-0.004118371682781187
-0.017976636147090264
0.014957342085307471
0.010324613800689941
0.01437559661990176
0.01979888601276492
-0.01064066085812592
-0.010689705545572858
0.0008350823223144711
0.000473734649963118
-0.007258057717283599
-0.03189030982488266
-0.05851073428966452
-0.046951825215363306
0.003311693168314785
0.0016762684440911548
0.025447698408273284
0.010589856808399684
0.009368736498337738
0.0020967331076020695
0.01196654472461987
0.02406634799493613
0.00913636575649688
0.0014885379199957882
0.009455617039747666
0.03345182648236538
0.017272474085145144
0.0038928723360503984
0.015548796408567952
-0.005987169151679584
-0.004768575539832303
0.0011464214368858087
0.019388979491493985
0.01612643173118475
0.010250782463959005
0.0012078736676511695
0.013631395145755402
0.01295178955983676
0.0011479554550690922
0.011941285499085737
0.011050665812662985
0.007931510671891958
0.020363903878686113
0.0015177805327475833
0.012399781174346878
0.02968881050257808
0.024920347703729764
-0.011794772733408978
0.00030430531481910074
0.005560984072763749
0.005605618874199608
0.0058756902813642655
0.0033873221465522104
-0.001973478588099404
0.009897133548918613
0.014805333111130152
0.00020000949650262473
0.004874869655726502
0.020212044077108835
0.0007267104108707974
0.0010792985044406588
0.020195269400677243
-0.004651247362077302
0.03076293449629538
0.029922821889110742
0.05179046382039048
0.020869099543566715
-0.0019539423090257028
0.025145831842410912
0.018176784102503927
0.03033362615051096
0.024935766747160498
0.017163045185815715
0.005250158856318549
0.024722974858734276
-0.039742244761900976
-0.04478326740620591
-0.0397482815793998
-0.05634154139014276
-0.037112178919055085
-0.05621562123612322
-0.07540440531810239
-0.05599947501182757
-0.05789472200944425
