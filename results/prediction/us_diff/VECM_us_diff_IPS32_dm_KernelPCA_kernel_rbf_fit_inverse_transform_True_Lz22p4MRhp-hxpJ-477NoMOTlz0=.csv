# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; IPS32
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=11, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.008548453837374192
0.0177116410719709
-7.642640323859452e-06
-0.014856955052654826
-0.010297019920102663
0.0011815236402382442
0.014377596864860122
0.006040661621991081
0.006008736655599344
0.0008182268837410801
0.01788129802882854
0.0006009287187405564
-0.00657849461637256
-0.005436083277889013
0.0032767669600079295
0.01118845921299827
0.015189884062767724
0.006542837141482474
0.012825478169643936
0.010717649301141068
0.005948906217481746
0.02212455025581824
-0.009283674124662966
-0.006673933328171679
-0.008144556368382443
-0.00415646841653799
0.005040985138485601
0.005568089472928358
-0.001530284416900935
-0.010006987076453136
-0.004218569019350256
0.002349399445809911
0.008938943946991365
0.0008158002574230434
0.007303873772409115
0.011315787066486914
-0.002432453485900052
0.017322075815817427
0.009193050210690064
-0.005866146594652376
0.015018163941262546
0.013592016332994086
0.019554380002298862
0.01133815140741185
0.01532072767945452
0.011504169780208235
0.011483395563268934
0.0020173472119254902
0.00131086492700149
0.0008335379870772998
-0.0008093727009901382
0.022537828443772872
0.015750762088236083
0.019386537811009418
0.020083817962505607
0.015303009054128605
0.022341097006220726
0.01607267159521186
0.017962180263229186
0.01419544572536174
0.00329415749522434
0.007038411770011143
0.020315726705757757
0.014192888112977567
0.02576023479212716
0.025677518443577824
0.014029185342001723
0.011557529373294068
0.0055631630512273525
0.0014884781042429668
-0.010482960504039514
-0.010250294608544066
-0.02008877734687573
-0.023708435446886094
0.02335795643714888
0.015268788616322464
0.003671420530264595
0.0016321461183191233
-0.00943382403012942
0.010376048077882501
0.008720155816122616
0.01622319854836086
0.0064201587704981605
0.0031302402745938865
-0.0010103884254777267
0.0010364579232658758
0.004358537001428107
0.007657457373069273
0.008414053776469711
0.00029888796762237053
0.02122597062333565
0.002100506273199509
-0.0023347716288420572
0.0058814127542410515
0.015638478247834847
-3.088848530584734e-05
0.006411892995292208
-0.0002775390734654589
-0.005734539752989947
0.0015977889749206426
