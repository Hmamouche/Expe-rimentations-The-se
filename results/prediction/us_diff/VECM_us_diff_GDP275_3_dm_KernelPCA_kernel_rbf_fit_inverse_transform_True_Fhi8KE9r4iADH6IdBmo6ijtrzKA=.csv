# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP275_3
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=12, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.011368445772173077
-0.018008472614382723
0.004989069133541423
0.0098041838491855
-0.0072013906484853785
-0.00305077265595133
0.006316207824709654
0.010810716305341698
-0.00155023048374032
-0.0001772631517568176
-0.003153528733763898
-0.061169097014430164
-0.022456255304815997
-0.03290497941636768
0.014540358274132456
-0.01509588332865292
0.0015424744286909272
0.007302587040118604
0.016889215479601045
0.007814097517384851
0.002564894049964552
-0.005903520504104998
0.004883513813080894
0.02412486473683678
0.004263248468635718
0.007203141110738026
0.008130476171125675
-0.0034465723452553965
0.012937974377112096
0.02357513809757624
-0.012073543115858235
0.02890229157397285
-0.01800700050457383
0.03935797431094131
-0.035348587541222776
0.009026555429819665
0.0001465358652109781
-0.006630749720849849
0.009516667478565246
-0.0003900982147434888
-0.030629228576328684
0.003960846164841168
0.0036207277850176965
0.014787666196250618
-0.006449883293953051
-0.00681651153502482
0.004553228477132881
-0.008085518575209324
-0.00953727029545338
-0.006727814479023115
0.006472269202702333
0.022446122760507288
0.013867493685147978
0.003578942353685254
0.003167996946553063
-0.00529370014710379
0.0032825287888583222
-0.010408666214548853
-0.015030378122448918
-0.004047508219065375
-0.015373388384655929
-0.006584020424323142
0.005080673575184368
0.012790843428471928
0.0026328601417167433
0.01706626237377593
0.024778180846775272
0.0041428598937936975
0.0271162032543288
0.007901544391424493
-0.0024420993538963242
0.01776466880904281
0.001804257416024642
-0.014283836353207329
-0.01977780312568045
0.01795591727981853
-0.029195051919509298
0.01248842815302524
0.02171562493330551
0.000737280918731124
0.04495633102149969
-0.024625003535266483
0.04154503975580838
0.010147030437816661
0.02914344714797163
0.023317962947384044
0.003384191286868265
0.034644966101695776
0.03807444009490794
0.012317105597957892
0.09417853888936872
0.011836901949561114
0.03191301920334796
0.013583810725848286
0.0432453240603754
-0.05701362043972059
0.01663856074836874
0.06479672129478392
0.021577886673508552
0.0599112744772239
