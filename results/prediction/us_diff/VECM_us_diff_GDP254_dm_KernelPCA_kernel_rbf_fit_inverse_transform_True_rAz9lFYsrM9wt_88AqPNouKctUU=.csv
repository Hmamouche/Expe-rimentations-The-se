# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP254
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=5, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0004884754281671057
0.006972075947321392
0.006655540792666491
0.007201982741806867
0.00037870429786198
0.004953301763315691
0.005448303428856768
0.0021703666764253038
0.005409937628989906
0.008692227179823727
0.008945206735274176
0.005141496294315656
0.0004550130337251138
0.005744689472326789
0.00799217258689389
0.007203682495935316
0.0016193042651748953
0.0024500956565842646
0.00429208024220656
0.006045550027567136
0.00764113721552832
0.006333321419104832
0.004278693147513932
-0.0001447965898325465
0.004732122494409627
0.006843767807952765
0.006117363261871087
0.0022658535165346726
0.0031844466118335383
0.001301810236937258
0.0017855039927354586
0.0015351770779267835
-0.0014340815248631406
-0.002202670471346657
0.007375495686913856
0.0004275851272439106
0.004262072349963138
0.006540607166907105
0.0058912518488407955
0.009870197906778814
0.0065519945544095706
0.00892221425718871
0.004086490922115443
-0.00020780240033425922
0.005946686966016139
0.010014131572213869
0.005269358091809765
0.004397862814866654
0.0034443800019143458
0.00455893758459487
0.0038236024127955986
0.006236442163623246
0.007899128483552996
0.007302555296416293
0.004405622536610606
0.004550294560137832
0.005748569523553308
0.004282214727714126
0.01105538340052682
0.007374905891995581
0.010803460644831704
0.011723755107148601
0.011924283142284012
0.010633928086950774
0.008932653412180481
0.010996848082109047
0.011587354043026485
0.01145852828391284
0.007410767908540893
0.008719554205917386
0.00998375063320759
0.006940816163231615
0.001840311782661185
0.0038990547617830467
0.009047850067914162
0.009183655178586134
0.008832487660060284
0.004131923059557721
0.004181301882223403
0.012540856332140825
0.008855491369211337
0.01427405318766911
0.00844970513512449
0.010231577222503821
0.008774274208310581
0.009596851765457687
0.010898736882483391
0.010795187875131177
0.010282729547489279
0.010155369287508067
0.014818003345582734
0.006774290427940771
0.011671004299813109
0.00893886570584624
0.009811359339242423
0.008522950117107046
0.008814208380200425
0.0031967239549387932
0.0033776271769580786
0.004062758169441164
