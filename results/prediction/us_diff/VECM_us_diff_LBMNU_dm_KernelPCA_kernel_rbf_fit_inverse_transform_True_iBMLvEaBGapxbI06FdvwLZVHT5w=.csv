# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; LBMNU
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=15, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.03932208473317676
0.042842246246577995
0.05189901386558662
-0.024314357149462455
0.0018699297503645945
0.005029271114495273
0.026235267858567564
0.0008218938219223849
0.0338157628189524
0.018927062081351635
0.030378310650747184
-0.0038831516795246536
-0.009202552776003453
0.0053612912865609015
0.0022015997960673165
0.02107408261777167
0.020222968489191504
0.015362201916527384
0.006557482810397676
-0.00591520285236149
0.004718850028127052
0.02252885983851092
0.01240456031691585
0.006580109708353762
0.007232775513180593
0.006323499418760763
0.009147663615786204
-0.007607980504519989
-0.007141583117927425
-0.02618723463303309
-0.011061159397566928
0.00668775731549566
0.006572451015043567
-0.00846942882887461
-0.0192451802888933
0.009177612798084663
-8.806003332682008e-05
0.009437994513282756
0.015821425311870883
0.00627091111342027
0.018305553081911986
0.010544790186505663
0.020029306445955034
0.01033961569203851
0.024105563452905602
0.014117058477339451
0.02458148512999432
-0.0017343040798802512
0.009178173675557589
-0.0004972388942560144
0.0030943165950513374
0.008184231704776446
0.016277368606799722
0.019533405276498626
0.022850015536734176
0.0031724592675541124
0.026342311780211507
0.013713052589745136
0.0064247070491202235
0.011009030114570443
-0.005290094505765508
0.004960697444586113
0.02548213988467654
0.00682944975960518
0.023577590865390144
0.006791521090395602
0.004748219728298371
0.012449672863590307
-0.0020417588209702625
0.001326058909754008
-0.012143184744672296
-0.009287533032064033
-0.017828576780509184
-0.02806493148409018
-0.00023604405208881973
0.007775596664707393
-0.009911343887306908
-0.01770613310750223
-0.007702357423059852
-0.0013660801289248018
0.000738133558134345
0.0016531183091372198
0.014366681381306548
0.0008122924522124637
0.002723448117431609
0.004676532516470609
0.0011077059201500478
0.00530311776932842
0.010257241874785293
0.012030668162716633
0.009269534382964906
0.006751528051711465
0.0048559518637714336
0.01101381119353438
0.012421221800314047
0.0020732432080033695
-0.0024858051256970723
-0.011720132002839001
-0.00921137733434447
-0.008825053756918697
