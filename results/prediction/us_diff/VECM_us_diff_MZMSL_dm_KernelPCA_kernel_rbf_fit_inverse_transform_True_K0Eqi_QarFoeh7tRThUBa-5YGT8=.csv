# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; MZMSL
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=6, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.015394699578534125
0.0022110077952362467
0.01237043804045626
-0.00016247401101376934
0.003735734914536847
0.004492894939626669
0.005600596759228081
0.008910073640245566
0.0026994790573411876
0.005705677110518542
0.005360685140711108
0.010301517213214022
0.007238229951518404
0.004673699253505487
0.0034864606098571854
0.0024856594199042514
0.005375261100149893
0.0004622939559168174
0.004220698988802799
0.002201246318527075
0.00026412148580754835
0.001398355493558569
-0.0013505525327761046
0.0014210185842043182
0.004288467554311103
0.003083548686845356
0.0016042632142671967
0.002955436690978537
0.005510936452263591
0.004140387585154629
0.007281526831314759
0.004186042924965172
0.004979164464171946
0.009650542749858056
0.009433962952506415
0.007053801956682861
0.007913318533972128
0.0036927087439490437
0.005070445310831265
0.006013517305103712
0.004386515183025623
0.004952824021169189
0.0015861026340183802
0.0003010583890900949
0.000288696608942487
-0.003022695046223895
-0.00027876863867476936
0.003111207239462708
0.004534155760662375
0.00418274285143249
0.004602464705812742
0.002078311693193463
0.006194052617114637
0.005460311940826383
0.0050337026799209105
0.006721971706294778
0.009230076412206864
0.007325697142852975
0.011013556746271884
0.011726039402785843
0.013192836384966974
0.018426352249801225
0.01184047298722915
0.011118730364602867
0.009856805088120962
0.009633742981772744
0.009686831670960738
0.011362620598883075
0.010862899593812458
0.010647556053827823
0.026201134890406652
0.02456444957373477
0.018745427015612996
0.030213121601336077
0.017084694613488344
0.01598929065440319
0.012857319309313144
0.019339133946660723
0.013579080367813159
0.010264709303289075
0.014703826081647576
0.00331465198496355
0.005602291155203495
0.006238151653900717
0.009602363355736512
0.0063985489262089
-0.0010147328305150846
0.0066080548937023295
0.00444923845114536
0.008556770329973777
0.009188165349463083
0.002720309088410466
0.010791291763900614
0.011686943822853627
0.010979546423926565
0.020818512489820133
0.027262514177189626
0.03228634951030389
0.03783666136444253
0.030392130937270573
