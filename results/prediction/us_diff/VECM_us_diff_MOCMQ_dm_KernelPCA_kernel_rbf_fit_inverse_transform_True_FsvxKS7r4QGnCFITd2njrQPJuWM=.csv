# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; MOCMQ
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=2, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.022602183168614884
0.008786865594759934
0.014878083391246931
0.007873511027646093
-0.0046587015810845515
-0.0019208844944130343
0.012291601944704056
0.0029560824848348212
0.011988192494761862
0.006949120501026025
0.015522716419270733
0.010607701014690225
0.0008016046556716294
-0.006708248198527876
0.012502876376316634
0.01753519323809928
0.024841027776546537
0.005906219380593282
-0.0025165553407736655
-0.0008887838189555882
0.0005705158178392573
0.017931673985034122
-0.002301223170634391
-0.0022772689108425674
-0.005742721472826843
0.007417477500428482
0.011106939993703286
0.008645580306529304
-0.012089295109603207
-0.01777144038750972
-0.009860742639719412
0.0220129594211214
0.014535666613793581
-0.004587794579330838
0.010080318870168421
0.010345393412687955
-0.0014184306711154393
0.01584592315097355
0.012832172178667736
0.010180610254622587
0.0037890863277984937
0.0208186218967352
0.025361447442387525
0.023370179021660317
0.01313413912380602
0.02032376730154087
-0.006732408955827963
-0.014113477048443762
0.0054395247011770976
0.005510499370561819
0.016436188644282892
0.02610000169598793
0.006231722407036508
0.02125174937091819
0.010095707548663197
0.018279516241473823
0.017954784539362854
0.008737560471772255
0.014474599534670465
0.00760827056140323
0.007302834284592477
-0.0018510297737723124
0.0047904637189924056
0.02460705031014613
0.03339967548107257
0.01831062478884154
-6.227327037725558e-05
-0.011633341645636258
-0.016987973402538537
-0.013042899446966428
-0.01049744479401702
0.0041393658310851416
-0.005994356073574972
-0.015021300103487331
-0.0002678791989991682
-0.006621685125337912
-0.01379996942566123
-0.01907085627387644
-0.010625429018385587
0.007540286616592902
0.0299587791877692
0.022157458290298842
0.014963579611281672
-8.426179222734056e-05
-0.02292745223891206
-0.02047941995617776
-0.010779210118311299
-0.0008481313243476243
0.016712915592329975
0.0214334018916403
0.02077610452801064
0.003589348870782047
-0.008575553907549705
-0.009829569276192064
-0.012729888271946054
0.002949044636217508
-0.00919376378834405
-0.013425006223348523
-0.017500193662281602
-0.005675930848692521
