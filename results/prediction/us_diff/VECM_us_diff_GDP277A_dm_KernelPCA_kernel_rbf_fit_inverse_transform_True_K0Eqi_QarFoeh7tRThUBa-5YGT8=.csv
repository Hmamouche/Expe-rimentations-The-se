# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP277A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=6, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.0025338644665046156
0.00413538090601759
0.003469947321020721
0.005737282068376667
0.005101904879101128
-0.0005420646992901526
0.000801602511461043
0.0012294258052000337
0.0016706209005618797
0.004072122055398902
0.005024956260460451
0.004330339296030309
0.008912999949723392
0.00824542009069353
0.004352819046234083
0.0016022008267582734
0.002275166713531041
0.007439693039787769
0.008059083102198595
0.007025138170187038
0.004572475126441051
0.009276384034991545
0.007998150390349077
0.004439715463952469
0.004636212583175274
0.00405321782710258
0.005385413627079231
0.0031924380187317684
0.005054202466432463
0.004221386126041627
0.00456057875978514
0.0024282236715435198
0.0016919803330441468
-0.0005351242564580142
-0.0030315636193238666
0.0011537178951148363
0.001663390885425606
-0.0003104254097066378
0.0038695185783577573
0.004463915491957893
0.000791082662983838
0.0023416451168628244
0.006305455134764857
0.005554357711745344
0.0056576757948185695
0.003256151585189917
0.004620230705494897
0.003660751344964488
-0.001081172187426143
-0.000554651812973234
-0.004181995329258895
-0.004307410713225527
0.003400181407891655
0.0004904927471176411
-0.0013030678664088884
-0.001179738294435905
-1.4105990754137844e-05
-0.0013932037348514611
-0.005697831447974094
-0.004496475838630536
-0.0016672574841318532
-0.0027886890842177894
0.001068812708711812
0.0017545835988288772
-0.0001680387858271931
0.0011815621367491762
0.005254367941480898
0.0022991563437430246
0.0038323448433199548
0.003130809141477132
-0.000762884885852375
0.0025217210668777197
0.005231303583798568
0.00013325251316538295
-0.000517886412452281
0.0028603290632650273
0.000253769087549005
0.005337689320772777
0.00803725665040691
-0.00011361593807574118
0.0012639023373845761
0.008435146600298255
0.010164441723362096
0.014561016360722935
0.01250717331234608
0.01157297300499117
0.011679934040973434
0.012017832125610833
0.013963091759465059
0.01596861883114504
0.01597550956662014
0.0129690723242093
0.008381610201848034
0.00903454182199909
0.006823492915020387
0.002238716692444659
0.0022415555182241
0.0021385407424269875
-0.0009956049794737987
0.0004926834840339443
