# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP264
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=5, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.002923128103913916
0.00746228887718575
0.011525092194717637
0.010913188557193322
0.006962941201551739
0.002742673780400262
0.013988887264987043
0.0025058202063595663
0.004763273108616926
0.006640714157271947
0.00445082894170785
0.003949105958705354
0.002069519986030497
0.005312450215416143
0.010286134604937628
0.006909213756758744
0.004297486796905567
0.004232826293783684
0.004378213912048486
0.005731655485554729
0.002260994142879752
-0.000584936742247859
0.004446741341199397
-0.0025351895430557655
0.0012910220584262042
0.003147333296919219
0.003989172610117808
0.002549115635451225
0.004507823517939408
0.0004046850063185391
-0.0032577024003673204
0.0014924770259368103
0.002643975038856096
-0.0023647193914924963
0.0062025996163796214
0.009156100779761315
0.0027966939348204886
0.003598178596558038
0.007840182873879628
0.003727615819690514
0.007231049167485206
0.013701959532209363
0.010760729063906207
0.011631658304516585
0.009454864228787276
0.014103408745378175
0.009986312125550505
0.0057240112354974
0.010377812484443426
0.0070037891961385905
0.0035476504796346183
0.01040691749616839
0.010572662071052535
0.012214568816357184
0.01581112085430431
0.012873411293171814
0.018060037021175097
0.019474878548800718
0.018646254930650377
0.015569852815987327
0.01456725913574056
0.011263971067499092
0.017931475949624773
0.016206685429285654
0.016747321503750502
0.023592510094817675
0.022223089846209007
0.018188687206506477
0.01865636410872893
0.022180161799384455
0.0174822677000399
-7.649863727629807e-05
-0.011115448348520941
-0.015279098036281049
0.007730349134100492
0.012269005503258393
0.001289448714957316
0.011885022987907432
0.0034732042864832587
0.0016083457387551432
0.016987571110816772
0.025413531639651512
0.01928149319481128
0.02382575158377209
0.01576903049331214
0.02130082487779964
0.021329322365769163
0.001428648726139255
0.006581319262393819
0.022187522984007578
0.02475523370007422
0.005943563933909771
0.007948786860626549
0.013640951979074379
0.017523278970123093
0.0015389145177817896
0.002082101586462827
0.005751334116440645
-0.00970250207183026
-0.008791492161463368
