# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; LBOUT
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=9, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.010125976390444822
-0.0028598078869243784
0.00551048168325967
0.012815908085597108
0.004445906590494388
0.007975444683274605
0.004891624581030726
0.00100529752729543
0.009177642002345563
0.014658533603363727
0.006928094592157737
0.00572204910606245
0.008378224017499922
-0.00031397809114725155
0.00515127123637007
9.896158948372816e-06
-0.00010812053970903155
-0.00016330350109884065
-0.00027535089022290076
0.010503020665930255
0.005422762985750585
0.012475931730164392
0.004063854581672132
0.0015544557791395213
0.00029930753028864976
0.005178044182100214
0.003273151479649739
0.0038505863788981507
0.006873459493682386
0.005747787405509196
0.005494127363051081
0.00648913354329166
0.006576192268850346
0.008829871537447333
0.0025663943942788557
0.008816706002299588
0.0033239292637292366
0.00935884408729263
0.010756053623220609
-0.001309552374505864
0.009646344065921563
0.002391258374847073
0.0023213508698023515
-0.0017214838021803246
-0.0033355395986496283
0.004596319825788882
0.00445276070283589
-0.0025367238060898865
0.005169657262349689
0.008860944210987744
0.0051441058262979445
0.008832342946624522
0.0014677377225388371
0.001653309104545966
0.0021316550648734986
0.009058490073420886
0.009109023086166537
0.009018119370043619
0.010266677955474554
0.00557615098218944
0.010143221730659825
0.01063853336018275
0.005813111876610816
0.0020966994981148194
0.0012671880218450796
0.012976760932469987
0.00945540271507894
0.007081885772854702
0.011763573331677808
0.009846738222328889
0.012024559766671878
0.009974546527166726
0.007551401726246172
0.007035246167844479
0.01781137135441312
0.016487238799481448
0.004750099771955099
0.008498188488257914
0.005429577261980232
0.016354636994600918
0.015075236839821567
0.01449037981175835
0.014620999129608365
0.007108266967064637
0.0044927506276815805
0.011781338069348104
0.015383023378957179
0.007258164431943831
0.0032009449196198584
0.007486796962740052
0.004812085335265827
-0.0018363267747301664
0.003391297277140588
6.319491271386112e-05
-0.0011589592416705223
0.0032363147894533865
0.0060596163317263516
0.0025746521324722044
0.01011092510575521
0.01730675928177842
