# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; IPS13
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=11, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.007232523249889045
-0.01298846667847281
0.020652865344175576
0.004161398754665488
-0.008888213175602039
-0.014176466279893957
0.004364906204932012
0.025558699512983042
0.013086418545995026
-0.005252695784494638
0.013561907905491458
-0.004283737617028473
0.0014480774900257065
0.0010328897829039573
0.02382201621331151
0.028462124604643348
0.013543079302284133
-0.00562743747733613
-0.003441564959213942
0.015038662266449558
0.014845626697897168
0.03710196941463516
-0.009324080315245327
0.003020879369430982
0.002237864207683458
0.00428749243408493
-0.011189995355340689
-0.012913273152548688
-0.007436544526572146
-0.017238737867045217
-0.005929477750805854
0.004982057405762299
0.007700295487165225
-0.007997990240435668
0.0014826717266238944
0.004297916858257794
0.004704017781132221
0.034210464108684904
0.025843244568617446
0.0066130157525373665
0.026381119407758148
0.012961706405390766
0.02356767287557307
0.0036954360503292866
0.013897577167770734
0.010621983758334973
0.00042326212414980045
0.01764739137376719
0.009580184916003754
0.0091597929922708
0.01420547404163676
0.015663305875810267
0.011448021296693003
0.016803971055626712
0.020162308344475743
0.010381262710917943
0.01491164062678978
0.0029774381878316537
0.014884837940097477
0.029954859115358782
0.01664848841897339
0.02258087356859063
0.010550950325354276
0.00911822023456435
0.03915847377030681
0.028273506385814606
-0.0022989988659573492
0.007495735577019896
0.010360627975100383
0.002189259003948477
-0.00204032770731726
-0.0039013818254302213
-0.030002195249310873
-0.010824529281211186
0.037182073333872884
0.015905678205801754
-0.0014422801324512028
0.005299385829375179
-0.01247276890026064
0.04771783226314132
0.023708267345304748
0.014833452447911706
-0.003338709822862364
0.008489938739481824
0.0006961047304450537
-0.009633192886758509
-0.018328805309858025
-0.009084433413134385
0.019058231202634755
-0.008980014779524374
1.7810555397913905e-05
0.001723005516331191
-0.02050882819225725
-0.006053343826780422
0.0033506230639649324
-0.013707369925479157
-0.008474040635294028
-0.013976180601173475
-0.01989168913421824
0.0017918916842289846
