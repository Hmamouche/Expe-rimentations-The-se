# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP275A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=12, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-4.459404370194941e-05
0.00572246409195319
0.002975278568414884
0.005344083712372769
0.004054971636622998
0.003791422240984249
0.0050143303650563836
0.005064130795688349
0.004426620827440147
0.00600216756331112
0.0022849181230893746
-0.0178965656086211
0.0002635275262659958
-0.009474020538899283
0.0011415869948700641
0.00902628646689588
0.010779502866538403
0.005020239495354982
0.005837697370185223
0.007447539850949772
0.006289797405511465
0.005676459967692589
0.008796608921213306
0.012418052186446947
0.011358208040399918
0.008565808515260637
0.008977170650815791
0.0070268707840128695
0.013869736206581487
0.01235155502346637
0.004339376621077227
0.009703649298709146
0.0037222546820804047
0.008300798524914704
-0.007189953545998033
0.007596308468780128
0.006472360904635993
-0.0003353906038121735
0.00770106023497171
0.0017610202270911797
-0.004378592428570657
-0.0007469036688738234
0.0017045829394224678
0.004824680955450844
0.0009899905774427766
0.0025126979259402623
0.004179931582272592
-0.0028176332408383522
0.0018956918003175537
0.0035906796385431258
0.003358219802407059
0.00779190380741606
0.006127493046444634
0.0034565775378968887
0.00305903823312489
0.004587122100193978
0.0008845721874968923
0.0019781331224405906
-0.003589105662366507
-0.00011439873136216499
-0.00011691006082904437
0.002095106474613543
0.006768958388763028
0.004911248530661074
0.0066625065691120365
0.010861919783836872
0.008418520757563877
0.00917571958862898
0.008990361960459926
0.00893575786795944
0.002222945777934083
0.005318132588791444
0.005731985196148259
-0.00341509641597572
-0.0017690407670000905
0.0061630623721503595
-3.119095695998809e-06
0.005257849009230678
0.006892375090842497
0.00114730743162896
0.00706026029478973
-0.001308483428537038
0.015301601472434773
0.007812142194944922
0.01039955068796256
0.00994447859569331
0.004621956875957074
0.011497652820953606
0.010966283040502291
0.011613391147026798
0.019794614318172192
0.003964661432492103
0.01043044359327724
0.007666802885892271
0.010174326151514274
-0.006826097697240342
0.013914968707772615
0.018448662900717706
0.013528202073000276
0.018783745405446348
