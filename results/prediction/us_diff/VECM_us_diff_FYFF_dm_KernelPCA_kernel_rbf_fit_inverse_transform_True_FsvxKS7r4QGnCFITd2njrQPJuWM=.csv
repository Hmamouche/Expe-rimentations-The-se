# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; FYFF
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=2, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.019735965530111768
-0.024586906256447535
0.010134457549714874
0.01227621915415333
-0.03603674213703994
-0.04681617327802784
0.0296331791413142
-0.03415737554484331
-0.044442188608266285
-0.07388309779248303
-0.027433034249272834
-0.014896795482086068
-0.00814001792787775
-0.02443017647024629
0.014712132612047043
-0.040502011194743934
0.043790484370354696
-0.018927862920729992
0.018990105250545068
0.029331419304043323
-0.019515669925070304
0.03729885242147533
-0.012356281929451561
0.0021271838537107977
-0.004865457815717303
0.00555764618785334
0.036573163706123596
-0.0063626733357318305
-0.06333257828026065
-0.08637490168997963
-0.0971149041653431
-0.003078520072847173
0.003944140870131053
-0.05002923503400395
0.0004944867440847892
-0.04411258763098265
-0.04815623074890562
-0.0037911340310345584
-0.028033975224959817
-0.0213468772290388
0.019435167046589947
-0.014072734319190181
0.03321539789583469
0.04521041346357718
0.009053618185518433
0.07624975595046088
0.006886026449070017
-0.0069223354272039544
0.0045886405016886435
-0.022643411013581635
0.014158896841447633
0.04091899070096661
-0.010506239275801087
0.03892020795190678
-0.007147549505665554
0.012648541549540577
0.020632208490150673
0.0073836871891830745
0.005073271824205257
-0.01896129819576812
-0.04430628058067451
-0.016202763614983507
0.026327671904247
0.006717187021010781
0.01729080806651998
0.0045481831654893
0.010614869879078753
0.004720592244883177
-0.019885861686698772
-0.02991806327277753
-0.040887650497211735
-0.04002729011238737
-0.05513503679045408
-0.10140834569846674
0.024833624736286884
-0.07007029266075052
0.022618948692001175
-0.07754311565019116
-0.00405336787715792
-0.04106447743188835
0.024764671931191366
0.033063947173606056
0.04913349617362539
0.03427714302207469
0.001725714683644762
-0.03162188357623339
0.014753161493050997
-0.0058751978280155385
0.04565327664049646
0.047235360848812274
0.04733624066002458
0.03722413844701689
0.002419690259895319
0.0043322034305671355
0.008261267638199602
0.007970143225998438
-0.024546175782568357
-0.019202652193267444
-0.051315832343301906
-0.016723637638109468
