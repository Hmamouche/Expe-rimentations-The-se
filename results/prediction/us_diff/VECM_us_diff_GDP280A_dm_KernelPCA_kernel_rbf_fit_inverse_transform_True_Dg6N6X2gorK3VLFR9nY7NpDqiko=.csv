# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP280A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=3, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.0001086967282913715
0.0018577450660794078
0.0008339864454407595
0.00483001111870053
0.0030114007177391186
0.002248326035092527
0.002843832710861517
0.0007209047642850046
0.0011503746885378923
0.0022896694460042884
0.0021157941821865474
0.0019273694836484656
0.0018270890927052261
0.002054319930770549
0.0004813975684214906
0.0018754340925399705
0.0022924934352436953
0.0051204297898274995
0.006463726191371394
0.006071286886674838
0.004529852420657112
0.004591585281629826
0.004423717829077072
0.004610628777048838
0.003430488393762208
0.003520972175859404
0.003914868810213943
0.003314778751916255
0.003041075773378098
0.0023338094744612395
0.0034110114946733763
0.0015479242497759538
0.0003747342090591234
-0.005078974782798766
-0.0017497033474295212
0.00282719704941184
0.0022343086795038516
0.0031376798002323908
0.0039859045401656815
0.004272712949312858
0.004029221451315331
0.005226384739612326
0.004977249022840254
0.004105237970887801
0.006767528011189492
0.008214258656208364
0.007040724914621468
0.003063898558016717
0.00519496022988837
0.0046614347425048
0.0009256258200218621
0.00230541292455903
0.006743134186682699
0.005079541696955582
0.006455984938697626
0.005556701396583777
0.006559489369270836
0.0070474439575017355
0.008241346748038916
0.00721236713756072
0.005318535952729104
0.00489580940901226
0.0041959204146558154
0.004372679758645228
0.004531183784059982
0.006055151136401343
0.007463361149036391
0.0059155854130181615
0.006671515289283846
0.007318803632764188
0.008316279159372709
0.010311533019859051
0.010783790561707812
0.004577054727304242
0.006203925076222133
0.009079630143718204
0.007308419911291258
0.009643808849073999
0.008430098997573608
0.0013833621285812788
0.004348541698865295
0.006724920570556774
0.012949767141693005
0.014428398571450137
0.01825351835946471
0.022935000661841738
0.023646844177373057
0.02101158987004158
0.029907488973480365
0.03557442431503009
0.032802288071741334
0.031061851635385537
0.011737992162790253
0.017557893876603153
0.010305719311067534
0.002958399499884427
4.984902027189113e-05
0.010237307206576271
0.006750904367907928
0.007340071557196632
