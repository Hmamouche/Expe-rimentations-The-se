# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP276_8
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=1, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.008015243809317103
0.005293495561194848
0.004473925711788568
0.004564664241388963
0.0023544935579440577
0.003954358753508971
0.00775724238732062
0.004581326733402609
0.0017784760899588518
0.009511391175441614
0.007115109149510677
0.00860481296818509
0.01172330278923232
0.009484567660848419
0.004031631263659363
0.0013046199938417657
0.005721343704095039
0.0027273922288733898
0.008916982245949844
0.006757731440958211
0.007351571079653387
0.0046625550590096865
0.006588532958808811
0.002943755734303022
0.0023866243154544967
0.00451324194840276
0.004099106916086946
0.012056694383239643
0.005582575890822719
0.0060301183611870274
0.010724116638448172
0.005763492812134971
0.009399843882476106
0.006748926370632532
0.01262689420242762
0.007900345418522718
0.009123074101022989
0.006904712713991231
0.0030765172918981562
0.0054321286092220335
0.0032976632525828975
0.0026105636138660953
0.001703564411020667
0.0035466418984316495
0.00830272585947169
0.005429086931838744
0.004381804605960902
0.005375223051289072
0.006582406739826249
0.0051887752889195745
0.006088544480810748
0.006949507951247526
0.0069311328775975446
0.007263156777951906
0.007043135624536015
0.006943239902128068
0.005658629873878374
0.005476104585868138
0.004821110251040768
0.0017760198505588445
0.003251515962824364
0.004941663273158251
0.0033054792607003095
0.004782172542704097
0.003624171457992099
0.005987180272992336
0.008610228993375713
0.0027438295308098585
0.0015090725065118682
0.0005599124501589629
0.006182771201890725
0.003474599468806386
0.0016987719477188964
0.011828073217404561
0.007656959865206916
0.009781635316156632
0.006004084466491045
0.00776365204432952
0.006308010576258542
0.007103930301808434
0.007493402114280946
0.007957425507404714
0.008099384738040971
0.008752245782411995
0.008200662277329565
0.008671761884676082
0.008062459758040631
0.009617442539273663
0.00804156468058809
0.008325170544114475
0.00841395856705033
0.009372601198691832
0.007487812613431068
0.009628256836196293
0.00677901186993241
0.010558312173349267
0.008990233696290628
0.009818157058694255
0.009768868446175503
0.011681365563047046
