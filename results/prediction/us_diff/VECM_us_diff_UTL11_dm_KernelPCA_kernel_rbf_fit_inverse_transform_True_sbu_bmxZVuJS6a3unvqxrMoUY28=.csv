# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; UTL11
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=1, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.15464105272302778
0.08327917866729687
0.050578107014312514
0.03997070386976239
-0.0337728757434955
-0.029416716509652087
-0.017267534154931204
-0.02390938377578785
0.0027529021837004513
0.02447731113602715
-0.005904086574635528
-0.012067334202125093
-0.021755259324749525
-0.018361759486689277
0.05001387742354823
0.04076413898701073
0.061270760506785024
0.018393109862781955
-0.025389368808257286
0.03829261225027438
0.012941983795653717
0.04605482837512614
-0.005426974398826882
-0.04369192167432407
-0.06077355514264353
-0.03237691371436718
-0.0011242363226997764
-0.022816248712584676
-0.055274051695407375
-0.07923117998066431
-0.07190131848190472
0.009850962400292675
0.03618399438039957
-0.0255143246154174
0.0206793722621128
0.01709580355562213
-0.006903016640237432
0.01853550822708639
0.018604341917333088
0.000508282823137007
0.019782925391895887
0.04393762985687703
0.056201735916847545
0.07700870859705805
0.03398089715384188
0.058885720629041856
-0.02546849829433538
-0.06731008502805141
-0.026363063402719135
-0.04144913171220599
-0.0073973903854654115
0.04677200621199038
0.014898305094033847
0.03653324206052325
0.01057872150039149
0.026642437210243154
0.028590876114601958
0.012357803944347651
-0.0034584407859770344
-0.016295065148821383
-0.026210477597885667
-0.031923581469374976
0.010126166689108665
0.015832437642304208
0.030592863985315025
0.03593835162986145
0.0022224542372311735
-0.03638324204549857
-0.044940947936471194
-0.05358938265595038
-0.08451880991039026
-0.05063700499370643
-0.05694879243681222
-0.08699813350698007
0.0285542299499904
-0.0030011903044258274
-0.023314391471429805
-0.0345409147148107
-0.02652685987303774
0.009013827397360674
0.05611747489017954
0.08765764390905806
0.06280103903062366
0.028213817146488743
-0.007568909542847196
-0.007415733336800896
0.007256297762487753
-0.012173695445349431
0.04051783584676273
0.03691129379279086
0.027750035200861077
-0.011314164868447052
-0.028164138872537093
-0.03208375085065917
-0.0157167369881521
0.012590404312441128
-0.037140477017349245
-0.03792515938143478
-0.05501068869188243
-0.031366650348259216
