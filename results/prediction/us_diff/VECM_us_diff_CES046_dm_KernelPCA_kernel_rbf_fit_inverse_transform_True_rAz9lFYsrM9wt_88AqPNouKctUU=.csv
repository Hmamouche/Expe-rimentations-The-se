# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CES046
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=5, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.008938308645077848
0.007865836207583899
0.00905858726803218
0.00928301299597297
0.008044995769661896
0.009231582257045609
0.00912277373564108
0.009237088176499127
0.00854425549237411
0.0073789861633139844
0.006119886632375166
0.005572796215379726
0.006385108496585814
0.0072410207671252565
0.007953771838642522
0.008265359480041274
0.007290483012653908
0.009145016639212421
0.00871526805878503
0.009767291107146144
0.008262799351812318
0.01054524168988092
0.00886731555910045
0.006357668695790828
0.003463965831863098
0.006422380144353238
0.008230620228486737
0.0059840560841081195
0.0011184343410301821
-0.0013164899420532472
0.00021068264824207613
-0.0017218859714672782
0.0029851873028568965
0.001030640064641889
0.0021451730279978963
0.003995407172125748
0.003054683356747976
0.005406199189479579
0.006410490452458235
0.005973919558230633
0.00745413988419918
0.008689120939747332
0.00886168446718927
0.01038090736403945
0.010365840659809718
0.009980100502485571
0.008123503286151598
0.006353186766545925
0.006273789577610297
0.005838237601739749
0.00528781641579171
0.007969058467747727
0.007089228495972854
0.008601466402044391
0.007661525618965919
0.009131005231910034
0.008584179156946661
0.009166918876352601
0.007429740809677979
0.007951771546242901
0.007778752189955997
0.008344773406804873
0.009615813613220016
0.009416249339010429
0.009083026450070567
0.010605909465924683
0.008585052356322323
0.008415533890521262
0.004651721070949003
0.002593692169191245
0.002979290090152621
0.0012037505570089352
-0.00013856542641491314
-0.004075821998319662
-0.0003820903115850075
0.00064074689283138
9.161037731027146e-05
0.0019948455611399148
0.0007459474087886263
0.0002280608344639079
0.001947556316947066
0.005171972994453194
0.004247645968567721
0.005492785603375453
0.003950543100976269
0.006222489168080065
0.004841616579442127
0.005758690313422873
0.008418377893959859
0.005105044338828178
0.006645169756797807
0.005179244789371527
0.0050420682500749055
0.0060727383278018215
0.008049826317116957
0.006224983397896566
0.0016484830383461375
0.0038784263573220876
0.002171863814735462
-0.000797165821485449
