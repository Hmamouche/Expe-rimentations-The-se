# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP251
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=8, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.001066011244326819
0.007743302822331174
0.011724665301551194
0.004849906620077347
0.005951492542950418
0.002617798364230638
0.013652410472479507
0.0030450988762926656
0.008042790729040135
0.00936689161528043
0.008725601753331425
0.005508407562958929
0.00231368346655075
0.0031455216598408756
0.005427997879031105
0.006484335191984186
0.005095601543806913
0.005369440408283706
0.0080621979941143
0.008218661729470939
0.011351892029119437
0.01184813320465518
0.006070764586692892
0.0025197621079461256
0.003419548469958655
0.007132885876619273
0.0044947648035731785
0.003771162218459233
0.0003976518817035854
-0.00523515822132817
0.0005528247050806739
0.0032234705431076855
0.007859311507555214
0.0024291831676713396
0.0003199173272924417
0.0049601919870211775
0.0033325842214294897
0.012067456908557515
0.008578886449512654
0.001092919723383083
0.007790995708031274
0.00725436019542895
0.00938125691940468
0.006586965020614483
0.007151691414537631
0.008390487717960684
0.007389282558618776
0.0022334127470216227
0.006500333547857223
0.005766580813206596
0.004147829631139269
0.008764331641751215
0.008030388345245354
0.008229951389080148
0.011219787193958091
0.010062641124048243
0.013858770402004532
0.011101751148715717
0.009630697345955536
0.00798683741947562
0.006828983501072294
0.01012997885694829
0.014421931005574339
0.0073994860106837155
0.009273722929216402
0.014667246022030537
0.012195066625152228
0.007879919645056327
0.010248307158543959
0.00387986161413662
0.005922225041675006
0.003207042296460476
0.0008182758432270935
-0.0055219278398734375
0.011280533692076846
0.00717471068842432
0.0056138665465526585
0.0029121443627943746
0.0013218988109726926
0.007434157253512676
0.008391538849996537
0.015203296626054753
0.011802350544087237
0.0081486052207765
0.003617679292425964
0.008942884417430751
0.009972137872477797
0.0077302714890009885
0.009048050543145702
0.007536366883011606
0.009812169010444273
0.003953387701984575
0.005235395310314416
0.008831200809115756
0.007297529209564185
0.0042158648608304145
0.006194963986797831
0.0002451818009988871
0.005538895566495538
0.008477758700824617
