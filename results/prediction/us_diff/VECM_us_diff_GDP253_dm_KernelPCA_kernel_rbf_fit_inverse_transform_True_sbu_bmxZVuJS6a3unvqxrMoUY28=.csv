# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP253
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=1, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.014968685845868879
0.004633472640210232
0.007729335578074663
0.010643125711005346
0.006640833318654549
0.008265969239815051
0.008719396846324945
0.00937444357278789
0.009167937038711946
0.021247171970071674
0.004070175131607982
0.007301131049359399
0.002430807398943421
0.0053322133469778776
0.011477120217812393
0.02673945887581763
0.017881977179550933
-0.015208434916444621
-0.005781263910537375
0.011500119640899023
0.004342259547175816
0.00480747276324406
0.00549465735553515
-0.0026428214086904934
-0.0003854766252156276
0.006335888986013621
0.0032652721684313813
0.008954154363241238
0.0015054335934332943
-0.003683527948454346
-0.002943813921744121
-0.00846336354772096
-0.004192030211378675
-0.00434658777707492
-0.004062398412339838
0.0009553976643151873
0.00298751759897532
0.00451123748016511
0.008501241696361489
0.005329583466342082
0.008628845080841916
0.008553626834616832
0.010247748113817507
0.012515507897795045
0.00779440697271314
0.007456759212540927
0.007372552751014262
0.0022169513191476684
0.0020524041290639586
0.005018032389661366
0.007441559602109796
0.01204199802828311
0.0126189406008568
0.010534582092627344
0.007447435082708842
0.012063300819010954
0.006819670092185679
0.009986499053008746
0.013368913849801252
0.008758432966155765
0.01471480769726282
0.014809645926383747
0.02572439994229214
0.023717703912292252
0.02322447779278462
0.023198088458169407
0.007410025013334277
0.02772732911331373
0.014307120233808677
0.006687236530393098
0.009812831528274456
0.003111681941993136
0.009315514806519445
-0.004773627853133766
0.026382583405921076
0.027682274758772732
0.017039041573759357
0.02567265580976899
0.006308513122741404
-0.0008286828560889448
0.005948967870710368
0.020684846679424378
0.023951954117332818
0.017197175206395007
0.009453833872286432
0.005851906181132258
0.014992135497904334
0.009850278414591478
0.014227459150544342
0.024048875997617788
0.00431041364705145
-0.00019027746508103356
0.011202775992666086
0.00596313977427001
0.015874939077257722
0.013136870223937318
0.01738769280474755
0.015241528732795028
0.013766024608554169
0.0059369992223519885
