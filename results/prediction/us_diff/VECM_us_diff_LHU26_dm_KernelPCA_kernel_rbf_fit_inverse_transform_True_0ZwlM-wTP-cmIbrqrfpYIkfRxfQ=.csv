# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; LHU26
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=13, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.10399891415013385
-0.12612105167777518
-0.02698135658757636
0.05146548321494274
-0.02402974634460226
-0.0007768179619498661
-0.08088359544156576
-0.006973535408488989
-0.001762223421950898
-0.08191893856800919
-0.002732809793302886
0.03290250543003949
0.007304170031706626
-0.022829228803796425
0.018614695226750966
-0.029627086286381506
-0.06765838184216014
0.011678219298856235
-0.010278940342023729
-0.09348557855407583
0.02857836022090446
-0.09677682096341458
0.04532721287062251
-0.011584549661573483
0.048766200320566756
0.017803789147722338
-0.028317193436766353
0.04706271726362962
0.006410080593085697
0.09980682031482482
0.11983933518444834
-0.02010984732406415
-0.08083793010075463
0.06830755217974549
0.07237060899773494
0.032538815773928906
0.021123481903250377
-0.04243389150696662
-0.015901051198531135
-0.004141072131826542
-0.0221143369600254
0.009588451883189578
-0.03525866352005167
-0.058299530457774015
-0.05587156484722125
-0.04227978092359455
0.003930344632485611
-0.011439785914007187
0.038369100849996236
0.08707124162570869
-0.020625884077762932
0.01342268102692034
-0.04111934606940061
-0.07035404265054053
-0.04203052283392507
0.022439205137016645
-0.0703243574730758
-0.022603542346893005
0.014850349836080103
-0.011623224318491247
0.019744879687743456
-0.023495377760465383
0.014953050480534531
-0.04300865968040959
0.01404106124840182
-0.027379120115864082
-0.004506707096104751
-0.019804441954306227
0.02413208898333426
-0.0207740918573596
0.06715266709045127
0.08996011118898821
0.13275425669801386
0.1102478469662865
0.02228290015871314
-0.03590962618372338
-0.058459859110850595
0.07491400489969326
0.05265188120733273
-0.011918129363393206
0.007034715704903088
-0.05069300703596102
-0.031853032104358185
-0.04061380798003047
-0.019731785517745872
-0.003390011876590566
0.004121631160106942
-0.03880354009648894
-0.0209166637039919
-0.015845236801752483
-0.005361212734479272
-0.030484435824924026
0.08503767339196866
-0.08333067581060585
0.009878197417477166
-0.005703526108446169
0.03091694436188156
0.08121960046422587
-0.015042381895038646
0.09019760122245384
