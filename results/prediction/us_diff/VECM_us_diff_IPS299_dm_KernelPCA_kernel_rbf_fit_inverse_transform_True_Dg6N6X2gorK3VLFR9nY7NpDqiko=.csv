# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; IPS299
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=3, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.007928233649397107
0.005133136277855307
0.014448497602665162
0.008787381256421384
0.00594601238447099
0.007084542333541607
0.007538798866848639
0.008266413042749615
0.00409527649444222
0.0037908219694905263
0.004234449702698796
0.0030263114136856776
0.000783191899304057
-0.0026530889277390233
0.006831793512191417
0.011458280780866279
0.013132282907456841
0.009140635316497794
0.008638154377035167
0.014759982330734446
0.0130414779819628
0.00857991635133065
0.0013346212261322403
-0.001634023783873327
-0.0025444078249234085
-0.00036578639837057725
0.002397880257040469
0.004970819123110732
0.0018017035342202388
-0.00567111330133918
-0.003792580999566851
0.00144225377925997
0.0031028599971241054
0.0009538075769060241
0.004023880414590362
0.006677852731766291
-0.004147780961967067
0.005597971292681517
0.010207895842579888
0.005397951721096233
0.007390491524733695
0.009356051030489896
0.010833216964571691
0.013100832650976233
0.010194059447166995
0.013423696367580201
0.004111353048638566
0.0006882760182159841
0.008786323271825287
0.0034769828928420954
0.007942796238589359
0.013779589785740346
0.00888452679164864
0.014260393431694529
0.012518271988600994
0.013179955614189217
0.018102872107033124
0.015894555702779624
0.014922312410242085
0.018570591252616862
0.013353887850585208
0.010661393960675163
0.01015140282519517
0.010295778475176029
0.011547612350224105
0.011936165403490231
0.0042350743700818975
0.0086481992206365
0.0013959844280859533
0.00403550295983895
-0.0007439254993247478
1.9535679497423384e-05
-0.005239014340062487
-0.012843194134658058
-0.0021554808875589426
-0.0050873914494949275
-0.001226407708204856
-0.004447794758485172
0.0014394434516004477
0.0008285406264987561
0.012257770547255388
0.012834850310589662
0.009354791179170327
0.005803770368727283
0.0037990868895619733
0.004443660101466011
0.006849575096815353
0.005865519291928547
0.014126509974627338
0.014680148980512378
0.009870978314210424
0.005041595896438057
0.00358754576025831
0.0034543309275685153
0.005717002570892543
0.008254538149479079
0.003888755612386961
-0.002608320481916657
4.581685308438336e-06
-0.0031387900740637215
