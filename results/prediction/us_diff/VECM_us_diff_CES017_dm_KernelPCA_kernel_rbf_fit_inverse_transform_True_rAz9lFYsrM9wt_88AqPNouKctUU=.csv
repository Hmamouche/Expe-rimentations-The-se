# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CES017
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=5, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.05201653397888267
0.04466083361276453
0.04599651809902941
0.01004851385962452
-0.03924105758048214
0.006220719067217395
0.019661634866779926
-0.0027718284723852148
-0.010914662965010194
-0.009761237670684441
0.004303080534376705
0.0018356326857326653
-0.039963438702317965
-0.04198864610269113
0.0048855419694677615
-0.016364740841169654
0.005975746406121968
0.00698328201399924
0.0044163430092775124
0.012306266800465811
0.009998673809645071
0.030895177290182096
0.005180697774241779
-0.024867032088544707
-0.032368583908740874
-0.01110872952666354
-0.007322957739748887
-0.01534492452665878
-0.050851677675483827
-0.0679265782524235
-0.05654778754095466
-0.014740817657095156
0.03751563669748133
-0.010775119480807204
-0.013518165512064861
-0.02706319828592227
-0.024360298501621955
-0.003451804362158314
-0.0008065683592013212
-0.01964045708371714
0.00587808612855775
0.02107808117699164
0.023530836088721873
0.013524729544148507
0.016575488300412694
0.03618500475270174
-0.011821380031142489
-0.007493614726144616
0.010566091999517717
-0.006157715316825116
0.014106604176711389
0.01982790818399644
0.009475600522560785
0.03744985488400314
0.0054071839711052755
0.01972720475310261
0.03476970096696564
0.024509532628151337
0.018771355518781084
-0.0015870919243171093
-0.017178075937417263
-0.0046172325060782225
0.02333663367860777
-0.023152641531299915
0.009620895029198311
0.015713875754215432
-0.0014389398440092628
-0.01647933000803112
-0.008401461204782947
-0.018411024926876445
-0.033291639222391395
-0.04005824160111361
-0.07043950952547415
-0.08319757209376558
-0.020602594931386043
-0.040032921469969576
-0.024623049095083886
-0.04881151557493412
-0.05269576482875577
-0.03139913172124153
-0.01383249314769436
0.018472210411223763
0.00911272349327504
-0.016498258568174752
-0.008961173306827568
0.004196853825969679
-0.003659834401754759
-0.012781475032007876
0.008551627565425489
0.0007271734147670586
0.01549940403111017
-0.010668043010261164
-0.02003469887864469
-0.0140679449352825
0.0018837015447158122
0.0002491714293586184
-0.02325119887194914
-0.02851449094251678
-0.036231780409120125
-0.019609576283190794
