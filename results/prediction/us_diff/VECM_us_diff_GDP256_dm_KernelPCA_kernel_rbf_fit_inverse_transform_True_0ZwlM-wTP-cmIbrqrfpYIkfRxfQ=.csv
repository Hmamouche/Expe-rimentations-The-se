# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP256
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=13, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.021461306098015488
-0.0210357847537106
0.018462061370803425
0.03618763428189425
0.0024884560009000973
-0.004505366053970679
0.02926591764734908
-0.0016980596791043258
-0.004522938726097101
0.007746312427364293
0.03416919712599119
-0.009648360979799922
-0.008901652608877349
-0.02027323818799076
0.016343426522216452
0.021554615862257747
0.01985907826372429
-0.0011730157808091952
0.00014738566423092405
0.017468691494074543
0.00633722286832494
0.001305494524065848
-0.00424556718248241
0.004799325657965075
-0.016998221116560172
0.003706256770219872
0.017595807566311746
-0.006250477255518583
0.0016858986189365547
-0.026339291261478708
-0.02885740023012915
-0.013594577604561547
0.005228078166690067
-0.0072632518675252705
0.01745270553558131
0.0015817207744280443
-0.016285796587644875
0.02291712177856678
0.023609182037357773
0.0010222070386870508
0.029362132300847714
0.022885747708496242
0.01929488471576661
0.01371644484495635
0.028409634182146953
0.013149658925205516
0.008648123557298364
-0.011477166123637588
0.0065716385578784885
0.0028683855366351627
0.00635391001350202
0.028323829013078144
0.009569047205955621
0.023998059663679728
0.022761247255975142
0.003862637006148896
0.038423207845889276
0.026304142067136913
0.0060853472448914175
0.03624162534901209
0.008723360596414292
0.0018031887116941345
0.020161047960588256
0.03692859137268572
-0.0004543826939014165
0.01942777622829474
0.03764101185221433
-0.020708862197782653
0.017069840010691617
0.015526768693140122
0.006047560597981051
0.009581748757549406
-0.020557871760663288
-0.05137083610369229
-0.0172742061487712
0.0026149573545625783
-0.03596724946527228
-0.009907270353318981
0.009112911108273234
0.02211505307413631
0.002284471273872768
0.041741648133432445
0.04113411891512196
0.007565733268982797
0.0034561384153811055
0.013864992507217644
0.03629575216281156
0.02017555250997046
0.016231020142518912
0.007791559731583959
0.011063688534651311
0.00860739082464539
0.006825727301790097
-0.009460823802444942
-0.009524639880752745
-0.013841651654535143
-0.030636302137708585
-0.029202334272407912
-0.011055349768809983
-0.013509608488857839
