# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP258
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=3, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.014685645182883697
0.009386803992273304
0.012370595018082258
0.012991711351159632
0.01005171517225217
0.0127179556156257
0.010275325851549721
0.007968877951030007
-0.0031080058438791138
0.001995666188800414
0.005062298017085859
-0.006748124367779618
-0.01030665734316427
-0.006686500491468556
-0.003801375415365067
0.0018071212761845029
0.007884673233909154
0.006180340226652142
0.001017238206603514
0.0065165068376267215
0.003858960329188226
0.00883366981815514
0.00432403271616006
0.0021576894212262912
0.008806858426499222
0.0070001736474678885
0.00502050719608731
-0.0011174986601490107
-0.008789952947473706
-0.004370542521410527
-0.00968011174491865
-0.0032726517639196655
-0.002486585704035435
-0.005246806349649213
-0.0020490525909500823
0.004775019780205388
0.008901749455888012
0.012727148042663127
0.014225362331279152
0.0055921834782060665
0.00966214733936586
0.01412719535055041
0.017778928364333264
0.008928410411492269
0.00837199300312018
0.013725951049815258
0.018619648531408118
0.010685660671637866
0.009809756878667803
0.008413989144185912
0.008529446915859534
0.015852736305264473
0.018562263127860894
0.01947478086548927
0.01925443403841296
0.020483865837345364
0.022545339860697698
0.02339148542025585
0.01455521291907662
0.023639124783812814
0.014868559755285539
0.014057892178662436
0.02265633613917203
0.020954553012953438
0.02324615382584213
0.020957408320118824
0.015830946951241782
0.019874763297621813
0.018195702937525596
0.012404929534514293
0.005161403830170037
-0.012587684553760492
-0.0228000756777486
-0.02865669084195537
-0.02204497913318288
-0.021903274316341283
-0.017791686906002243
-0.010662265909697422
-0.007484027440637243
0.0022348475179173473
0.01780401996809172
0.02225373650675619
0.0042839736872833396
0.009650402713194147
0.014897841928498985
0.019947075757562004
0.017116432017007882
0.013844915667248308
0.014743220892845393
0.013503506610831988
0.020423893306397795
0.01883813102268336
0.015470468870860185
0.0076836468087542725
0.009164211361062772
0.015249344011595296
0.014489201466027517
0.009270546670810143
0.008027062140656906
0.012408283871122418
