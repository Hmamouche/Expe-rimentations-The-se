# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP273A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=2, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.006263727623115337
0.005831786765546716
0.007018080012346853
0.007342894557145001
0.0057602483620986245
0.004695371731923175
0.005567338281500795
0.004828452863152996
0.004820138683482564
0.005197676808348176
0.0038761365640445074
0.001789809018920537
0.003400995212575289
0.00354573491564262
0.0061300670819704915
0.007862973733709562
0.006836089983753719
0.007254746424731298
0.0059311027376960515
0.0077492985075421975
0.008257864237825896
0.007733332805777578
0.008628483077899322
0.008997974589976868
0.0067332887943125745
0.006811265182055519
0.008297419172813486
0.007182776129839226
0.010208143471170543
0.010560905066196367
0.007560454101142927
0.00646465813930124
0.0049966377692495755
0.004332238641631493
0.006199687978372527
0.0067234287014393945
0.005960901664816755
0.005327869852392716
0.00488929291535848
0.004983677249801544
0.003410734962539349
0.004600503716599744
0.003790421692788013
0.004543158394803211
0.007000155969355635
0.005481505726651546
0.005503289408856525
0.003949379223897184
0.0037357518720700987
0.004169193923736587
0.004432694331991963
0.005528335502786253
0.004876489916679959
0.005715882162483577
0.004582450936528052
0.0035182124084102116
0.0029918432587541896
0.002213348708165529
0.001326406918292057
0.0017566126351512468
0.001993420125352402
0.00273373583721459
0.0032168197497748456
0.005109338914011474
0.004789872386731751
0.0063893401963140296
0.007846122200902386
0.005654371632060526
0.005777092446044394
0.004038855958165676
0.005220599416679321
0.006158052283220093
0.004657895207008134
0.0023751819389458357
0.0014689981642456503
0.004648590771729205
0.003962367973368413
0.004906934212193935
0.007191690361913444
0.003089112823113539
0.005776355371154716
0.004018238071349196
0.00665923859057665
0.008608711864686423
0.007326660340106837
0.008262580692243218
0.006648176962935313
0.006825295433667361
0.009585339951931796
0.009450586132964851
0.007717166040990563
0.008075974050340454
0.007820927447985543
0.003756546491768989
0.0069166932832856135
0.004768042315675337
0.008540242355070482
0.010300531881485706
0.009200898036482273
0.012222675638902315
