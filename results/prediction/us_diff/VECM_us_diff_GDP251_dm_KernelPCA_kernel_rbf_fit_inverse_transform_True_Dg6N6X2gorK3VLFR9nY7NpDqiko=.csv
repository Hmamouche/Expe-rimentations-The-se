# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP251
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=3, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0029474392198489434
0.0032555894393674215
0.008309365513767457
0.006668212621400183
0.0055277685244031535
0.008845465880003395
0.011463126195087965
0.0063274514129916005
0.006346456216918297
0.009828597208715272
0.0094050369644101
0.007312150056876914
0.002513031122620076
0.0019446648637815838
0.006268746379388823
0.00489186517621895
0.005693773848275611
0.004984682344231195
0.0073282708125656
0.008637709620653838
0.008951841432017934
0.007776163485590242
0.00667361967238981
0.003157212723508701
0.005397769418928019
0.00721722264483074
0.00584860037872663
0.00477214797668845
0.0007431969672676942
-4.281744185002511e-05
-0.0023124181155278556
0.00337394627231455
0.005960915503264283
-0.00024789909638432434
0.003857845442703745
0.005045073802574497
0.004144473423673915
0.007643366177045068
0.008628445090325692
0.003757752829343264
0.005330053004032659
0.006895909773471292
0.008507617978822782
0.007399541406075417
0.007592218457323948
0.008904686372572737
0.006934472242672753
0.002627982806767088
0.006307737605948765
0.004862572099299125
0.0038566882957595905
0.00849233825957943
0.010060640383747228
0.00988772668587477
0.010552322166437311
0.009454323405385635
0.012475886794769332
0.010949463485124083
0.010128045460194456
0.007520101349742557
0.006654977047168033
0.010253822442757831
0.0130115917723714
0.010609200194980281
0.011054711353713586
0.011769719298647176
0.011630993833583451
0.008939415113880725
0.011229555127239997
0.004468071159047083
0.005180166646210654
0.001717716399759275
0.003959356234614623
-0.0022838164336461708
0.006342382133875228
0.005245991069998262
0.00491572178669906
0.0033197813454470485
0.0023510790381198574
0.004459795839999011
0.008744529642086225
0.015733591585983826
0.010717319293534363
0.008948062796364991
0.007524988772001221
0.007785485212333419
0.009218175040829288
0.008297677777331708
0.009025620368503993
0.009375291146813493
0.009207441302364646
0.006720220249028601
0.004903858307493384
0.007068415023273596
0.006737463474580933
0.005311544225667265
0.006239756099071341
0.0049673418259435454
0.005657151745763937
0.007798783104554776
