# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; IPS10
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=8, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.006497068206662395
0.010742862811893236
0.01646734344667362
-0.0031804242732365014
0.0012846298520225578
-0.00042819261303476356
0.011653786353899976
0.002813472690506631
0.0075439276304732385
0.0009242554108679244
0.008623514257960558
-0.0025100968561693904
-0.005396640969513373
0.00032716166280200715
0.00929585060679258
0.014940597228128995
0.011225507690321206
0.007380722559470986
0.011963813428282136
0.013713813097297559
0.010771572049083753
0.012259909563312781
-0.004609400428708181
-0.003404685292392436
-0.008416054042361747
0.0014572492748662423
0.0034281642405977397
0.007433410002293386
0.002229855597188698
-0.01234045827518053
-0.0009854530283989532
0.0013301192863608364
0.007576534709194551
0.0044658001825997285
0.0001448435161274075
0.007109667310422008
-0.002098365390690224
0.016186325854237887
0.01340484023970592
0.0009945215336375976
0.01054407227748664
0.011279853597434043
0.016120308355281998
0.012160883346017478
0.009719115143428946
0.012385950868096792
0.010244725109781123
0.001604718439302181
0.005678344733090344
0.0019182730746412188
0.005155845835685276
0.019189056799756615
0.01684806081448655
0.017649743665935476
0.018262198144415258
0.014430655985901843
0.021811077482096295
0.017407120842680413
0.016786277918272297
0.017298719566891576
0.0051600240318815625
0.006882711030812045
0.017074702359130157
0.012999898979010209
0.021945853499821016
0.018100186375574083
0.01203079124083427
0.009879170496837314
0.004191918841723314
0.003582663818943994
-0.007398931770707535
-0.006907413928312563
-0.01818847979215295
-0.024030416604643848
0.012845316739138614
0.007424494428242443
0.008249106125358306
-0.0006053158593515564
-0.001909066288912098
0.005717190960732364
0.00975124686219548
0.010969024129595491
0.005437972991852782
0.007770935272209227
-3.8702771047316974e-05
0.0005316006883346078
0.003287779398726041
0.008486275110938146
0.010374282753802854
0.007095633947912896
0.015035096751980708
-0.002564731296646733
0.002338372487993245
0.007536495277361464
0.013402779504199843
-0.0011106900355702257
0.006477976025300621
-0.005561334692087609
-0.005636277328867909
-0.00443578859291846
