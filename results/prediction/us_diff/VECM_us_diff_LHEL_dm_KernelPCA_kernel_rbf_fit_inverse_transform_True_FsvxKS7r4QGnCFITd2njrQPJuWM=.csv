# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; LHEL
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=2, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.042430993977805795
0.09360553514275834
0.04471361896153244
0.0501316394250759
-0.00343774238776633
0.024268745695304454
0.035333347181492676
0.01789237941299837
0.00850953556920904
-0.011653483715044896
-0.0012428112902208948
0.014373979154289061
0.007877445929125221
0.009655689050905601
0.0002669932807946539
0.04524283295122494
0.043875627269161804
0.012246382423283122
-0.02051624365845196
-0.01694033766291576
-0.0014636557146853232
0.005951346421266293
-0.01676239157065247
-0.03135827364121148
-0.030584438818945864
0.010462372406269143
-0.017105035555774507
-0.05961809275567028
-0.05314248988661
-0.11369649699062762
-0.07786208519351269
-0.005577221505308766
-0.009336978356716163
-0.01015368577715809
0.025599965981616395
-0.003863700513744248
-0.016851040467394045
0.023958151306124775
0.003287045439519209
0.001498358790992858
0.03129581548339047
0.052455224210740135
0.09467937316499819
-0.008630528188026655
0.011105250882840248
0.0342919355861955
-0.021488104655984566
-0.0420415882160029
0.01525806910561833
0.013788034383666613
0.008443158439182688
0.0026494528935605824
-0.0005487429481002789
0.013935886162725123
0.023118537515965206
-0.015543301673211642
0.018473124147978567
0.012953546662004068
0.02247229046051925
-0.00827166838731067
-0.010226629353585155
-0.017024349561541714
0.04209097922862368
-0.029615256133022277
-0.012182833576715126
-0.0026021338156636707
0.010772228457536647
-0.04545357585923928
-0.054146047925639124
-0.030096316025856808
-0.05314604015728594
-0.0755081803014172
-0.0399806071638934
-0.091546931022952
-0.02759141233911634
-0.01284401132440554
-0.05621207862364429
-0.037057518475787254
-0.021332472294576316
-0.035695955600339335
0.028971962175600625
0.009806609001965698
0.009033712419978936
-0.007134898441854876
-0.03314344332292704
-0.016797720872977984
0.023825123600791556
-0.020024854812477934
0.00400706122438234
0.006312792607229467
-0.002109095383243115
-0.04742030410547307
-0.039985145120495544
-0.007037364248982361
-0.015927207549558835
-0.0015104987616469008
-0.011030582394937713
-0.03483516843409108
-0.024783301706625474
-0.028186307372794213
