# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; HSBR
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=14, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.08845188812464819
-0.1297064657249619
-0.19390374349179004
-0.05625819416867574
0.003128757924801641
0.03501809858719375
0.019269091547831088
0.02652615986913004
0.06514010024521891
0.010406288310964795
0.2119262081013703
0.13964440323767977
-0.02318098579018507
-0.004112642085793317
-0.15264150572946883
-0.051605792848213365
0.001626090644071221
-0.052263733648140395
-0.05806753161360671
-0.14437199925472216
0.04931957085214552
-0.006368896124264218
-0.010732967986455233
-0.03698950037999357
-0.0051967422874477495
0.07717792079142802
0.015136546108912081
-0.0322092104469122
-0.11512547660049534
-0.09628090018816274
-0.055535970858989536
0.12862287095634994
-0.02900708418660709
0.02285308211689
-0.020040403630193496
0.030734628040734964
-0.0069745755099449094
0.005604941604636808
-0.037347879374806006
-0.09065005791452682
-0.014749156955964113
0.06020901751223329
0.07833915728248572
-0.08851437211729696
0.08635016584256335
-0.06738947094003112
0.0334014039788859
0.05107941164728505
0.04762938890846842
0.0632005594830803
0.00010042368262123784
-0.061188978727670804
0.026518171076339983
0.013405133000329004
0.027561018164383375
-0.025276245497764097
0.051322554923100616
-0.008544930712479295
0.044341179311989075
-0.02444070628208906
0.04858981317265918
-0.009421080920236143
0.03673217201735613
-0.004533009386738905
-0.006709441596464066
-0.034139660646768794
-0.016235363092838927
0.029186079845815498
-0.02332481075003956
0.043799652211922335
0.005317422667444517
0.01905919757927348
-0.007952717492845674
0.05752954058718567
0.011682620660384908
0.01775527223923778
0.023341745186971463
-0.015443670282774736
-0.06911861478169584
0.04617433136923518
0.049567575475608375
0.022606564598247555
0.03419301524663393
-0.010750261462373983
0.02121439259443052
0.0005383994355533939
-0.0142785172571937
0.04174595210727389
-0.04800311801314509
0.007553349118830327
-0.0006438659982102805
-0.025537733062621533
-0.043312164756284015
-0.020727518282518755
-0.053977468560215264
-0.06626251705041518
-0.007460764889365949
-0.15127591245930067
0.026042962866602355
-0.1581018000212618
