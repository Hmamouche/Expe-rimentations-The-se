# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP273A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=14, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.006186389130947638
0.005778210080905906
0.005843721345374403
0.008553724249018964
0.0036323033971764306
0.004955784308270959
0.008747452960484486
0.005022707042467897
0.004512013619917007
0.005916625895092826
0.004349647830225539
-0.002752315256869914
0.004903302387494142
0.0037385118071177675
0.0051670762053203055
0.007263762397988315
0.009208391004626696
0.006430289526792732
0.008262606191613567
0.006843812581945544
0.005611770731189507
0.007726977537329356
0.00902911817925444
0.007356645177161458
0.006326796480414069
0.01003945447237793
0.008944489634906844
0.007052135422484594
0.01035686240006985
0.011148728630662895
0.0032623341724087604
0.00821874076396738
0.006101681756999025
0.009116361696484415
0.003558811803714813
0.006431706289562313
0.00487263516328376
0.005037613743793133
0.0072781782904165135
0.0030313600380990264
0.0037048808404601535
0.0034779982142772946
0.004774933347904831
0.006315235048891217
0.0066130330466561815
0.002900430389888977
0.006444028644102201
0.001401353626847669
0.002571089080314444
0.005089764861860487
0.003075368913379349
0.007840530642193833
0.005531152828867083
0.005765142869232103
0.004636601929486669
0.0035739452734758815
0.003461257476542858
0.0019178618943849087
0.000576813288744102
0.0007233827458801793
0.0014355183612617668
0.0029827329096102887
0.004899330630641045
0.004828821754308161
0.004604774509134319
0.008464367844296276
0.005167371446369109
0.004534483732652429
0.005572657136214786
0.004984998825586173
0.005371564280690903
0.00558063135623557
0.005312526629068691
0.0017058220003258314
0.0032866506789392936
0.004348017912579961
0.003271006164672326
0.004203990640552903
0.0057288829871127885
0.003225917429763219
0.004268775303919913
0.003935327159525835
0.008088912044829446
0.009308723232979899
0.00599585800443925
0.007780933772531503
0.005970463729966254
0.007102965481083541
0.008584189720504853
0.011590899252538712
0.008727670043424035
0.008669161828922599
0.007041403113809405
0.00481555418198395
0.008376614878651406
0.0031278585499005043
0.011472975913654985
0.010044403978641257
0.01037981984359241
0.010427644634491423
