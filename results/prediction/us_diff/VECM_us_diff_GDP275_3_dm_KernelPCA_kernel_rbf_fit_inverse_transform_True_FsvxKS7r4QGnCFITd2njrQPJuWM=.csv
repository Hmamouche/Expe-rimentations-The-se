# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP275_3
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=2, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.003689639588281459
-0.005810276949519784
0.0032351527455542145
-0.0005148464346473865
-0.0020450844652861212
0.000737754892705298
-0.005300008926296106
0.00512846084716121
0.001230484882507643
0.006490547715394812
-0.012550160394718655
-0.047547371747105806
-0.019440206027530278
-0.020123714361464283
0.01589702616326386
-0.009643364753690688
0.0037638861560221164
0.005503616388850904
-0.00013504195549645694
0.005086835107455975
0.004952629557337045
-0.005194482420430964
0.005243380838638908
0.024244361611723796
-0.003474292704484222
0.0016783959440571069
0.010265801755282538
-0.0017149434894905098
0.017327775953172274
0.029489109595119366
0.0007465899846111753
0.013881320672907895
-0.029176865963096935
0.0241037562901891
-0.016870980396577525
0.003594566927039182
-2.3863645791920643e-05
0.004374980173979736
0.004916145576948188
-0.0028808055428725336
-0.004506009998821214
0.0018939960161526677
-0.00773451365656591
-0.00019052021520083958
0.006474603826091054
0.0022026051365381027
0.007084053581034081
-0.00298091637647838
-0.0005032714355512414
-0.0007954125729254244
0.0038774039923128276
0.007760925977035661
0.000669637408979151
0.01159483014552841
0.000653207560799091
-0.0018826829739463143
0.0023499190749816873
-0.007785662153811707
-0.008993448912147487
-0.010435533837209882
-0.012354564069670218
-0.005891421344017527
-0.00818268532861131
0.012743008600903416
0.0061108087015350546
0.02565920839349598
0.027928245562142427
0.015807553580893266
0.0298296401017865
0.0053873007616895285
0.0027173482984609804
0.010926682020488968
-0.018993092414756108
-0.01763880604512451
-0.024877103633773923
0.009426127959730083
-0.007160983841317876
0.021730917145783853
0.03154573173810135
-0.014002003696204616
0.04196757367454665
-0.02637779012307245
0.025862498350505265
0.013775190870668906
0.022335886663360043
0.03161491238077949
0.013499593242725594
0.02377171070099988
0.04606771644989764
0.0269534436873363
0.05909953759267087
0.014492923374072188
0.037278863382361985
-0.005991230163739495
0.028614855437515227
-0.045977910208260656
0.004097507553589008
0.0629443673064832
0.027305836706110857
0.06959194083058493
