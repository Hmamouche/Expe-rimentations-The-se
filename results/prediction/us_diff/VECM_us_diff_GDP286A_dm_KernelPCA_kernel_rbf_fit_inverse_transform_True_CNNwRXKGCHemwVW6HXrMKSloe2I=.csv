# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP286A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=8, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.006675434991989081
0.005051982302229112
0.008319343370066144
0.007724152183564443
0.0035578325985480457
0.002673476324670964
0.0056789260444963085
0.0022619121526669113
0.0051002907938015665
0.005727878534005299
0.004737604700394731
-3.694078636589434e-05
0.003411978782711526
0.0026451815922301065
0.004267482528356008
0.0066565715143035355
0.004341364552158372
0.005011080309182559
0.0030302233003289547
0.0031099884294944068
0.003382290478503445
0.004685374884289035
0.004775680299305605
0.0034192329242983526
0.0035625771753605437
0.004946114006268313
0.005232536574527845
0.003888196474055536
0.007257296194350386
0.008410748433931244
0.004745110889204535
0.005981899325901676
0.008586069950280955
0.0026152203308700476
0.0033117579426963813
0.004877216378949522
0.0027341285104132717
0.004378745418542826
0.004549595936755893
0.003547018714476074
0.00447559115685994
0.004486998789600486
0.0039855090637657044
0.007069423233416087
0.006961902115024238
0.004598274657071718
0.0037774057639709054
0.0047609508016531734
0.004893773325476153
0.00507194430116654
0.004336549402445043
0.0033364250628053044
0.0034857640333111127
0.003962546563036574
0.002126449761779942
0.003605138915827466
0.0048857110488888895
0.004125091357049315
0.0008999019086206502
0.0038886483199236897
0.002812883846550852
0.0032879103789975705
0.002378643842157627
0.0038304547527689857
0.007398704381915049
0.008296480364184606
0.00842457434572445
0.005261092604678917
0.007675509127601687
0.009317469697889859
0.00388640778106133
0.00680805500960794
0.004688713479217286
0.004265805104052303
0.006471076274030449
0.004484105538796296
0.006078427973318915
0.008323771936615595
0.007423927493896119
0.00583514190549916
0.011338712948872941
0.012922229991924439
0.0013577610757235007
0.010361330602494346
0.010993535887036898
0.01285314232545422
0.011209217992003941
0.011800469558014517
0.013897768858316655
0.014893706999108821
0.01105631877805301
0.015550544588375837
0.010000389616570642
0.010953863227190238
0.010699551244785187
0.008828703495988466
0.011384389958432495
0.014446337743524985
0.011476345020554172
0.012729222823233632
