# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP287A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=12, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.013129375636404091
0.0009430346014995777
0.008731100627238052
0.009378328291098761
0.007537367537181196
0.0106373921302232
0.003524043093962217
0.0026429296048541334
0.005699036500085956
0.006876577008819145
-0.0009011868584745075
-0.004812461791275515
0.008368970163377454
0.0003836535856639043
0.0012303753292039767
0.006128636351038519
0.0031675217292102533
0.00449559771187245
0.004179921453119871
-0.0016225457762359965
0.0024419209284530863
0.007654367879478221
0.0021160015754726896
-0.0008242880327012706
0.0028065906205411843
0.007371385984498683
0.0014713199162123152
0.0020374378558477403
0.007253739595570999
0.006993404432871367
0.0031950240691945037
0.008572830259099494
0.01144003205915702
0.004159471059523323
0.004577983375282035
0.008065523185720135
0.0014870793476524581
0.006617634136459119
0.005689387733860037
0.005145889827887084
0.008449829385780264
0.007772488540339493
0.00024296703820617766
0.008935786917798966
0.010644501047587747
0.002726597719093807
0.005359644715453195
0.00042318962040856526
0.0069720885297254636
0.008765055323376906
0.0023483585618974115
0.007435832890964422
0.0059159131649907815
0.004278331334963846
-0.0033777138003249015
0.0020406507042098026
0.006170120372807788
0.005334021051841056
-0.00013805400666582076
0.004288170817263896
0.0030718009296646026
0.006346899690892341
-0.0031263799895913423
-0.004197599122914246
0.00752524584015398
0.011969364691067144
0.005254591617568052
0.004302448127178319
0.004517351410000241
0.009456962202044375
0.0035427942408718903
0.007443593964410554
0.0056020260011341565
0.0036909786485573213
0.00571461441381994
0.0026781648141805618
0.0058674622998075975
0.01482788512098515
0.0012312689588510868
0.005603763613468468
0.014466672335633812
0.018136116148819117
0.0006172011308831677
0.008296950575889781
0.008327967405368895
0.014822153070293172
0.014076825140204035
0.010786658265388304
0.009865794751061713
0.019342929084691703
0.005257999578009475
0.013386598130746928
0.0034401478048795395
0.017418258757162384
0.013136546681674788
0.0032541926308537806
0.007384084102746727
0.017780551270983387
0.006644263029829832
0.0028116661328876453
