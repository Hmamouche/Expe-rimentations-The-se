# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; EXRJAN
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=3, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.03203719480477876
-0.027459015420333063
-0.0031452264046843096
0.057528506432038905
0.015812910624083028
0.006535286425050523
0.033351687268520475
-0.018167173212268177
-0.014132502298246464
-0.10398560933567833
-0.07055751801116282
-0.04210244441107659
-0.046067676116216025
-0.02044777785209102
-0.039377320710713995
-0.030399552028918926
-0.014361787375531072
0.01310595238974313
-0.02291341615874904
0.002427195898755277
0.011248255632651003
-0.02817105097786283
0.009977766784235034
0.012717428261399474
0.006104655665996482
-0.0005545767718514293
0.01132821916448302
0.016655391599368144
-0.03353590748575312
-0.03732668881413975
-0.010772660918879053
-0.001204630630333479
-0.01395250813138148
-0.006678561079359966
0.0022752144436108714
-0.0036862000086515974
-0.016222405561090253
0.005189071557075715
-0.02214754794417513
-0.03115912388399796
-0.01796724675333454
-0.010302674915110135
0.0076303914604702126
0.0017036561156430251
-0.011175518186056206
0.017806918542677908
-0.0075245822951221005
-0.023417516102694484
0.027123681172279042
-0.002696057290724675
0.008025715804728089
-0.004776271678241828
-0.016879501315968916
0.029836985692486245
0.02993573304912616
0.001886318234871532
-0.00033027388930119677
0.036450986384967174
0.010786161982368939
0.026077206690954036
0.0005066422436129617
-0.03920883958383631
-0.006124849090639458
-0.004835464077251252
-0.03217662905393353
-0.016348514398533777
0.009961043705973267
0.0019120009609986067
0.003442469692042124
0.003776797813201435
0.009228116727765322
0.0014533936339102688
-0.019360891245792683
0.019153027935664903
0.013461149546102946
-0.0297967162280209
-0.00507883883386848
0.014420391235241081
-0.020879613981183
-0.015003397097052602
-0.0020511011714102194
-0.029859790243718307
0.012292274496949914
0.013767763456140105
-0.009913818832621053
0.009684274940682448
0.0032295512184333736
-0.002948614105713612
0.002813034558201765
0.008660726834717723
-0.009773505618962777
0.02428499848776798
-0.011756993126410842
0.003939525916990748
0.007936903069003687
-0.0008923224155602009
-0.012105730370974576
0.0025239059469800364
-0.02621301652440916
-0.0011112494772545535
