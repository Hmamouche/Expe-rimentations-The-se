# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CES015
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=11, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.05231556380656861
0.0787901234392918
-0.0039531248947620844
-0.016019644869513516
-0.06019601098045468
-0.029685943510000666
0.012386044293782704
0.014316385603598497
0.010759051383782789
-0.00029872561645723737
0.024569699245232238
-0.02489450823802939
-0.028744577069490917
-0.023088286135263557
0.0319455256613624
0.031014755434406894
0.005908357681361274
-0.012351862021215975
0.01866574472033898
0.014670916756445607
-0.002400726011990529
0.050656068553901555
-0.020202374669068563
-0.020285491676605337
-0.0351962328733839
0.006533332549695423
-0.005848144690657006
-0.033139924254902295
-0.027726435521957835
-0.050453583058738614
-0.060852337794696926
0.005814240011585677
0.028228594328530136
-0.022502981315603802
0.005298310958210435
-0.008503237559225614
-0.02513264988850319
0.024367067486812704
0.019430260924127078
-0.029148135095495284
0.030302551107654813
0.016175029740159597
0.02338869035613175
0.012918818170731363
0.026358667634429983
0.03143529461025519
0.0018590272436699116
-0.006174980725935215
-0.007491008929388395
-0.04157057936718649
-0.01841352364357764
0.018441499703552723
-0.0005698930852811078
0.038465549855363046
0.018684755060645694
0.002595035803697342
0.02336983890569125
0.0022641251725268527
-0.0018272637986269944
-0.004061562277096222
-0.03903641115469717
-0.009873379885281953
0.005175349350559149
-0.02074568338062585
0.022976578997826846
0.012060019536032716
-0.0023854468949799992
-0.01563869772120662
-0.01662277506574914
-0.016610939178726074
-0.04238216044150778
-0.045796893407254485
-0.07861201068890832
-0.07160718851003141
0.0074815228206058255
-0.029857165727709113
-0.020666636003692358
-0.044748916403708865
-0.04038082427916508
-0.018111330262690503
-0.014073353645849856
0.003218351264860004
-0.0028392734826986265
0.0044903055212650415
-0.006632481844940378
-0.017359253739866375
-0.017057499817218505
-0.0059075857860594345
0.01234327964208868
-0.006296312258709559
0.016086636933697076
-0.006879361439865961
-0.03402230308717317
-0.010381194402585055
0.012865889481243828
-0.018049872857057777
-0.026613931695538474
-0.028647846819864167
-0.029327164024965678
-0.013066876297163802
