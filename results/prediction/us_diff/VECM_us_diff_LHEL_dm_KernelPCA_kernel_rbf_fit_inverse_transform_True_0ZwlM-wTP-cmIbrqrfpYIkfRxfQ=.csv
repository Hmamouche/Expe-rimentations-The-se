# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; LHEL
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=13, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.0655577596287368
0.05448528801783319
0.03800502862165964
-0.08084315278048278
0.02529562557481283
0.035419384879338545
0.006363347059927346
0.05988924040729899
0.06276557081251964
0.042800738312014634
0.08456409711272822
0.003830990277112513
-0.02929435766841026
-0.007038632948994705
0.0002735569905601941
0.011457498395049906
0.008194773746153685
0.03905661078684705
-0.009959309258433068
-0.06610202792725738
0.05266257983721163
0.058357268030389584
-0.09729154021524994
-0.03735415490106104
-0.013304923924522424
0.009193431154701965
-0.03308215830484205
-0.09769283642590437
-0.06456747046401025
-0.09119076280671648
-0.06816823451720053
0.0016433214698205988
-0.023438351791421938
-0.009309996256380206
0.07064879115680095
0.01239260648862324
-0.019282824550001562
0.019674952935928317
7.86961017051036e-05
-0.009952740391786105
0.06679733089769367
0.045562063306427696
0.0884878984393876
-0.03655665152900071
0.03260297291792027
0.003674445545135851
0.01109125368141358
0.025519567759740833
0.030612733638766213
-0.009259402980268925
-0.031655264455938775
-0.04508842300231108
-0.007616643505821769
-0.007200413208432906
0.08652212170971728
0.019034451094400443
0.013878444724891336
-0.011742906425461292
0.03470998737712173
-0.001270769562072416
-0.02477109312431009
-0.020188841793706436
0.013606895978321085
-0.04932868744192942
0.015858155719940308
0.02116100718970551
-0.026144502607871038
-0.010415847893073479
-0.04132040393804887
-0.023421986883432135
-0.06732285323706555
-0.05722344389886892
-0.11565774086301034
-0.07138185724432182
0.010562556568735417
-0.005280510502774519
-0.01310584551951876
-0.013433570243018764
-0.06842817047084843
-0.024697057405911292
0.013457734177692277
0.04608269860033168
-0.04525713278578784
-0.06889890193926634
-0.01752223875002442
-0.01863332221551026
-0.017514389334602906
0.0016359989964004479
-0.0025653004656590976
-0.012057715291839665
0.0073170131006137645
-0.05736339089223388
-0.042581753492566196
0.004903315900420417
-0.009407581329524767
-0.0017340500064098926
-0.020806219816193766
-0.09063172611707782
-0.02538189688889013
-0.052975475516549304
