# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP276_1
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=4, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.005697422017262777
0.0042965296077403115
0.006704021791849548
0.007148616089968682
0.006236511763283902
0.00786506849580587
0.007671727438939976
0.008330643841439762
0.007913878752484227
0.008141244743717108
0.008567711838458334
0.008358456606659353
0.005618256500351332
0.007844207836161495
0.007013653644527076
0.005089222596317191
0.005298278877903865
0.008319576467257474
0.008010186864333909
0.0056751370014562165
0.0068204853306725625
0.007057436937785742
0.005341663347447472
0.006418660064605133
0.007838431278416012
0.007589121399770684
0.006396321142713041
0.007665653550120001
0.010610528311191782
0.005638892929123579
0.007079816300183473
0.005579537130823364
0.002487480762934254
0.005663875296686409
0.0050106261607941105
0.004541182232048259
0.004645255260129789
0.005361297686056467
0.004519848480429474
0.00630630669782239
0.00429411226623289
0.00459235199186925
0.004984557527750097
0.005662769134441256
0.005255616358513718
0.005200520317860412
0.005702653776301311
0.006479671115133901
0.00649066026592778
0.006856541067641306
0.0056858803946644885
0.0057856196112830655
0.006001216128052729
0.005214528301386162
0.005626420542657019
0.006556304850055801
0.005609192099711044
0.006582601292635028
0.006592748699381675
0.006826039977152678
0.006720623372751927
0.0076912105943554385
0.005075782566048305
0.006045297848024793
0.006025096037879352
0.00547235459612448
0.007217618394772972
0.006598206264903728
0.0076888528862369505
0.008184691439939013
0.008207251982185486
0.008768868279310086
0.008723396243859755
0.00973493693154521
0.010189986778358232
0.00851298753836171
0.008101311945831623
0.008111438609769801
0.006270449892178799
0.00514612773230454
0.005614694154549906
0.006214762369245571
0.005042485109543371
0.0076420875348105575
0.0068397879379016625
0.00626471417656465
0.00707144518750526
0.006334029909379434
0.005832615210801372
0.007068984841066026
0.007967859515008134
0.011087207783928674
0.0112383478118045
0.01242432454573414
0.0105256311950113
0.00934735575733409
0.008660942177612626
0.008439854003532333
0.008499105378583845
0.006358999358539335
