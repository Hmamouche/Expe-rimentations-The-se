# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; IPS25
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=1, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.011842873661563324
0.011053659618172229
0.012628386118009179
0.01115231927750689
0.007796140771771366
0.0074150627279101645
0.006795277333176502
0.002793372421954442
0.0016126095811459262
0.002833695786677023
-0.00018139201892793547
-0.0023347098212871497
-0.0023323188485581416
-0.0017184474872583117
0.006423299037980183
0.006371797266175759
0.01130172835004145
0.013917975901489967
0.009373223039059035
0.014651817411261616
0.007209831701965042
0.009477935728116851
0.004435152966868082
0.00019794867873210522
-0.0007657413315344472
0.0011057915928658572
0.007230382740080112
0.006606842203367718
0.004068502580070398
-0.005330496103072164
-0.008640595266944778
0.0012090827236038556
0.005488260217309735
-0.0014806388298839851
0.0017008514901118992
0.007363639830959068
0.004686754224789984
0.007123568246106876
0.00737380026509632
0.004998430829833421
0.00360636236874517
0.009251853030087647
0.008375314993747933
0.010281118513305538
0.008726340742578062
0.013994600612797777
0.008816970006425668
0.0053219532584196545
0.01154158986162718
0.008422959738171195
0.010787516078161866
0.018381609509732527
0.017748192823579933
0.01942573598538104
0.0227828175640078
0.026056381456829696
0.028158982928125895
0.03036370071861835
0.02535511630442503
0.019352843259891592
0.015967882693492794
0.015661557871323853
0.014582996263164946
0.012774603512071147
0.014227400820517102
0.013776273954683765
0.016697138215135424
0.01934845705643067
0.0166282632656325
0.008654457210275492
-0.004827697602762207
-0.031204986036314372
-0.036944885046183776
-0.03729470136716389
-0.004107139022506704
-0.007577259777119826
-0.005586995621257872
-0.010045819475760933
-0.005171837504301594
-0.002343964135740024
0.00894755545787097
0.015493522064427593
0.012995338994797951
0.007506619641834981
0.013582404833376567
0.010014929170167181
0.018130045530625
0.016033529793446667
0.005566401786229885
0.026735894098312837
0.03040623039917379
0.022671770597116905
0.016407617023186726
0.015382422477316898
-0.0057290786404517405
0.0038472555992643456
0.016308614522927666
0.011535419283654081
0.0066810151142779415
-0.009504619736194396
