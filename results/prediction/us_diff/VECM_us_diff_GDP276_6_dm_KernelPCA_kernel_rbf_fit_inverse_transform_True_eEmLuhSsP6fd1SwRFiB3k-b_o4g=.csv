# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP276_6
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=4, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.007788303755617858
0.00673126139428371
0.007739958120521067
0.007620146556855671
0.006498328543206787
0.005010291507755613
0.006238184207120972
0.005261626316132054
0.00422847226966652
0.004238254097137158
0.003769277021053561
0.003820206705548611
0.0037630826420655744
0.004382161945101801
0.002653639803001516
0.0059932582206033485
0.006587724194092465
0.006782339877905007
0.00855377306268343
0.009437110581900813
0.010564917221118492
0.010414654511683538
0.011185177206294732
0.00981261873275914
0.010281609361941743
0.010038324570529184
0.010155971845382559
0.010285176808483492
0.01024173155368021
0.00977254834182963
0.0077993084693859845
0.008212369817932554
0.007832459968365287
0.007883771376825974
0.007987751025189107
0.008678888091657918
0.008454349214224919
0.007826251586413669
0.008263527244659168
0.007443203677901062
0.006813850485200382
0.0062564773398210635
0.0075274375771152416
0.006875243129155471
0.007187416765108473
0.007455050819915467
0.007555413054345091
0.0056332922604044365
0.004690021578184345
0.005163628263363205
0.0036525081210300736
0.0056637280502217675
0.004935627383119633
0.005222912223665799
0.004663193732036608
0.004869480183365513
0.004579461415627619
0.0034116660008599005
0.004477894072046894
0.0056608783896887884
0.004878355601196109
0.004560799197953847
0.004638866011154828
0.004367661247787733
0.005448166607766975
0.005654940249796122
0.005136768079813835
0.005886722694485851
0.00688550379073655
0.006431397958154613
0.00919196816932503
0.00784524520431021
0.007085349233381556
0.005491652452049694
0.004044527840867725
0.004837725318820635
0.005716993045200916
0.006818228215295674
0.008260786882300006
0.009882756769043497
0.009787731071219094
0.010809658750161811
0.010589041427429464
0.009390500299911907
0.008527961768507206
0.006931303619915645
0.008651347446018825
0.007882305570520326
0.007916127044801682
0.008422024626938076
0.005913336445945873
0.007445299432443788
0.007612891009526534
0.008107011263594439
0.012083579464679525
0.008969524774199333
0.009805169566152459
0.005166842871839125
0.006980857226460348
0.005654001082276367
