# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP254
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=3, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0024493270191630096
0.008302883411224008
0.005446377334338646
0.006398633385701846
0.0006409750785555551
0.008494740650347034
0.006258888425643756
0.003403058212871439
0.004784139210742732
0.007292195369169507
0.008905682988131203
0.007685623794565584
0.003217831536126318
0.006022118374609963
0.005823205474835009
0.006595317573926914
0.002732056695007688
0.0034380669701521236
0.004390870048483702
0.004878450124407879
0.007503161077266966
0.00872882958215509
0.0057831766189880346
0.003088323548594212
0.005672114881532342
0.0063246984081976616
0.004752437220820926
0.0040365818742860386
0.0033147424431634715
-0.0022133167758385513
0.00039292552578299204
0.0020238835767271536
0.0017354697513752501
-0.0009321922076378777
0.0052031804427025395
-0.002034127912206421
0.0060626998967427395
0.007353350074070036
0.004494832325450634
0.008862221879124912
0.0047862079817457175
0.0066776624041188235
0.00754502711610078
0.0037354112868275605
0.006552942143178523
0.009078966000306877
0.005520172422332762
0.006273569086143692
0.0036348792526782188
0.004079866329450883
0.0037505011821270286
0.006109864256042448
0.007156154440740402
0.009125215123860353
0.005745208532603259
0.004190903396519595
0.007775317926298949
0.004479621744171463
0.010380862821246537
0.0070135349609078655
0.010404614270399067
0.01228287341217403
0.011545818595880301
0.012039751325549398
0.009705453088821472
0.01303333365602727
0.009111393975726184
0.012768038998992233
0.008720038789586002
0.009387171694201555
0.00874109155773952
0.0045608707979954335
0.0037905955628472912
0.005053244976928695
0.008964398396339742
0.010231023291133234
0.007342946626034196
0.003324121749430549
0.003927389719065885
0.009016526307776513
0.01255603779012383
0.013541333648391558
0.012341082327538142
0.008782953905003579
0.007779667643523438
0.009748142374560228
0.01015197860508175
0.010325859883329094
0.011179983444606125
0.010977087924964529
0.013995737034686352
0.010223591333794212
0.011199133311534652
0.010147391640244755
0.011248182984429686
0.009804839427584866
0.008005890338330237
0.00477373005631921
0.0024135602866455852
0.003431994545160349
