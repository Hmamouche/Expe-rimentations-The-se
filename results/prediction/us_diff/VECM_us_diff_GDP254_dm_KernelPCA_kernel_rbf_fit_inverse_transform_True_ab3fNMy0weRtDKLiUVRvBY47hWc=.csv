# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP254
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=9, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0034651519745677864
0.006200395706897793
0.011462250470436143
0.005271178152692388
0.001339726760908583
0.007079408298639124
0.007336457917778581
0.004278057105384486
0.004426570100020486
0.0074349237363209
0.009526677346970765
0.006019428833358419
-0.005206445029231348
0.006754799445909298
0.008312842911846828
0.008914293947691242
0.0016642712063390584
0.002054743458342621
0.0075819176018815685
0.008102398600176978
0.0048849722958605605
0.007437963867769893
-0.0019626648246158646
-0.0007201031371833462
0.005626930619013848
0.007176166813903708
0.004719334494358679
0.0019398373375866525
0.0020216587932051153
-0.0009527764633945714
0.008111080215181577
-0.0004342145353596332
0.0018485596246993142
-0.0019470889284684753
0.005819039031523266
0.00046263017749763953
0.0007263697269992392
0.010981951698836645
0.008809807802203027
0.0076695124037836964
0.0072995067224745835
0.0073246739558876705
0.005083569074462595
-0.0025955225375519217
0.008524857680539594
0.011373544767137698
0.009254637434818868
0.00736812787172905
0.005266468292538757
0.0027902927466218726
-0.0005072131478194028
0.0031571605523971836
0.007807530512905535
0.007794709635309826
0.005488019151961692
0.009102586926875867
0.005638954215554091
0.0056149381269762
0.012111939010290342
0.00543335678564872
0.010196264997001677
0.009327797520697075
0.01465703248511274
0.009728035070634624
0.007232352831561584
0.014600248872866975
0.011400691945319343
0.01063856141882427
0.007816002649234896
0.008216812575244758
0.009289367987028244
0.00685992284034904
0.001470391209014317
0.006981523629551463
0.009143591920102417
0.006011558262370497
0.005791855220311898
0.00638001786608086
0.002486689352559122
0.01750401767943715
0.006792976086535306
0.013695903307941477
0.012548577374923956
0.009483134946611503
0.012817395507416179
0.007018463926240756
0.010571580216578658
0.009763314676789658
0.008472420852379791
0.01095747234381622
0.018840649830053475
0.0054822988882129884
0.010710333261045138
0.013712644896298445
0.006265568119533374
0.008769928635585535
0.013135540786440183
0.001012426258552191
0.0008561666244534458
0.004438874093711719
