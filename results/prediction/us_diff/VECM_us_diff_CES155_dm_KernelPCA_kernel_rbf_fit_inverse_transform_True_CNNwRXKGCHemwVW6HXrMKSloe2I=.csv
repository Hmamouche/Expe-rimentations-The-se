# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CES155
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=8, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.02691717400815153
0.052378209480511195
0.03367362940010027
0.0205791175548776
-0.09350123305418023
-0.021396309670701774
0.13121421824115267
0.008442927338258036
0.012943389412351156
0.0203563534208495
0.039724692125936614
0.027688241387642462
-0.030915298980323493
-0.016060563030839716
0.031037975122184744
0.04593292994715753
-0.01872434052889752
0.03414002744042416
-0.015428189772354673
0.043257688727483645
0.03604774826276269
0.031060313443139156
-0.014713122893272639
-0.03649671633212251
-0.018778701809909183
0.009515104418110966
0.008012515670314335
0.017866007025077804
0.009898071564900066
-0.05614012688214472
-0.032379660812839654
0.039360657464588056
0.11497188103979696
0.031965216550818354
0.00954507019220631
0.014265009799826108
-0.002244271962530733
0.035239621488447344
0.00883222833771058
-0.02505000706885734
0.05593502896701946
0.05522772657809475
0.05461273066050948
0.04337232364969586
0.014168432992229453
-0.012355795847504954
-0.03950317435374896
0.00019596775393201232
-0.010765169602172452
-0.024455829408054408
-0.01356899170293516
0.03562884412345145
0.042122930933650916
0.03359582420939037
0.04682166245569748
0.02863318248811441
0.03817710879066423
0.004927537726513451
0.007543031875429155
0.02126962000304643
-0.06699212870546388
-0.02337368059922764
0.020715633977286405
-0.0064558468723404875
0.032453406033347
0.022156910318200718
-0.040202129991269236
-0.06501280649388548
-0.045515770798381525
-0.04502526761287742
-0.059231473923927025
-0.019678063705353722
-0.024831256314975063
-0.02181968321547591
0.06064039935107521
0.008981770463422911
0.0005961852487859874
-0.011250929024762312
-0.044497166736698616
-0.0018336951648748948
0.06573186873675088
0.035611641205712724
-0.012703894105214612
0.021580583436328262
-0.01118395972603791
-0.046462249455605426
-0.013144617150353784
-0.030418005244986668
0.015687329144312583
-0.016531412266860376
0.020285089708832138
-0.01096838887299472
-0.04845944773002901
0.0035081337807525374
0.016296617992664107
-0.01719552095441048
-0.0344640119310014
-0.04143205183992988
-0.07345936973355308
0.001730666756775523
