# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP261
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=9, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.01550568805618669
-0.009708228184870455
0.031403548294762725
-0.03527360502528308
-0.01854173264712515
0.001747502028024801
0.03723287750769358
0.030338262307805
0.0017538790732777396
0.007390183009088129
0.021409146200219626
0.027530807707438678
-0.0031962189458710766
0.009193046662522217
0.014389051044661073
0.0002757296065749159
0.007057220519631307
-0.024152077700842718
0.004379301147247758
0.006206077563829621
0.02213015016200778
0.03327190396131423
-0.028282182974733207
-0.01955810592750176
-0.019529957183053483
0.008360336446897074
0.002353194124420679
-0.026557628270113782
-0.03804846620327083
-0.0517523284358887
0.007750713036493641
0.003158572392914811
0.005178377208047408
0.01204574227813272
0.008482915921802569
0.02348774286575572
0.011523524640235533
0.023949770973337246
0.0028834643425306684
-0.006633939935423024
0.02811866821063841
0.03124515077227185
0.02927281971559596
-0.004370750322560055
0.021337940585045245
0.007831936375071472
-0.009969170620395953
-0.010546067881084647
0.0073655564325594055
-0.0013409038182824946
0.015275450552508724
0.009341888116603463
0.00795340486278183
0.009797750649141304
0.011124258594311119
0.008662843867765231
0.019273714150098778
0.005506360205684442
0.010493171377269184
0.008810394703792725
0.012777861815330641
0.022057883306125445
0.016178122995202965
-0.00168318443897032
0.01046128316309319
0.01589533688936298
0.013452469357758495
-0.006819421078213494
-0.006151689204442026
0.003104780356456717
0.007741247390337346
0.010639490137184885
-0.030162106455650206
-0.0027742785705767957
0.05827593768602159
0.027516979707176335
-0.005910106592767131
0.0073502091525974025
0.0015016389778290482
0.020820847751843577
0.03054645258180493
0.051365143099277026
0.034520571302524984
-0.010519550495968671
0.020752589959659992
0.0200337511465075
0.020217601348812137
0.01822692396655924
0.020414477408444282
0.0019316477188530557
0.01446064515891455
-0.04052602036562189
-0.05096334365853013
-0.04568570896317797
-0.04594477342696242
-0.03355057106164486
-0.0635931569964021
-0.08855848811393827
-0.05090554695917507
-0.04364334502409106
