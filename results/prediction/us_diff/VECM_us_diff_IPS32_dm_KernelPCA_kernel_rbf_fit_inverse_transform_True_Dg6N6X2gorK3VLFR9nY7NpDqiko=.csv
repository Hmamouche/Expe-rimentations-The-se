# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; IPS32
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=3, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.018228137796454328
0.007109213119910243
0.009806907220780349
0.009666965362014033
-0.0047353836955574624
0.006220267622470054
0.0074019772670302925
0.0004415544393831321
0.0002028213600955668
0.003144885239522538
0.006669481986747445
0.004515782955959369
-0.007265807108331204
-0.009144159803678107
0.006306864683313792
0.006641801369182217
0.01599864748824812
0.009818874566545819
0.005972704120225452
0.013488184529030766
0.008605363322205732
0.015410503247730363
0.0031859224008169303
-0.007587365009828989
-0.006957197126721921
-0.0023327821531753164
0.004346666579726022
0.0009292926172805519
-0.004802870232115289
-0.009803870345296724
-0.010942562455009948
0.008792292354511502
0.013436542546208637
-0.0020641436820990388
0.006238742415654778
0.00238314403211286
-0.0005016803032001824
0.006219442349249684
0.005557076375850083
0.0012812330825614916
0.00838276289903376
0.011648089841093322
0.017232452588276194
0.01656806047823144
0.009872294042233281
0.01696072326449013
0.003923887020571991
-0.0017056021266764882
0.008717090079113223
0.0034984428635255567
0.009452986288772348
0.018070798263419403
0.013638270920890332
0.01874355221361739
0.013056609065233343
0.016378612472238714
0.019154703513441083
0.019622385519014816
0.0162580533369304
0.012692200907255202
0.008472456902018973
0.010344226694568352
0.017169527364611782
0.013825423024909503
0.021557163490983574
0.0220228723715557
0.01755792443242904
0.012826788692156966
0.008625198295716327
0.0006139753818220186
-0.006789717700385363
-0.009602017255426186
-0.011766040781081396
-0.021034711866048668
0.005878134222258529
0.003357084154076727
0.010979314619250767
-0.003345632252984865
0.0028461447655917086
0.002556534747961159
0.010995519302686878
0.01828425945562362
0.008032010699867684
0.003739321044079847
0.002485275922076081
0.005980088546243091
0.012972881531565958
0.003686585499373486
0.005551797192210444
0.0045991146931999
0.013240491534220054
0.0023852400579379056
-0.0037215519991649283
0.002049568722800361
0.00771400862023906
0.011908499978182918
0.004448243209609418
0.005424634414721854
-0.0010970350511889364
0.0008148567630797375
