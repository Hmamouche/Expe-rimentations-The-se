# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP257
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=7, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.02317047118703106
0.016660963667682778
0.021767400914283166
0.006696659319998154
0.00653886805056874
0.0067798067018437005
0.01963127719653861
0.010707598738006845
0.00017479808866395323
-0.002099610719700243
0.011363874591574367
0.002411672566520905
-0.008401084444938168
-0.006886688217807608
-0.003681350185417073
-0.003071443769371923
0.007429841221952769
0.0019641995648415136
0.0017856181333304392
0.007917637944689887
0.01373922014975858
0.018681663122101906
-0.0019387089284217639
-0.0036078609119580877
0.0005689331983303597
0.007509534479262261
0.0028775265031493235
-0.006917946417901929
-0.025074702946981886
-0.018468163046054295
-0.00877089813245791
-0.005578313813829295
0.009230326358067338
0.0007709202053575743
0.0009298893501965893
0.005388910849912135
0.007407701337751757
0.01596255555220038
0.01463666120878012
0.0033458545863086137
0.01874114040404448
0.021908589121033682
0.02008692660244761
0.009980168738777294
0.014035957305768993
0.009459381715542635
0.010810695258359716
0.00881894449531476
0.014252188808955452
0.010811150626240676
0.008898528708132838
0.015438626653194728
0.015844179404029865
0.016075431089055337
0.02137125229694588
0.022156429148582256
0.024040093133085073
0.02217540665363859
0.017073277523498125
0.023950551212508525
0.014726792268123434
0.017968355215253664
0.023060046834429717
0.011621804069216646
0.022017041427483536
0.024796691184316648
0.013710243721198254
0.014891846387532675
0.012319187030995885
0.01171366270780317
0.008248797901545521
-0.0044916816590761955
-0.024266719064956314
-0.029768742075571158
-0.006123721557836403
-0.011592020174055556
-0.019272638772053187
-0.0010718593761646967
-0.0037354469027447205
0.009465602819164223
0.025938057387487064
0.03132783012222811
0.013338481677578473
0.009884512058174536
0.01618149462773657
0.020937079390285617
0.022494000743790314
0.015073869293260933
0.01673674728449783
0.00915199221876801
0.020244082864110377
-0.0023557019700019798
-0.004482435864009042
-0.005188013694031791
-0.016902555536862773
-0.0003802678133064436
-0.004879345864501398
-0.023670669454370533
-0.015229234639283244
-0.0033194705524521805
