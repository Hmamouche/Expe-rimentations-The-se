# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; IPS43
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=1, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.02170774781216036
0.014217856640812978
0.008939668619003492
0.009746913031129307
0.0009479463766962925
0.00022005575905627685
0.0027855663120313957
0.0031819742672917007
0.005725295661221229
0.008397806694422225
0.002632745028849588
0.0024517635158192623
0.0007636940031798063
-0.0010553560884715998
0.008786713525137695
0.009581718536784786
0.012547104544123607
0.0037596392518835318
0.002576965944100791
0.014241240592918085
0.011714374397787698
0.010763812959582704
0.0019880862466496556
-0.001393417510788595
-0.004489454817865408
-0.0031561526128966225
0.0005084420837105008
-0.0005195691995413928
-0.0037777160819814186
-0.0034984418045732922
-0.0024657662244007045
0.0032279570718866456
0.0026424210593198796
-0.003177410489123501
0.007038698116094625
0.004527618640546272
0.0010397966807237128
0.0063639165848813255
0.009359363926660914
0.006473765008676774
0.008212610770686947
0.009728428326456727
0.011466691947680185
0.0127504310280337
0.008574622464157182
0.01236451726855058
0.0025904035898996476
-0.0011857171982610983
0.004818846265556061
0.001385014840214496
0.006655279689612813
0.013241278301533892
0.010025198432592301
0.015007459699826997
0.012023468930570306
0.01552372027946252
0.016705539713830823
0.017593575803481806
0.017521329713669695
0.01826016918786231
0.013917186691932606
0.009293592211308776
0.015373579920878271
0.01790110902453068
0.019046668050792772
0.01449820236698553
0.010742448829730149
0.008340349439402596
0.010609327997297554
0.006097022732309717
-0.003404445888995902
-0.006806546670705474
-0.012438739516516856
-0.018057445286891353
0.0009763844535005405
-0.0023250594707326278
0.0019331015334068608
0.00027693961890190805
0.0029785962088729402
0.004896277102229338
0.009110897167437536
0.014385293603658937
0.008141678709673543
0.00643578625879711
0.002403332530589547
0.005519605154620411
0.011351788142441302
0.007986160183416864
0.014436171735712338
0.013691267811711448
0.01043636697308355
0.004730515053775958
0.004350027101418535
0.0004892775589511338
0.003387415659868672
0.0075037559716081715
0.00041406837867140475
0.0018137609651288926
-0.0017528585619065356
-0.0015449809472454377
