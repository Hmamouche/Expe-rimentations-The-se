# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CES151
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=5, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.06018267891642019
0.007452341237796756
0.021088511542449416
0.0039331905495175665
-0.07050282937515667
-0.010954180460018201
0.10716175596457415
-0.057609657531417516
0.000776125466915566
0.10783961550107829
0.09740446906863788
0.03792736385141113
-0.07192796118799127
-0.03999623470559211
0.009829594657048428
0.09957291064951326
0.038341519684392804
0.014052742855718128
-0.05067355517376389
-0.02408713112927824
0.043072132457392935
0.023671178108520242
-0.010695334268197913
-0.06839386687306151
-0.06686278409716051
0.02725626771175169
0.08592198603177678
0.018035772796940144
-0.09156635124782707
-0.07859205060410071
-0.004909889429291098
-0.03665348046304336
0.07144021742566435
0.04789391943973184
0.028124678432362337
0.009794864598597817
-0.022919468502489958
0.11871392217161833
-0.028037198280913892
-0.03993179066207966
0.04441976347731166
0.10928356295105632
0.07773609230187624
0.032221500181573784
-0.002755985390145363
0.03132082905269136
-0.007963505830694224
-0.011405333537298293
-0.02881978313598671
-0.053490126768861716
0.0038428036484834584
0.009281898222722487
-0.06749168137520818
0.03533520705238776
0.07911232669751006
0.050924298722448275
0.02885576579151262
0.029566503266732547
-0.01587636717371599
-0.024759944064122137
-0.07265103859272135
-0.04881636846684019
0.08165182218019874
-0.011888945440876934
-0.01498317422024104
0.025442960316673556
-0.038678476365034554
-0.056880131543227776
-0.022909128844595898
-0.02720475347982234
-0.08144394624488012
-0.011993691808839283
-0.08089543239725669
-0.06342465531313451
0.08770833416279189
0.01122394017175074
-0.08632621870551592
-0.005244426526257114
-0.12533204100987777
0.009809014426629218
0.03676273615267564
0.0568478013549914
0.0260271013412338
-0.004169908889686651
-0.046355309586377
-0.019685556834618423
0.009023631433118604
-0.0585046526090918
0.005297729640310635
0.012200548647255722
0.025887781487920328
-0.0069114089303659795
0.04984344440857969
0.015005106427487102
0.05221863904032114
0.10116887220582767
-0.01870659592120067
-0.08095544725761014
-0.018225983656901243
0.07237234504490409
