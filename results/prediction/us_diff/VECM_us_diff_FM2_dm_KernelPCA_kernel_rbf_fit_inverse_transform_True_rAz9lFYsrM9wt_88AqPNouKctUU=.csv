# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; FM2
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=5, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.00902537656416599
0.0033775001535585932
0.006650053480868175
0.004249040551160241
0.005778211270409821
0.006287008250059373
0.007031209920600635
0.008258183889763869
0.005558245007050385
0.0063910186634175015
0.006426679751318976
0.00797721576092111
0.006893644135777148
0.00556923663515428
0.004838757855027108
0.004682323299920285
0.005798164400969923
0.00398938215690227
0.00632550666008839
0.005513602922706379
0.0038983814227006074
0.004806396222909243
0.003575846219986338
0.005160645597622368
0.006542308080904039
0.006025405985457203
0.004031431607908751
0.003352833632462163
0.005902074908989376
0.0040987085198277975
0.006148907500182892
0.004383017904438984
0.003652841778151972
0.003311559201783155
0.004152738640594809
0.0011623616926914524
0.0016000804423942957
0.000939716811825896
0.000512520361295916
0.0020380764474823517
0.0007162848873725971
0.0031369091367852314
0.00029585841383158106
0.0007750669945669022
0.0012503682909063064
-0.0004089349658416472
0.0020834383404458963
0.004812879778671926
0.005355370260510679
0.003997331685791829
0.004939709619880807
0.003184004274502372
0.005913482349327071
0.005615141088211304
0.005237825507656537
0.0058253935463678675
0.007915101855979668
0.006818034182426094
0.009407810338179619
0.008641014192984962
0.009825578967760063
0.012921700824902058
0.009282663492194847
0.0089596735966194
0.008129216630342022
0.008766998990274357
0.009175354053347736
0.010612888744410787
0.008531060732997389
0.009076869118141997
0.015564535488495922
0.01323111111588251
0.01415486348449187
0.014091897185064426
0.012097545620766731
0.009438521829356509
0.014789052071938614
0.013708144812441193
0.012489909673173035
0.013567845037454923
0.012556248161679343
0.005565561933341382
0.01121716330446542
0.008028384166684766
0.008514297786622632
0.013582326966206494
0.003173554539516888
0.01279580254605216
0.008547586605242286
0.009929171527816742
0.010894757164031113
0.006772080609037151
0.012367924273446287
0.010993111495260357
0.011590754106722615
0.01319637511386758
0.01290421537143541
0.014632540246578712
0.018793617006238057
0.01167862146197009
