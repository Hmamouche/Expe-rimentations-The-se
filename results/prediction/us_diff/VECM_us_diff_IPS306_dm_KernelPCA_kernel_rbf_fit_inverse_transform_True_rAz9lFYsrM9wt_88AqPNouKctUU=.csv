# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; IPS306
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=5, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.020246919980232234
0.006929594434268063
0.0074872270602943936
0.019342706159922805
-0.021134932485786052
-0.03100310296418604
0.035359207633386326
-0.02287754979263265
-0.002450789339310754
0.0033262915395586273
-0.014784970800122603
-0.014883642978877041
-0.005297108494693349
0.0018863817258336227
0.006516829238761871
0.006558693845301392
0.013950780931077083
0.03370471046499283
0.028615288281945137
0.030050965052018992
-0.002622030270712377
-0.009788990341637643
-0.0029725785345232902
-0.01988810354014673
-0.0064724923983937935
0.0014571196302457685
0.00652835155382373
-0.021592108310716007
-0.005225152461312467
-0.011952355896557581
-0.00040367689812321073
0.005812057129995052
0.017422656350992927
-0.007685211741729854
0.007113444987818525
0.00779358007997796
-0.02941332330493633
0.003920355805895483
0.0004927824475691924
-0.01597948242131578
-0.013135740090158573
0.01925808069011092
0.010991886172181674
0.006384668733434109
0.017620123977270245
0.01689342581616525
-0.005309698054923569
0.0030403453518471728
0.0045190246610068915
0.0032579278671648667
-0.008545797632698388
0.02807827209716515
0.011205090941350365
0.0013455321335483338
0.026681462790553886
0.0068976600589448975
0.01838951064181532
0.004490179572428661
-0.012750160648819918
-0.022287995260552106
-0.025577492358339754
-0.0006270979536575115
0.01733436082913876
0.030269418315507588
0.022604045627300926
0.03573874761087637
0.014206451046962672
-0.018796310533456005
-0.000807230814513009
0.011760371048233112
-0.01523740469647483
0.004403052895692322
0.009533312511829985
0.0006007795829890009
0.028825487968144374
0.02677991790207103
-0.0033523806847223676
-0.007100287270092646
-0.008888775920151552
-0.03105259141919365
-0.003496205098672746
0.004450135464216603
0.030157574655071934
0.026224011254267536
0.02508538944944739
0.024020447185241225
0.03780982736974901
0.024126394187826347
0.00937944548849005
-0.006517722390075701
0.0037034213362817777
0.003489416489195326
0.001019946359876683
0.026760356821073902
-0.008146551108037432
0.0009608458505114708
0.012271073464414013
-0.0037223261367947094
0.01773810163294175
0.023307576623479983
