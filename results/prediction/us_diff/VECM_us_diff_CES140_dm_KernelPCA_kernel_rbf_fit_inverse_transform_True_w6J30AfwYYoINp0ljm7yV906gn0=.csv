# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CES140
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=14, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.005705006067001153
-0.005084687886622781
-0.022832132088469133
0.006174572139481026
0.012963169872399512
0.007591783191233512
0.003378500507766494
0.009754104592139828
0.013535365325852589
0.004938274526208004
0.006112738771489108
0.0015115017423076044
0.0027968216878681428
0.006560709963139283
0.00533029749485343
0.0016608247434427446
0.0024635230897919382
0.009753167097203912
0.007934236141973115
0.011873982715555202
-0.0008090882804911074
0.00420834547220808
0.006179465123996704
0.01680305435084682
0.005545346243630502
0.004427825333452137
0.006744452662587096
0.014939059071732512
0.009411653544407726
0.0016210974730290918
0.0009469590239782545
0.007367203145315861
0.013083720326186165
-0.00589144029513625
0.0035598542830496257
0.0013244221948856129
0.007353463623811719
0.0025784876812316917
0.011318299493481166
0.0009848074609252505
0.0026633543811653113
0.007871140526523742
0.003353605023926223
0.003458208419749813
0.003177192610643884
0.001454904358160739
0.001750565874066443
0.0017615388640976558
0.0022686836810499834
0.005251001806699237
0.005412960508724013
0.007196914891635669
-0.004189531361752071
0.000540506219902867
0.0009447205465288502
0.0012437409370831469
0.0014031569382624881
0.00515037883542079
0.0017401873523682112
0.0056057725392818945
0.0076164482855581705
0.008056742255351192
0.0065399300940200845
0.0053618918148267405
0.0027507788086146593
0.0024884951117410637
0.009920251315326317
0.01741485442449821
0.00747615610807436
0.006141980826526188
0.003393876130699242
0.009565456524626734
0.006873847061052476
0.00428593984747056
0.012157659252521966
0.004045320489978093
0.0013051250623437717
0.008144496764534702
0.013081315255222378
0.0015724346381567394
-0.0034986916363861256
0.0008423156836533329
-0.004328271656202412
0.004932307606168698
-0.0021300833955407122
0.0017763598603152972
0.0030806011685282414
-0.0006444020854011887
0.007608226555245977
0.0016455439889977216
0.0053472798786272
0.0004369967868669953
0.006187338363228046
-0.0019974880646922207
0.007234726648086197
0.007220285522718358
-0.0031030435330802156
0.007142240411005071
0.007348005916295986
0.006420546493815205
