# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP267
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=14, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0032506901972037244
0.013081558961730728
-0.01211852271094892
0.003508650198771117
0.0041703922958238925
0.005050497755903214
0.016996332209664303
0.0032840706180457036
0.008779388996276801
0.01651848992546497
0.02467489226709625
0.019861396617417267
0.0038052136721232104
0.008763319032452685
-0.00025970649326056625
0.006741939886103134
0.00883688136143762
0.015159871073901005
0.007356391994161188
-0.00978553314395391
0.005326505727488407
0.011317297230108207
0.00937692126399857
0.012308151472122386
0.0032044571265748886
0.00893520158262521
0.011378421225395514
-6.532361202627227e-05
0.008415224145328337
0.008348071188240044
0.01739169693668681
0.007713094401948372
-0.0030071951463462015
0.005813631824801459
0.0062294754767838615
0.00024198390160460465
0.002200600411351004
0.008307836699449293
0.011083743647775795
-0.008927365226702325
0.0074864581916389405
0.005495088863452152
0.0024042494830798906
0.010033638148236795
0.007703184012699508
-0.0054545541082786
0.01947882578326808
0.00636117889125516
0.004106952231290602
0.010263149834953297
-0.0025030971475235647
0.00783299900690354
0.005561307644359262
0.004127059161490863
0.01586963443733419
0.0077737530981978175
0.006526613483441683
0.007829342355685904
0.007252346827600059
0.007244127570387907
0.016413137852634888
0.014074553647031446
0.007095894434444326
0.009833012096670354
0.01666509155158597
0.011408410174545695
0.013222605083505454
0.006355790392183518
0.007921009246290085
0.005538629806466674
0.00654597202980118
0.011896705991471142
0.008449387770159517
0.0077583578028553885
0.015761132866983357
0.011772367985273795
0.006674863318664274
0.010317282918586947
0.002693127769471431
-0.0065950774507364035
0.012930042191725704
-0.0051051937255088145
0.0030135620906530077
0.008373770971781734
-0.00700072762915652
-0.004441975307586249
0.0021278392563638606
4.516472503000792e-06
0.000755123791490917
0.0022194003506811584
0.0037201009677759623
-0.00015881264874279075
0.0025130655126059708
0.007187020682964913
0.005945358692341167
0.004888553273013413
0.00832078101369517
0.0016271664393479159
0.0037153130393026636
0.010119102883836965
