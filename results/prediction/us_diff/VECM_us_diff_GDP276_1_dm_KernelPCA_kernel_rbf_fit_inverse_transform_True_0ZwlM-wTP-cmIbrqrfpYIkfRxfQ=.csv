# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP276_1
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=13, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.005536146513114355
0.004240529015667487
0.007072254631719574
0.008324211710850713
0.006844875638477418
0.008772897668795616
0.005883462917900994
0.009287827057020512
0.00662144817268512
0.007378745087935805
0.007691443424420689
0.007556700298044927
0.004083964865749924
0.008748101946332442
0.007861667156843156
0.005043360854727766
0.006081805746806914
0.009411908160050851
0.00780299702381519
0.006803746354942213
0.007504177232163093
0.00788048724714251
0.0039128262550763085
0.007160839596977345
0.007319023547443185
0.007530788599734474
0.006648863829877059
0.006933790675106861
0.012085383358527699
0.005537621946951972
0.009947962623545113
0.0034443867418237815
0.003342153223454671
0.006553677807805897
0.005382679597103349
0.0034842109403323404
0.003910974999613423
0.00526066988690115
0.005245474631742516
0.006010800622480136
0.004738642927846382
0.0045503359510708895
0.00500278270122748
0.006117839224400101
0.004403849472076023
0.005528474394292726
0.0050960744910594135
0.006008905169802863
0.007646898426687221
0.007733508487049397
0.005284689716083971
0.0060121378566091645
0.00572864116386562
0.004051794822214304
0.0061160365126643286
0.007123829500343029
0.004734578309172413
0.006782369368142692
0.006789146551238295
0.006662023315324157
0.007254887089018028
0.00795132238988165
0.004520572810207338
0.005990369201096683
0.006568562795753791
0.005627278564963347
0.0070565120511978515
0.007280085260686974
0.006833752757075242
0.007827699618984949
0.009060235191498523
0.00853587371330853
0.009292301946152307
0.009162735110420284
0.010279446937122785
0.00805971868050478
0.006657796752972241
0.009847177834888747
0.005289054445817276
0.006064194836213796
0.00485683079514319
0.00663024041716029
0.005284160425222047
0.007009774525328238
0.007056031468729847
0.005837025427458393
0.006729492277755425
0.007153677667529646
0.005884747008457394
0.007256745502473147
0.007951699658417652
0.01076349470581638
0.011394719922914132
0.012354354880626653
0.010464114435629087
0.008849978577773523
0.009266570087853646
0.008364499699425267
0.008595543234366025
0.007136449364358375
