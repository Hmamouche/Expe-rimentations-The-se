# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP255
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=5, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.00547416185224097
0.005591587589051901
0.004520683051829485
0.0033854375246683472
0.004484311313310294
0.005740898929462312
0.011618990238091929
0.009396592826616437
0.009425376627980884
0.007261551361580296
0.0046606887593889715
0.005547896476427708
0.0046988780478149274
0.003943991198648858
0.005785642292187725
0.0058638085573315185
0.0054629169500828535
0.007110293513374373
0.007930085835749077
0.005455170158266697
0.00661946843352845
0.0063134813867763845
0.0054281719454114955
0.005009418251047965
0.005393068012323482
0.006199382802916343
0.004085334218729035
0.0059050839309322005
0.007680490468744836
0.004328101331476109
0.0011399803704232906
0.004983021404440113
0.0020369405094319967
0.00479831528070859
0.0073992231822184945
0.004611286911508285
0.007958529512199814
0.006049948685495826
0.003232591799872137
0.00518217453836512
0.004951624571442459
0.005554983334193855
0.006796046833217582
0.005410511007305491
0.004852527389217629
0.0036307378017988584
0.004770983098703831
0.007915909397922779
0.006108783821757893
0.006125836552719908
0.008652822345275245
0.0038870141384815663
0.00505443917394402
0.005630376749393295
0.0061067025274136235
0.007224575747654642
0.008146790962515024
0.00909994543582159
0.010261528460372428
0.010389723718843363
0.009717955856209801
0.007376981514321041
0.008896343449155074
0.008689189766855905
0.009711372633217582
0.007870822222172382
0.01227726981974641
0.010958886659204185
0.010750824885848132
0.011091641979940753
0.009033416292155766
0.007295862296580215
0.0032970781750347763
0.006391800013690228
0.003164051328268378
0.004349876673276054
0.005537976296320158
0.004810784794674326
0.003009769307352097
0.004544918572677093
0.005020853831151493
0.006841576836946058
0.009314770748105359
0.009176772914923867
0.0070494649831751915
0.008975396073537515
0.006207551154985258
0.005803583240843396
0.007654986358865304
0.006404723751250284
0.007115654504316216
0.007243078524269539
0.006494174413484313
0.0074668118184310125
0.00915739094074483
0.008181627592410399
0.007587235113125359
0.00604311322176709
0.006252376038494115
0.004298815246276001
