# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; LBOUT
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=6, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.004381975267505133
-0.0014393534366285389
0.006048844804868574
0.0021976854411904587
0.0017857964588553605
0.00924593670106205
0.009901968751212995
0.002484418527236396
0.009303826840958158
0.013353354353561876
0.004918237019419951
0.0056487611899203455
0.006477912248185677
0.002693648501951326
0.007073774287010584
-0.0013241492509600502
-0.0012812244433388262
0.0013132122720522848
0.001638749239393761
0.007800325728106015
0.0021684722733781793
0.007213044700978616
0.0035911477790832
-0.00019522720980726408
0.003797553176556079
0.00550549648177423
0.004001243953095517
0.002697068102156075
0.00624728235056606
0.0034103740913203374
0.0008338706111725327
0.011026774370671863
0.00813341476470594
0.004918868729256695
0.000991163598745111
0.008245833618934422
0.003379439750640145
0.01275059643661099
0.011855808530515481
0.000541128420988349
0.0063598064824941965
0.0036439618625890595
-0.00015948914493544826
-0.004015845037121411
-0.0015290799821660137
0.00246493523218326
-0.00037700655394405213
0.0002639881369625296
0.003063726210725121
0.00681190516091956
0.004966492417380367
0.010272050848863125
0.003071615010617055
0.004532870686080364
0.0016803266781713001
0.0029313912831379716
0.006713128637390737
0.006613708743591145
0.006849658173945576
0.006950277868684976
0.008255352033982418
0.011805161971526095
0.00959968692971925
0.0018928079032177359
0.0026865658821100774
0.010593437002792819
0.0066340464377209266
0.004312321698978221
0.012743735480162124
0.009816275368155523
0.009984929738060363
0.01113399712000826
0.006771495189215819
0.006380084319136967
0.014050170837511729
0.01379130523048322
0.010280042009511431
0.015173969967507684
0.006467601445204668
0.010006146065739128
0.01456608186302738
0.017148618951306
0.006327043846677886
0.007852634469333647
0.008167832594635101
0.0078092183847643225
0.009553485168314342
0.010010115621697666
0.006020167508382803
0.008609521715315318
0.0022386982211354987
0.0001413758509272345
0.0040046768754798704
0.0004485917892588483
0.0007945346517827128
0.002492495760753408
0.005922395277820049
0.0021383038780788464
0.010317371809539858
0.01686821913532678
