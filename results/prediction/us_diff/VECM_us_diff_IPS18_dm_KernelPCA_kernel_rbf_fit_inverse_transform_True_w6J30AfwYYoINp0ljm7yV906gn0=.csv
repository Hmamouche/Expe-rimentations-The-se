# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; IPS18
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=14, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.022012188922993704
0.000716626771663488
0.025548384653643147
-0.014709803042609073
0.01006567769685371
-0.0006185160880034504
-0.0033313099146691037
0.005614581516696375
0.010076026469990954
-0.0003029473480178199
0.028703948887289762
-0.011908517806976679
-0.011026023003983566
0.018890990274355982
0.012865082780444266
0.01296165892303722
0.001288052878918318
0.014073110550074108
0.002445381346763513
-0.01534471883957262
0.010086958219037198
0.022502345512610523
-0.005042657438353578
-0.004869806351826715
0.007556806113390665
0.0010261949246588803
0.004810926194821706
0.014608095893498367
-0.01623364085179478
0.005182977889768024
0.027314319267365057
0.023498394227333227
0.012060134106903805
-0.0015329372546933825
-0.011902861163783892
0.007233235316426822
0.008517009258232039
0.008601992882737894
0.00011097125096838547
0.003445915252807151
-0.002425402297982906
0.006667716820107652
0.016006484780358637
-0.007410806430615579
0.003493334668043714
0.0100028114793744
0.006687067193386995
0.0015694875123471838
0.004077591769916464
0.008216607644960124
0.004814446720817022
0.01605131062087154
0.016476270363174
0.004190917345249342
0.00678447165145496
0.0023835323304853264
0.002989718123033651
0.008853292562524224
0.011447519691449054
0.011458367096269542
0.008213407301256902
0.004802804505392368
0.004999047577357663
-0.0017159347584808026
0.014981644193413367
-0.006662871014626214
-0.00031579337978595787
0.0011869187377031134
-0.006087706446170576
0.009447960597127948
-0.005149450786865363
0.011166593175224254
0.002320223318363694
0.013394846721477182
-0.00311884464304077
0.015468189612025746
0.0021417817278862996
-0.02065769559476755
0.0025331398777440647
0.01882046826954787
0.0031118452965533732
0.005243172076717411
0.0026516936694931338
-0.00787644900058515
0.012231505004418853
0.0006558082194373671
-0.00266673021124581
0.014023380134861487
0.012710436785587295
0.009846317257685417
0.016072170476071332
0.0003496081037722056
0.0077412369029631915
0.025217074401785118
0.0005446125479827498
-0.006461627407196871
0.000552854954842804
-0.001843530249676274
-0.002267106343225085
-0.0010081366544014547
