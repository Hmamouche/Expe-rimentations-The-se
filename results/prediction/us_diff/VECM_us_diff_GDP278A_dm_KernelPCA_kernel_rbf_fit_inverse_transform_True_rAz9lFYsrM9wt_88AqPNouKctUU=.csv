# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP278A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=5, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0003016581277746704
0.0032397423116068916
0.002938405651322814
0.0037898790555650833
0.00435144611920271
0.00051215838051617
0.0012441624671088636
0.0020946097131109196
0.002215013732975163
0.003926167855960726
0.0051674331119973315
0.006195101428496471
0.009792916135644076
0.008138746253443598
0.0034117264845574214
0.0008248704727827269
0.0019471886741429876
0.008018802558495196
0.00963445887988967
0.007586793735287224
0.0048923657246114265
0.009279821828491274
0.007458127947824421
0.004751319291089761
0.004508595499524221
0.0036266309700267083
0.00567282249330454
0.0041760872069050905
0.004120881948076243
0.00509804430799819
0.00595819458335336
0.0023868652397550445
0.0015775750598273368
-0.0010469884785058114
-0.0037907891167964615
0.0006655600831692722
0.002255665819381006
0.0017610094780772362
0.0037458104566514038
0.004524658348237574
0.000297662369361711
0.001541911264870957
0.006111298022738548
0.006066591233805929
0.005402403079096818
0.0025902472380886087
0.004307397970058569
0.004131628251603392
0.0004840257524305068
0.00027521534408079455
-0.002919677113849185
-0.004266154529963986
0.002560609821785012
0.001118794052106254
-0.0016587436888252545
-0.00038655678740278813
0.00020677197264325388
-0.000944639640579293
-0.004899694573887656
-0.0037325073862225703
-0.0015616283908327572
-0.0021059952215146723
0.0008632026923030215
0.001278489327124501
-0.00022316607534430077
0.0008160608639672686
0.005385585299135602
0.0036078763434039354
0.004021633930763675
0.0031282939513066054
-0.0016260232753226565
0.003006880948306359
0.005610592707893346
0.0012530859388030732
-0.0006229507949912618
0.001700895266618556
0.0003097121696581084
0.00599709890496719
0.008083316123064165
0.0010874265864697424
0.0015733339475252001
0.009003054364263033
0.01030228414861866
0.013672775221545358
0.012277755592187812
0.011094469055962957
0.012611573797232076
0.012293584428514949
0.01399199405602262
0.01604752890309053
0.015963874394829408
0.01247205329598125
0.008317674332826597
0.010485155647316885
0.006099295734587694
0.0013744791786055371
0.0007087950383149727
0.0020102471601817114
1.4449258145830053e-05
0.00032839474683652776
