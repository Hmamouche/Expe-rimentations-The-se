# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; HSBR
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=1, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.026624664883831445
-0.02350458052635654
0.03694122365431868
0.027303446396492355
-0.040384968056386444
-0.008649602758040609
0.10287963990132877
0.042968053024106126
0.03456714749693089
0.027487401225713037
0.038203953844364494
0.02432676702821853
0.007824604300436966
-0.022761571109474986
-0.04126970496910739
-0.08211918343049174
-0.11979356828478889
-0.08194639217870721
-0.05508448579811569
-0.06587369066248572
0.004926735029254696
-0.01364446445103128
-0.009928689976810949
0.024059726730197562
0.026525776382133704
0.044055068435399664
0.01037051144081947
-0.04936592205912203
-0.054087467203182214
-0.012449120632276692
0.002749597967422521
-0.0799811960517348
-0.018362220417526845
0.010174289140521754
-0.0035771425388514693
0.011885566806348528
0.009216692993104268
0.02000561527487873
0.0139196644558745
-0.0003955387713151029
0.02381711448597934
0.041018963898292016
-0.004977157611825151
-0.031240548845945224
0.0026912991026503547
-0.024751644553831588
-0.024512242270561625
0.035911596897249404
0.042918686030256295
0.08745155290031968
0.02397746855220618
0.0030537094729119127
0.014595147093155666
-0.03519697334602306
-0.02237180393114294
-0.029146059943313124
-0.017218916052604092
-0.005102063883651031
0.05661798508655441
0.03358123846904665
0.05534848007651715
0.0679400401567983
0.03864923689587963
-0.02239559383045805
-0.027492707182686725
-0.01908927450965031
-0.010763845531316098
-0.022110865714056002
-0.004707690764830998
0.04329118732775362
0.10245335370437554
0.041325855658116945
0.03176337857089612
0.06554926332699951
-0.0064487493169618805
0.00715953700413618
0.008266094554429296
0.04781222562410482
0.033191006748760105
0.017642965822158557
0.0195727616154166
-0.009702164767525126
-0.014051770344677472
0.012962628095040911
0.026060527894780798
0.012728372218733769
0.014972048360258644
0.05587215962723001
0.01785489717883974
0.0014251723528656956
-0.011032515518275207
-0.053526232044730074
-0.08860677959667751
-0.0942896070509498
-0.048944990475529
-0.10045453900336784
-0.0697763030120071
-0.09256532827180736
-0.06616482036962439
-0.040322893357255786
