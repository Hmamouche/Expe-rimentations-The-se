# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; LHU680
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=1, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.03866215860933719
-0.08823198005724245
-0.05932811737143312
-0.0657853858600306
-0.03986490714341345
0.0018771594590360798
-0.003363588108398957
0.013942940501901148
0.0010225238408753433
-0.002578991845870727
-0.026622614784237712
-0.005597757585908549
0.004002250460159218
-0.008099874683192338
-0.0068476295020659175
-0.015790935528642067
-0.039632695144169144
-0.03318481381873422
-0.02044885924560043
-0.025510876822378292
-0.006552131038443704
-0.022629709789280254
-0.009254521449374931
-0.014592018238547123
0.01744016404828518
0.022699702672725374
0.01126799248487434
0.011681682923880356
0.025885120755680193
0.03399232704596988
0.05405571615179971
0.0570321954151244
0.023820028017090447
0.03128409722579995
0.04562461194492648
0.02628980780556981
0.02761498821425479
0.04593018079427402
-0.009918528634411459
0.002427461376232851
0.004834754380024993
-0.003677820113093773
-0.0068352883411258985
-0.01828167815288852
-0.031895707530778375
-0.04219276042609563
-0.0529450794302517
0.00337590787183455
-0.008662891688823955
0.017495906668201933
0.026548102545264667
0.03310113165863191
-0.02452479233216058
-0.034017591558080415
-0.030545097358988773
-0.035859605093189244
-0.0018850203136130464
-0.038254204748940604
-0.022098097278006865
-0.02514594343538499
0.00045465666105763605
0.012411473958162899
-0.023112755111337188
-0.00813546120840276
-0.033742257004631286
-0.027999895509739303
-0.046395342271902
-0.016009251687029828
0.012802735315241835
0.00869418174248038
0.05230942857939233
0.032197869779835325
0.062220466816686845
0.06621062472447703
0.05545030866520537
0.0300913857370051
0.03415461758763412
0.054217417497903875
0.019428048763384588
0.07217027948850771
0.023189890602335297
-0.004190253149393402
-0.021225034418396526
-0.012142320795206342
-0.05165705361910089
-0.0070636417625231426
-0.0016190865945679843
-0.0032570497932374125
-0.024653376771344538
-0.022339216530515002
-0.032977508515928
-0.0233292637560654
-0.002233910251828744
-0.012113970437604702
0.01963571843096519
0.015513012519376798
0.02359304301568571
0.019303117378566194
0.028859268865159084
0.037212035911091734
