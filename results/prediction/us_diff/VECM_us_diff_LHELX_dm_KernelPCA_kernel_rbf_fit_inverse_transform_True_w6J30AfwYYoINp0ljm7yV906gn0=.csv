# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; LHELX
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=14, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.15434956021625612
0.051041770843472625
0.005902987963994397
-0.025642973187681075
0.002721992627069944
0.04099427270548286
0.022291954626115218
-0.05121351831943237
0.05873249380386389
-0.02459107269146881
0.06522100036881168
0.0518653008258125
-0.015506339312980021
-0.005089168486224118
0.004870513324396912
0.03642556939657148
0.026869505198353995
-0.044104271478554676
0.03720982213948705
-0.020563042858928425
0.0018940802980579423
0.09629685002142499
-0.023184924932265503
-0.04960160154400231
0.047867093561545546
-0.03282604383605022
-0.009585040351045073
-0.03516306070288809
-0.08941791009028578
-0.06441703330540521
-0.04290965403750547
0.025354919177161633
-0.028340357849297455
0.004563373976981221
0.04886036547867484
-0.032081106776809566
-0.07825354073004132
0.033730584543432786
0.006157495989703715
-0.012413674024264543
0.06285459086389628
0.001720518655931121
0.037931452670801044
-0.006444027348395019
0.028787827042348727
0.013355932024073081
0.020213811566948035
-0.020190982334109042
0.04163368326359703
0.024760952809338453
-0.018174285462654687
-0.012989133524741896
0.029339041925843537
-0.027002669500140766
0.05278559415933654
-0.00010906772670393576
0.03782508953204193
-0.005469838313475596
0.046439618847377774
0.015557030224785315
-0.0318882445425892
-0.016309911603913728
0.04960696069019917
-0.04018849791320078
0.01986070106063928
0.027816723024631774
-0.019187188341979654
-0.019031694048246874
-0.019153302832867817
-0.02162749376993534
-0.045676270724968146
-0.04035896470173022
-0.11457775590617174
-0.018684802795747364
0.00409048039474676
-0.01740700918298144
-0.04041823897456387
-0.007298835693091401
-0.04679517709650674
-0.020657857818494843
0.054979165321089804
0.026513543045699983
-0.00781946851398643
-0.05343519147433076
0.011959054254001253
-0.011687380756413242
0.005532124494611991
0.007054857528640102
-0.0005145273208323701
-0.002402579880007102
0.016511470459455734
-0.032363618199952295
-0.02048712070094831
0.03426102121776523
-0.026068203168268966
0.007185584524295063
-0.0007864252926502793
-0.05317187041119535
-0.02109856887268188
-0.00379818254783929
