# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CES015
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=13, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.025713886959716166
0.027318224300466366
0.024910279174027185
-0.029206113147317275
-0.06045591838446529
-0.01995813752990284
-0.0003294417815297816
0.020255035206624868
0.03283189823503115
0.02980998297288842
0.04296250893469105
-0.03186062369881308
-0.04885410937076648
-0.03574575547602089
0.006760143323488701
0.023337812383948765
0.0015340115926982625
0.004263353809337237
0.02916418291413711
0.025252646881914222
0.02201631275619856
0.04180797212353034
-0.02386216591461763
-0.018084424961786992
-0.035355834308575765
-0.0061974058775256646
-0.0070054188619994035
-0.012508434000257126
-0.03528517364292935
-0.0505818956465559
-0.06719320147494048
0.004646919402133773
0.054064569134048196
-0.012062058644735783
-0.010329127622072509
-0.02153001951890134
-0.007161278678827711
0.019576431021760023
0.0021612616471713367
-0.008278789659145972
0.028892085166733857
-0.0025742331860007213
0.032234927853857634
0.005257721538814733
0.014503402993431338
0.027728364255844386
-0.010533921852456517
0.0014972066298550354
-0.01465468795299462
-0.03628562925917877
-0.006994020496557094
0.014596700985232768
0.00990080661175015
0.024485250316799156
0.010275205855324767
0.006546565598336413
0.020022682673975098
0.008652308758054172
0.0031453724784837878
-0.005281799623769026
-0.022047601380607712
-0.016708394918703934
0.0051043239472816256
-0.021144134779603304
0.01820570841849713
0.002585091660524324
-0.015134990612603332
0.002917155994349347
-0.02036664374804117
-0.001359045586329292
-0.044427867063142126
-0.05614688607251832
-0.0690673579564079
-0.066189863939828
0.0025599073394720027
-0.007999038413553941
-0.010445850973282048
-0.05534185883604166
-0.04494510742453669
-0.004684196568514996
-0.024775908254765607
-0.010761023039378214
-0.012293613902169768
-0.01862999624082217
-0.004900331531855418
-0.011063438195698909
-0.02153712106019396
-0.005583792662581647
0.0030042394204688855
-0.010797364203556453
0.0027419868648972823
-0.005086293145449377
-0.031110835473235135
-0.0016882732115030266
0.009538446810723751
-0.01511667640600363
-0.02379859978930205
-0.04386699975499148
-0.02084773824752067
-0.02029379022333198
