# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; PSCCOMR
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=11, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.06539970580672967
0.0989709697172181
0.020713866265264197
-0.09777407929938539
0.009321843615778695
0.040534620666441534
-0.014705614622890724
-0.007991525938123295
-0.04028185898616691
-0.01641553569910962
0.015262472877642104
-0.06244914430469451
0.004452101489506699
0.0006133491023901858
-0.052634718922023795
0.06224456909274287
0.02539191353115664
-0.04356288381446677
0.04712834734337026
-0.004168271797409629
-0.020812531767835898
-0.010244313554050224
-0.06168915296527506
-0.005168422677659993
-0.00897486818723655
0.02573390142082834
0.01998352916240685
0.006424286022094208
0.033710253707728816
0.012127224034305911
-0.05855216020190958
-0.0985840661675015
0.011218959213310328
0.02486153209268382
-0.01264840923634556
0.021529170779153384
-0.0603755423623007
-0.0321564547126144
0.016714741782978427
-0.03139613890944738
0.005468335286318723
0.0281680911668271
0.018045502684436353
-0.014603148977489079
0.01835830143802122
0.03671365642567914
-0.03194177213661559
-0.012113260535751656
0.005238656469097214
-0.026764662008798824
-0.029737889269277305
0.05664659407718513
0.027920225945454534
0.019258975774426222
0.0363973786251009
-0.02772149585086394
-0.013560383551381042
0.0036478094676229873
-0.03402024214137299
-0.008749446213215648
-0.043120944153174065
-0.022876696185510734
0.035861225756067094
-0.013958596886687026
0.01388074016346627
-0.006496181729188946
-0.020881414741872592
-0.06627869470202952
-0.032105313480522146
0.001085830119628265
0.0035986957639550735
0.011286240107545906
-0.04015632152502034
-0.03418671499778718
0.053435570380300924
0.009015717574184106
-0.024767611191311656
0.028425439855289635
0.03635377262754767
-0.0016517231211496354
-0.01679449934465736
0.08331394378221256
0.05004206193869432
0.009659655942826327
-0.016403588267287845
-0.021511193592902246
-0.026140848897993556
-0.013303565571406738
0.017880370027588917
0.033782270298328414
-0.0005576979452972981
-0.009168372436805934
0.02038404539047033
0.013500169966086155
0.03746687111510346
0.04735546487915339
0.03753390111766963
0.008928031734801563
0.013967932716924897
0.007299834382587127
