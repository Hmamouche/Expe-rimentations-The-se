# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP284A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=13, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.011414928575468188
0.005287434991301359
-0.009834657171688672
0.006076930297486073
-0.011870564640489668
-0.009847733268628513
0.012909075434222934
-0.006628475667301868
-0.013758565425640225
0.01494145419438392
0.011215643981295714
0.001810794028594302
-0.010083508188881159
0.0012195125906791049
0.009118837470810551
0.008159636595385412
0.010258933997001103
0.007724773817659757
0.01710991564958417
0.011437670201727977
-0.003661704876830708
-0.0016450645442695239
0.00761312646142464
-0.004634720773811228
-0.0020159187735514436
-0.0014207880603056954
-0.0040207125800320025
0.012028499538593413
0.01416773374394928
0.02328653692163409
0.013128985489404124
-0.010394821667605737
-0.012341827726710978
0.0014264669194287549
-0.006282350821259431
0.00155371589973043
-0.003153186330382172
0.007186874698898892
-0.002303072912475096
0.001517863466239245
0.0032882112328297478
-0.006887781535630548
-0.003787807988536169
0.009370397003270614
0.012952977080226052
0.006687256667994246
0.006799586145034286
0.014960014463436151
-0.010454982780657814
-0.007958977295881
-0.004072289376462525
0.002145587162190294
-0.0061282526076581805
0.0006067136944805976
-0.00871579389742318
-0.009382518280914375
0.0008892884913181901
-0.010363619101138994
-0.009545085431691266
-0.005042456090777531
-0.010376077289632978
-0.0051804235427337746
-0.003360429957007988
0.0043305553310201556
0.006373602108843969
0.010973802059391899
0.0036154702281494316
-0.00830189665997569
0.0035494463470088135
-0.0023955610722131314
0.006685308455502908
0.000345448527378539
-0.006844818650295739
-0.006271833412064345
0.0011967777074300863
0.005109822145271228
0.006704651158680409
0.001649513018057637
0.008178813020453462
-0.002350750359382914
0.0013163135084688958
0.012669818449743919
0.01642638757418653
0.006300945757946837
0.006793243903260721
0.009478077446837548
0.0040286998036303855
0.009518162268338896
0.006463994002589504
0.005822936644512876
0.014140538980034607
0.019353128766982447
0.008489149661753863
0.007974846591219855
0.01602672624539278
0.003736419606589235
0.010455288994680038
0.020717310115240258
0.026296024692899152
0.026103290936006315
