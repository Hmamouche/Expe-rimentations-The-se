# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP276_2
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=5, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.012318251590746867
0.005291002496049025
0.009944716128537031
0.004076013310864098
0.012062258830486998
0.008914968374186366
0.0032809456599694952
0.005575567284147877
0.005270938511648565
0.0028338582986014377
0.004646889092328115
0.003126620589677864
0.0025444088274954165
-0.004348777378842645
-0.002573494382292985
0.001500805163215756
0.002032768762379522
0.0017332973193616
-0.002134882654190658
0.00282577612979359
0.00469030169841423
0.00530127892452955
0.005124541069055547
0.004133151557159667
0.003924518898692175
0.0026080796136134605
0.00464194535170444
0.003973750560659036
0.0003307465316113041
0.005184421434985735
0.011089329711302807
0.0010623560892502985
0.007919231597237208
0.00817646381259884
0.0013118527223303243
0.003726002293645294
0.004529797011798584
0.0058939309897376255
0.005531512832731312
0.008259291994580439
0.0069424373316578645
0.003879939233842723
0.0029044176330748407
0.003110552110419479
0.00373413947443226
0.001539842548261792
0.004661423563718517
0.0014666679187224296
0.0007087958891310728
0.003167693646429601
0.0020033986809185524
0.004526155049239544
0.005789083542583787
0.004206303689395313
0.00625431981988068
0.002694903070300139
0.00104926433736098
0.001017825024034505
-0.0036805054627692176
-0.0011043260278339997
-0.0018080936441812964
0.00019545047542423493
-0.0024227978316979826
-0.001397270072530136
0.0010429908240498918
0.00264058981946148
0.0019947027388583544
0.0024463705579917793
0.005770295318574961
0.008612396691470025
0.02375202286090272
0.013417426517382317
0.004358739401313934
-0.00023618056042890414
0.004177605608836801
0.0012074882369980183
0.004259193816666181
0.0008017600765463553
0.011828569014258019
0.01086616831894644
0.004280030163237219
0.0014005941569605763
0.007152999588647296
0.0050971227929995245
0.0077502262380633145
0.007442919987334336
0.007348602666037222
0.013725803094658361
0.014495519469774492
0.029788901263869096
0.022962540802851407
0.003238517515595495
0.01183616268525163
0.01316686881304666
0.011467404114646577
0.006382174105776858
0.0020139947798337565
0.0062342421005547625
0.012233842804243751
0.024037443894084395
