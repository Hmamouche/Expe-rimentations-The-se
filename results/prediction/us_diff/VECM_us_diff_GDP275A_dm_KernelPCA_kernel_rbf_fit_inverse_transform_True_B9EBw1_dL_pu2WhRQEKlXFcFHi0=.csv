# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP275A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=10, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
8.39756235182278e-05
0.001406501437705474
0.004461749757846273
0.006495038798455616
0.0024316786151816704
0.004825145311043072
0.0056811530451642556
0.0037955437078097745
0.004422752360237798
0.006635429078367043
0.002408750130038645
-0.015045406268031036
-0.0033882866199827335
-0.005230268759697784
0.00562132501410687
0.008221557668866635
0.010166795862158755
0.00445893269528136
0.004567941806820933
0.006323999608678404
0.007505265210453797
0.005864281744400892
0.00786613261250848
0.015870807498785267
0.008434048632769876
0.006349346829687973
0.00889933495284344
0.009231601216865056
0.014657872606688814
0.011478026247755497
0.0070959528099594806
0.007488640932003957
0.002900737499732407
0.00925183266279635
-0.005644202471288503
0.006185055672467414
0.005949303339041623
0.0017809026455543587
0.007874445932941197
-0.0004436793227518234
-0.001615652398832964
-0.0008476428591197469
0.0019579630324193338
0.005500797426855376
0.0007001223559930119
0.003188726068376479
0.005057609478639455
-0.0018388242460696186
0.0028615597360668707
0.0022454880068077084
0.002273088929041852
0.007452897388895301
0.0056538413466676665
0.004340349236251219
0.004681915958402134
0.003903883635148103
-0.00042552541444182304
0.0018551009750385212
-0.002363191846893484
8.745337607894205e-05
-0.0003143952187991555
0.0027460048588140292
0.005570008498919582
0.007241168113910509
0.0077567263404220025
0.009578827168670152
0.007007520946723831
0.008059182667405714
0.009462988480089906
0.006643763608416636
0.003614923961570337
0.0045598827301897675
0.004573948816371456
-0.0013584897242980756
-0.0004662204555128421
0.005567941736455584
0.0021133400400610972
0.006202001842968083
0.0038374531912047276
0.0008187789677696331
0.009751253824940014
-0.0020807309357795878
0.010657208760347153
0.006221033419478284
0.007343713310557323
0.00896056466326075
0.0045279959191303525
0.01075335333844947
0.011536836292021579
0.01062644807422082
0.018296873204855665
0.004237797226969873
0.01049100283164184
0.005807374103695046
0.009236241990870897
-0.007286916952418315
0.011215762377765778
0.018633485396379403
0.012562668087513992
0.020788483345638563
