# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP254
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=4, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.00030379299055218205
0.008583838643407374
0.006929861593343266
0.006893656688622379
0.0002331284212492425
0.006652574314614117
0.0055622114489326906
0.0028867351622680615
0.005459364407718042
0.008484295899953642
0.008411762648093657
0.005521842377489719
0.0011845020441140388
0.00519398658917546
0.007359880956549519
0.005689253222615492
0.0009612707405562419
0.0031753969589043843
0.003963537290682878
0.005599596549324015
0.007106528495905841
0.007236372722587378
0.005671874076992798
0.0012697000860810064
0.005191519058656642
0.006466959425653065
0.005448411167179243
0.0020791435954254913
0.0035751971328392275
0.0009054536034151057
-1.4366700378057881e-06
0.00032986736241449074
0.00020543725143336918
-0.0008095691021927967
0.006260635058024799
-0.0007185167994917842
0.004877337710011229
0.006458350662957451
0.005882503193445996
0.010601754906035933
0.006971155271701135
0.007954298536586527
0.0041446994047788675
0.000618792164210727
0.005881975868949116
0.009671012758154164
0.0050983827827119224
0.00472678143078693
0.0037419284020402117
0.004844553939420633
0.004167542785235137
0.006009806151088132
0.007028910402682231
0.0072418597722917425
0.004379200466266183
0.0038095307558783293
0.0064140307095661014
0.0044228529779450545
0.010803055118050435
0.007405023824951593
0.010835469574178162
0.012355356732312904
0.010691390144372146
0.009846004233215041
0.00868517657742773
0.012295365191280726
0.009995003970245154
0.012321605637638193
0.007658870376563069
0.009373832626386858
0.010672277629181827
0.005151522481413724
0.0024695226906798397
0.0034565182835347296
0.008299629491052401
0.009914342960708943
0.008902032381108937
0.004056890571452006
0.004990770012330437
0.00995070522921285
0.010468001140036085
0.01376638443243514
0.010144040115053828
0.00879124764098405
0.008666092270087536
0.009444904014296727
0.011146174984534197
0.010742217619978851
0.010725202802163877
0.010935608412735975
0.013056461667096626
0.008634664023837278
0.010059438885655084
0.00877085089495908
0.010357980707357321
0.009624553768361773
0.008564419747857814
0.004897896058319287
0.0035059605170017155
0.003456928318549732
