# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; PCEPILFE
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=8, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.008774299313535681
0.00802485191370653
0.006427795980009928
0.007734119586389976
0.006463212063058501
0.004800625439265073
0.008776766680753938
0.00669359901753223
0.006168394798517599
0.006273647031968044
0.007251961295917762
0.007500404892595322
0.006633014386431456
0.007797357658174346
0.006360671810331248
0.006552797930701731
0.008952233426664421
0.007033127479002994
0.008944436570688325
0.007936204627267034
0.009345338500882134
0.009022295033669327
0.00922005361732426
0.007455424359665996
0.005258586564051879
0.0064828672897660165
0.0080684511751313
0.011604837380003764
0.008776297879372572
0.007769665997291708
0.008690628458746073
0.005833942162107763
0.008356039213821179
0.00828852402953736
0.008533902290595634
0.006307025027991407
0.006074473852936983
0.006079782883957292
0.007620483022601663
0.005262958872612622
0.007214974646197553
0.0037382423148594585
0.004829602327948188
0.005910221962608268
0.007474705423226627
0.005479446397185412
0.0066229030595185475
0.0041763878704254445
0.006322384348048517
0.005483522701212467
0.0029813434400107804
0.00417079654018405
0.003566527979348356
0.0033607994065790593
0.004869177971660863
0.004760292289000518
0.0024983464958675296
0.003308109667564577
0.0030694415323868486
0.002013999103663362
0.003440516337703289
0.0029771975222371693
0.003651688091752229
0.004023940226237298
0.0036268317027287043
0.005283845986013757
0.005577245308019545
0.005188779520679164
0.00229197444893047
0.004710503964719274
0.005787138232340138
0.0043396743125174615
0.004912800982886121
0.004770740749080753
0.005704781285191141
0.004426153109038069
0.0030020794012232607
0.004840566473238235
0.0037145614892064873
0.0031484021656026854
0.0049767777815392005
0.004761659226730688
0.006667104585305628
0.005403977024788254
0.005297053458816578
0.005919196489931768
0.007172297294813856
0.0065251198521068
0.004766875011190842
0.007025596010216016
0.0060485338905581516
0.007513009139720436
0.007091786519659683
0.005983163005570658
0.006978862584055281
0.006068303380941382
0.006655010598308046
0.0059589429892608166
0.007066571103644539
0.006359503766978809
