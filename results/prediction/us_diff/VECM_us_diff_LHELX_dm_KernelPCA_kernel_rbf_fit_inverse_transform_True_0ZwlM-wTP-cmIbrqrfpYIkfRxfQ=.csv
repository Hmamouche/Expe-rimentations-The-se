# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; LHELX
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=13, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.15995777633223252
-0.02440929595650458
0.026749656945440254
-0.0007384724047556912
-0.022734028443491594
0.03939875114708562
-0.005680365454009198
0.03864640886104038
0.011987496204969122
0.048596357422095574
0.06715271432397457
0.010392969713614655
-0.04036710136312288
-0.03236081730406859
0.02245240032435019
0.01984549360609
0.03697864819104622
0.008114480612448642
0.020866588984615436
-0.006184350648089566
0.02872093909601477
0.08736423154248574
-0.062188113247151136
-0.042202436727191574
0.010149197834844014
-0.008989625475000748
-0.02443940825874478
-0.04177849958922827
-0.05905572274769604
-0.07501982110795472
-0.08763983051159191
0.023237228599950744
-0.005805652863685999
0.0036374520468340915
0.03483664670653166
-0.021499773988298842
-0.05656636852400551
0.0226374451804746
0.029440350455040797
-0.01620486272226921
0.06730568954099225
0.019786387226842336
0.033562230547857536
-0.015774298724948364
0.050701397004776924
0.026349215202421273
0.0031211693493230913
-0.01102334805126973
0.011537227901214996
0.0012298964784736742
-0.021900412200554976
-0.0061339535745959135
0.016501537881321658
-0.01349428765218805
0.058977157430284706
-0.001505522179848711
0.031142086306520635
0.003527565725934009
0.03650957869889752
0.011351213884312802
-0.019253556771751595
-0.012997196653066994
0.03397209117348443
-0.026542770355860106
0.017013247902584315
0.02785463834740685
-0.011077411942927879
-0.0063205144150274405
-0.027449918763855465
-0.013000720568928734
-0.055961325271314255
-0.05620806871079197
-0.10486995465583772
-0.04627093326773884
0.041235725637706465
-0.02876110515503611
-0.0155074647053664
0.006614016722031291
-0.06180569858820399
-0.023942630321133966
0.03329944059977811
0.028144322547574763
-0.01021692678820128
-0.05646492480168651
0.014218645401747826
-0.008281993135884754
-0.008536984531977201
0.001422002375507287
0.006070583433848378
-0.010398553355648307
0.01648871057338483
-0.02548265802300439
-0.025493170014532288
0.018663215739728796
0.002334634102406051
0.0009834479464175799
-0.009616257442202167
-0.05639809982114526
-0.009530613443150268
-0.016981468586017578
