# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; PMNV
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=9, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.24207086529598504
0.010263919930038223
0.007404436862707156
-0.2728254548434553
-0.2494139410089277
0.056886851150963196
-0.031010310939706992
0.07092668725235202
0.07677801534909724
-0.014709204288474588
0.06659576871072051
0.02632783046696427
-0.0023588453378171233
-0.044059627282581344
0.11147794087523019
0.007765821281647323
0.1103442001209072
-0.00020703094574112124
-0.10453927408741431
0.0985664719466069
-0.12481049054582166
0.07858881417650304
-0.10585376637109127
-0.08439281852562716
-0.029854706961063814
-0.06366082403086704
0.0040992910704114455
0.1265138298174582
0.06030966262660718
-0.1543385973972185
-0.006268690197577531
-0.10689905013804545
0.029527451095880577
0.17858170145009106
0.1505878721011727
-0.016494465495610053
0.019558044104272962
-0.052383527041618166
0.008473133903518237
-0.08409671018279666
0.016395492395541195
0.08515092918284942
0.09643096412188701
0.08320095423822263
0.06294254915773968
-0.011064208265453616
-0.09028200435088751
-0.012337650999875202
-0.15207589578347475
-0.09899654828879312
-0.035889085258632665
0.014212079553637047
-0.003162105644177071
0.0686205910268304
0.06834638300073016
-0.004264607766095718
0.044979314016118585
-0.03880185403545832
-0.026906016113827414
-0.07070631983861679
-0.07541177607463681
-0.09239321792957826
0.11551156511379232
0.035415931590124024
0.0897088861660975
0.11067708103296672
-0.04592110466672285
-0.06689247094022824
-0.043519210414619855
-0.08433780993027735
-0.01747189103351378
-0.07370671109716175
0.003769504581956285
-0.05861361797629179
0.1728322224321684
0.05542905762049721
-0.07288526699113088
0.05034961088799742
-0.07312055216433538
0.04447729461268647
0.01630247078499634
0.09360566787691339
0.20426049408462357
-0.012976601317601769
-0.0031409665401694615
-0.07477493141535062
-0.07974827580297712
-0.06492408714492538
0.05219818633573671
0.030236593867432687
0.11036480138151178
-0.03647754639631607
-0.04665104345830449
-0.06062379703365258
-0.00971531123653998
0.040604747868418674
0.027937062488699538
0.018952613209229304
-0.07076788472489273
0.04674199902962482
