# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP282A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=11, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0017975230690400528
0.0069772055386532195
0.004543125513086198
3.138725803961108e-05
0.0031816501058483547
0.005561095270016789
0.0017660052388421173
0.006084635361658392
0.0053690924722116055
0.002865754479516568
0.0037148133716839154
0.0037568936801866248
0.006106171595657083
0.006270376919652108
0.006741762399060969
0.005753089752425902
0.004610942633815873
0.005186386951505829
0.006975029206536186
0.006706989341497673
0.004194733872814453
0.0072075319844608025
0.005862893123564953
0.005106651962559298
0.004075768271718893
0.004764710786393142
0.00352981935361703
0.0036711769539224766
0.0029594525714373063
0.0025661457339700364
-3.777888388979396e-05
0.003428478816582436
0.0014204078372936036
0.001499802171097482
0.0006449152004510234
0.0016922454776694064
0.0022298366521537115
0.0016674346236968426
0.007155978794349733
0.0049362907522670415
0.006510502157465038
0.008389127924881456
0.006607842566274946
0.0031375580566531773
0.006829808007132687
0.006809303450480923
0.00998083005390401
0.00929749098175085
0.00381502851841449
0.005013589117264209
0.0034105002653768202
0.0008952256194123588
0.004791006616410201
0.006298164971043336
0.0030275075634392376
0.003887844039266475
0.006203883529867135
0.0047133185977749625
0.00404210848987879
0.004508214113235062
0.005293356089904596
0.006144528533366407
0.007320449382692866
0.007063272790671571
0.006685469246357954
0.007506081166303323
0.009667774223018104
0.009383073825561323
0.008008117032546211
0.006390132130717516
0.00846982418975477
0.011875937940890993
0.011873966054724232
0.008662420709983163
0.003696825217217675
0.005265147114389234
0.004455192975577789
0.01027637737424971
0.012360662289859962
0.005197396765897074
0.005153621582876517
0.013948959211597316
0.008992326220811751
0.012356951953260113
0.02051681490439019
0.017882025725028054
0.014265584947538119
0.019508353008520034
0.022593325823011417
0.017281298850551137
0.017019776878737163
0.016155027665932097
0.014090090299415882
0.014735307833715605
0.008917564282378842
0.0016285272523603699
0.0066594760838051565
0.000361482991634006
-0.004915409832312725
-0.0072899645621788646
