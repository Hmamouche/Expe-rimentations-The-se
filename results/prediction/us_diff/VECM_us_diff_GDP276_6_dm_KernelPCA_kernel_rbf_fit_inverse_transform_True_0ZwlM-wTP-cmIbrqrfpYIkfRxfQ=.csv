# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP276_6
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=13, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.008326017642751565
0.009652266451987725
0.01023262281325984
0.006297190273632647
0.005778600292188055
0.0059381125149271345
0.003561016095969157
0.005317970599346193
0.00494179277089116
0.003988919209174794
0.0027613138892237654
0.0025176946451812765
0.0033475476128221977
0.0063643978994793945
0.0037262549123348956
0.006436626699956923
0.007902207810541054
0.0058845728193944995
0.007945983190220537
0.008679588312426269
0.008932342273475249
0.012560928557403811
0.011972948739596227
0.0076544056330129315
0.011104295476120955
0.009538712751468496
0.010519882255767676
0.010660583454386193
0.010380827528465749
0.00978125884148488
0.00780379987487088
0.008311856677322673
0.009187835281580849
0.007996231990438476
0.006708891562970201
0.008811592521768111
0.008704129488698526
0.0070108763103547975
0.009105021305743356
0.00697964453900145
0.00656199606313922
0.006743689978985855
0.007985845848016905
0.007581020876589494
0.006994904068445949
0.0076878989204566305
0.007190853795101697
0.0055627264991991564
0.00435828904106438
0.00614546545797101
0.002747586877697011
0.007404251638863944
0.004733279430593589
0.006526182702952884
0.0036578515668880315
0.005155664036079481
0.004460497801650852
0.003490215028327426
0.004079514221761123
0.005114274728793075
0.004826584184756876
0.0045286128191668685
0.004498639540080162
0.004694004839143374
0.0054508513914484505
0.006847395213465554
0.0051708138484045756
0.005198001162144552
0.006387470873832017
0.005335023931294059
0.009257106929904906
0.006965759146108621
0.008177279150865436
0.0049102632746331944
0.004848569696865271
0.005856981038987962
0.004983133186252271
0.00595969236806849
0.007353925158049914
0.009830197309905274
0.009152114992073761
0.011169351996617763
0.011202488373423525
0.009053498207950601
0.009070563413197851
0.0070725326878888104
0.00997062592754745
0.007151363834411286
0.008116956709771526
0.008489639403614729
0.005832744595458843
0.007459125538173032
0.0077983563937064695
0.008418714483300158
0.011128739867223063
0.008123647119408654
0.010223954325067473
0.0045627403766363124
0.006296185332551352
0.005270645310584512
