# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP276_4
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=2, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.011787398445094334
0.004594021491793792
0.013074538482792445
0.009126778456467267
0.007744761455088284
0.01012915073877449
0.00494711187674211
0.00875865818660591
0.009289571479374743
0.010166576618272857
0.01035943369168098
0.010281855422478153
0.005161021182679902
0.0028505390695746594
-0.00025707532379851963
0.0027114413798217463
0.0016270525177085825
0.0013066570538190782
0.00046211887226752717
0.004478119070878493
0.006215159253385029
0.004392585794131457
0.007298200017194518
0.0031761282430791456
0.004354114071330335
0.0028734972033785814
0.004730747375274562
0.006277289990908508
0.003447502327140902
0.004631961537989013
0.009699897869486584
0.008894661635975049
0.011412592117626793
0.010975191266411895
0.006079658991635805
0.006519327986764378
0.0038138607624838574
0.00362880583366622
0.006359818861418535
0.004918765665742217
0.005672979483347286
0.00709821545989645
0.006953954484417338
0.005454496331437164
0.004860949865195195
0.0034962760948540504
0.007468293766485851
0.004545898622809225
0.0027702088894138773
0.005657920113614689
0.0021270572054543874
0.0049809731224116065
0.006269257185343225
0.003918215613035339
0.004829368279246339
0.003645489468064072
0.0018124465730386362
0.0006245666699483746
0.0010348235842871569
0.0020880242282971233
0.0016351691326904425
0.0016873342619980133
0.001989534772215069
-0.00011869109948815489
-0.0011134041985695524
0.0009989380371849775
0.0002238053816693137
-0.0012514233926215806
-0.001160080477784181
-0.0006036921170178451
0.0016891689272949518
0.0015917146039236794
0.004518822880473285
0.004498274703802217
0.0032197126763613953
0.0058457058609848594
0.007361802234241177
0.008234663061619832
0.005515218350067
0.006302018360874169
-5.471285610916007e-05
0.004196564137540631
0.0008731910736351513
0.0017892594225926233
0.0026296122037230193
0.0019099043423227093
0.002964339399086509
0.007278601136786192
0.002845189151891913
0.00725952217771832
0.008180612196025845
0.0061912278603243436
0.007367043259624698
0.009429687787372786
0.008388188931993883
0.008865765361306831
0.011014014710687666
0.00717602443869317
0.008026281934405678
0.01072205529835411
