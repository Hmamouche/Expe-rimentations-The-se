# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP267
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=4, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0039287550080182535
0.0010792932542380866
0.0007020961669750496
0.0032442237766989717
0.009709358788466124
0.005958785875490629
0.009522361176578526
0.010343060330814112
0.01275670248257479
0.01210100069995996
0.012650037492972091
0.009788941041985619
0.011105257271967093
0.01412666895668168
0.010227675351906398
0.0010558256174970206
0.001645402184067963
0.0026541239659315236
0.0061331992114441
0.005874160276437053
0.008353501277178176
0.006101461029628625
0.008158763510517664
0.006566462532030897
0.007995606847342783
0.00963744250722198
0.010131798304046962
0.006401633340870068
0.007155418396967402
0.013371563273021237
0.0052376847689687474
0.0030638711345712293
0.006545371878110805
0.002019844284950667
0.006031517368435973
0.005472851508570044
0.003606734093778638
0.004032024147275472
0.005052881610336181
0.0033794706333018535
0.0030060189844954006
0.002416292064485146
0.002337002186512201
0.007810986905865692
0.009954271827663605
0.0031091269014838652
0.008718453724106161
0.007543651175516768
0.005462612926725104
0.006314473538467991
0.0007564186752328666
0.0074292198086684125
0.008970716357304112
0.00602463295346472
0.00971807348720016
0.009699209368513446
0.0070700148615125795
0.007008280715830302
0.005385553596063605
0.008107126432107873
0.015034997883907017
0.010207059741274853
0.012086859159146509
0.01479382978036706
0.014212961765680779
0.01165938484442529
0.010664134357474611
0.00568514475065924
0.006293959201631441
0.008748294065279112
0.008275252729789493
0.010238010066249154
0.005623629140855055
0.010490085352420474
0.016542964193966742
0.012376071236873266
0.004782724527265037
0.008752298388433662
0.0049350866452408364
-0.0002946434493237447
0.0016259515105630346
0.0020482892496358866
-0.004418914205100066
-0.0009692454358719477
0.002315942450762468
-0.003569338253251903
-0.0009471612135876367
0.0012230454405574849
-0.002062979864240732
0.002930026474063047
0.0016405162886782003
0.0034226265258173053
0.005550231385073182
0.006121100975140396
0.006046900473551972
0.007059131251534803
0.007724666641859121
0.00624554908116091
0.006404014817170248
0.004981853721226388
