# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; FYGT10
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=7, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.09599297510917106
0.1255486305647227
0.10135167911879886
-0.03400976008722609
-0.0014331990756483986
-0.08053066731473696
-0.05593209899217226
-0.06342054279015494
-0.014534894530122609
-0.04656922567001295
-0.05407828371049682
-0.02005778611663089
-0.07485824677943856
-0.011177523958728588
-0.044524203550943664
-0.008609648517247468
0.08137682235365337
0.05412250093431635
0.05137141524005349
-0.05777376055867344
0.025786325333393756
0.07712942886318613
0.006196525941609667
-0.02059275897826094
-0.03324208651791467
-0.01996188171299941
-0.006634700785440026
0.006185126597369417
-0.03933781574169086
-0.04821076062958776
-0.004142191812903883
-0.06336933657185853
0.04466166184420272
0.049257007934978156
-0.002701817748230917
-0.022648193378884136
-0.06670641501177522
-0.001052730415297555
-0.04943917771472977
-0.06719784868002135
0.008681033343921628
0.000778889396163291
0.035015771147210335
0.0585931080803292
0.054719175627110796
0.07165675538878999
-0.0051479655746896604
-0.026653815543891485
-0.004365773282734985
-0.026755990908194825
-0.01873389384691526
0.00963565656807508
0.007630240364747135
-0.0034316866220327775
-0.006973024646782622
0.01910977842442285
0.03591308258857955
-0.016575951247773318
-0.005792227076333311
-0.044790198120092564
-0.009738341932775304
-0.04515332108420776
0.014891233832509716
-0.019197684336995653
0.011925784038416341
0.0585327966090732
0.02284829776142193
-0.016994234797905745
-0.011784592296471592
-0.02343104206170032
-0.015175612060569752
-0.0006051379911760097
-0.020018312957792203
-0.06516916941986392
0.010887335237372163
-0.011433646309070431
-0.037332471321984306
-0.01860701229081202
-0.05249798956445627
-0.0030665126433271524
0.05765317106802601
0.03076610341328716
0.07075216565979778
-0.0146370628602759
-0.04030739247066719
0.012222931352709668
-0.005998887208644398
-0.01313327069456041
0.003548297030274568
0.02529725962501963
0.04696437958365593
0.008187514492763667
0.01214256181802422
0.00145178995475196
-0.02172038884185673
0.02739633639802634
0.0364850338140395
-0.07143981493603958
-0.05695161400357203
-0.015690426570152335
