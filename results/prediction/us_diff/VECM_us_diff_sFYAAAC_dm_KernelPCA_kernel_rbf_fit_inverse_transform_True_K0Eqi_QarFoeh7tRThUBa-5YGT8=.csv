# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; sFYAAAC
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=6, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.27197523862360445
-0.08132353530290952
-0.14335018991819026
-0.09644930136928517
-0.052748519328346385
0.0401391060023595
-0.030841926911968076
0.08789807346765358
0.06572018815379556
0.028488601789813967
0.08678287663072043
0.061159370185776496
0.09650638614570214
0.05342863538298583
0.023143835552333354
-0.01749643335001723
-0.029036807286931733
0.009657875567846672
-0.04641751745335972
-0.09609209296856044
-0.027666651249418816
-0.0772942472922273
-0.1074698112624411
0.031762055202056196
0.06705545425218987
-0.007825649488002621
-0.007146245205254802
0.039534589229794796
0.062338485091426143
0.077129664007446
0.07222520875466573
0.02247303528097538
-0.19009058090034936
-0.07528868903799829
0.035446089132106916
0.03819460048220777
0.15255623052444242
-0.006455148205291909
0.041449285251330216
0.0214217514634603
-0.06510945533250159
0.0005017865545623515
0.008463242802188697
-0.039346420072239305
-0.07761096550236417
-0.03387088988589923
-0.008408699892395573
-0.01897474365674109
-0.013740386312769519
0.043890084157588855
0.01875164949600354
-0.028024867659703436
0.005869110142493257
-0.021733445682459572
-0.03541959019749664
-0.009065146971172083
-0.01747023215205587
-0.03035191630057895
0.017408233723209585
0.068080102881059
0.04285696960173012
0.09089993834534513
0.002584902939789295
0.041014875421374546
0.03776248875599089
-0.021155678992759334
-0.02768107598686483
0.05725048622154692
0.04488278474196701
0.001253380049099315
0.049341380607269364
0.04550880541123195
0.07099641626735752
0.03537938389605787
-0.14476013686848258
-0.03145950421689685
0.07924548079402971
0.08718224426740132
0.05347468190478112
-0.10081424243719213
-0.04762937181629247
-0.044751083772756384
-0.07040437715650757
-0.026153790623799578
0.004925514792526439
-0.006723750930196148
-0.08167121663123392
-0.025041265317675376
-0.02445311984863696
-0.028889953259611436
-0.03689277681022364
0.02008275458367371
-0.02460443068244649
-0.007153622944755616
-0.015708678427236566
-0.05867233949321231
0.044195619525066836
0.1265339677267036
0.09537662320589717
0.025393054277224384
