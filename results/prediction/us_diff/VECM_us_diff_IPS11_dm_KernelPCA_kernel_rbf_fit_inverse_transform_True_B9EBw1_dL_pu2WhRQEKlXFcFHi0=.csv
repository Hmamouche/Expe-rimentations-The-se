# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; IPS11
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=10, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.009850806358881244
0.0029275224379008663
0.013365789729320763
-9.89411754469191e-05
0.003637886133903433
0.0026420282083014553
0.01723143676901583
0.007176888205255171
0.0067481213952185915
0.0014996889119634625
0.009512394025114793
-9.50253513333772e-05
0.0022204425763061317
0.0035369662990684036
0.012136813596963416
0.012176668542816139
0.00933071493979473
0.005464485153637949
0.01080705599225681
0.012459160990692726
0.011882982459275538
0.007746111383899653
-0.005987081405464778
0.005576034000141187
-0.0060775431278207665
0.002509397286474687
0.003150122319979707
0.005753323064521131
0.0056550039113225205
-0.007119303232380439
-0.0016773142581838559
0.003473519378684303
0.007349631216507172
-0.0010504827858147624
-0.0008171332717423025
0.005147400620687052
-0.0026369581518224405
0.015912836414584193
0.013635846842026903
0.0017399222970762816
0.006920726845256687
0.01218893624052795
0.012362837842295903
0.011389927198122443
0.006873136102577645
0.007356562988825735
0.0005857722041051885
0.0012256359640089138
0.0012766978957031248
0.002987263422057688
0.008101835889403466
0.020243293924987
0.01257552330284498
0.019812138145421643
0.010737316385641908
0.010208474705871013
0.01710516682455019
0.014380542026354517
0.01448611110775489
0.021129098570720088
0.009938298171570712
0.004832289967428948
0.017147528476486734
0.00969044321206401
0.01497363190849119
0.013957414610430364
0.0011410277757841394
0.006847866647822373
0.007047005580495284
0.0006345445559406047
-0.00048403614417272603
-0.004353056215224149
-0.017503489323932857
-0.017653177580097323
0.009127948532814772
0.0069549498079572525
0.0004608107887018554
-0.0007362317480895742
-0.006622714732388357
0.010229789686735064
0.005873762649864439
0.014456187624841105
0.0005579105072058932
0.002531140148700402
0.003856387074775233
0.0016456878947077214
0.0015417774398219283
0.009942416362026628
0.01709976595733528
0.010106276314533666
0.012590181707674588
0.003935458110464811
0.004210358667411834
0.003242271505230604
0.0131431874275847
-0.003352281108275395
0.0004158601976131822
-0.009844943833614884
-0.006151136811808738
-0.0028319060126135833
