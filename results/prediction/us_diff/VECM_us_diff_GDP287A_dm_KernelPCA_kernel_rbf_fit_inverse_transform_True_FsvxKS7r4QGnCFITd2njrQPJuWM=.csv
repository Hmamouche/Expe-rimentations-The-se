# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP287A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=2, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.006731947164696939
0.001713266362755074
0.006633377436524356
0.00910679445740423
0.007218636995864458
0.017657260256264292
0.007041356600568649
0.003895624043376706
0.0019939782225633406
0.0032748244507577427
-0.0007946140717367988
0.0011155900703555502
0.00412030660234127
-0.0012681587234167331
-0.0005799045756784245
0.0008738617631189221
0.0028424228320074294
0.004202122791390732
0.0023095995601438704
0.002229666631841432
0.001923357967316867
0.00506194818289184
0.004557263756334869
0.0022797928381894754
0.003606196558985074
0.00676987437105259
0.002168150360805821
0.004104710639611651
0.002315963043060543
0.007066870289466463
0.005429743070611936
0.005655624171449785
0.009605798113683572
0.007881660813320167
0.003759188298536342
0.005000877418115492
0.005486720965412767
0.006466599749548185
0.002766624203104592
0.0034190718319955975
0.002064587877066146
0.006057045113339801
0.0059439619497289615
0.007744185755919496
0.005822873013138554
0.005016163456489299
0.006721423482183028
0.0031425656479984977
0.005016785488533996
0.0056494308336205055
0.0040825038519660085
0.005571407908283902
0.010504636406450074
0.00732334430412753
-0.0014197197121671638
0.0030929148099000272
0.005512936362796145
0.005607963467183166
0.002228477249451122
0.0020648014066979225
0.0033520473621484158
0.0019964342317359525
0.0014526633945783623
0.0019202450305812757
0.004198226729764329
0.008357982945887252
0.006086633952943441
0.006203258868325958
0.00707389131828123
0.009766989969259612
0.001605003152237404
0.007069114082535717
0.004069518190325654
0.0034478861509588724
0.0035181224844950745
0.0048029921710417405
0.007583878724147718
0.013184442127451693
0.0029102360884413125
0.00448293468370488
0.012132812356127582
0.01662725738770124
0.006768981595508018
0.005461248193535579
0.007014196143112322
0.01989256168168693
0.013632564204068954
0.007900907921304963
0.009167202744835616
0.02144978168992574
0.006448050861088683
0.009633882800711277
0.006281970824187207
0.020166616956422606
0.010814417600774468
0.004132646216262737
0.005177123217806872
0.017550818924226327
0.01043931312390971
0.0032139768633220253
