# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; IPS43
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=9, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.009037242590702758
0.009230090885763554
0.015762756939548272
-0.00581951106800444
-0.0009237332918154548
-0.0022291200483006706
0.012920520839620893
0.007209010495419544
0.008369090895162867
0.0030921784185404147
0.010552422640901518
-0.004375825450861567
-0.00401440981701927
0.0037109457273146237
0.011287583538442756
0.013921317777411357
0.010608577950010136
0.004648001525016752
0.01262398960753958
0.014334405262037397
0.011480879827393754
0.013889519843476202
-0.005560110100179769
-0.0016032229826065784
-0.008810994639396039
0.0005366051406400715
0.0016824026032011786
0.002944723798094952
0.0037168079871882902
-0.012499449996939312
-0.0014378292060016112
0.0046679140095404765
0.004973610156906914
0.0013334554967680025
-0.00016854364200665525
0.008282647651562657
-0.0012625062444828912
0.014861523873541891
0.014334157840239685
-1.285963613307595e-05
0.013700057404387074
0.012587306508285975
0.013663533790920616
0.011088924415604214
0.01028540602238932
0.012479481073057777
0.011695769962381378
0.0033071925380170663
0.005567625720008926
0.0009722294967695103
0.00391932352093123
0.019927673023851893
0.015272214637653932
0.019317009029746084
0.021204386257170513
0.013813898356189949
0.02401248873066683
0.017999531300214065
0.01775105633117825
0.017593526143497903
0.007036024362722848
0.009919461662250835
0.018674224738048403
0.014295667281036347
0.02399863848337061
0.021204903648754634
0.012584723111588106
0.006940261083603411
0.005604686910305554
0.003476322617926778
-0.010326097049105377
-0.006963191125607912
-0.020031728390188536
-0.020617766219744482
0.020260513903023247
0.007396214294670264
0.0030495939805211024
-0.006252218277762343
-0.0021537172076514736
0.009691178201318124
0.009059320543295241
0.010816839866122158
0.005690090294881775
0.007308753840095689
0.0013497604450211555
0.003874657182427105
0.005004871004091124
0.00530393778436958
0.012798484624145437
0.01231888646827241
0.014763096502236665
-0.00039248536850467706
0.003340854944927243
0.00076573090585896
0.017127082646315777
-0.001194911728578366
0.004713897509073845
-0.006562474774647711
-0.006824791201249145
-0.00046869146242027506
