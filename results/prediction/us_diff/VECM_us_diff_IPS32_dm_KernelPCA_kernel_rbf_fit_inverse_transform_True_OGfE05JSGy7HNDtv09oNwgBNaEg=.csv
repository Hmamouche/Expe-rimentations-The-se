# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; IPS32
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=7, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0024257929324677293
0.012161523268650776
0.014181403847107319
0.0043608542204461535
0.00020603337649793916
0.007171277008216372
0.006621955698639576
-0.0027334973174088376
0.002813356384595997
-0.002164278118901069
0.008367115302076162
0.0012497839759117928
-0.011156567597199041
-0.009818444385329951
0.0012235167420860606
0.012238798633561115
0.014191314993230179
0.01036225215737485
0.007694428631272669
0.01560724054128117
0.010162658198759496
0.02414515149671087
-0.0026721127856881733
-0.003623064403865279
-0.011084816069951686
0.0008245353934386544
-0.0014694423064464078
0.007128055367279306
-0.008307417259522406
-0.014943510464837367
0.00172060877496388
-0.0027927115127686047
0.007653896428848941
0.00899738744198153
0.008734179884343541
0.004831480965494876
-0.0028059586642117055
0.009109308217043272
0.008843594785027638
-0.005065561665647932
0.01443190069958332
0.012506530317166885
0.015262207596015098
0.013959262562662026
0.012053454496379363
0.014576665842917724
0.011898635805008852
-0.0022888953573604173
0.011265468495931774
0.009166023656799149
0.007011167384945611
0.01667622478303535
0.01632730249458477
0.0172442293085588
0.01590774166599332
0.019458864886052078
0.02425537866170405
0.01914610732523342
0.01929606761618756
0.014187220695467587
0.005744165536731658
0.009799378347630052
0.017384391390134327
0.01057539271201404
0.020738221158068663
0.028801532436333654
0.016394135685166837
0.013869711073851508
0.00550927455716849
0.002253236869900124
-0.010039057779002932
-0.007909274422357837
-0.015772633007748588
-0.028254333097845894
0.01511539899248741
0.007202426216097185
0.002580900084399797
0.0032664843676308685
-0.005487840417532571
0.006591853618580061
0.013308354691148003
0.016234641926806705
0.01376939825729254
0.003826082204160139
-0.00023762964276542037
0.009380657210351763
0.007782383127763627
0.005228681456732571
0.0007215716384105222
0.0012007347909851508
0.02145680355192752
-0.005920546372721654
0.00043259542676154345
0.0068414945269748804
0.010507398946724035
0.003837937570942099
0.01583950611051101
-0.001074156783535247
-0.006404090131507011
-0.0003309321886778649
