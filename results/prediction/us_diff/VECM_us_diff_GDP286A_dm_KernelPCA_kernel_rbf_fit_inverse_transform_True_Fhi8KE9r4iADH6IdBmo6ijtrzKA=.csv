# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP286A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=12, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.008112387476593872
0.0017205045381102268
0.007058501069762708
0.01004277574498109
0.006322802920294551
0.0032600850498185644
0.004698230562647563
0.0030463736198122373
0.004000238772403892
0.006058928067780051
0.0005330839087968717
-0.0015022774372036789
0.005686019356745746
0.003011272039536746
0.0038477325513831292
0.006204759717067276
0.004457485985963811
0.0043861949213893385
0.0030828851934292436
0.0021566057030273783
0.001948850506228505
0.005029346718815567
0.0031428803196003165
0.0025875964514620806
0.003978364473918087
0.006447563438658211
0.004722058324855921
0.0033956268964834735
0.008311001121132415
0.008532489835256129
0.003705139950261128
0.00893017730687326
0.0076322751215715245
0.0011516669818354014
0.001795127961873626
0.006079143995311329
0.0024088007676863555
0.0038748553130627224
0.006667727584952503
0.003810466353180566
0.007236765048680958
0.004634495962660232
0.002530048461666722
0.005861928588660834
0.007087454555153898
0.00278462684356696
0.004851825087941375
0.0032376591705774657
0.005858719395332539
0.006179203408545835
0.003951672783683999
0.0036434565733184446
0.0036164705380057286
0.004258740843723539
-0.00024171462897327653
0.004065639590863647
0.004199287371859761
0.003807610129523729
-5.0038212122960985e-05
0.004203130624364263
0.002852482054268121
0.005614062980428128
0.001970623439636065
0.0015227161930383398
0.007596034237587357
0.009497587090914937
0.008001896512252167
0.006034901310310772
0.007582681548743375
0.009315752471278608
0.005030474301883218
0.008078760524682206
0.0052084669262821015
0.003275800166500288
0.006344827441655936
0.0037649368009329697
0.006545765241026629
0.009690170538547612
0.007406839253567614
0.006400102351574818
0.01018898820349128
0.012906811503811424
0.001562296566990576
0.011085263844446629
0.011081225374009237
0.01185227339444983
0.010749748915900843
0.013190987454115182
0.014750591042462348
0.015010677918556852
0.010099385699884236
0.015914217208562044
0.008837380306845706
0.010459165231340571
0.011701244765963346
0.00788389320134416
0.01352775415957339
0.014500397549729342
0.011737551551450636
0.012076187274446653
