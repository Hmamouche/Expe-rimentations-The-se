# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CES011
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=15, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.02355927588797651
0.04074482108630992
-0.0006333201404357201
-0.008998928742057363
0.02072912189382555
0.013966087026265424
0.034049017224796446
0.00034732507725710945
0.009704326591991922
0.032457297201336305
0.019311049328393302
0.016051040529810878
-0.012207186045266277
0.016538283798756714
-0.022856333594829022
0.02695510337718776
0.025121681605294748
-0.0013274767870390244
0.010940963634789552
-0.022999672228104756
0.02103894590567444
0.01585785508919782
0.014894650789748436
0.012403501586942485
-0.005496384339310045
0.0006050426303166423
0.018932235863984095
-0.011810999464023409
-0.022380275095347357
-0.032425059239782096
-0.011728652248075662
-0.0163054504795588
-0.016026482680312534
-0.0246190534158017
-0.020191769001523766
-0.0016729076781133905
-0.00831978310411946
0.012659208253095454
0.0005001459937692011
-0.007245974380722454
0.025193589286307355
0.012713094502319557
0.014523734465486509
0.011177822823678452
0.016662820406003753
0.010065190808289555
0.025976443005849937
0.0012583325116533564
0.010804952631126866
0.012843660798326871
0.015214401335629237
0.005887003390069196
0.005917646813307002
0.025543498892437125
0.020814388310533557
0.00484262027494021
0.023097509163904753
0.016727693445033418
0.011911763117555598
0.0197731427788898
0.019129252153442484
0.017594116726221784
0.023378528355128103
0.017906802285521408
0.01741515027226906
0.009369411749747744
0.019740228634507282
0.009751183078163334
0.004415314217420869
0.008951285393539038
0.0018789937244186694
0.01072632120766384
-0.016289989355490836
-0.00806638197856967
0.001580210495390675
-0.008761151573345644
-0.00021263039494924963
-0.00656283714795465
-0.010762646777143125
0.0032645738472059805
0.013925936424412012
0.0068053771784677775
0.027919365872501233
0.013030537063860283
-0.005662335660399777
0.01627665655191911
0.017911260006852257
0.024049573328793854
0.02387256302202034
0.02006605811028385
0.02823590338019934
0.008074272276593462
0.01218731601176201
0.01047428468804058
0.001135296958912885
-0.00403368116511907
-0.013267508252234637
-0.02181500262041331
-0.016813777987428516
-0.037798034974366845
