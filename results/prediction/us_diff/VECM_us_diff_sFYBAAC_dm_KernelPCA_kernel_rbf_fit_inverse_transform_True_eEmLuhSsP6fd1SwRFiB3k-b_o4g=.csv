# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; sFYBAAC
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=4, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.003776990932820981
-0.008977358783170448
-0.028915844234919295
-0.006702043681043775
0.02994379437569731
-0.022385972340469417
-0.08442950261289899
0.034320096386080454
0.0480399625246736
-0.011283463236098901
-0.008533383727906053
-0.015120772588505983
0.09949734165696668
0.09624206114094709
0.0037409805551728873
-0.012217746173682754
-0.049064027496030435
0.025096474985087405
-0.06761694796090949
-0.006068547154494344
-0.033448919207502974
-0.06664909599135183
-0.03122468507607649
-0.010435501523886196
-0.0018750338982171928
0.013875020183295991
0.020976432508027096
0.029172585329939674
0.032187225134929456
0.05094539710304732
-0.02789665596966705
-0.04366146351405235
-0.020430446435007653
-0.01074942477448101
-0.03597785259018249
0.021915161919496603
0.043068186093982365
0.008815892712375727
0.006972873682523379
0.03878912132083854
-0.02230156677287273
-0.03644881236979499
-0.010350297252037153
0.014782795009213841
-0.02905110275543011
-0.01791183260607748
-0.027977288896162945
-0.04239120899811756
0.0009141844582884876
0.014557410787839373
0.02221625868874419
0.03726793823346075
-0.012221140139414879
-0.02473743102667727
-0.013716913112400028
-0.014998031301636456
-0.025580648433816005
-0.002456404889982152
-0.010068385390915828
0.03579007379254414
0.03453967664146986
0.06703739152465367
0.0035538252500675834
0.03211685053782332
0.049132400329635756
-0.02585043024998857
-0.045469698689310396
0.03778131155575896
0.006245555287288613
0.012907878274243022
0.04701894050133296
0.018134749727474312
0.04027220285913994
0.03500770471263699
-0.019794544800197354
-0.001362676906549985
0.02764898872486006
0.014703889418196094
0.04241515790967783
-0.015635613848998794
-0.03785077426692582
-0.06511865036280587
-0.04653687178683844
-0.012081554219453918
-0.0031450197721349825
-0.027031102479707626
-0.03394703046404257
-0.0004656676775650452
-0.017979958565856064
0.0094861862859677
-0.03494622250262695
0.0272854587793029
0.019198388391319966
-0.019324632222403545
-0.02714666378732294
-0.0013848371994074193
0.01423721502041068
0.0630431633726565
0.09057892538557545
0.05261476632997066
