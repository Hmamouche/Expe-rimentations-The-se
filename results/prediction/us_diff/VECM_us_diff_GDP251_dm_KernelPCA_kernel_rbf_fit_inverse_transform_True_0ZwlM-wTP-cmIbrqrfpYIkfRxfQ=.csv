# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP251
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=13, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.00533438508153751
0.000997368145927987
0.022233427531740894
-0.003291967872668874
0.003897017311629541
-0.002301571198044588
0.011549024520106152
0.0050325924252053785
0.011863540448937223
0.015191100331754782
0.017962899905949598
0.003929403367921971
0.00038850230876767786
0.0015907453082506945
0.007408831491724685
0.00776250184848133
0.005397473361180832
0.008302427474816576
0.0052546824787118385
0.007981261830892436
0.011045468651565471
0.010352982672370413
0.006652075437725585
0.0032234404623912947
0.0035706837509356776
0.0055448239275094425
0.005137965956984343
0.006241011027519036
0.0010714800631192528
-0.00681404451322326
0.0010312516095154942
0.0032152011600445982
0.00622437035366211
-0.0016297631628735974
0.0032413862644499157
0.007243775489013517
0.0007979904499306635
0.010885556480125931
0.01147206180967695
-0.0020934553977366875
0.005017375575321989
0.00769516071133068
0.012107240132015515
0.003381997109838467
0.008697175007655536
0.009581664197391388
0.007900348289177855
0.0010166951409784687
0.006347787928494134
0.005830256246594485
0.005545891570667441
0.008294514796475302
0.008232924484934285
0.005757434001167509
0.012964711463514222
0.008034677383349032
0.014612128054881955
0.010783548392626416
0.009546601303733212
0.0079186911475164
0.006820452814418668
0.00914149834981373
0.013585284803983006
0.009954391312301993
0.008735369352275556
0.011607017632472223
0.013394522738093547
0.008969135642015099
0.008879589662318449
0.004864949914034941
0.004583267306414615
0.005115043830146997
0.0015990205887877256
-0.007264040079707245
0.012327374551772326
0.008306643462712874
0.004166188650994746
-0.0012300491625352684
0.0053427600483009815
0.010051880606397175
0.004913061996071094
0.015440280010158128
0.015353270231276772
0.005707965246865968
0.004771045081536673
0.01043390117509055
0.009457693192313488
0.006268193151279876
0.010358370697205637
0.007065504079196416
0.007738519716167701
0.00623672051099168
0.005108293061086151
0.005241217987519504
0.00607383559244698
0.006368231737825834
0.005618170240390108
-0.001165924167487392
0.005259203743060566
0.008789442013053105
