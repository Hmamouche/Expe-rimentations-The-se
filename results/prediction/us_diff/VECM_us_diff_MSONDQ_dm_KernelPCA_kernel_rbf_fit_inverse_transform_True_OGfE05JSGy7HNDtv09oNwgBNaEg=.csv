# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; MSONDQ
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=7, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.04550102759152749
-0.01758321339926464
-0.0026372155722629784
0.06180726615916842
0.00886826212650545
-0.006624619728316725
-0.009842974599431023
0.0286760264861939
0.005068440792643472
0.002567271739625992
0.03955207252758235
-0.005791864133458483
-0.04320150457016211
-0.045772907965629044
0.016836484287163878
0.015069185291754774
-0.005238639136447205
0.015775767476487845
-0.016561882915845736
0.07580829165409667
-0.001674077985090278
0.05112097653918266
-0.017197052549366817
0.012195726745405448
0.0017522655111285495
-0.012582518001392977
0.02843280558748229
0.007811638374865119
-0.05143633630604391
-0.01974681594684539
0.0006915382096580247
0.012891028293553064
-0.023894489655972136
-0.02244609089686246
0.013059025278052649
0.0016148012818178997
0.006096011005620915
-0.0037277803387794958
0.012632647746314873
0.010659387562051462
0.03472849730824399
0.01528557755924417
0.01088524149682549
0.01060592202588911
0.005368259317613727
0.03255188306527868
-0.0026504587585733704
-0.04009697126086117
0.00979305408533495
0.009692046316053
0.05982983958219164
0.06629628192774899
0.0069617044086709955
-0.0010917781812977319
-0.0012326416155509306
0.009559287240478123
0.023715591585847278
0.05394881401522863
0.06881587597457713
0.02897957827881548
-0.005166159851250405
0.008629637813356565
-0.027904491885729847
0.0059217905512987
-0.007532002800942368
0.03763654042435326
0.023007612857091114
-0.004779063207890724
-0.008707117971382104
0.03808493894314685
0.032644245630048495
-0.0427057236089514
-0.06357979003603322
-0.08932786847051574
-0.05172698448145475
-0.04430194377715167
-0.03698808601084132
-0.011061984465656116
0.007296963316514731
-0.01692842935494095
0.026038356527669334
0.03614471722387916
0.04631000861679748
-0.0059865147302133916
-0.021501607545727167
0.01583183877948997
0.007457328128515419
0.00388612691984299
0.048968404243059094
0.04408923095207671
0.07158435122826512
0.03538436696131374
-0.03562027680345432
0.005068447213097037
0.032389640473279885
0.015045440656340834
-0.015990776364278664
0.015214753276486973
0.006320050260074142
0.004208270827411853
