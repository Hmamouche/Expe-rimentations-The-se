# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP273A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=13, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.004559622614799321
0.00645027269158364
0.004378230973902176
0.008688586803121725
0.004341015673821431
0.0050027979021092265
0.00873445172569474
0.004580817473730839
0.004633530450031549
0.005924453725544011
0.0052467955560042785
-0.002642713124004337
0.005805697740946192
0.0034568385719637956
0.005190716449000591
0.007151368834188935
0.0090739368623066
0.006555896669424229
0.006707915490889673
0.006650040307481422
0.006375240038150594
0.0076753568646259936
0.009285453324274013
0.008040349253021573
0.007297894265295117
0.008969146679835857
0.008037155011323675
0.007081414938624247
0.010582587799018942
0.012524148975254692
0.005296371529272658
0.0072064936957301805
0.006378543397017792
0.006371864418909492
0.003824229568755487
0.0066780509204838025
0.005717291863629961
0.004930507178559262
0.006516549114249517
0.003948704354632432
0.003960604726355304
0.0029597151381536325
0.004108681069731746
0.005858508642535807
0.00653100717891366
0.0038151875521108733
0.006445039984849309
0.0021318850456389224
0.003476816872902855
0.004559003852785988
0.0044612217171669044
0.007133370584654381
0.005824015364273681
0.005820597817483857
0.004580435213228555
0.0035041816899582055
0.0034985144911215816
0.0018336687448310257
0.0008100619520930233
0.0008749010812781848
0.0019177379133468266
0.002869493962129271
0.00407972132830634
0.0053143606052812225
0.004565333310692387
0.007859990125841767
0.005459880197417377
0.005114967942107064
0.00512215148518772
0.004794030289681136
0.005888942140693439
0.005964094490745364
0.005375552859619994
0.001670470710246803
0.0032766561706017187
0.004509476756313265
0.003068887410240507
0.0038222263119879166
0.005076741931960077
0.0034186562496599663
0.005612818505063836
0.0045465966030087505
0.00826212059017124
0.009072394052831024
0.006317277861979752
0.007713615886032179
0.006203676683050892
0.007853747960612256
0.009101177389078419
0.011599290414546054
0.008685131427450676
0.008577217371873455
0.006966602603086478
0.005177980518651043
0.007979381912274605
0.003733412145862873
0.010970149626443357
0.010414579637897653
0.010154424304727246
0.010119727882457779
