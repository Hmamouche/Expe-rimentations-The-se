# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; IPS10
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=10, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0069592871814185405
0.008103080906837774
0.009351237200005863
-0.004049241688691381
-0.005313829648753695
-0.001432587218804667
0.01206614254392015
0.003083875680467491
0.007533873248467774
0.0036361488424735402
0.013249350937716235
0.0011647105109281511
-0.0024306042777642598
0.00048416943186074693
0.009540451264079628
0.013316456167893323
0.011011350006282773
0.006572324761733768
0.012461927638319424
0.013200549626911506
0.007656466855161461
0.01339435241790733
-0.006252907579023911
0.003364209502689403
-0.008665821275709201
0.0014637563428332378
0.005137564480271037
0.007856958471934258
0.0029345692641423006
-0.009565134294340836
-0.0022068872120131556
0.0019171352285801595
0.006894754732736125
0.002789936469671567
0.0006720934485943443
0.0012017989486223179
-0.002961109986038762
0.01669641933195832
0.01432933249448609
-0.0007317554581517368
0.0075824148948590185
0.012198724789147328
0.01543387538979145
0.010444465792209217
0.008786828723542259
0.009287396647202963
0.008989218903090321
0.0039496699430854034
0.003035731557136035
0.0029485498636881184
0.002381174529834934
0.02093158603020972
0.013514553711944476
0.02021393054886892
0.015211363160198135
0.01349053249531303
0.020533627064740646
0.017322673131944927
0.01665353024907827
0.0173449070100191
0.006110188803954507
0.00561689379674394
0.018032231854296723
0.012769135258620308
0.020297977442167468
0.019890631798794245
0.0095205928719383
0.009911919901024151
0.006043094483364176
0.001111470700736042
-0.004182449454825774
-0.008354280965134022
-0.01901313501829209
-0.02271533344908498
0.015400817759408162
0.011164442862131493
0.0027448118656785447
0.0017178937727829252
-0.005798240058721235
0.009562208580534023
0.006235886683272209
0.014498808733179385
0.0033038024918533556
0.0034635750670114923
0.0005083697520469671
0.0014446367834702982
0.0018159302602628689
0.009330567460902781
0.014479732139756583
0.006377721561232549
0.015976323373620403
0.0009800948822616263
0.002440410163023575
0.004474078487674816
0.014727157647682121
-0.0031536708950347025
0.0037723155701319525
-0.004694977942165605
-0.007231713167494408
-0.00031639628784410146
