# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP285A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=8, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.006243316885191837
-0.012194469924106697
0.01263170003764036
0.009566332897310131
-0.02052004973393046
-0.00839715761659494
-0.01126501204254894
-0.003037765664576455
-0.0007312510143505238
0.010284955758507658
0.016829528947245643
-0.03376870874999403
0.010933480031312996
0.003982282246578683
0.014091940472250824
0.026217376629498135
0.003474550977896478
0.01810961144909486
0.019804103264832215
0.009924824403572721
-0.003988224751164319
-0.010453607043443764
0.009446293283254146
0.007630236943308041
-0.01463458365348425
0.008450841692713993
0.010785486406301092
-0.018015294296565152
0.03149848983084427
0.03551116146105572
-0.009348264277563169
0.015443613041594865
-0.027999353256124626
-0.0012209206522553768
-0.020017794677313933
0.01422402917111089
0.013051524475956911
-0.0027267146332950656
-0.0011151018047774416
-0.0001494721419296732
-0.015274247980134895
0.0010297293212123116
-0.0014467638623086101
0.009110003014298347
0.011856161883482765
0.0030245560268865723
0.011564913671366176
0.0129916919095935
-0.021494708394338848
-0.005596213698665074
-0.008080574217697003
0.002174263502083968
0.0011167761459525746
0.004796350879156379
-0.0035477793229931683
-0.011994632686489733
-0.005911355086014546
-0.013132471914028951
-0.01957481254240313
-0.010336968945944528
-0.01858250233812376
-0.007630861273037876
-0.00016746859301752445
0.013432605654851066
0.015314241735441263
0.011813442796982265
0.009899183995227757
-0.0015928218102567214
0.007199118088527052
-0.0033784519958903305
-0.0017155890405363798
-0.011906362885489043
-0.009466017444258215
-0.0218279797365395
-0.003138124570238319
0.019476064268936298
0.011039236143673224
0.005909899788443052
0.007414914932755857
-0.008150588574915234
0.011046293342710862
0.0005885813428497351
0.014941101597718753
0.018859443347778063
0.005796711855655395
0.00799937265584758
-0.005233335805251775
0.01812336737897321
0.017861752028214304
0.01815289433900556
0.014560178429507475
0.013338169616250931
0.010038552497583335
-0.009654481022794049
0.015587312415315229
0.0013741523876821642
0.009882334815711828
0.02706891901442721
0.02583133929400446
0.05574138657618588
