# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP265
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=4, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.006158905253875939
0.005634479675568368
0.0005056080088631464
0.012430409430648813
0.0035705344908625886
0.003747075973018817
0.020775153949573147
0.008716916817110901
0.019573965744912963
0.018903784181564125
0.011420563473758404
0.016539263468873504
0.01775919230241926
0.011230181654853613
0.012050147343071003
0.010885520862703698
0.004322556887162093
0.00027774298521674617
0.01128757102011051
-0.001367135820328731
0.01079872744252031
-0.0005713768866500604
0.003773575552609737
0.003950686139829953
0.011272636485640477
0.007357491222682639
0.010550235208646851
0.00680073224352799
0.00606529496641626
0.011718418319378742
0.007190014768270371
0.004686923043574905
0.005441928953892678
-0.0023225106958610357
0.002434177081062666
-0.0010216324987083485
0.0017030403439345597
0.0009253028287800741
0.0038569560786458072
-0.0017723388222834727
-0.0021536924932831613
-0.0016803330403670467
-0.008414001000881504
-0.0008249262426756033
0.003542634187853492
-0.004193925115669413
0.007009239929204953
0.003254195223276418
0.0036298224226085207
-0.001604740046272679
-0.002673219927407136
0.004608618257064715
0.0006913849952682089
0.0018015817287603093
0.011151747261032942
0.004539943722197963
0.0027356229967249925
0.004808519941935978
0.0034426405299868706
0.0020231959162897574
0.007584011636299931
0.0032060661938221138
0.013974064866487975
0.011773763196146704
0.011348154756426254
0.009702917629020983
0.008719246930660113
0.010663216899704524
0.009351100151313458
0.0038207220100654263
0.0059721751324669295
0.006709189979982414
0.009086530663305175
0.015498509943628724
0.017643084176967735
0.010325073927974007
0.01660626780027348
0.012157207558243798
0.012867248360129232
0.00914736092443819
0.007960714361343655
0.008079787819587504
0.0031323449033168007
0.0076184019679956215
0.003549739574999313
-0.00023016120167626618
0.007699841284184468
0.0008219261912377949
-2.346315316538206e-05
0.0032503314805959103
0.00494827465624507
0.00302019957533443
0.008619692356705065
0.001587199564902616
0.008751123485625567
0.005730517273687416
0.007092618934073998
0.008885288632989097
0.011515179204644179
0.009729758970084447
