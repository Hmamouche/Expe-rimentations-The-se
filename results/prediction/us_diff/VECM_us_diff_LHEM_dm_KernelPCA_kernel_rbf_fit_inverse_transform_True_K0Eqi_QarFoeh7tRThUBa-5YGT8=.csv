# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; LHEM
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=6, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.003658659129405964
0.008709273205782526
0.0185879557270313
0.01256507465416853
0.004717600618405789
0.0039010230594703327
0.015246770032983248
0.0008570600022249431
0.004170242746319502
0.007745497676764892
0.009032736266522078
0.008536026343758923
0.002416153520968698
0.006525750025772641
0.010563162904512858
0.011054109374510733
0.007462921043947645
0.008409396428049994
0.010858386537398412
0.008618126603891009
0.0084280758945102
0.011246071657739295
0.006629766599923716
0.004273176809024611
0.005298142381364566
0.0037247444284044325
0.00896936000866861
0.00238465332418849
-0.0037981199506682507
-0.003455568828488838
0.002174371174870026
-0.0008576027677537192
0.00551930693460902
-0.0006821172631171603
-0.0036305532201300946
0.0021006249210515637
0.0019686081774275394
0.008103889944241225
0.005699011681288883
0.004198665742332401
0.0069718384169314175
0.00918121302361647
0.008996892525668156
0.005819158289404329
0.006429557008839786
0.013341762189830065
0.006842585052664525
0.00425579826591024
0.008134792675531133
0.001662738912589479
0.00016505682580986777
0.0047348924509985875
0.008870679295370935
0.00857240129845074
0.008960848334838891
0.011849354057497208
0.008309096762896893
0.008899567308653506
0.006531345679616798
0.0037084907259375597
0.0006829224416931335
0.0060721485073795215
0.009538949977337598
0.001466857912382409
0.007060533591798322
0.009069013237281315
0.014301672202994772
0.005888506553969582
0.008964786190691191
0.010712252588336277
0.00011802601547707798
-0.0018118547521561998
-0.0022519768026949384
-0.006094088789355842
0.002791738773868317
0.00045123129120533357
0.0005012175022205971
0.0017467133572002607
0.0016997301232632087
0.0053412836130067
0.005686281001602749
0.010002024015982642
0.0038864976696228906
0.0009901299617454792
0.006541969919273739
0.005071157077285525
0.005503244541447804
0.00847533092851647
0.006533368898590811
0.007713226756984809
0.011810906883688242
0.0032647181244145704
0.004092561054425316
0.011479780201085268
0.006302575359218895
0.008250461426370464
0.004487311371211642
-0.004258152630894662
-0.002707644861318417
0.0006912683973634419
