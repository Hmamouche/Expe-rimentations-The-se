# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; HSSOU
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=10, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.08642667097337162
-0.019345602911562246
-0.03713412930078924
-0.21664309587997088
-0.1056950498606294
0.08279044457435256
-0.039411191781004565
0.03204315348682494
-0.008306416033640268
0.02556222711370837
0.02701832473138434
0.0788082543267747
-0.10805104631040469
0.006075138342263442
-0.11685957181017
-0.12558640202839708
0.11081268244128206
-0.006985663384642078
0.011350708302344196
-0.13045084789466438
-0.06615815247081855
0.016717983722802202
-0.06115958768842551
-0.01910746058321637
-0.01628622856589949
0.07230597276487348
-0.010667988912999166
-0.0194179571552048
0.06929903475464458
-0.055837169733096416
-0.03159416037604401
0.07383971490454579
0.03450713914538509
-0.018199334057093064
-0.051609739617628846
0.06303672023424922
0.010113225208122315
-0.07477039797549223
0.09153946779844713
-0.11773816938343534
0.029728988076450087
0.07582238172633063
0.0011549605079132792
-0.013248995201958984
0.08990578813159614
-0.11473092932244883
-0.04400392542837191
-0.012847636103151379
0.025473415219536125
0.021516505834410143
0.02973671481684421
0.040304078687091155
0.08282523658007741
-0.05157427792462531
0.05565265304049069
-0.03166476891176877
0.03943025114408266
-0.006793854219598494
-0.015774176270415562
0.007279052928209831
0.05589682705717336
0.04774356721961722
0.05011319281671821
-0.016212067988229745
0.007585954641155426
-0.03538080447113434
-0.05680454851574347
-0.0012374967188018681
-0.0333603477784814
0.03850926575016988
-0.002121381169121861
-0.0020496421226495545
0.05156075912958212
-0.0026246820606912677
0.12741023422013645
0.10024086959285941
-0.07697410387122547
-0.03381201431330003
-0.024336021284725312
-0.06547737529195263
0.10197942939897724
0.039954583511427506
0.014350916386974685
-0.03195889170873719
0.028345685431491074
-0.0117685882331709
-0.017245127602972574
-0.0056396238076393615
0.04713893280699498
-0.0013731404392810717
0.0370061729742529
-0.009563158494228337
-0.02156953160303679
-0.06816353998520329
-0.0022834702304187215
-0.019989376176733145
-0.1133975754002959
-0.1528588490194136
-0.0488746649958475
-0.07489209214045651
