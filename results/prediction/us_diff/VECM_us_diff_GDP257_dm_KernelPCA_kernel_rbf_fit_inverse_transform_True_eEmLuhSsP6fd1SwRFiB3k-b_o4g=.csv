# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP257
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=4, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.023577069212316653
0.005254774296955096
0.022326796850535895
0.014368281857960827
0.005923448031017885
0.011036706851178009
0.020246694371376727
0.011802709587068737
-0.003987207183165676
0.0011663980228474348
0.01033796151557487
-0.0006242574075767809
-0.004535966805904731
-0.007072437956591974
-0.0019171772300105485
-0.00707770394795786
0.006242476961794516
7.635163656739342e-06
0.007789425806521633
0.00893666811021692
0.0029052548209214575
0.008659996537461658
0.0024486806587672755
-0.0011051659708246672
0.0029199113644014407
0.005672453978014457
0.0031593183476310936
-0.0056539034368712875
-0.019659327605366223
-0.011300068877175516
-0.012444712668619422
-0.0042587952478215
0.0023419947964283573
0.0010726247723940948
0.005606364942789232
0.005964408264102322
0.007083258840811419
0.013893608276415576
0.01657636060733474
0.003928807916844037
0.014922509012684012
0.019777150869061243
0.01817365830805524
0.011037532347636173
0.017550916380078475
0.010534318279064448
0.008381460244531016
0.010043658573925803
0.011884004283787676
0.01237689443941329
0.00885171038647466
0.015680341544923846
0.017935940260654235
0.019730237228736448
0.017876444892280553
0.02024644114759736
0.02434281768329973
0.021199511664112134
0.017722696653042214
0.023743446921836848
0.012749952857932121
0.01990208455364322
0.02525502843955032
0.013972259359347783
0.019950110161228017
0.02189036776325201
0.01618207539062417
0.015963060917815197
0.013157118972962869
0.01078012877659824
0.0073921212011552485
-0.005386419517394341
-0.019218163857084466
-0.025218589608791184
-0.013886980629691549
-0.011145159986745468
-0.016559748508162338
-0.0022092572060458076
-0.003723856684071773
0.003594218481708696
0.02650529353345836
0.030004010918410623
0.013366590074716416
0.012971106445848982
0.017015993155039426
0.020187435294583268
0.020286339346946174
0.016281153207482038
0.019294722717444732
0.009103400229305569
0.01842823036179357
0.0032907492847683963
-0.005637389180899032
-0.008526135292013029
-0.012477863383623132
-0.0010181681529623078
-0.006971841350219263
-0.014552787872226686
-0.013165764772967615
-0.006380676839272868
