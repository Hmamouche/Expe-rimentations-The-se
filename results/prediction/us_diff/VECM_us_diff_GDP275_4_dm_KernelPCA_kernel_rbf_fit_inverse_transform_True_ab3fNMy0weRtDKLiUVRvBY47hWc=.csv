# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP275_4
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=9, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.011412450932741751
0.007575284351930537
0.009360641128414114
0.005370927326397601
0.006849351428718868
0.002182955068246701
0.008598889268107297
0.00817757465433526
0.004280435617461256
0.008341452013367626
0.008286863043516966
0.0067389468301465175
0.005772584905377965
0.0058206432421653255
0.008156658008151761
0.01087006490489751
0.005212911579203857
0.005654088457453982
0.009733788303811119
0.008962082418378474
0.0072133645680107885
0.009614735150020662
0.014029054140708793
0.010175832393112401
0.008160425361400886
0.009056176483511839
0.010205837363425044
0.015525461612231183
0.006056331971882503
0.008758510044579832
0.013692688833256394
0.011431767035076985
0.004823518870704065
0.011884765423209884
0.00971507518709954
0.009246698966802235
0.006940124554892666
0.0021703447311127826
0.007919218133416362
0.007592155724733685
-0.003451549689834618
-0.000470840047639625
0.0016234087722826912
0.0009418983758037921
0.0046185950470011596
0.0022279781459817747
0.0017160002970358279
0.0038917810220172083
0.0064425641154527485
0.0038611762607649027
0.0021736671773121457
0.0030594147789794897
0.0017483381343228372
0.001559401109200516
0.001540577081150332
0.006247782810202081
-0.001071830796426422
0.0016930545252534907
0.006914755678254898
0.004271978362390301
0.004439629583176509
0.009394815509790008
0.01802410908363583
0.005871097580977919
0.00978557875415814
0.014652383552075616
0.004749209417205345
0.01205767880272746
0.006573982159226809
0.006388610285128297
0.009666468324391173
0.010703539931220894
0.007769720355519705
0.00684210783639619
0.0032598919428066114
0.009631442936422447
0.006397446909932837
0.00046095627308445977
0.0044926937772354816
-0.0013675537096661957
0.0026461975696722025
-0.0037123934271336713
0.0037013675933162725
0.0014233930011382087
0.00039673283619233056
0.006331073629176858
0.006163558746512152
0.0032481497870716874
0.0039863905950855835
0.006149304588856539
0.004909478698429122
0.0060415610841602005
0.005792814782365313
0.002867246366481046
0.0027069330790931313
0.004446289713196532
0.0033127179182615464
0.005706928248517507
0.006425266597010341
0.004648076966021733
