# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP252
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=11, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.002934733069206855
0.004224222340125816
0.010942735479965172
0.0008218900650564208
-7.279388577449957e-05
0.00815638203794719
0.005675388792840297
0.005004531935787901
0.007487495701130142
0.007831679542896873
0.009524418679164098
0.003583299664421129
0.00233579083527973
0.004054753752342142
0.005806064987027603
0.007238640492947472
0.0036378651236318948
0.008670323484894852
0.00538995098747032
0.006658548829205886
0.006169204309465874
0.014640621053716524
-0.0003429531220411452
-0.002520748631342532
0.0026153879534460234
0.004394684552177919
2.4347065641063632e-05
0.004206437180239169
-0.0010935589018300092
-0.003172759780969553
0.008218806438157792
0.00463613293798412
0.0029158124999260687
0.00043019143569915244
0.0032475384434575687
0.005816893594695028
0.005276511045956333
0.008675411537061455
0.0067693477101698355
-0.0005132922816752812
0.008792618602993602
0.008248276654517751
0.011394231375843429
0.003298416986600109
0.007560217959160455
0.007992712034216105
0.006204851706436882
0.006303928069276005
0.008510997469065983
0.005390798930125629
0.003119583776094063
0.0022836557633807205
0.008171316303660648
0.005478142282028289
0.008068649039684345
0.011314686274492513
0.008656239788154708
0.006640794861716701
0.01301609866198869
0.008482437507828263
0.010093252828403804
0.01336761500946887
0.009621669561614088
0.008477402033048602
0.010196033063624084
0.014449056828325858
0.011683770047875781
0.01356136781723873
0.010424593488308253
0.007720101919732712
0.009378016147560361
0.008291541608337548
0.001724638233106114
0.005672918357740603
0.009895030142789923
0.010280704714866525
0.0033661425700062825
0.007271547345307174
0.001474549194243589
0.006622476006985864
0.010965889796436762
0.008192295751861397
0.014026514150657943
0.0058298780880484185
0.009388531405570456
0.009965446316496237
0.00928215649987007
0.009253337265156708
0.00835534607561293
0.008677380469543966
0.011599205869210854
0.004545388080915992
0.0049592352781984705
0.013080350228508295
0.008279787332480052
0.008086796956700455
0.012439653856290391
0.002282616799034822
0.0004598287316108583
0.004011753923123993
