# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP253
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=7, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0031237414101068766
-0.0005163440984715089
0.012043206782802613
0.00938480502042333
0.0012266999768893432
0.0017620376382432884
0.010647341068302106
0.0036764740863587343
0.000680577302913616
0.0248925876715501
0.008607895297523548
0.001321420004799759
-0.008125616858812558
0.0005712332113911624
0.01412460886358582
0.020299190840041607
0.022023814226865585
-0.010647863001395847
-0.011912536075655827
0.018511859977649953
0.01283361753115157
0.016953012877887835
0.006852170955001988
-0.0056976945478124
-0.0028248233846483463
0.010194660120397894
-0.0025682984970177318
0.004126908592207435
-0.00818127105977294
-0.0163129324640745
0.00609720067907613
-0.0029292525199993476
0.010217313443545466
0.001870696753517643
-0.014642962705993271
-0.001002605701059276
-0.0006984899478706713
0.006839419217862715
0.009160881937374
-0.001455803802862962
0.014327795410662435
0.010926256561000863
0.01514204919066116
0.007579114804945163
0.0038887009094223293
0.003999220798921381
0.011679310554971617
0.009247263920035245
0.007273894771632412
0.010401964222144896
0.003041645296811662
0.0037252826608175117
0.00674226172095572
0.011022446953799747
0.008454610214249696
0.01704865544146593
0.01023996029158712
0.009431858307903204
0.0185706950297507
0.006938989234988812
0.01028029085925198
0.011644728582248274
0.02344314430815768
0.01683802428766814
0.01601881891588507
0.030966355921637573
0.0057437943679044395
0.03149912491105675
0.01575980673519646
0.006320309333575415
0.01294146691839921
0.0031209026807668674
0.007423423951092536
-0.013751986737028231
0.023705906544729212
0.03332382300951151
0.006409742154695432
0.02848566718387623
0.000606244148857172
-0.0007691108269940626
0.018552041329894766
0.01955346470542072
0.03168067135612077
0.007219809386283499
0.007979343318909546
0.007439614782835724
0.013580299387249938
0.011934546116702735
0.008757578934405243
0.021691007339544346
0.005889819913601339
-0.00432555275272729
0.0014329777724057012
0.01745692318008264
0.015277186271016006
0.007620402225141942
0.023307268268364652
0.0042802309327485515
0.006616447726586275
0.006908667973452905
