# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CES011
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=11, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.01226574337231661
0.04675318297246748
-0.010725561135675486
-0.0022762146863354385
0.016973881943296562
0.005924838085670685
0.03650493486186171
0.004322964734029908
0.01601021428156391
0.015155392884341133
0.010261729940977212
0.0035795720327469593
0.007554775569672781
0.012636854696362776
-0.011392331292818997
0.021616432952777202
0.017682114413910693
-0.00022051234111787133
0.007341072185793436
-0.002095229695111607
0.021532448714750844
0.001864401476004242
-0.0029667790485527023
0.003941527652002179
-0.013200541119149032
0.008558836631574442
0.021298256968165816
-0.011405738970046313
-0.01703632606063759
-0.03514059018397095
-0.03394812432825168
-0.017559458756187585
0.0003397065112898377
-0.023751276121005922
-0.02677831268773121
-0.0001536645499274486
-0.00047716823824510684
0.004842310293147467
0.019410833162552692
0.0019446803540385856
0.01451281254370894
0.016468871703245784
0.01945630061879731
0.011851957934821937
0.01984403488654412
0.012442660041022954
0.022226312597096582
-0.0029769913206681587
0.009258019259388293
0.013701480805533852
0.011780039028578191
0.00992702611715723
0.010893542246840937
0.01787756142273637
0.02282789843689976
0.008295612255238357
0.022400198952766785
0.014870853344911825
0.009935173465059155
0.02256733808462275
0.018917171638892293
0.023050593082441125
0.022107436215870583
0.018241288080204796
0.01648318070884792
0.0127306263349862
0.017358696628102938
0.0046534585263291305
0.0022562710818051536
0.013482430771581304
0.0019526451492938271
0.002040051793102549
-0.014969514582589254
-0.01282568891755953
0.020763656753251945
-0.008818771385817704
-0.003994628970790285
-0.004744413029025205
-0.0019959519382650812
-0.001632586320841248
0.004534762526023686
0.014702559846423928
0.020498044709108806
0.014358087032518611
0.0006724169472452661
0.011519993717257445
0.016788071335335785
0.023950029402813173
0.02635738814574179
0.022551623138366648
0.02745837575204798
0.011513471273339097
0.003698489520090345
0.0019190084229156737
0.006562192355891138
-0.0008697303963925446
-0.017976308633459497
-0.02293850646340178
-0.016452531918291748
-0.04038471610142433
