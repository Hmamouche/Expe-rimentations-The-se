# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP274_1
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=8, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0076284021423355716
0.01146295603776888
0.006500706768775402
0.010609718224270027
0.005823488001699004
0.004157946871572381
0.007680070773093359
0.009113669344924653
-0.0015710949223806947
0.004710328082385687
0.006068812897280752
0.013889630698890112
0.009057638987577757
0.0037874907476271157
0.005270602175750273
0.01671151192038077
0.019890941635426353
0.009134241841937264
-0.0016852906771915132
0.010167902582362557
0.011867498397150957
0.004808462823329267
0.009933107235258814
0.006683886309605655
0.003164705123625329
0.00795315432160763
0.0023438412842918307
-0.0010204796806630649
-0.004926225742117461
0.004973578885316694
0.015936390269436978
-0.0030015970669294446
0.005710124540927314
0.011151783736873625
0.0044193200128570045
0.011329626479600681
0.005564892755076077
0.006369464188862679
0.008576371250173107
0.014629006268741819
0.017117817187975507
0.012209204982920668
0.008318738622278957
0.013726382918808046
0.01898697792908024
0.023613502600535
0.014923405224374093
0.015356281428483238
0.0034517045333375043
0.012988433790340568
0.008481373365120844
-0.002541479115862084
0.006094136423467022
0.008240291297667903
0.007665577687041133
-0.0037762303198888452
0.0012735932286969728
-0.00021750823788070986
-0.0054620828090064764
-0.007854073996587062
0.003292124733543937
-0.006245193414596241
-0.00037274342527384135
-0.0016174910125512755
0.00864034170684256
0.0032119445719321934
0.0014386366250516579
0.008404110642144668
-0.007287366304536344
0.008550816808472049
0.0010418037130507157
0.0002936311940753394
-0.0033821469852436583
0.0025011372549573726
0.0009481451209788262
-0.0033073767872203686
-0.0007187348313694706
-0.003498417848192923
-0.005363831911631373
-0.0073945936793370585
-0.008841534810773944
-0.012094621389939244
2.869185613760478e-05
-0.006848916721634956
-0.0024356920027277834
0.00946216165424701
0.006748274114204444
0.006315669000765116
-0.003555010382303487
0.009792202656852014
0.004391012610650566
0.0037521797955526737
0.0008635209671345322
-0.006880525841840522
0.0028686982998617477
-0.004916959096782132
0.002704182458754884
0.00233984695012145
-0.0028086430971721067
-0.000886825547924181
