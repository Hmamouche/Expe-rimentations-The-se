# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CES140
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=4, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.009497225673345155
-0.0006767164339165444
-0.00012392599683657527
0.002698229311349097
0.011920867785810054
0.005022727132251306
0.0005711083693254386
0.005653325699660429
0.01080958291700796
0.005744689723533088
0.004411976453440837
0.0014381330286399813
0.005886483280633785
0.008850834334288092
0.005691120237157248
0.005834678227319421
0.0032558167505243015
0.0067305526204151115
0.006555014248409718
0.008206702556485496
0.00385737398445947
0.008494578305150652
0.006516813909991176
0.008687000321095102
0.005488023159309766
0.005333855163848045
0.008392167272388366
0.015068968409466397
0.009089025405387854
0.004573696148983763
0.002817412327546745
0.0047372326299338985
5.7490316850696715e-05
0.0017435736522243555
0.0052032507502635435
0.004552258110872317
0.006371443769722642
0.0019599836772789076
0.004583170765754268
0.002081666604906799
0.004511605735359688
0.002991681629992872
0.004509462612346671
0.005602253040206222
0.006230902865293995
0.004392315522066344
0.003087328068760286
0.003529914530751063
0.0012447324025289164
0.002451584890882358
0.00249361981295578
0.0021497864723594323
-8.515151972459528e-05
0.0009241555402476156
0.0016357453883776706
0.0023614086781808636
0.003010060314640498
0.0033122266782229493
0.0030241066172865118
0.005568813053569336
0.005562674207489981
0.005056243229827636
0.005476093608705892
0.0076826509292829154
0.006661181201504913
0.0075155435101851575
0.009127336846935617
0.014961077346069579
0.00558167662752891
0.004933511752203478
0.0012913680592866895
0.009147102635798408
0.006347991079597405
0.004842075858404307
0.009138505483755388
0.0078914993749521
0.0036516310553218563
0.0040816210922020625
0.005937237972548012
0.001613986661381273
0.0007026462475321204
-0.001486033831393014
-4.1194812393164715e-05
0.0011753418523430034
0.00040156167139159373
0.0025069033234647294
0.002765445860462902
0.0024348130530293935
0.004648194128333375
0.001223351033461094
0.002495922506218647
0.0012219639663697687
0.0057560296437692195
0.0024550149340316707
0.0031461631947320365
0.006166027489605596
0.0026437187717904013
0.0057444089191033935
0.004884834725840292
0.005799096716752436
