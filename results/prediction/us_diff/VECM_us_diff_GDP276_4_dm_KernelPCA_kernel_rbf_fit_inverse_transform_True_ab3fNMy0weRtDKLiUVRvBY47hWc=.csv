# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP276_4
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=9, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.01024697757860589
0.004397857798568431
0.019256837526796782
0.011099457632341426
0.011370590854114102
0.007640039385338491
0.004138762324934159
0.005843144108546402
0.012685599810148093
0.011223109176989562
0.010139326954578743
0.00722449062880266
0.006797924114566379
0.0029971402304205075
-0.0015887097294941112
0.0032466141916643845
0.0022962888537252767
0.00235108955051972
0.004197088400606471
-0.0011547648904021487
0.011893850496141552
0.0005616988295661413
0.008399078004218236
0.002129018269885164
0.0038520078587495283
0.0022227223778833313
0.005228395967881783
0.004047279876523484
0.006033733971353358
0.00548892992543967
0.005845155043349101
0.001995281388913882
0.02052461796012854
0.009685599892820454
0.005037867353108471
0.00216534227479183
0.0028800859258071164
0.005711661877029022
0.0076666810814859186
0.006661704196293693
0.005822955384322594
0.006962059343713224
0.004978918534612867
0.008570787357998275
0.0064865298248556755
0.006443564228639335
0.004058675194011368
0.005542695514594574
-0.0009540644510167154
0.0023348924343451947
0.002170319096389351
0.007657050929935251
0.006701436495810526
0.004793626390929904
0.007232973177963019
-0.0004972269125056361
0.003244016725176213
-0.0010103172211576666
8.116823313494744e-05
0.002635070899054827
0.0025323713168855827
0.004516990456603593
0.0020021359969863745
-0.0014386685430297476
0.0008981826070419935
0.0025568555768135407
0.0028078857549375695
-0.006496370378339615
0.0003524883999787107
-0.0011154843475202898
0.0017433986258513948
0.0014089448251517675
0.0015227441455647741
0.006361426398522325
0.004891506888738621
0.004998765464124613
0.009834349222103436
0.007476668814293038
0.006151304596706632
0.00459712436348737
-0.003378622525621845
0.008528576596440265
-0.0011717252047768383
0.0023043946614807456
0.002818711482708312
0.0019700853837468415
0.003758733577584836
0.005002089037983453
0.005801684967732989
0.007241039783441982
0.0078470343911402
0.005042118003718441
0.009382584625299567
0.005737589328068509
0.00986780828196411
0.01162842553705172
0.007239146378280995
0.007914748665066003
0.006771337595515542
0.010874099079510948
