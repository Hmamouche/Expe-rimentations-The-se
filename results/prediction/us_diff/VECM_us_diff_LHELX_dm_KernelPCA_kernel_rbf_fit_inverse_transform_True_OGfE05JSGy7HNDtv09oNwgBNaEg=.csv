# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; LHELX
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=7, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.08132850394381562
0.0033322425090231075
0.05047423259308094
-0.007779497056193456
-0.013516618463256195
0.04376453732071073
0.03820763365114446
0.010896014076814488
-0.006082775935562159
0.00718695631847822
0.007955909242553065
0.00818876815173245
-0.02903188759243064
-0.01206643864587974
0.012681019362444484
0.02499114460353985
0.05671122342518844
0.01135035420985767
0.014631015025058869
0.015950633049141037
0.02053727751275041
0.031128024991930476
-0.016945216093196925
-0.01776847400258124
-0.021656349389760746
0.00104463048461192
-0.023618011606403484
-0.025176176696091578
-0.07815258686628193
-0.11898859774794453
-0.04218224532983679
0.0035968137558957313
0.012198959635491047
0.03347901608359881
-0.003731884563436409
-0.03174025728993293
-0.02824052650437188
0.019194749094718622
0.008601100702555925
-0.011495697545816466
0.038694612542844925
0.030886690714680143
0.03030642955753656
0.005621213345722023
0.018283164048815356
0.021080455140673533
0.015908915785393607
-0.027491270634653002
0.013657203348506959
0.008517056141521477
0.0017098993408906221
0.004876749487146566
0.005492093855574276
0.009291543277540183
0.024317385814555052
0.007775845156881574
0.022429019553702585
0.018815673931392524
0.028260623953157697
0.006032410561176019
-0.020950773313631592
-0.0046067227641574645
0.031233920287815856
-0.015770187522939523
0.00446872604104832
1.6112204565785736e-05
0.004264060631748083
-0.00986327107778865
-0.034340647217383176
-0.013784462988291613
-0.05355366180828874
-0.05559005843505018
-0.06633706168175608
-0.07789749759866668
0.0254404878950847
-0.03405125094508857
-0.020482016511234068
-0.012183090882337008
-0.040935179385444845
-0.00022207371019937732
0.022168854153364614
0.01201994971625835
0.007776994878573269
-0.03103853299275805
-0.00859790737187535
-0.008749113053204784
0.0099461961454623
0.01020932866656035
0.00013282977727907888
-0.0076176932917206295
0.026605696143167
-0.04398671574828055
-0.024451544386943008
0.01443984316843163
0.010545726774565183
-0.0035950010461800134
-0.006796291229721732
-0.053191492034794556
-0.00028486092723169903
-0.01499618264311562
