# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP276_5
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=4, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.007130771373373321
-0.0013934843016585336
-0.004072707432730734
0.0009714250241749777
0.01770361345926453
-0.0018871751049021513
0.029586661299969244
-0.004129352362836332
0.0037390494904849143
0.0036927612991101803
-0.0003840942899645569
-0.006290694332538536
-0.0031027717500054478
0.008580545251184799
0.00962946220254747
-0.0024612825118055003
0.008603358607739755
0.0010242520181808006
0.021519421634118414
-0.002075104517147976
0.017486790757535974
0.0029046230255869933
0.009564675973394872
0.010394844733952632
0.009942919782267027
0.00981760542939113
0.002799236099932918
0.0006623960518565774
0.0019087608400149298
0.014138872020678386
0.00803718077212481
0.0038203132141569245
0.008815308833851027
0.0026126062160209173
0.006729231181458531
0.005093253380707565
0.009729843747810427
0.006310787472583554
0.007193252805056756
0.01124464979099876
0.012772313470407495
0.005527905152668076
0.004728987868309429
0.005735710952672507
0.011354040391721578
-0.0013677355035541221
0.006931197583880603
0.0036997670359505508
0.009531471144349537
0.010814905315507651
0.0027397914832318713
2.7542944607188776e-05
0.0027171436083099926
0.0014806466822013375
0.006726175780880509
0.008889705211990367
0.004029342797515461
0.0020716321988456026
0.007656196767261669
0.000448050543244967
0.00707000649993463
0.005689224252159147
0.0033586977647665542
-0.0017458657279994707
0.008862641742899267
0.005016251145278296
0.004707120105401362
0.004590672628522198
0.006992829142711552
0.009080742210472652
0.007877716965023814
0.00028937952187080794
0.0033165325451872426
0.002333693060080283
0.00824083969233166
-0.0020271755044801365
0.002718892149314041
0.0008786502381255721
0.003792609030929216
0.004276392710715849
0.005936217453598407
0.010775196424761166
0.006402155315395318
0.0050656298289662735
0.009940708919803991
0.001890114429006461
0.008377099953067967
0.00678601173486751
0.007673559678100199
0.010358255972265173
0.012997370990262075
0.005676500256813805
0.010722195245164663
0.009866365730557007
0.007244374013079557
0.005199654956900685
0.004531981506688695
0.003075712392154147
0.013752254209107438
0.009345184625268128
