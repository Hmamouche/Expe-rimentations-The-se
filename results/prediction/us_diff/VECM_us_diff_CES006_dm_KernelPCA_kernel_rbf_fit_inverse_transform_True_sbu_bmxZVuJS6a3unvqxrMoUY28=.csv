# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CES006
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=1, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.0735396732421874
-0.0015678684268768985
-0.032110417959514456
-0.0002304511375667978
-0.005157686106459541
-0.006602006763063228
-0.004714275587900877
-0.023669203906456864
-0.002697493359361272
-0.020723610905010445
-0.034074181656980985
-0.04633965304852973
-0.07002281813080606
-0.06765618788430797
-0.047453468397289464
-0.04290592762156961
-0.011808030191738024
0.012326046325698828
-0.006483227274787737
0.005850903575725344
-0.009600578940060705
-0.018297182338049167
0.0023949947944908916
-0.01859449469091412
-0.0035690087324504395
-0.0034747434692275984
-0.003901313023802186
0.0052296581488748845
0.012819629027247925
0.010171511262134399
-0.006738689508448156
-0.00500307031919364
-0.015538359744734855
-0.023134736488500007
0.009877004658202453
-0.012068924352589081
-0.0449367350208659
-0.0024306579901127445
-0.008752256909717072
-0.025136179362906956
-0.002214613735922936
-0.00043934976826057745
-0.012429494717403879
0.0049080703955978935
0.0012912804851197947
-0.004417404885668255
-0.002687467395303787
-0.019693345422126713
0.0033926748138808785
-0.023189907369357658
-0.01681560178375534
0.02181146481444115
-0.0069798741254037166
0.001635247224015485
0.022882632332184703
-0.003556168837837532
0.006101658344383271
0.005545043493271739
0.004620785858574068
0.0010622862990191375
-0.008355644962628243
-0.01596952134486855
-0.014298827242848238
-0.02170152870447902
-0.015792143896262913
0.0013988098321334832
-0.01098124749103602
-0.004772742001380907
0.007985166010236511
-0.0016388966040168339
-0.005871205913793105
0.01039888415905458
0.002446774428912878
-0.009787879644956874
0.012256269052928205
-0.006632828065445398
-0.02396381325804937
0.025254463839414168
-0.013651927883740598
-0.023548863470722763
0.0028670999679917134
0.005270521771810558
0.0034854744969099963
0.01633215946734614
0.01828532875886666
-0.0011903804743921033
0.007221350057956717
0.01294990514339301
0.017226152221567228
0.018794034359040958
0.01509649064964365
0.033754044754929394
0.02218552947270485
0.016352851296806064
0.014567942562673344
0.01948371443863256
0.01050429777961057
0.01814864396352898
0.024254941420869765
0.0056039181296759786
