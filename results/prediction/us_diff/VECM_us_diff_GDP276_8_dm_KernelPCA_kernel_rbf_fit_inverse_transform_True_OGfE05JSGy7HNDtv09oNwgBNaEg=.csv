# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP276_8
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=7, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.00727112084218059
0.003408540638577876
0.0028452204144453533
0.005971419609816567
0.005104327057267221
0.0028027669039292122
0.009876606752458314
0.005528327474319635
0.0010684095893637548
0.009492187332666439
0.007900974818090593
0.006768622672325609
0.013717855547459485
0.009205182111660054
0.003327577856005805
0.002349701593370618
0.005559972654158998
0.0016694791754682937
0.008909529286472977
0.006608896692004155
0.0074146136178142525
0.005915157512534828
0.0072680134143808155
0.003816352657509594
0.0023269874093976585
0.003292535225865914
0.004084655763813013
0.012750168820274481
0.005907325931527858
0.006696047262916949
0.01034152075287059
0.0025332795902067123
0.009923073749519295
0.004773438160182423
0.014028660595908389
0.0072932291420328005
0.009328302269408978
0.006351526082696762
0.0030359630784263436
0.004783321862337353
0.00316693755001474
0.0026909489117434814
0.0032708919770825942
0.005618121236610234
0.00573159771221886
0.005327646372522017
0.0037754270467643706
0.00678516453711226
0.0071234927955386345
0.005657865955539821
0.005439249642280538
0.007869419878074822
0.0056862589563408585
0.006489252241665014
0.008263572852676253
0.006486780571044334
0.006375188026590617
0.006621259623411759
0.0043139652343774015
0.0021918880287172234
0.0032309361234090337
0.005943297167558771
0.002153892406595146
0.007110298801799405
0.0034883622730898355
0.005290324686202644
0.006904604528800023
0.0040866773941792296
0.002015090409463165
0.0016852329754008517
0.007276890742818218
0.0009828756647995542
0.0029365692850619606
0.011928241922847336
0.006110304393383937
0.011065028897238309
0.00610476372381978
0.006270931183024804
0.005753170114217735
0.0032796614934777193
0.010797301620845436
0.007426016104406419
0.010316034956655283
0.010013119910441492
0.005415058064742037
0.007653442820159204
0.008040729137907472
0.010068394645169338
0.009022031975488443
0.009862286421542934
0.007310688771932515
0.01246790843993237
0.0069463871531911
0.00746893624515531
0.008161786419295198
0.012812772099213445
0.009943617452015512
0.010502086289915943
0.008630531150390721
0.012990318734061566
