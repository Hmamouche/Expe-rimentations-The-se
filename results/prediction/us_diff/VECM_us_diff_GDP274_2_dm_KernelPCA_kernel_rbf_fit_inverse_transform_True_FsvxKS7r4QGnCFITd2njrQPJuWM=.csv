# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP274_2
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=2, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.004414201213452786
0.005408059837587181
-0.0005554527457877682
0.0018295767886239971
-0.005253549004476573
-0.004920765312225596
0.005625119838341463
0.0001902392778398808
-0.02104882659275453
-0.008531946820893027
-0.0013230005044223688
-0.009873403522507844
0.003816157781328506
-0.004812596624262573
0.0073439622995369585
0.0017008371660893616
-0.008376895652238531
-0.0033903028573862375
0.0035086437269295453
0.004764241815210875
-0.0003388023090899977
-0.0029836400783969544
-0.0015900667849413125
-0.008968114473982451
-0.000661043995642939
0.005360656511025564
-0.004349963023126435
-0.006860513895551341
-0.0033548431640819717
-0.006417536579161194
-0.004193234013904821
-0.0032158749167859753
-0.007517425540981046
-0.009599852761670802
-0.0016156500583381771
-0.003940161630350256
-0.011644863624003316
-0.008173031462962834
-0.01164362188729868
-0.009274106699519016
-0.00609609046130864
-0.00568718048010698
-0.00034660995317425426
0.0018673571182338334
-0.0006977138703297952
-0.014015575404606927
-0.012734889085073475
-0.007627210931535005
-0.016874061497152346
-0.02041118505269695
-0.016531278985861673
-0.023059944186816943
-0.01921224242531954
-0.018334231481605612
-0.024298329367290178
-0.024240946893538957
-0.021088146427428026
-0.01947285767882582
-0.019172317727512895
-0.018030761959504343
-0.025009018175736836
-0.0293091662786933
-0.020914884259773905
-0.016887807260877196
-0.02126870460278874
-0.02152822024363441
-0.013546587205519326
-0.009416533445509311
-0.014586471561529053
-0.01752660738041018
-0.020070070449104502
-0.022063240011071315
-0.016922242445636983
-0.01626604954143932
-0.0217246729063882
-0.01688756883324121
-0.010699797645508385
-0.019751086770777013
-0.01559897292933976
-0.01880824146597285
-0.020685659834777777
-0.013504838186747088
-0.00470508788867457
-0.009129512612467625
-0.012530655120390404
-0.009224169994433432
-0.007163942716696657
-0.008422599904691443
-0.013453164562028016
-0.011947231386700053
-0.009211028964382353
-0.009227587464162551
-0.012974508745551757
-0.010882846192758675
-0.010512755116268877
-0.009540267571589657
-0.010922498302102235
-0.013085353941361825
-0.008243975398272823
-0.0097917567262651
