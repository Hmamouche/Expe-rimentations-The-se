# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP275_3
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=3, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.011698621818004584
-0.0122788390399067
0.007698186038920125
-0.001492218620934606
-0.0020625440390126346
0.0026182662778102906
-0.003325083545130422
0.0055695912222345646
-0.00010972528521017164
0.006599943171628131
-0.010045938716916888
-0.047201576366829485
-0.024333613645310923
-0.025809133581035953
0.016829484765841857
-0.008321530296924897
0.002234502894333372
0.0044651333710559096
0.0025693254582292904
0.0024335185812899545
0.006762265567560717
-0.007048030392617299
0.006517772046637621
0.024181028973732612
-0.004227810782726505
0.0018315859801811413
0.01035131369242152
-0.00019723928615528012
0.017190854684209445
0.0305576349017976
0.001145972561175275
0.011841220653624668
-0.02886779866472532
0.02554685022516399
-0.018342661036105115
0.003996863065543778
-0.0005999391005700374
0.004210536942554636
0.006061534643316538
-0.003540367148090773
-0.003925059790884829
0.0005043893114935358
-0.007169200116100257
0.0016407608641338064
0.0041806708327091265
0.0022687610378535807
0.006218217665675933
-0.006554764332049252
-0.0008647436617316121
0.00010424727642423053
0.004863936924127093
0.010048270759455495
0.0005287452283178323
0.010571776576105809
0.0006558516934835491
-0.0022437817647554007
0.0005440990160796204
-0.00844523002133587
-0.00930310499454873
-0.008621930473501068
-0.011767875030870265
-0.006797064914370593
-0.006362798753780931
0.013593623204560047
0.004930369152221624
0.023819641455511808
0.026630129567570514
0.014002129146391333
0.028355371453316184
0.004821088484111892
0.00457954447443771
0.013332291577026647
-0.01734345800211506
-0.014969190363056934
-0.022877450730471222
0.007636821983159127
-0.007769899603844958
0.017849644937245276
0.03133638078105491
-0.014720556311364728
0.04166635910274509
-0.024727338569998373
0.02582069673186508
0.0161459761842677
0.021016811118572398
0.029011211383204387
0.014443379140480708
0.023335087366899716
0.04591170940166326
0.02710668719084929
0.06043195024620593
0.013455952631164086
0.04195226965770299
-0.006116828915560847
0.025057369457612368
-0.04620565783379493
0.006074170222145179
0.06289866362880385
0.025570156724154143
0.07103677040945419
