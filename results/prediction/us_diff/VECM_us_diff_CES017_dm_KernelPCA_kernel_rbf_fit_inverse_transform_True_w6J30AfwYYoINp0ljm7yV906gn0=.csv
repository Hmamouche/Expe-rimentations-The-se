# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CES017
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=14, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0827230788429051
0.054050555152139905
0.028804506227939536
-0.04845478390537601
-0.06121507408023208
-0.016689160238621797
0.0007597538958454518
-0.0108874254287167
0.0542370240079936
0.004768052273045059
0.034933119777423395
-0.019978441223740123
-0.03810274766021447
-0.0377001216515022
-0.007951733412683067
0.044069547373878165
-0.005551845685486579
-0.03282301153793995
0.04482688634494876
0.028271347928877432
0.01286980662192953
0.05400691774724521
-0.005797303960381025
-0.018357544110211087
-0.033092487399775196
-0.01676022570714599
-0.02095570779327303
-0.011031312071982545
-0.05686655076041563
-0.05024340947778925
-0.06088508705753604
0.009232337663538898
0.02146348569849791
-0.014588053394907975
0.0004262766727316774
-0.033585341853483996
-0.03521594891207244
0.0292161515896742
-0.02223764762225506
-0.015705040200260832
0.038776496527699086
-0.008137343749588487
0.04100023681504274
0.012149086757002507
0.010640258298865066
0.02503221277600921
0.002971172599580872
0.005616484432628639
0.0006601994104703714
-0.010706411313616663
-0.0018205606246648569
0.018567311094079775
0.027394483569826523
0.031022843886318763
0.004176446902190212
0.00940477678703687
0.037382375168734085
0.00838780812427736
0.02123486216864759
0.006929864774973276
-0.03653869350137604
-0.01714433341097938
0.024817184480081238
-0.02703606446807656
0.026850631214660792
0.008350002244925124
-0.019002002607390676
-0.0025050145376556004
-0.012240220791036698
-0.006351856710486905
-0.03440553379197447
-0.04026631597479151
-0.08764985187159448
-0.0673798938561895
-0.022613171171407015
-0.0010519574659620771
-0.0249504792813657
-0.07200623621273923
-0.04965655799524964
0.004717833829158184
-0.008884546247818117
-0.0015621348636309183
-0.002762400980294992
-0.01566118030926334
-0.005990577483892206
-0.001320746600110819
-0.00815110932483228
0.00635904792522464
0.0041196806758437565
-0.005463382858612547
0.01036244852789298
-0.0032880333610775577
-0.03250689560259794
0.01315390918141196
-0.0005948515772428858
-0.020693230337095157
-0.016524249531584094
-0.04883829300872651
-0.04196667724150923
-0.010031310093997204
