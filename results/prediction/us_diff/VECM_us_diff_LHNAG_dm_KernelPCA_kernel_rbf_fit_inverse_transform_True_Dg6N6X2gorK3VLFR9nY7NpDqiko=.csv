# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; LHNAG
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=3, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0014578025091858487
0.009893837272866763
0.01451111772815129
0.01258739166554456
0.0047499412017713094
0.0071077744559018595
0.011392289569511289
0.0036421300907155682
0.005286826646916442
0.009261855811260213
0.00899601426208968
0.007817095271314465
0.0050472386761909625
0.0031551293004495216
0.009717723672009923
0.009447152284453128
0.00975508890933042
0.008342737575369177
0.009336735101656802
0.007556594765548959
0.008418375729808494
0.008164691297822255
0.007901469919195088
0.003770615587237119
0.003131597203262384
0.005030595335931071
0.008165506351547672
0.002761258925163451
0.0027533121460075766
-0.002677399195021789
-0.006498137969538547
-0.0005603625414323538
0.0026104614327342917
-0.0006674464407206553
-0.0001318970369951272
0.0021052722968943898
0.0024682461499209575
0.0028813931374682385
0.005398766009058168
0.003914730518829337
0.006803877522987796
0.009343027183947328
0.01014662067784401
0.006959539715246084
0.006452530516112169
0.01108652000199391
0.006595678381800613
0.0032386014726181723
0.00512554086129055
0.001617398875482071
0.0008551529915497534
0.005658588558594535
0.007944885046615505
0.009324875123759265
0.009757043031865986
0.00918887559974045
0.009713861980507485
0.009324009724069235
0.006316479441894672
0.003228637153180235
0.0020380982689604077
0.005848435311531108
0.007660176627557613
0.004827747695905609
0.007908157481580263
0.007889026217725414
0.0177834978728415
0.00638661827569644
0.009209551463701064
0.011461751081648243
0.004951987615855191
-0.002361910264695578
0.00041257821992301695
-0.0039483773630151105
0.0001413984289500782
0.0015656193559436997
0.0016278385778846869
-0.0023864707838306214
0.0026008016366817206
0.0014268402349654988
0.005767951869890744
0.010021899144856428
0.005348852502633396
0.0036126631277473465
0.0040702591777866445
0.004980243571375045
0.005772086912771533
0.005688314511590765
0.008118495666707685
0.008531658494270015
0.010205227227155077
0.005701235247317804
0.004482187146940133
0.006564826955789862
0.007015443759578759
0.006755499567182155
0.0037553945982552635
0.00044597877214841214
-0.0010138979424680389
-0.0011278453343207754
