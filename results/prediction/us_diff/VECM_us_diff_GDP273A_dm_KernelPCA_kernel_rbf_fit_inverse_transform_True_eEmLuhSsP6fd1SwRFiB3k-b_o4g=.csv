# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP273A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=4, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.005672403042818466
0.004395476664276617
0.0068542950299765116
0.00697621687324186
0.006428584654728179
0.003869040872029149
0.006730554804974377
0.004939002539556437
0.004187050484961039
0.004651223086822281
0.00385857395550402
0.0022697562484325895
0.003740481700128079
0.0032480672077759925
0.005548592897484851
0.006979495993192799
0.007427124204776366
0.007174965370773422
0.006857493480276184
0.006946111745446232
0.0087223139400857
0.007719744430700697
0.00879106518109317
0.009260326861402745
0.006868506827051181
0.007001294826453733
0.007584901236618074
0.007170437177515485
0.01003016050898993
0.01041038820630201
0.007714172413236017
0.006281857918231536
0.006169525796876729
0.004943872879551667
0.005731206650539082
0.006150582939473563
0.006092003471471506
0.005562431910490186
0.004789955386366673
0.004089111830784472
0.002807125550127671
0.003915996269192401
0.00434327500028073
0.005752913827401733
0.006842752437090115
0.004865982601398595
0.005919945994847642
0.004199452709063837
0.004258439688308998
0.004333845778503304
0.004049394408620678
0.0052906664517590775
0.004871647548421268
0.005919481177782225
0.005151689207774483
0.0040602138214552285
0.00278116257377574
0.0021603136968482203
0.0017063600792657698
0.0014309279100517608
0.0016824728885604088
0.0022978945326540086
0.00363561352830063
0.005393816597187883
0.005171752693275026
0.006345320417319076
0.007201732711670922
0.005658004123573594
0.006294210240833391
0.003983586642120909
0.004980339663245759
0.005696769376109016
0.004707261873312413
0.0032585382442408533
0.002255988533090948
0.004057260047023568
0.003694390678932912
0.005033146228856855
0.0057625444001760395
0.0031613777783631603
0.005686179805661601
0.004411813758301976
0.00723578549931839
0.008666609609248227
0.007531800180397904
0.007420290842673682
0.006033385306997127
0.007326343288225179
0.009039723722845347
0.009451791484553782
0.008560545649402965
0.008272207651975196
0.008730970105251774
0.004002609743779794
0.007413421368172759
0.004405107083105406
0.008777841805538436
0.009985623783816799
0.009221441666794247
0.011888569738475309
