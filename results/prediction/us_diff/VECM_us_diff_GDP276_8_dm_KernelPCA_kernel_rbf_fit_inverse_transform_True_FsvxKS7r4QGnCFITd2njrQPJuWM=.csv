# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP276_8
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=2, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.008218069266827053
0.004482603842378264
0.004268167397417734
0.004557808803888407
0.0030541282126784566
0.0038184736348912227
0.007437070669247017
0.004476222437014419
0.0020261541732934057
0.009516416226834957
0.007211972118711305
0.008276153631555764
0.011572623014956051
0.009747596980684977
0.004839449862706431
0.0009118835326286745
0.004957776689787872
0.0023554628123385415
0.00908705113060916
0.007120567514701757
0.007480736891417416
0.004519830716711355
0.00659491136898758
0.003063629289313559
0.0023796060805669414
0.004383406307585029
0.003965818679236935
0.011872630696437625
0.005609222286342902
0.006300115382944024
0.010831361430232257
0.005704817726646137
0.008999593027346304
0.006362537379421797
0.012931217989814585
0.008055445249680764
0.009310517559640935
0.007053600867101918
0.003359771942883294
0.005614193820809391
0.0033944339657125872
0.0027313226975109804
0.001423462504801089
0.0035094078843727877
0.008511070956064055
0.005538919177128834
0.004426999384670144
0.005314138875293941
0.006477198774957045
0.005112442785412576
0.006064042170950201
0.006844995114240613
0.007152699233539072
0.00741885710893646
0.007094825077088874
0.007123049678401147
0.00583486402963782
0.00564651901366791
0.0048221639579229345
0.0017897220351551046
0.003206739022737391
0.004826982621121684
0.00324451911383991
0.004731618088764501
0.0036954461284110568
0.00619659205360982
0.00869510319598977
0.0027393430055547593
0.0014190388932409498
0.0002474723622880074
0.00610640429184827
0.003210526933433981
0.0014161052811555016
0.01196903578386776
0.007538409755648326
0.009993658470632029
0.006180750217557654
0.007936087088818704
0.00616448258916139
0.0074324516610678746
0.0072745639736497714
0.008342783947534451
0.0083693750246566
0.008888012831756073
0.008265569422437289
0.008818760763422145
0.007913885195007206
0.009767403262986505
0.008076608936215115
0.00833549364709833
0.00861246837111606
0.009459292966551746
0.007491766710518648
0.009483895045850878
0.006893671032677674
0.010660343527854665
0.009170729132692654
0.009978037263131727
0.009477477862710647
0.011625553588219414
