# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; LHU680
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=6, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.0008321970625337766
-0.11383182416956424
-0.08804504157560096
-0.0737007859356992
-0.03241202844500431
0.020976992463614834
0.0037925365127539565
-0.003659635228221842
0.002205065387105811
0.006540267690731821
-0.025235533725295634
-0.020906788239068518
0.013017751628274923
-0.01601407705391581
-0.0036324719501134627
-0.023065244615374715
-0.03253640166408976
-0.04423926401989155
-0.014923320332447771
-0.029005362323184194
-0.03331217666497489
-0.03283829231328264
-0.039971247359598054
-0.015333049551066581
0.007806019303468179
0.006632717006997397
-0.003980747900938128
0.009212218868465995
0.05914625028743033
0.02745411597265829
0.08007841995427506
0.06899335998657255
-0.009083578132863765
0.01794510526189133
0.06035421257888859
0.046373287783897765
0.05281203966736877
0.06208865676313096
-0.011598455661970774
-0.013218817718090537
-0.007625134501616965
0.0044938715748395015
0.01715972927159928
9.299621063574119e-05
-0.007307609094050441
-0.005562160396061275
-0.06762742305645282
0.014775817088929537
-0.04489003095323425
-0.005546214798020429
0.01465717860003412
0.0437135267484035
-0.02531031206098623
-0.025538785638279424
-0.026372044870949764
-0.04977771077193242
0.012855454406442922
-0.04336729058402439
-0.017848986088887735
-0.029359853485773187
-0.005899268832886773
0.015894221390432263
-0.03430558977729639
0.008201075999455992
-0.05828576660848184
-0.027856752886927308
-0.05948541093519337
-0.01710859177917054
0.008981647221936723
0.0016790328632050162
0.04573888027557449
0.04005458845100054
0.08897560340081849
0.06523190089417669
0.051280445294553396
0.0361620925552321
0.012176936299393447
0.06324012995982434
0.00820027157170283
0.07546409946919772
0.05058762642959076
0.007309897965105929
0.017371480850479213
0.0004125187864269051
-0.06005160389963336
-0.009460472193184872
-0.0006194346372386857
-0.003653290522123121
-0.027685909819765566
-0.022196014539939517
-0.03455106466445045
-0.032383249816916544
-0.016730979452468188
-0.018699938965896508
-0.012506971234850162
0.003972556475802216
0.04225670374049227
0.024944554555161168
0.013494278946989364
0.02520690432142342
