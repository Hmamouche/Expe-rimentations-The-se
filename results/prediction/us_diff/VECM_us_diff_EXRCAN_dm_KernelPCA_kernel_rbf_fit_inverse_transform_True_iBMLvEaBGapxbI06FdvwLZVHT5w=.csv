# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; EXRCAN
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=15, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.02000762419428421
0.054144037888504304
0.003032861008035813
0.016732506419226793
0.04689904967375714
0.041285631408939615
-0.009903881691765756
0.05384326922967163
0.06122077723129929
-0.0030345395677949067
0.045896309966827656
-0.01409279904250611
-0.03538758868852364
0.03488257067358975
-0.010114000486166716
0.0010426142820839576
-0.06153959920615247
0.012035051149960327
-0.055245909235214996
-0.05633980393510081
-0.05740962339565288
-0.010222403352292781
-0.03343119820310229
-0.015443262798991155
-0.03825650604870312
0.01127761436430442
-0.010359471222499705
-0.011697559936488869
-0.03286874887270742
-0.03737560244502811
-0.041332845379846696
0.02497391600058973
0.006192593675316951
0.009874925635145554
0.021464721441694097
-0.030750993255078178
0.02870932112392891
0.048829693441162975
0.0302790519723614
0.07800291525799488
0.057447010023567543
0.009758232081186272
0.03866563414716509
0.04938883391555336
0.015010220396526648
0.011232562791039293
0.022152081904180145
-0.021189220710155866
0.05140359795846803
-0.06530960980111121
-0.008331262566981048
0.00382326413599513
0.03513176411566482
-0.021183952643567282
-0.029585545491918473
0.006727454212057995
0.013439560235588299
0.041106939009368695
0.0037280678685934904
0.03255380378955677
0.06956896721909954
0.06491147989769241
0.050778283930885015
-0.017916936830873594
-0.024891585225134485
0.015071153655856987
-0.03705727078317351
-0.008295107956138765
-0.03321644990439401
0.05945302998298362
0.003005631139952597
0.03210144022748191
0.020552813812556175
0.046180477847731494
0.041838602594778215
-0.01216162979208255
-0.00923758061452743
-0.044800993825594576
-0.01879590429430972
-0.012051535669628598
-0.023534020595248388
-0.12768326828611296
-0.027072465445380386
-0.06353513081856514
-0.030001609637977836
-0.03693902781166317
-0.04275893028731819
-0.06000860193033851
-0.016645116680687178
-0.041656527501225185
-0.028977725029259063
-0.0514686059974739
-0.003827363519572023
-0.0063648235081812535
0.027796783130071112
-0.016682591564083304
-0.02059450716990073
-0.10551916293891692
-0.03177631503240934
-0.06049045338467621
