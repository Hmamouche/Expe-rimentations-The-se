# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CES006
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=10, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.007956595509041688
-0.021304201416515713
0.006770669220346637
-0.027453534726231577
0.005911218966117446
0.019017314974659406
0.016939018214323295
-0.07387780056363372
-0.02637206755173677
-0.053410089774495934
0.0032664410751337336
-0.029049945403339824
-0.0700175363192646
-0.01806419321313857
-0.0505600486743947
-0.04401043697334803
0.007060788548142743
0.037838331012681144
-0.047367722672603425
-0.0008669827896688406
-0.024345777781246657
0.03779442234901878
0.008153013239699424
-0.005651084540757548
-0.012097083718480756
-0.028129325819621097
-0.004655196052366913
0.026215371756274353
-0.017701843541716233
-0.0399820390174916
0.0512503580552775
-0.05245516304277266
-0.00565082825337887
-0.011022784265710552
-0.032735448675384006
-2.5764932952317132e-05
-0.03272751425843816
0.0684265632690503
0.011170524476945078
-0.02666769159147209
0.008695006981884102
-0.038471559556707224
0.00711089301218509
0.042202351618395556
-0.01956470287977025
0.019618717963402105
-0.0008003677882053861
-0.037320673790063395
-0.0025483028169593037
-0.018894761601594486
-0.014958283958420998
0.023860951624415705
-0.008504509312220134
-0.04453453766994583
0.03920272056144924
0.014207254858691176
-0.004339472532826547
-0.003299279312041655
0.001383004864706697
0.018060193887504447
-0.010483068769777164
-0.025555312677297555
-0.007100558035405332
-0.014782433183823464
-0.012391796940733418
0.006052108816472251
-0.02276639896112738
-0.003828034343113116
0.008591952689185719
0.010298238507385664
-0.012849002179081108
-0.010932848429746157
-0.03615698154430859
-0.04701536289166611
0.06536887884250003
0.018300959646370372
-0.029326801398983967
0.009665952548349302
0.00291867812691168
-0.019835826724029303
-0.007694645841047176
-0.009646346979471317
0.03647116820797139
0.02282435824086173
0.011348919294947926
-0.034343801210988976
0.03269563350500239
0.022355642190000607
0.023795753276631467
0.011430804152710482
0.017312142010510824
0.02391754429921068
0.027274156905055722
0.050981789411109674
-0.01314979149914478
0.02270483111738979
-0.001460738852194791
-0.008869850935951959
0.008062285311944287
0.025183668012753572
