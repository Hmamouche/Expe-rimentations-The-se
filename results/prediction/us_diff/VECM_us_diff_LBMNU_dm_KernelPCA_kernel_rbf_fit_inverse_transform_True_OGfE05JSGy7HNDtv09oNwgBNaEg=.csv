# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; LBMNU
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=7, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.011015568860424672
0.018643902162240072
0.023709026389433233
0.013088760321588037
0.007385635453938749
2.9486445839889755e-05
0.02598112098697517
0.0032925504864003583
0.010617121172645275
0.00966823286477605
0.012197220773210699
-4.7178390119414354e-05
-0.005708480396204112
0.002299558631458496
0.014078526607747248
0.015022751979048673
0.015581034329315874
0.01297820762232333
0.0054226770251455175
0.018218394123112505
0.017853578646929467
0.02262483465838932
0.010034253654956936
0.004456205057191874
0.0006433555741460831
0.008539856756704673
0.004061433630367368
-0.0039340583038172654
-0.01854348647423361
-0.02108987467196737
-0.007123765842648988
-0.014918400993897282
0.014691951289800331
0.0028894740124037303
-0.011019618987866669
-0.005151573099080942
-0.0028291693320573645
0.006021494542993207
0.011709860586549346
0.009993968322408326
0.018257720535729747
0.01766668768543474
0.01580499285303945
0.020411366461953396
0.023608914206118402
0.014219719528310705
0.014726547551096893
0.006185832796647705
0.013529695331192738
0.006823699477392921
-0.004029650238476201
0.007970654414357693
0.011882707727037195
0.01706866550200123
0.02513440265697863
0.015446206515144717
0.01956522726331249
0.013275504606787041
0.009640497044593084
0.006488675277870767
0.00022046210736855452
0.009038185616620174
0.014370006112910158
0.00560154802210003
0.02072509216803906
0.01884726287973023
0.007326900101372534
0.0017418776590657332
-0.00033216896386087597
-0.006121190130709988
-0.008629241874899139
-0.013768003593208775
-0.01832420087365697
-0.023597775727400648
0.0028544585076221854
-0.008473410579904521
-0.014861620247743033
-0.009958235353764987
-0.010938447038374103
-0.000427247592425213
0.006849348937553252
0.013343007344808434
0.00964830588974565
-0.0018334988586189362
0.00133918374643555
0.010609002635275252
0.007123811265101772
0.0024511322180249986
0.009643777938076824
0.006197618615375877
0.022025624149937095
-0.0006158969831020489
0.005618790897702574
0.010967735774337762
0.011347057046574618
0.003941804897172406
-0.0023127282113419734
-0.011296756167198645
-0.012940755913739572
-0.007263017447478934
