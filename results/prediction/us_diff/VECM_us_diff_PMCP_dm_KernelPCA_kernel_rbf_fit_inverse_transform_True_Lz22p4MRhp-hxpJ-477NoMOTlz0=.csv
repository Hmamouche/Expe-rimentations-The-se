# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; PMCP
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=11, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.08600448687483941
0.13672492410009193
0.21383015235466796
-0.243819273183467
-0.0646473447202909
-0.048307073263363795
-0.04507934766104191
0.019145415823478534
-0.019297961705951237
0.015003147591686528
0.07511909998800304
-0.09703007412645012
0.03662780538283965
0.059009488346215416
-0.050342897457370445
0.06500504065528254
0.13605834378286336
-0.0024040613653869697
-0.018219892426182216
0.08562222553183985
0.06374404785613928
0.08504978119399195
-0.1258666956363395
-0.14979285481057364
-0.07633120549783097
-0.11693694016341787
0.05388892107664414
-0.08478344689529238
0.041311580445660794
0.14807018589445678
-0.15594457464237743
0.1379804538315907
0.08760125062261438
0.05261290404198386
-0.09064223642872496
0.09171139276214098
-0.12228964327622502
-0.001428288578032351
0.006504794283922109
-0.031109241931149872
0.0003919089834478334
0.047767119263701925
0.1110031407932054
0.11603286510450436
0.07893331548046877
-0.024378140597675138
0.028802390129402486
0.005349015922582266
-0.08619896496476587
-0.1595354269475428
-0.16388134408061797
0.17553895063554187
-0.1058568526107399
0.027323255812065753
0.09796685569099868
-0.0379148552284309
0.029650485291529534
-0.03033335482464805
-0.11264237086501794
-0.03186383292111617
-0.12872380748157514
-0.091606624700806
0.11101777061808335
0.05245414888751335
0.2004427217688907
0.13206014455614193
-0.0004522121928284273
-0.12567938374383014
-0.021263978256071375
-0.1148603128304165
-0.06305429825030846
0.048855141981249614
-0.06663207081895306
-0.019744383101999538
0.2266470132346506
0.11300972266719943
-0.17032833863791186
0.013486183162752796
0.01936820583934007
0.13858659083610972
-0.01805214274255361
0.20882972733387872
0.05641316524851589
-0.021043875746840638
-0.050839470204107284
-0.05537018056490789
-0.10462519301964865
-0.0373863990986323
0.021211474919560706
0.0394013796057701
-0.015089785806425015
-0.007140406481427251
-0.05199924274878061
-0.03359823943592756
0.05831967931893302
-0.0586545321352106
0.041896748773517435
-0.03667633946208368
-0.0245012493796547
0.06476685917232232
