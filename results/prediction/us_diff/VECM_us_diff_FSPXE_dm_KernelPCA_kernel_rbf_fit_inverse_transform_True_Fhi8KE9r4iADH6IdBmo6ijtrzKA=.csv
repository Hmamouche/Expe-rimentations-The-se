# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; FSPXE
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=12, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.027692264812613478
-0.0728747044072543
-0.03679122940927162
-0.057171926908086104
-0.015284715780266543
0.009778453844190868
0.0417694371055736
-0.025112490641544367
0.028212003404220514
0.05215843423277512
0.09354577059168831
0.04837173387586717
-0.01782190241562795
0.021439541314097168
0.04855097388217665
-0.0020658801070182658
0.02456494754672119
-0.0875628477110058
-0.06954457770848436
0.02855931925664057
-0.043868541755204535
-0.041966152966157785
0.009573073291914713
-0.022671537195297665
-0.02872035545369534
0.03467226675349715
-0.009622562649923717
0.0035427603897565715
0.0038082656689399394
0.007665385139240761
0.0776880134451831
0.008002909565032412
-0.003081161069743616
0.042292589924623106
0.0635978704452676
0.01048947791415948
0.01767490965070732
0.04853592374647865
-0.017485425591345367
-0.025669167469463346
0.008411744701009445
-0.0036825691358759157
-0.05682432186303375
-0.03161513025573901
0.009071475246886774
-0.061859592027106704
-0.052197735259954116
-0.014153107568274216
0.04837046426284269
0.012153854662177218
0.025898271238508623
-0.010338174750027804
-0.0142582937469476
0.0011224365880466453
0.035469268928933026
-0.00970396662761623
0.043498191272296156
0.02726665351947242
0.04064006774967697
0.06245669096604883
0.020927758483638502
0.07045122613444313
0.0529629598552532
0.01382427374726867
-0.003737492559587811
0.020375518765573822
0.009419817780286381
-0.021942732885200596
-0.015635303650457205
-0.026291064341475216
-1.740360806031004e-05
0.022966488110376673
0.01356305591890149
0.09458992509484047
-0.08117303885973064
-0.11773671770500077
0.31243324919145854
0.2139742568292452
-0.03570935864912633
0.0270568234278257
-0.010007685707629114
-0.03182066393686782
-0.05804801532851693
-0.11645356930317285
-0.11158751913109458
-0.042700243437896995
-0.014234580872292256
-0.04766909390258423
-0.01644141784255683
-0.0274794371457784
0.025749563084845987
-0.07926370580005217
-0.0032516163467407547
0.011874063731834708
-0.035947064105471334
0.007808285606401005
0.008831367171571576
-0.025796057919253726
0.010724581407870722
-0.003775006618993473
