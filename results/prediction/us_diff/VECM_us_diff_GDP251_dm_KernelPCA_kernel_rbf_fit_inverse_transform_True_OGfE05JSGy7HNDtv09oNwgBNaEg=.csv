# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP251
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=7, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-9.632789917726065e-05
0.008094189792479362
0.01222858201678959
0.005370159783802858
0.0051979611734901425
0.00448564067381106
0.01258413057934681
0.0028996139202267885
0.00787493151808593
0.00921929815068228
0.008880969208768477
0.005876734259573842
0.0021041804004245388
0.002714814531934652
0.005520071410759889
0.006245052928827542
0.005246009191525456
0.0057376228668553665
0.007485454788806087
0.008889462056487595
0.011242960953881973
0.01280798364343412
0.006154890726571579
0.002878001693992837
0.0033186317896967774
0.007305337766116534
0.00411413179287393
0.0038768075424736566
-0.0011714761565620154
-0.004861479216421991
0.0009313453771333882
0.002726404322642392
0.008035254363713561
0.0027051831121842314
0.0007819834035504162
0.004652582573056355
0.003503116871287742
0.011657013128991305
0.008801984717104094
0.0009735552986926211
0.008077370826002787
0.007424130228299493
0.008935053556740308
0.0067283775892430136
0.007868576450396157
0.008246324752161914
0.00684816749288424
0.002500665908757346
0.006910597411942899
0.00614761972212372
0.00420631538051048
0.008344937297560707
0.008049781020383815
0.008165587939468021
0.011437804011109639
0.01062907054117904
0.014066081738058659
0.011122660016227387
0.009889430279340479
0.008162413664122986
0.006827171974669373
0.010198347836865419
0.014058019508969623
0.007339780969870942
0.009494777866571479
0.015071601690857361
0.012294372400494052
0.008401425842035584
0.01024914127613445
0.0040640340648749225
0.005906680930246244
0.0033313141943668136
0.0014806699377937034
-0.005704271879544011
0.010009664131850013
0.006014283901938252
0.004318314560158314
0.0037429056830146114
0.0008559280890016092
0.007433702415456026
0.009246603677981196
0.016421728827403077
0.01066654384981851
0.007618104328957927
0.004763030831673324
0.009997809053815346
0.010300156770877767
0.00738041169754236
0.008496807460369411
0.007585142349345416
0.00955512487325921
0.0038479827771164955
0.0056183057147572305
0.008638389288435872
0.00658486010860362
0.004865932395302289
0.006730274968843932
0.00039693375251900786
0.005122093771349131
0.008272113970115682
