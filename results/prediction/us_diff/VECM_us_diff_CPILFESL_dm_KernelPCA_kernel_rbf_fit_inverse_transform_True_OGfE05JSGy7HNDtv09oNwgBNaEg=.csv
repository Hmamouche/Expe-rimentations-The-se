# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CPILFESL
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=7, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.005508091270403852
0.008633244240873847
0.00906041275590267
0.008604199650369772
0.006126769709187273
0.005282632479499326
0.0073818945741600285
0.004344001555070727
0.006003240879656062
0.006080334961494332
0.00710012356289079
0.004118165538923004
0.0054787812948252634
0.0067780624773616125
0.005165472354884449
0.006449196998010812
0.006452491669629081
0.007475171413813644
0.007141716384076017
0.008679975097552688
0.007107279300249769
0.00945749530892806
0.007966499883620484
0.006887862797241483
0.005745874898359555
0.007750354262077927
0.008350013598841438
0.008892165820574607
0.009986458268166954
0.009429967513912889
0.00980667688400861
0.006338337307414182
0.00867092198906201
0.007175751673893803
0.0084802804388078
0.005636312442259133
0.005046940988104571
0.009441284609892
0.007300391717340837
0.005867407605102025
0.006694652057353516
0.004713514505864369
0.005863057293802135
0.0076459362592876815
0.006271888443116937
0.006839434301031084
0.006121183643828841
0.006722603351605944
0.0070180482921529804
0.004530680682593021
0.004873348639101608
0.006664487839921087
0.00483771115556165
0.006016706387552733
0.006422347899830472
0.005215388351852179
0.00473573858331029
0.005042780546843743
0.005234221839493239
0.0051589621276325656
0.004766773598870218
0.005194441779564577
0.005589471273747802
0.003810534884267492
0.00504999215168742
0.006487556370483621
0.005950211565560049
0.0061337461274265865
0.006651888704901729
0.006164081097931473
0.00481314147285793
0.005593992949907397
0.006360744017615459
0.005337089753080476
0.008593943949802223
0.0047437462821490785
0.00586080397209284
0.005401523947860489
0.0036740890635763397
0.0011581050380313205
0.003756080466333974
0.003348060238068634
0.00449570246094722
0.006980454803491664
0.0054438950122603896
0.005548900416491217
0.006960655099737179
0.005790305575456912
0.004450488137366358
0.005554000289782551
0.006579389836398222
0.008866323379235888
0.008344472121330163
0.006274804106714448
0.005432888110527938
0.005928083063963195
0.005715238255729816
0.006762592472273557
0.006018004258935182
0.006319305899381492
