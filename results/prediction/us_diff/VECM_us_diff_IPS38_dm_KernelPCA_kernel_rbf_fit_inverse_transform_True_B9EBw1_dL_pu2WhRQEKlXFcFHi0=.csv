# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; IPS38
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=10, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.003587134043478428
0.009167739650157124
0.005875225301495597
-0.007573225383857626
-0.003690066260635341
-0.01623076487484501
0.020715787989602108
0.01227161033901404
0.0016681774954963261
0.010438871117655141
0.020185956156380705
0.004732956518422983
0.007940572820250257
0.0001253572857643605
0.013145914713442746
0.02510068331664673
0.022245359791430577
-0.008754726382067833
0.003950084461666895
0.014884193654931804
0.02345488613980882
0.001887587261855562
-0.011542731793550975
-0.008713291323822314
-0.005285865300377832
0.012167757451992833
0.01209423219076933
0.00048717954808238494
0.0016482593711744996
-0.021305609594351606
-0.0007407972091911519
0.018140806668391556
0.010488699002561977
0.0013263882273066244
0.006652653702383553
0.019558322899372704
-0.004264190870320234
-0.0032098059088838168
0.007252247933984676
-0.014757701572053994
0.01717516746304975
0.02085875982026708
0.016898655980724903
0.007465478904224425
-2.6818644764653194e-05
0.0008941430413795201
0.011085695362284325
-0.01626520010506773
-0.007117229712766486
-0.012308496146986115
-0.007106400889283835
0.03629112633840606
0.012176078280957712
0.02373348458900173
0.012856732454982183
-0.0007475604821435625
0.012109722417674905
0.0004416570232803059
0.010450634952344523
-0.004384563136595712
-0.0036863821432307213
-0.001018390915926799
0.026009571258040924
0.014814096996319241
0.01809316048297202
0.00047057442653570744
0.0011306049286385206
-0.016826795551890126
-0.02655909221928884
-0.007674039720709666
-0.031130481500062895
-0.005331562893085971
-0.01704696054428332
-0.006727136209210444
0.043150856301941265
0.0032419928166327787
0.0032558709763567473
-0.014390802351121609
-0.01947884878191987
0.01566643882224447
0.009998919382981641
0.019915779046793754
-0.00026043231798596016
-0.004852159084756672
-0.003450456806470483
0.005206846324900352
-0.006851822029198377
-0.0029616477215332355
-0.00837133798580883
-0.004179685377108404
0.05304401067956728
0.014920556831632879
-0.01753905800225505
-0.018115265321175963
0.03084506601779957
-0.006832886851263958
0.00767596862210212
-0.006613583669435538
-0.012507389250285455
-0.010317753359284714
