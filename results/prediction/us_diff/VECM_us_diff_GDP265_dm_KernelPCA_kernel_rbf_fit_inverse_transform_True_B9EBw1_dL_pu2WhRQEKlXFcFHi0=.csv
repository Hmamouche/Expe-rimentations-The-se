# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP265
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=10, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0016601715681912824
0.005364059725122417
0.008259649204118879
0.002933896964378081
0.0007748443536379278
0.0017711047538578571
0.03006239175279452
0.003526442362307634
0.024657078453712573
0.0067630499668495745
0.014676003673363752
0.01282180730059081
0.011800258002622736
0.012906219352598274
0.0016016495306343833
0.0127941860784622
0.011450382510142161
0.008148276816076987
0.013792264906008428
-0.0037904367075363744
0.016058084403162417
-0.0001264928364664952
0.009735484418512373
1.9322698173375452e-05
0.016892038946080153
-0.0018170654523702937
0.0133386920852786
0.008514814693799106
-0.00043208126724364254
0.002303781917739268
0.01064663369485719
-0.00011348589862600973
-0.00019788865650057462
-0.0006440627852996681
-0.00214210750013028
0.0014235282602174056
0.0003330426848796614
-0.0035839794388889696
0.009275272773903321
-0.0005367071275531438
-0.0024244123297999004
0.004555068585570454
-0.007738487263113597
0.0004668955364899663
0.004332850486213058
-0.006261447912924937
0.020324280169730695
-0.002916465255540409
0.003228155539751478
0.0007108268171980513
0.003421463344469879
0.0037074754574847628
0.0015609023682077506
-0.00537149166186421
0.015248194056549357
0.0025950596832831616
0.004857015720441466
0.005866609292850282
0.006242496853955943
0.0012328136047981405
0.007890021291027938
0.00332801007378042
0.013424475552338534
0.013122524772510642
0.011456315583274299
0.0023450152660583696
0.017418543111305557
0.011562102148495294
0.009823802059235845
0.0017918059926412488
0.0071694278812860866
0.003164219238776209
0.01015120479334133
0.015787517576195727
0.01741180580725415
0.015825857542387724
0.017428037040340363
0.0026173519733710847
0.022408708486667143
0.002093198997296237
0.0038123560816842915
0.00574842457318534
0.015273271413472341
0.012088451827468137
-0.0010384448512985476
-0.004035167706556018
0.00998066780630662
0.002532275790394633
0.0044418349638891234
-0.0035339424742478307
0.009087036053658414
0.00038336522147241884
0.00472658871922505
0.000537521002797707
0.009595017923104635
0.004947052750050465
0.009217842721573104
0.014573406625096203
0.018821519901690682
0.012590567406124215
