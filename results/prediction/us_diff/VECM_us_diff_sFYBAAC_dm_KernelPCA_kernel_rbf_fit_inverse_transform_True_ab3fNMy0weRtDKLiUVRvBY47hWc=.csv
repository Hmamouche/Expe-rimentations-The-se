# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; sFYBAAC
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=9, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.01289958501845656
-0.08149591138521442
-0.09969334578463099
0.05993512671437398
0.03209563901707897
-0.015852922436234873
-0.08458918723976974
0.02943538513381909
0.01398218564979431
-0.021829087148602468
0.03799023267421451
0.0013942076399581262
0.08876489773142537
0.07447599284858976
0.03213757929943914
-0.02983019297577714
-0.0004188076723968589
0.05847075884942564
-0.09257482120290217
0.006687780650916705
-0.046425789186478814
-0.09596255459777936
-0.019901663555343466
0.03082644885996551
-0.044546858857194914
-0.0028542834069889243
0.0015530638142386283
0.03103819479930387
0.05591298517131843
0.00770986609982113
0.09827553732384889
-0.003571135782041074
-0.097082320529646
-0.11374866417460279
0.003088617584420583
0.019617093115822624
0.06377894112612575
-0.02386545019025316
-0.021363424525416307
-0.003656772591858863
-0.033931943872588397
-0.03899790723438184
-0.0060695009890624554
0.02838709896335636
-0.042302604854233435
-0.004522642083282069
0.004718128394717067
-0.07666684965048348
0.023162311833586045
0.02000186551405668
0.039289420231272056
0.0076285991353880625
-0.023566312712139874
0.001676181200410333
-0.04979966847664244
-0.02229175804298087
-0.022157912714926474
0.011905451834187383
0.007432286024531831
0.04438495940565684
0.025083479854234154
0.09487321669479956
-0.025416296036765276
0.05043242221311606
9.075667661266607e-05
-0.002672792432228937
-0.031822577272893705
0.0705564110703588
0.01707498784606986
-0.03924005463492947
0.0992058812168212
0.01726974213179545
0.09737681258841377
0.04506005504644105
-0.09962069933672421
-0.018988942611639706
0.026254123063289406
-0.007357267679407822
0.11079370940447436
-0.09942098817387293
0.034862311756958315
-0.0908655228683659
-0.06475847685873923
0.009459534942074948
-0.022788376985310735
-0.0009556072869977734
-0.012907787954012373
-0.004777581987148172
-0.0011231730565297096
-0.027049126230407224
-0.034822046508416464
0.041085719000387516
0.002670994312914992
-0.018263487126403084
-0.017667817978640567
-0.034244696645608086
-0.01335410321679351
0.11406252353154679
0.10201543827094883
0.030355524579508165
