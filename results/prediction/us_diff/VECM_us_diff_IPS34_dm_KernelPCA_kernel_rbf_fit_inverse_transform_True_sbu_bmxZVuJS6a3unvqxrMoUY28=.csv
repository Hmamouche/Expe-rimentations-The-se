# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; IPS34
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=1, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.020349074952309854
0.012615485671557005
0.00785012374830433
0.009549911435619916
-0.00176123268331119
-0.0003119587237208612
0.0022059375225203393
-0.001004160267548313
0.00442007467812573
0.005844691183217303
0.0009424453280969081
0.0026108048453435447
-0.0008855947429424382
-0.0034312344475834577
0.006369757462133656
0.005525764950922025
0.010482840281975513
0.002292285657028139
-0.0002935882050260391
0.00922839631764447
0.005574085606257306
0.010147735771092866
0.004364229005027391
-0.0016906271531734493
-0.006708965926579501
-0.0038775892273400342
7.348345285864441e-05
-0.004209176495091949
-0.0066086515006401995
-0.0057207786642165664
-0.0048881434392563025
0.0024959348907024354
0.0025959700754734573
-0.0034228743527369414
0.004381539735143718
0.0032092069947952952
0.002434178955881298
0.006868556648497897
0.005416641742117983
0.0033295124304943873
0.006636864601046196
0.008079870182729754
0.011127428718654204
0.014497481421722693
0.01006902997140104
0.012825001965702089
0.0036338529287472674
0.0008665212866576367
0.006870913070267446
0.0045487561952083175
0.013555440001406164
0.022295524516981125
0.01684216233900121
0.021054675630860935
0.015152372998554741
0.016013437714156586
0.02136971117120399
0.021947928169687696
0.022321362252359714
0.020782132509325466
0.015194863311134066
0.014158668650825074
0.02040750783034645
0.022608487300655213
0.026205776535614737
0.02858145515179087
0.022633309107519865
0.02060983193017401
0.020054756450966
0.011555964771745659
-0.003841860511657206
-0.006740660825666483
-0.015451513277101677
-0.01966308762173682
0.0015391428241013467
0.007561954217832117
0.011125724175425546
0.0041881573186202375
0.0061321357583857
0.004849707738543787
0.013213786954990583
0.017733738018533778
0.014096512137797914
0.011305186716073706
0.007619507677248495
0.01267213483568759
0.01418187191352622
0.007405976327200787
0.016462258488703817
0.019981043328249945
0.014940784242701545
0.009717248869952887
0.003859279770201963
-0.002676415947666335
0.0054062937999034485
0.011722402826170389
0.007466727645200974
0.007577019282775174
-0.00018166309016419023
-0.0006811044837959756
