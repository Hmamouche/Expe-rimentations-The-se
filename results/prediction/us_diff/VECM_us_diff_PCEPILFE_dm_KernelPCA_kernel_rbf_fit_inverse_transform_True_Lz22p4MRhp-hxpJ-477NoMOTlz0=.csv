# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; PCEPILFE
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=11, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.008371854529168776
0.006619795913737128
0.004376624535543303
0.007741732066691758
0.0069630239055200206
0.0048834937303649925
0.010572090712475753
0.006174893723927235
0.004734389142480413
0.005662989241835165
0.008114470066772794
0.00628496061963733
0.007087558884923077
0.007877163468510674
0.006120983934384603
0.005749874924064715
0.008251290783994654
0.0065085555525578554
0.009259420580198975
0.0074762348569910025
0.007737257599053096
0.008322351526242824
0.008584901925188782
0.005874378491857909
0.005602583676224529
0.00639425174102604
0.008095569860696764
0.012474936801454738
0.00783860927831962
0.009426924146416884
0.008277392290882795
0.006775453635434895
0.008569283432008386
0.006964603781196101
0.009625870801083397
0.006480468473197796
0.006167064278173982
0.00560421908333073
0.007559790470292538
0.0052906876273742486
0.007226593772901967
0.0035199030805758394
0.004838125889234939
0.005522831617223741
0.008122231558470692
0.004833706161894067
0.005743164017531461
0.004214948807045892
0.005475770475637666
0.0061087677061430435
0.0032247080140503396
0.004796796684017607
0.004238300185753826
0.004303957207587591
0.003882517863423946
0.004937792606432826
0.002703165706115379
0.002954802179953144
0.003356907934540784
0.0023327870341477543
0.0034619718997866574
0.003561007885954729
0.004640056725955742
0.004167109809650654
0.0031282311279051764
0.00531680164617108
0.004259845948692119
0.004521635961086049
0.002158419375342617
0.00409790949878214
0.005686662544695873
0.0042684486675026515
0.004861919725432094
0.006038777611957479
0.006090414752018958
0.0049130390163442
0.002964793810859952
0.0046295951116573945
0.0026016303747550752
0.003971545211250305
0.0042771186998411745
0.004932171885855273
0.005923688473494818
0.0052012520951525976
0.005726328029876422
0.006054681153355029
0.0067567090528789075
0.005916330347404034
0.004017364141382012
0.00714333175248629
0.0055536564717207325
0.007975286368945485
0.007245517892479364
0.006211997206452541
0.007562109549576694
0.0058754961987200465
0.006860170069311424
0.005734546224682327
0.006680023693844273
0.006791993511866604
