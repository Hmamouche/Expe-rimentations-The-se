# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; FM1
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=8, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.009817930967038686
0.007453569458149204
0.006112185473886033
0.005557435653794212
0.007194911608906668
0.005859790029358446
0.006679712885230183
0.009328635387055514
0.010130625974416338
0.009544389055944588
0.012987374888778703
0.013534456014645374
0.01568057385304928
0.017482515321628443
0.015609533006450352
0.013404118118055738
0.00294202654083839
0.009546280184045682
0.008845655468524134
0.011132783479555985
0.006372001808050279
0.004243100696063551
-0.0020075807986393718
-0.0003877155996081672
0.0041383703876468544
0.008691259870487886
0.005927074024629463
0.002178815123401672
0.005073603254207578
0.0049826634686892125
0.010684357609565265
0.009539136821902121
0.007490027553290897
0.014730099521984341
0.022188805696916936
0.018812937378403637
0.01589249430679224
0.02167637032701089
0.02098006149820899
0.01949462835389468
0.01501297872949954
0.023569450007113694
0.012502563225661909
0.0074319574009254165
0.006126740298773979
-0.00035089045417126133
0.001979054567384922
0.00011132786875652791
-0.0008880732187898797
-0.0033249993163457716
-0.006946934738461901
-0.005307341729674811
-0.007739931093816152
-0.010523522673484663
-0.008850504249427833
-0.01097120216246652
0.00166679304546727
-0.0015320693813560679
0.006487851840794851
0.0009932015246948084
0.0006279585439527485
0.008581036017391259
0.0053451693163373126
0.004454095721331737
-0.003235027552127905
0.002867592783578787
0.0015249850946394926
-9.269368376358842e-05
-0.0020498629857872265
-0.004440029241274694
0.005664725155261091
0.006963853247256775
0.026464108511000343
0.018000592489493573
0.009118207237478287
0.005531099211260527
0.007554673442644738
0.009604086155375759
0.013459202513771744
0.01860447303239046
0.01139549650475383
0.009568764788353877
0.013194858473949383
0.01449075162341163
0.012606579243280418
0.010882049648515846
0.0027244105884394977
0.0004816056444856562
0.0033320785428388473
0.006491692532092317
0.004055515132555636
-0.0011788716424223373
-0.0033384005932763417
-0.0035870167362627866
0.0003472119789905265
0.005824374488288146
-0.001825234854731555
-0.0008992898404281537
0.005836855608689948
0.0016478936328644218
