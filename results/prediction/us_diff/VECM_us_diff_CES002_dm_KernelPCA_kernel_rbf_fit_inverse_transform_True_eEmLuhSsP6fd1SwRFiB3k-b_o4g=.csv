# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CES002
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=4, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.012043299730947424
0.009970753239400753
0.015104290869554046
0.011824693933483184
0.007154075255115841
0.011834581321558617
0.013431771611798407
0.01011107052258105
0.0068708835839749035
0.0076836459819639765
0.00783629328244509
0.004694516968749027
0.0035067546700277142
0.003422544076801126
0.009846168879866396
0.009888466570543684
0.009919537758893062
0.010625094215335173
0.0106647858255453
0.011975245253851458
0.009388179933737159
0.012495091901075787
0.008309420482140109
0.005136891513670023
0.0016039998418381162
0.0072598536659559745
0.008082798601679885
0.000976517802847349
-0.003641556915278955
-0.0064812792522646575
-0.006680180553920275
-0.004202520042756831
0.002926401603633
-0.0007119888936134945
-0.0016824590782759858
0.0016247822813900154
-0.00022967889096687204
0.006226106429163608
0.008004318518628057
0.003380816097311383
0.0092844858518587
0.01179537189550822
0.01267267458743583
0.013628407028703434
0.013789481029369508
0.013950079837183554
0.008579552688003585
0.008120481971365516
0.008130396730238448
0.006804302298878381
0.006100409383481255
0.010488888619294293
0.009450929532162963
0.013199507299146877
0.010331933037899354
0.012734333201423408
0.012610998769020831
0.011088801989438648
0.0108809074014279
0.007697736794110547
0.006808305185146045
0.009196346555278487
0.012143895109820151
0.00927286034608649
0.009749041371157974
0.012585377958854678
0.008515555438703344
0.004901698269687633
0.005628203798604409
0.003042968970414804
-0.0005357047122608583
-0.004948980852717384
-0.008368370191291736
-0.013047526799372355
-0.004809920619207875
-0.004795165264223859
-0.005165394157574614
-0.0016690087977649082
-0.004692723483805929
-0.003901207345126839
0.004458130393243661
0.0061270758698249985
0.006382508755220294
0.0061403313006719055
0.004388887769781675
0.006210081004757289
0.0063278709033166075
0.006353616424739061
0.011822811630191447
0.006798587198622756
0.012306846279938215
0.006465703411889957
0.0016930370667535353
0.006789769297261215
0.007480356682980014
0.005050327701963228
-0.000237156190675119
0.0015918791824453943
-0.00371627924130399
-0.005467718331694018
