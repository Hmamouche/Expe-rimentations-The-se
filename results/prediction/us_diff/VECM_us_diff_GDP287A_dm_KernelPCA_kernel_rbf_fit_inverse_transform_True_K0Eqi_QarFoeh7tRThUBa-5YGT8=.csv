# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP287A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=6, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.009275869763752756
0.0033888010090620804
0.005562354050611881
0.010178469722503388
0.004269094587332373
0.013733444646738955
0.007991385517790113
-0.0005457385707343205
0.004809014459096845
0.00514043023487057
0.0015346662753525945
-0.0009418310268566267
0.0026169644651222587
0.0012871019686668973
0.00271639919860043
0.005109015664609253
0.0025116282821506237
0.004716183056858044
0.0007216458050883492
0.00042664949155283866
0.0033457412972008505
0.004529269744904663
0.003955320457876599
0.0011925288250761053
0.0032007660820312605
0.007009789975868335
0.0014587135598254516
0.003470468588726959
0.0025611550731192393
0.008213680876020691
0.005721424073266604
0.006453084059571918
0.013271643689602975
0.003660307796488513
0.0035921769889711136
0.0047176440366276245
0.006252706566653868
0.008789388652983105
0.0030215181031601284
0.005230165447826577
0.0032045062083185367
0.0050855344817256915
0.00423983390042116
0.008746090392648424
0.007064864664423545
0.006634742670426347
0.0037125551085351654
0.0007219795486098558
0.0034955396775878016
0.0038008949354948244
0.004503106972195876
0.008405695492582124
0.011411829511864684
0.006429358569679185
-0.0013322439369846503
0.0025724457350407345
0.005402890916703136
0.005918205316453956
0.0014721632700278417
0.0026403445519433146
0.0027058908386075396
0.0026773978612626
-0.0001216758489759616
0.0014270017469357151
0.005128595160816431
0.010084608071062953
0.00585698217191938
0.005844514524962371
0.005272816282207204
0.009957852681514757
0.0020456480291135702
0.006155923693901792
0.003462358789635381
0.0038609717370144308
0.004242215566471637
0.00639209997509464
0.008942910267302198
0.010524156085846685
0.003057848839251815
0.004835865427825984
0.013679857879110455
0.016757353882051285
0.00428543850042749
0.006699411309917654
0.007915767451370818
0.018650823008049246
0.014120702547565232
0.007577278536983147
0.009431198288355834
0.02098012252107932
0.006395344093181786
0.009705018963412332
0.006191166491376413
0.021076622388887502
0.010192318788280672
0.004225123705119384
0.006169059487290326
0.0170430365043931
0.009901859466252527
0.004152896342192367
