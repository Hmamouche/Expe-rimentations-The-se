# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; LBPUR7
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=10, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.004414376546047228
0.00880410307049254
0.011110606958138546
-0.0055796019267887725
-0.005357484390615234
0.00981303601930785
-0.011219169696908376
0.00208749713329668
0.005564316184856824
0.007695311470646068
0.008757016803172016
0.024745768598163694
0.00948405386141849
0.008395922982123006
0.02234720353837432
-0.0007038715211218629
-0.0033134357268961127
0.0035071210606602912
0.0034840240057208696
0.009294015282026396
0.00066458811218176
0.012656786381906128
-0.001743593092651448
-0.015274455009766437
-0.0026049200393872653
-0.001675952519783903
-0.005542538099758083
0.01195001950760355
0.005878864192441711
0.001526036814420616
-0.0034967279572131194
0.014689299939844084
0.004412289967609158
0.008942525698858414
0.018670235380265122
0.005036785655260801
0.004948177864647681
-0.0001853265988769632
0.003622481101539778
-0.0027509474776538506
0.005545788438620377
0.0007701053883243476
0.0009117178045790399
-0.01091775225831636
-0.0014636066300202522
-0.005626289496270603
-0.006841818757773698
0.001193051161274392
0.006950540833144527
0.009714838088748427
0.006346388510317358
-0.0011879554375102065
-0.004516481024308431
-9.497998033743127e-05
-0.007343891789955975
0.009181579383429304
0.007053585777213865
0.009388921841145087
0.018292920916375847
0.02003971886271038
0.0190160507473175
0.015372645637043995
0.011232786144026665
0.001647425128690851
-0.0025759658561778924
0.012819387194208769
0.028210807677577616
0.014745608415973712
0.015754969824028957
0.012468835371338376
0.017475300297748454
0.008979346443382809
0.002596775527777216
0.011293153096950644
0.006974531240796373
0.004214438663811378
0.004892214753415616
0.007499081274623626
-0.0045328673683072244
0.010848322098662194
0.017410956552662143
0.009075964411688998
0.0034052766964245227
-0.0015067357914565057
0.018368674729816844
0.010021935270195861
0.0038432975930014495
-0.0016873615219134427
-0.0024319073624469367
0.0047064570526352285
-0.0009474592806872168
0.003742934628982315
-0.008605540666891539
0.014048169388882847
-0.004373916340949389
0.018717211561581792
0.012709274406862283
0.0022131433283930843
0.004948605074848163
-0.008211323433058276
