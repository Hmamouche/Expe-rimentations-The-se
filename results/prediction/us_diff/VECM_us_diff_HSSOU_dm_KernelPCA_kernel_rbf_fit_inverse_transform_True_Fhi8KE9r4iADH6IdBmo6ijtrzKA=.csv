# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; HSSOU
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=12, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.10314092058572212
0.016008683038521612
0.053709100829337164
-0.2116088735634254
-0.090343126383182
0.06443851541269034
-0.0701020465411912
0.04296015567863042
-0.044608789647621036
-0.009342918966016078
-0.01134470677235926
0.07328957775541634
-0.11875283075860103
-0.005283873303120452
-0.10450760038113137
-0.14702515551139594
0.11975699004955742
-0.007035736136404933
0.06108991439033467
-0.08578860099678667
-0.04786142345857956
0.030710651872092813
-0.010273021945323351
-0.011506157845445703
-0.0582987661408499
0.07607900577261677
0.0033276223200895162
-0.09115117762455996
0.0407186160358881
-0.029987596762982432
-0.046197384416700314
0.09458921647133055
-0.004532443285557842
0.017683784095945888
0.021881633422982938
0.04587820794391523
0.014250384213558835
-0.09945877479176601
0.056144168563476565
-0.12383094178887345
0.06987118384524585
0.06624084996456658
0.010303217680723153
-0.06152089300621499
0.09610461219432437
-0.11262889045245247
-0.06143482439153751
-0.030258556396932562
0.024462141095224287
0.014255196247823714
0.054087817223547455
0.03786965828957773
0.07721391592267976
-0.07501139831211016
0.06366765636937387
-0.04868571575426196
0.03811124350473349
0.015485775394029892
-0.010597539529970912
-0.03702692865934884
0.08454340078234883
0.039867387601765954
0.028492948801123102
0.0015812006042073591
-0.007818831366139917
-0.040974553005093776
-0.05086454864885814
0.053897129495367596
-0.03709286639618339
0.06118663914176421
0.02512840792456003
-0.0055663259271417215
0.060224618238344345
0.009220827707407968
0.08331456958822533
0.07756349873074744
-0.04351863806782134
-0.014947245432502504
-0.02783711952754861
-0.056358246185965855
0.0994542005313451
-0.01601929089061351
0.011088136353639595
0.0011421388726849044
0.02350937019362507
-0.016741855935615082
-0.007034196952976957
-0.015910900078388912
0.055037772775846636
0.016365500008850658
0.022513441787103232
-0.00846339680320915
-0.029992484645593266
-0.08505480211347002
-0.006656661214918862
-0.0379351173442856
-0.10487276445525388
-0.15830808837096022
-0.048080781920658545
-0.09250357218839839
