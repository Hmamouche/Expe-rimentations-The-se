# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; IPS10
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=2, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.01772086003837778
0.013087234510670856
0.009786562472224827
0.00928340566588179
0.0018156366445768526
0.003411285192730501
0.005429520749038756
0.0026120791503456975
0.003859678109110417
0.005669096100245626
0.00448683224153365
0.0028442531380649364
-5.6454163996797376e-05
-0.0035122263630724755
0.006281979778758613
0.011717691136257032
0.01586951170289463
0.007100405103962216
0.005840507845341963
0.012399539103578338
0.011331158454274492
0.010716777640702016
0.0008261541941714495
-0.0038698947982910986
-0.004778682757006998
-0.001123543593308666
0.0059088861721971345
0.004529043086937286
-0.002344983082265457
-0.008676865431705188
-0.0072494859075692974
0.005612211987553188
0.0053141957781788944
-0.0008801261556870754
0.007363389439461722
0.003659351496419932
-0.0017595694987460092
0.0047870001300912585
0.008653925261737713
0.0037375260775735154
0.006934838559577022
0.010445501432465441
0.015718435655911734
0.016462046244794887
0.010289992747866903
0.013776467070239076
0.0022080331691694223
-0.002670534177850599
0.007363002249913762
0.005604243410499426
0.009430121359345938
0.01779073643465677
0.012662393574713382
0.01512175719885798
0.011977668120461454
0.014615584189235784
0.018236402859049712
0.017060674439778437
0.015325721035513197
0.016824888559903894
0.01145011327745744
0.008874228412241532
0.014066783475955993
0.01587477096871825
0.017436463624029758
0.013886054397892906
0.01047768805383651
0.009380744195069976
0.005431060030410481
0.0022714531848690633
-0.002359103455637375
-0.0049287494879401185
-0.009420668779792427
-0.01850215941316355
0.0009316720265392872
-0.0015772687712256046
0.0019339867100320255
-0.0035104897151180493
0.004948603876529272
0.0006246087720109077
0.012893674426125478
0.015503502864089306
0.0076382522506854575
0.00693437216282225
0.0006647060821814415
0.0033920922332540846
0.010491933143796348
0.006521473994785509
0.011950423809745087
0.012225207215966469
0.008439252563480784
0.0031384031270998416
0.0029047792171275027
0.0010331244372709352
0.005336125112441943
0.009244238239219476
0.0034537918568249013
0.0017262787074718486
-0.002841615668591299
-0.0022358540304536446
