# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP264
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=6, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.0016046870761997937
0.0070746220045574265
0.012043736323640971
0.011276728437828534
0.0068128854448737935
0.0026521329436013483
0.014931616357924213
0.0009081100550852217
0.004782554206256929
0.004057394346646544
0.004120781306341316
0.0042184294194992
0.0016135502963053792
0.004904535173736721
0.009590802555105225
0.007885299851850748
0.00436953609759719
0.0041846471183187815
0.004757122852469908
0.008125229537605234
0.0028821064548710477
0.0004511095897949482
0.0035328604915879527
-0.003014610270808288
0.0020660091717527983
0.0029908075819626207
0.001750005877105266
0.00030843715396086744
0.003196824913465331
-0.002845011637928797
0.002481378542866331
0.005721701996027874
0.005795493231103231
-0.0067447135592467915
0.002239768440173368
0.008674605076095483
0.004634071587690054
0.007407996985346649
0.00846165879445672
0.004246620123906596
0.00506894609682727
0.011620540355400813
0.01097077956122034
0.011345835750846401
0.007062116394882338
0.013647143330208143
0.01184109115225152
0.0073517998680705885
0.012165399137058122
0.007809424532446459
0.0027445811561486355
0.007490425220681987
0.010160578784620596
0.013498473316814887
0.015488670944270453
0.012551265639305373
0.01781680210668708
0.020179771113126924
0.01838838957070902
0.01623094331937011
0.014267711755176332
0.009955279162945457
0.017344331140234398
0.014760698494919407
0.015572994843921262
0.023635025554772586
0.022179194468702604
0.0187975605223263
0.01932902304291563
0.022927912552827508
0.016451400924781007
0.0006257789222428034
-0.011542921798126191
-0.01545047980132552
0.0072051360602341605
0.011849957640543066
0.0021842585786654286
0.01279748729748115
0.0032888514191603733
0.002916858006796241
0.0157662933301284
0.025302573703181612
0.019426203138934315
0.02348270326289546
0.017991072932874413
0.020469548445136272
0.02207367480652753
0.002961807968826482
0.003992212306679661
0.020955392735194714
0.026964262962315855
0.006314671599829887
0.007982336251857782
0.015623387822414592
0.016210652079880067
0.0003653846764099971
0.003185088016055818
0.0041998787610605
-0.010317662057584014
-0.010198672038661507
