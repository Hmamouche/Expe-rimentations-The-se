# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; FYGM3
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=12, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.017414592781845914
0.03882579621560528
0.01886022266299342
-0.059662902028094614
-0.0191982600983268
-0.15610069323790052
-0.010956135865121133
-0.0634203562677624
0.11087080796019022
0.09097170395825509
-0.05459556498809096
-0.09979489170178153
-0.05567238269408749
0.00035912826909520294
-0.01633754279395637
0.05633882548369315
-0.018367532438077476
-0.1220383717840286
0.08566581212765689
0.005805895067648503
0.02100850031385028
0.06503273005085936
0.041150226737954466
-0.07030672062176105
-0.028797934045768723
0.06427977135663446
0.03364506307603829
-0.022022616715760748
-0.01573126317848357
0.06652140161858995
-0.1947344039213545
-0.08519310245006662
0.05385211833973163
-0.016539750515290517
0.01707565560904299
-0.018984998113126136
-0.09363096414547108
-0.05311781517148889
0.033877330730750374
-0.02481568536924839
0.11916702498789952
0.01445030173239423
-0.01779965999761903
-0.008991891091235847
0.02069656063134721
0.0727502889302956
0.013315350516076727
0.04963470396131102
0.03985098581115577
0.0007303606284253493
-0.031585593113030955
-0.038049539214070324
0.007736121457822388
0.0012691708420174124
0.0017504523403921242
-0.0033531501749554885
0.026189202728046125
0.0023290450353713934
-0.022481465616192554
-0.005853019608099748
-0.0009893073314185552
-0.04826942899172646
0.044429984629268296
-0.030570490426606062
0.020998740725327515
0.06705194470072993
-0.0012199183166292302
-0.03329684035067049
-0.030068942697765288
0.01394401552797003
-0.041256209821706774
-0.0053482737388644164
-0.08719250437864869
-0.12142115555662764
0.06965435784391356
-0.01460601862998236
-0.012302116328902275
-0.0313743813905208
-0.05248380324826599
0.031284043660059706
0.03691758535805447
0.03643141078960419
-0.022564140985261258
-0.023427559320906136
0.0016832373505273196
0.017635481648677658
0.017875235936809515
-0.015525377449672625
0.017581121288974145
0.028304215807760928
0.029807933684229404
0.04615903683928693
0.020553781903872557
-0.010951308734844957
0.025303030251653223
0.039123850946250135
-0.011420855454479635
-0.06038281464964847
-0.07491890819042935
-0.030841710606097236
