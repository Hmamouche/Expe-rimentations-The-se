# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP276_4
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=4, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.014267873441661479
0.005248045104075234
0.012635638085229656
0.006611850735788352
0.009328507305250425
0.009496250591427058
0.006413584755649551
0.006448412382279041
0.010353344165543645
0.013274805273271115
0.010941711972002166
0.009456906988613302
0.004625985380833189
0.0056561547632939975
0.0015445571378684653
0.0028851028713404586
0.0022983887518437836
0.0014144877881438725
0.0015935915378898944
0.0004407037193847616
0.007165306008390838
0.0028809256619973284
0.007958478235760914
0.0025949532507129856
0.00364638886531565
0.0036121171360702655
0.0045482969458091205
0.006385462780821492
0.004739613634381184
0.0057312504359150205
0.00903173471115137
0.005958836410476581
0.01358281668131072
0.010700532510310914
0.004485430149846843
0.004557577210025801
0.003547748132325405
0.003941036615560396
0.007380088988240663
0.004300600430526478
0.007280719043113446
0.006617965657539457
0.005083378444826017
0.007268445667906017
0.007245396116113007
0.003851172055047232
0.006985324289379985
0.0029152612542206096
0.0018712685412093674
0.004633257865388743
0.0012933327223529738
0.006543208789753325
0.008280634379808458
0.004253207765001193
0.004810787245745777
0.0028440409498330472
0.0017972493229958101
-3.283526429711224e-05
0.0005922134512729206
0.000600108763004577
0.0020954375316960955
0.002250271027307939
0.0025780209571502222
-0.0010257580611496338
0.0003760652047092581
0.0027420588262347468
-7.116592348251093e-05
-0.002653500195575659
-0.0016880964319420824
-0.0013766160980610558
0.0012928714861361918
0.000688003411511723
0.004028246942981171
0.004464521076633904
0.005352170618324367
0.005707606538705756
0.006992280273245943
0.007643513041122759
0.004986553912294838
0.005990394336326777
0.0005442114784471816
0.004441846663374132
-0.00016102262909343097
0.002111022234700645
0.0037294213842702386
0.002029389977578402
0.002389136054260438
0.006947464408482829
0.0038640636147821775
0.007325358046984862
0.00906968298154174
0.005336262742663546
0.00794263379190175
0.008687194086542113
0.009304520540986927
0.008015267280710357
0.010428977121093
0.007176121764682923
0.008192458675707347
0.010831148920117745
