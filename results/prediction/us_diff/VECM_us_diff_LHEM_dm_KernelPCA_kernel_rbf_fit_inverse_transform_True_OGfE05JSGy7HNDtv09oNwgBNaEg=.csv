# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; LHEM
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=7, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.007827952040505834
0.009990751434519515
0.014917970433251375
0.012980184402645535
0.004452020328316694
0.0008835029124997238
0.015660973167527327
0.0015008440057452527
0.004529914096378082
0.007635135691069636
0.011087739682530656
0.005442181199228523
0.0006554270399498948
0.00658364518016547
0.013023375114550796
0.012609079924858178
0.00795782647987227
0.006532935002047872
0.009174364218421166
0.010458390057640665
0.010679787528265195
0.011898256284032491
0.0036770299190025052
0.0038566413242633133
0.0033968880493818205
0.006074813969246487
0.009061809161243061
0.002304864572053467
-0.002025520967834549
-0.005118677250689571
0.00262538207750314
-0.00161669452061192
0.005240387170939643
0.00258874637573012
-0.003409707509519804
0.0006454872485010129
0.0008139282165921099
0.006018400147474378
0.00913368472767578
0.004914170258839214
0.012487059341660476
0.007794999638870556
0.007572515010078327
0.004840100540490708
0.007262275418307877
0.012339389708981937
0.008582062976153436
0.002119242802858981
0.007889297238016933
0.0018856430773315737
-0.00021687809928409678
0.004247608744245378
0.008519520322734429
0.007581206611585164
0.011192662364730129
0.0116108810961525
0.008435596601400499
0.007883727069384016
0.006391604102630238
0.004170315678109883
0.001199199402204244
0.005153386094851374
0.008341728914581074
0.002309547492674338
0.007960509669018864
0.010185743642516957
0.01390213865558371
0.004404763987503481
0.007023975293608155
0.011333692253185269
0.003618773371010471
-0.005833992125928544
-0.0032800405295297305
-0.008010623680425873
0.008160795275603112
0.000935625554260444
-0.001601099247243258
0.0025580191356720837
0.00204328196118254
0.0057450448252012645
0.005225402852876679
0.009729840752783738
0.004213223384989195
0.000983015363128014
0.005605647505420206
0.00616562296505068
0.005245880701569084
0.008622210603162534
0.006958688972703015
0.006850422927743034
0.01185092370769543
0.001828569856789829
0.0037932400663914486
0.011334283768878382
0.00827648947156975
0.006774624628763904
0.005267606601041509
-0.007340436636760223
-0.002216045622821347
0.002627919274556842
