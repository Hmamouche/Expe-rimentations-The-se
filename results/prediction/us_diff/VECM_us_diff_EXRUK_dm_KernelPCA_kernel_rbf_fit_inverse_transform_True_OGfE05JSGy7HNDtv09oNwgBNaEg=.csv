# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; EXRUK
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=7, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.061884627378966474
0.057681992302062016
0.00993962374278681
-0.05189899474981653
-0.0558160324317259
-0.013781639521074819
0.010616683923398491
-0.01742604320149166
0.03791381417357258
0.045826057463705376
0.07842899435337464
-0.008921504074087882
0.03013763583738604
0.008600631005317915
0.09317912003687973
0.030117651144418375
-0.05272544245384832
0.09106863709217282
0.043959361279138395
0.016130350961220206
-0.03768023944938735
0.008838672689650176
-0.005089156280325604
-0.047665781685804175
-0.01243291210995643
0.004027564413875626
0.009432925517200326
-0.04484841555558749
0.12141079981826514
0.0887861412159604
0.016832033465017007
-0.027481138501437276
0.05833212580106838
-0.007877758604783656
-0.07744726142696551
-0.015435187899109222
0.06125840952804813
-0.10841319235761254
-0.009558969126995807
-0.052866250956377446
-0.04682903010783797
-0.01655524750091477
-0.044112899419726515
0.028537269078971285
0.03026918299736906
0.0002492769639477503
-0.008392342606631714
-0.007894235358995853
-0.016211095192633064
0.0010147598787133665
-0.02720450741892002
0.028609465923007244
0.026623650357530886
0.0014774938173312338
0.028426314752938824
-0.006279109470368159
0.006059316174459463
0.0054332582904336735
-0.012394804446834107
-0.01627432893474215
0.009954260478408828
0.014090120407173959
-0.012784955342537336
0.012496352385913831
0.02353687444588677
0.0040490751118950515
-0.015488224279035036
-0.04263706064651998
-0.025253779816126122
-0.013017773937754223
-0.011824929919171955
-0.04974694450986315
0.017102422065959712
-0.000930556189427308
0.011314699040441432
0.021988800807113906
0.012600334147363373
0.0017081401796683326
0.03070019151903128
0.004063716486676708
0.020025257502079924
0.03978435103226989
0.008310865232103429
0.028149372023180973
0.015269922800226113
0.029109152764237284
0.0017535763223729683
-0.0007689471745426025
0.006085583257567719
-0.013165738475361562
-0.012338789571602496
-0.0056083286693810516
0.02996244500018914
-0.019384959565236216
0.07731406252865013
0.026983789418164015
0.006982348303868248
0.0008196421822323644
0.005395918807662804
0.03165386976119021
