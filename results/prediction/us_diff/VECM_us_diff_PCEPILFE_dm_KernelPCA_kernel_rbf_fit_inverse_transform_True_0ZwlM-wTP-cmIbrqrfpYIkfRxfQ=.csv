# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; PCEPILFE
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=13, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.009054097079809503
0.007812211943842121
0.004150295140660931
0.00800923197823798
0.006892538216352937
0.005417668254164767
0.010940964961634677
0.005087785628318834
0.0047677465118931995
0.004652791858729933
0.007033318771172841
0.004286705602696364
0.006725503744766572
0.008658826842254682
0.007695062125840658
0.005645496221007005
0.008278633978971044
0.006032572012788969
0.009157141229206163
0.006510109626308588
0.00796134017135455
0.008209242349782517
0.008600118280057642
0.006332419554514891
0.0049870755777363185
0.007319872236065725
0.00787774835171019
0.012270765787970988
0.008273289686233061
0.009465730202110697
0.008363596385084304
0.005891987225662593
0.009242372106059668
0.007082803375449428
0.009045783809301263
0.006637446138648099
0.007012893980927753
0.005798839424377338
0.008070903597085118
0.005699005901221417
0.006751467153208762
0.0030524802298889887
0.005441960567525269
0.005914987485278539
0.007636602279231313
0.004456632409305185
0.005610579307301203
0.0031209069646185314
0.004680919130743352
0.006122063238394171
0.003926675430835464
0.005469593326303443
0.004911949778496821
0.004624335947632863
0.0036989359501805423
0.004450624461288386
0.0032316967017994454
0.0028190452783485283
0.0033004894855882994
0.0023455907507666184
0.003155296079578748
0.0038430250851049334
0.004907459026010403
0.004290946085190628
0.003749381333376477
0.0057945138991808845
0.004026611962837347
0.003832828196367076
0.002449484850256632
0.003957258714522222
0.0056391879287017565
0.003971758350945786
0.004781188867092132
0.00576322243256737
0.00649412343855293
0.005060797738775301
0.0026783897916014226
0.003942102545427357
0.0029050540115134237
0.00345305483268339
0.0039309671743299615
0.004599147025773194
0.0061562364370293145
0.005622230797251933
0.005369277524056858
0.005918710546778189
0.0066769314255829375
0.005950761289709071
0.004920653256089924
0.00792509376711793
0.006087713654435503
0.0074950662025562815
0.007157919286568947
0.00562324314224102
0.006585647772696454
0.005416061322765031
0.007044791679427696
0.006208339092616296
0.006843617998634378
0.006800305893847603
