# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; LBOUT
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=3, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.00032185638397794853
-0.0014136330016184815
0.002767423777915625
-0.0003955263265012442
0.001518336222300036
0.008858554193454533
0.008835587943574542
0.004001788832134967
0.007307380663968298
0.010398512260439705
0.007783577040922768
0.0084596807216107
0.0054640925230540075
0.0036561508915425624
0.00529431993124604
-0.0018726513110530712
-0.000889319109316599
-0.0018918112848270775
0.002535569107195631
0.006262821935455578
0.002159266107848621
0.0059675924373287495
0.0016424610897777018
0.0005774047983002218
0.0051871313864648065
0.005302568485912788
0.003468494726596983
0.005112448726653226
0.005057226903416975
0.006582927785154642
0.003979258687694142
0.009868085051146886
0.008035875729828152
0.0005218618155374203
0.00851544870803685
0.01040604040035048
0.006206622184775753
0.011691907914082594
0.008899887448442776
0.0008915370165896623
0.002009580262354836
0.0017968611305917612
0.0007382181927802932
-0.0025279810056826517
-0.0021093589271621834
0.001740281255208767
0.0007246302759097664
5.1018062657728295e-05
0.004364087463668422
0.0038296560084003254
0.003889071980679661
0.006776014875334793
0.007024939075376857
0.006680083457520547
0.004082534029204091
0.002847898617942444
0.006494638490933313
0.005115857898021935
0.006508681145047326
0.007380784111878936
0.006647870899000434
0.010279100371697058
0.008199561939106289
0.006312863111574996
0.005781933970312676
0.008538167379362133
0.007362336125682675
0.005114768570440752
0.013040624422629316
0.009137464044113303
0.009954345302860875
0.008730618997583896
0.010430848887357376
0.008240778762447701
0.013811029956319196
0.01467958326132135
0.009737946401324955
0.014892679990346203
0.0064693125913099225
0.01029968304921584
0.015433076521468
0.014180019847248012
0.007495172614250537
0.009786686819178762
0.009050512419412474
0.005112306335371136
0.008566447749163124
0.009311615211556882
0.005618795734635348
0.0074426614345338565
0.003577096851633548
0.003149122279551762
0.002813899118974253
0.002830447491351121
0.003794770110674061
0.0018933270303502993
0.005751464149713739
0.005622180158471827
0.007484502639212141
0.015613783280357885
