# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; LHU14
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=11, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.02820200303101618
-0.080765346673997
-0.036667863701272
0.06410739871995241
0.0838657498270053
-0.008029957845682875
0.0016552647148373387
-0.08158141629455375
0.00986734645215219
-0.04706226620424882
-0.06229209731253304
0.07069526299319057
0.04291349351984649
0.0032753085567445274
-0.03987178917368784
-0.02280309753819466
-0.08568554859054567
0.04534744554850128
-0.011334609872815834
-0.09918748356452393
-0.017976781418468684
-0.07928174429556048
0.06697184899024955
0.02392265383421493
0.030473140425331325
-0.021504773281353706
0.01641141310172236
0.028197373093476884
0.017316780490469766
0.07456022961805538
0.0579692047232866
0.03043338969238819
-0.03845903984830315
0.002978850750203668
0.020121111360919743
0.014727673659254023
0.05777012550587428
-0.03746371620678827
-0.032871629901563525
0.05689252834549316
-0.06307809759105437
-0.04756420968545107
-0.05353421800507871
-0.0032973054728240693
-0.0245857445860393
-0.019771280243412175
0.004431341259733872
0.008389054638489116
0.0012227681327518997
0.04267816469741925
0.055643043055844124
-0.05275061759400085
-0.04958206014770017
-0.051649971069193557
-0.04708587316398689
0.030200322283004125
-0.03282204501680633
0.01371173287563247
-0.018693149609446052
-0.012008193694544221
0.04230744126142501
-0.008445656345333553
-0.04144210429938795
-0.0017251689470650176
-0.04647831576879683
-0.06608600126359922
0.04299950487612955
0.03819148331908967
0.021837050030771438
0.009299059394106189
0.064345734124012
0.017152074932493537
0.06364813923505376
0.06648317555088637
-0.10778838182085104
0.031083495252893598
0.048651794537961965
0.0031263879305609456
0.056800419616162806
0.022459825954657463
-0.048288372599089024
-0.050147193676354986
-0.018377431210607226
0.02175250857253508
-0.008079949391740567
0.03226339742388916
-0.002608190262071746
-0.013827572366205382
-0.027570021313322233
-0.01584684162015689
-0.045587626803081316
0.0015892393521506655
0.03043921584390395
-0.02195473034995233
-0.02907298613573816
0.005176969089408449
0.04524611420465473
0.05450413502003323
0.06975571557805563
0.054719863605325214
