# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP267
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=8, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.005654191201902517
0.01107968558310217
-0.003227094565827104
0.004585500214255834
0.009174690938155946
0.002252076938182493
0.012225528330118866
0.006612542357471561
0.014529746112233365
0.009503548677443813
0.01580360387646115
0.008582247678086241
0.01323615420777753
0.015682207065670212
0.006651504400104963
0.0046448638552253445
0.004288929394496375
0.004534394705053508
0.0060532639190326466
0.0019451522270190207
0.008272326409606925
0.008523201363643464
0.012153836457452485
0.007134144845737314
0.0037289781061580866
0.008648682711244337
0.011499848769924267
0.0072094100335675995
0.008362161338190082
0.010540697760976991
0.006772947940068157
0.003792478353441918
0.006493768594759579
0.002171097168031959
0.007019168770590505
0.003891435523466757
0.00371976164000889
0.005017666015201306
0.004523708294337661
6.508017384562628e-05
0.006763114865093777
0.00053149784915951
0.003457696293304163
0.011456944041872771
0.009191711039204208
-0.0003572106298447947
0.013037154344859445
0.004230617801910521
0.004912804584129699
0.007420059078590075
0.000949969161907866
0.010818359942073478
0.008343471378694511
0.003849171492052831
0.00999672456781071
0.008595138471818493
0.007298256571525806
0.00756627500763493
0.006627327236601601
0.00644116900388297
0.01682223786140421
0.013078705025037163
0.010756337879575579
0.01638748670474601
0.012818501546369227
0.010698855997174454
0.010740939767080345
0.006355277895779441
0.005115625877871888
0.006192153740977241
0.00909305402104337
0.010071846036254084
0.008734567232196335
0.008009330468080183
0.01685957698673934
0.016569202009021122
0.004514918839207858
0.004749748005683644
0.0013654826432317369
-0.0009995296167303576
0.008014090364437685
-0.0018992907081018247
-0.00197899246653149
0.0019196956015457328
-0.003931547220374543
-0.004997364091641605
0.0021718725200303808
0.002601853465393003
-0.0013617173648792348
0.00012750524034171266
0.0020594587339096654
0.001651898530323347
0.002460333476056064
0.008369854932723037
0.00569339243914981
0.0059455590524089535
0.010527134022976241
0.0033485362125371277
0.0030968914591610816
0.004958139328640419
