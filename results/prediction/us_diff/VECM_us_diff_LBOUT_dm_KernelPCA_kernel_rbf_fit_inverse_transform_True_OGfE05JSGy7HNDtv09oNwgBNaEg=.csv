# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; LBOUT
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=7, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.007219437042271263
0.0026707550473655606
0.0051303334112245795
0.0009768135540347768
0.00097600340184365
0.008562461539767767
0.007544829663282222
0.002224301789200432
0.010342961671848084
0.013491718321567953
0.0059921325713293205
0.005595243328581887
0.008230920906543305
0.0023764866186826716
0.005071510719199701
-0.0009215230698550497
-0.0005748907265275146
0.001244432112382831
0.0008433160554662754
0.006677254653217817
0.003094188510904999
0.010148266437979434
0.003391696643888464
-0.0005538325797143
0.0019775596208934047
0.006020889359065483
0.004083283767159759
0.004734830248696162
0.008159073340143794
0.0027913877335994496
0.0015922552487160338
0.010441495530552163
0.007247865173244704
0.006506480238151498
0.0018585921223379736
0.009986577334565538
0.00404529304764083
0.012414020612348236
0.012566431100748513
-0.0028975726040633247
0.0068548058432873525
0.00409533641562849
0.0011511574770902522
-0.003495697807963851
-0.0026052061995034737
0.0005686181459278786
0.0004079582815590308
-0.00024216194302036087
0.0030748042459354656
0.0071909572321359125
0.004405745409731172
0.010730004120815269
0.002924671592119942
0.0023808609504829643
0.002354262367123168
0.00417397813887683
0.0075748131929909
0.007258908862590547
0.007053708090368376
0.007526011710939653
0.008863644328276271
0.011302999856443448
0.008952038511714798
0.0017023784900988687
0.003181019936857455
0.011837957895357626
0.00682353908555175
0.004864456710276005
0.010933332308562483
0.00956013313102275
0.011797649467373052
0.012870647545324222
0.007438166205973986
0.003784641798040821
0.013984988647043227
0.01654128812946961
0.010318121363768425
0.014933667110630081
0.0053909206602386125
0.010703136523749133
0.015416519892123873
0.016730365244127212
0.006402226963406917
0.007897724760668738
0.007323048527987198
0.007887006764346838
0.009376806771754844
0.009162378343595342
0.0047947931212412075
0.007700136551384529
0.001438332610888768
-0.0004587028044103138
0.002815496186371708
0.0006741575589153965
0.0014070207007697046
0.0014700290670853259
0.007119711448372139
0.0022827100254754163
0.009099853397276583
0.0172103335046845
