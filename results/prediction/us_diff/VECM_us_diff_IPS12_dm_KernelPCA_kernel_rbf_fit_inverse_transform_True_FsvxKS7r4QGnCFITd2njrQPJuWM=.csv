# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; IPS12
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=2, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.004608214888093447
0.0026554123231314554
0.010225325978653978
0.0012963390237355323
0.00032395068517362046
0.0019688467822473513
0.0009984003811079848
0.0062960358825195715
0.008505588387763276
0.004652845270202841
0.004633313965192529
0.004997096041914207
0.007220793210284456
0.005876755856294513
0.011907123966447311
0.014629451673221584
0.010932939005290937
0.004245744236986636
0.0037026748578478717
0.011882023713285667
0.01376729262650257
0.009610444587708196
-0.0006864033847969091
-0.0016255184123845337
-0.00046990145112765975
0.001680454584848709
-0.001471336243566467
0.006471666115515678
-0.00013073462841471162
-0.00592308345331778
0.0009521926474553453
0.004856166072024653
0.004621584431736562
0.0032705456738900325
0.00855706550832305
0.007749711001764588
-0.007287488256742743
0.005706971120656641
0.0133386995413811
0.009591406500696743
0.008792691913203058
0.008038845206293293
0.013942097432590327
0.012016393516951857
0.00909372720255212
0.012176022714204086
0.002189643136073127
-0.00172670391707043
0.008868846274691217
0.007981789773815643
0.012672138597148611
0.015756724502518974
0.00623837083087588
0.010077492713098768
0.004159066718936713
0.008115663327009146
0.010734745731677911
0.0032163182352629638
0.007192115184053422
0.019313793329384595
0.011442063706612845
0.00918316724447395
0.009197623392196338
0.01020889487922513
0.01141588664376431
0.007636992331634513
-0.0016832118390608956
0.005642696005314243
-0.0021988955910678086
0.0033019614259743564
0.00013008997298545724
0.005151932619875737
0.001706454546899312
-0.002523780203488948
0.004048514225013384
0.0023854791725477953
0.0024288331434821533
-0.0021567303445183734
0.002160362417434886
0.006942532274530522
0.01903114112009576
0.014028412137838567
0.007698842687907434
0.0021354211843051685
-0.0025377944626682023
-0.004346302509876249
-0.0020955496418491332
0.0034704842881839973
0.016056797631166374
0.013683082168624723
0.009634528027635755
0.001220945613199068
-0.007342098717833371
-0.0035820269549509056
0.0024667888901798345
0.009626693915199519
0.006072467607178829
-0.0008752037493150277
-0.0036923705219152197
-0.0029261790072715767
