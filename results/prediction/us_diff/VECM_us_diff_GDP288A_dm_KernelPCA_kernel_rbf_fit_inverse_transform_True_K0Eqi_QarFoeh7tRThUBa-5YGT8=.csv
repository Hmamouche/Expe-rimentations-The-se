# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP288A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=6, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.003956445352579936
0.005079941697261441
0.007372963604042765
0.005710096860376057
0.004844063504672213
0.003777169576484891
0.006260364349348003
0.004195857210768975
0.0038263388743523153
0.0037465019518696744
0.003528655001515383
0.002364539540767576
0.003945937829600143
0.006176025619684718
0.006584107507944059
0.004767553689400973
0.005532804454660867
0.004360114862870292
0.0030187272395258845
0.005490469328351913
0.0037275655079628085
0.004263688188156367
0.004948260068015603
0.005831013344589497
0.0034736811039338105
0.005808711130497836
0.007715853884062648
0.005445275890856278
0.007483852304352405
0.006830409013028241
0.004823609968854753
0.003788362402127954
0.0052233103621148295
0.003027084843077437
0.002133984066899619
0.004013253983463672
0.0031963964181399383
0.0030417376657452273
0.004561277040852654
0.0024647967241678403
0.0026097465997664574
0.0025695076720763993
0.006155742115112858
0.0042623564135979616
0.006758892686977397
0.004666676816302973
0.004390469475304093
0.005369497078859131
0.0037108697933249902
0.002671472932576769
0.0052385675892729355
0.002023154727394294
0.0048377547115684765
0.0045932831274192515
0.0040203931993961824
0.0037534427533838
0.0034781264516729254
0.0036997664041069174
0.0013652440323440838
0.003326928923792224
0.003000063345430383
0.0033381795398122025
0.0039015958853602997
0.006697230511186597
0.006209686929715749
0.008919169278377933
0.010220209802657573
0.007225096837442336
0.008589388959024611
0.007496922246796304
0.005642651065981928
0.005850717815460608
0.004846212863522587
0.00309815921669536
0.0036637529224408352
0.005307552242399373
0.005219452009945887
0.006812551055430527
0.010715348167616505
0.006131633381512878
0.010143270652283884
0.008180610397539215
0.00599425431420524
0.01008056089560193
0.010474507246560757
0.013988231302527014
0.01216067291563422
0.013495111401294089
0.016150353910558104
0.015857790071727655
0.014558428162813936
0.015589965434053011
0.009120404825769505
0.008850391354991837
0.011787836482433403
0.011512095538103267
0.013911573861352012
0.016715970081852428
0.015028878972118414
0.017588879180377204
