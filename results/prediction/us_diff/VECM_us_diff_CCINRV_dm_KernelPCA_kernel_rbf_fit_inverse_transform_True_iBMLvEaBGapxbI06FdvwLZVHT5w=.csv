# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CCINRV
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=15, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.008211446463636515
0.007892952805607003
0.004461936245602131
0.006345138835940649
0.007478145287167072
0.00536576874510906
0.011536464665908932
0.010177017352917647
0.0106003133759927
0.011389087449553033
0.007240787673068773
0.007322179042951942
0.006119539920282017
0.0055398964420837506
0.0055525888279936535
0.00020715349389404628
0.002614034268214739
0.0042825413083802345
0.004967272816373992
0.0022316120557154657
0.0006543012419689999
0.0028320224154718245
0.011202508557512272
0.004785414326757641
0.0069932448529121715
0.0028654443942713287
0.0032501360510456987
-0.0037480578685886176
-0.0032751250205768564
-0.00554781590656258
-0.00019872312682916548
-0.00458484620214329
-0.003737161175996611
-0.010325407136409233
-0.004589026953984326
-0.0043772145241262
-0.001431201074996743
-0.0013684621276536589
0.0008024511087243583
0.002005470883101267
0.0009625840041996804
0.007073463114700548
0.009814983247649229
0.010105156377467268
0.009384017171528404
0.015543170781226405
0.013902814627020258
0.014919319138509116
0.009582880399914447
0.011249534733186847
0.008793702797778014
0.008454589190094553
0.008124374226594198
0.0068485833900709045
0.003963793365035459
0.007963760790238857
0.005801884648603525
0.0065060340652045795
0.004106423163454054
0.008448833936493691
0.01119282763756728
0.010545406480197878
0.013534889454141644
0.008284962263786333
0.012323468456878104
0.015480385656736005
0.011238551469662132
0.011090625572422848
0.020237874893665495
0.021043149731748603
0.019049742343601447
0.02023151918044965
0.012842140373590005
0.018635263427873663
0.015838554796675383
0.01726708924592514
0.016050407870022196
0.015722561759476644
0.014736579930508403
0.011796988493479791
0.014346102236947822
0.014108604069599844
0.016288391798160586
0.01322224731050796
0.009666271730684335
0.017365499785749902
0.01383943443371401
0.01303738921606331
0.015397771401405613
0.00889846234012267
0.005845199164890618
0.005916500141688928
0.008821805527502436
0.009026508759190909
0.008459020099518723
0.008237073850606349
0.012253247109146716
0.010890047395212661
0.0032196149695951195
0.010515300337100478
