# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; PMDEL
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=12, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.013766819163431504
0.24886407396552251
0.13789508675093445
-0.10103302657733661
-0.1440501429782281
-0.020699963324785513
-0.07418214193139365
-0.00035442813829662453
-0.03593752239703911
0.2555310260940564
0.07010287292692732
-0.07754881442641694
-0.08692042705350783
0.039682769545395444
-0.06410194218376394
0.09618530682681783
0.06696670925483775
-0.05736285421581502
-0.029789962336595678
0.016128074941055677
0.051080190051091184
-0.016820205664856716
0.03678855298644899
-0.14283476101163445
0.06335854643652103
-0.07018086150069966
0.0052915029528067745
0.03247225152805873
-0.12263838071165364
0.04663574327210791
-0.03834033680805436
0.158393030732553
-0.03300840945567877
0.05320697388531986
-0.026915574059089623
-0.02018411782875168
0.021135112632697142
0.004090952457911187
-0.06732431703603853
-0.02180196089001322
0.05009729745080834
-0.022210343954175454
0.11602058345375404
-0.0007669562682945039
0.05196812042994355
-0.036894033033383934
-0.020622064990465074
-0.02502457788928466
-0.047809585143756314
-0.018019274955598293
-0.04068253946492141
0.056156101235394586
0.01732487628733924
0.053042803227387775
0.02818200079059982
-0.023524461676285052
-0.0033127896642816575
-0.03275742335928776
0.013630414711713447
-0.01479935463794932
-0.0528771151984144
-0.07307415339161172
0.14053676129436676
-0.09623281432564192
0.040822935873623394
0.04699943033512867
-0.02137610230732801
-0.021625055103653933
-0.06687016528178728
0.001568024195277214
-0.09018479166108594
0.12761937087685382
0.029260770657926573
0.012610236082825205
0.06728658741388846
-0.017538025545822136
-0.043796147072918554
0.036337153673175374
-0.04749980532835337
0.043344650240363866
0.10961739673881953
0.1294610813125193
0.006435731874509406
-0.050896532500371544
-0.03864009744238917
-0.1039283320117391
-0.04822456058698271
0.05251720000950181
-0.016602837086972955
0.001064086666675547
0.056617316102020206
-0.03225434292356927
-0.04240797761041294
0.08808072490770541
-0.04126223824726803
-0.03307420042313326
0.05356334658081988
-0.017776778983343164
-0.029167531493516426
-0.040016197583381256
