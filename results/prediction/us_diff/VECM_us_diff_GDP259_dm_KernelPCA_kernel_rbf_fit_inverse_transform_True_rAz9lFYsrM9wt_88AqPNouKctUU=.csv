# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP259
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=5, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.03138583380202224
0.0025622849033734977
0.023467048099172865
0.03372675649669361
0.023323753572275945
8.313851522329975e-05
0.04739802702115392
0.012680080164513082
-0.002245587149331774
0.00922314556358927
0.011367431703011605
-0.05506019080526066
-0.055102724687832394
-0.03650380913064588
-0.037304644297928125
0.017341889222475024
-0.012494628341067371
0.04520468402587857
-0.012382586202500354
-0.0026245759521129463
0.008105724661664366
-0.011576101372761428
0.012895889940354078
-0.013969052647789424
-0.003230035871873563
-0.005427868127215813
0.023123612275454904
0.007784137063843085
-0.008184614410733749
-0.02536506391936393
-0.023611320976543393
-0.04883458152914867
-0.025777761903978354
-0.025098936535939913
-0.036366819363437185
-0.02245940063974765
-0.01816574913170259
0.019318328606521284
0.003978263161553708
0.006992918862998994
0.0006222888168247488
0.009741320953389776
-0.013506740710750885
0.02861681216559523
0.02212808497332167
0.01103337194803465
0.005782487882189422
-0.0030658017467363077
0.009274789211964974
0.012288524293900737
0.005181695998724955
0.015094898736046095
0.016613053945818215
0.026183064655976453
0.030275277047106586
0.032100886625039765
0.027319568142083705
0.012461811550291555
0.01694788884684643
0.02167043899881379
0.00248644377555957
0.004616559335615089
0.008753649310465099
-0.008909888213230147
0.005000576184297225
0.013693648746524751
0.012020220339764714
0.011466861991012035
0.021576921625550367
0.017256537787700896
-0.0017633894255298845
-0.0022532488367966157
-0.029398981859433508
-0.05812389455879717
-0.024347640627237717
-0.058108359948931605
-0.07143917040420228
-0.040649479906845976
-0.036386049594727986
0.007361016768574982
-0.006269455693727099
0.03105374557928496
0.011581305113668297
0.008410904651355793
0.006839691354695047
0.0123472059447149
0.007367513758681136
0.005802439746295645
-0.0028397905951562407
-0.0026044506111060385
0.006461158628462204
0.010269526354110912
0.041863430605145975
0.010899023903167094
0.02948989688487374
0.04625754595009317
0.039050276611270966
0.012238276118011092
0.024071799417297257
0.03885830248481776
