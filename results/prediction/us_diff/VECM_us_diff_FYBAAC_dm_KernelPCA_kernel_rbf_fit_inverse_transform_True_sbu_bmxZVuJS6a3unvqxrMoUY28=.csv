# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; FYBAAC
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=1, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.02772190738202405
-0.0059914115796051975
0.008649312890366323
0.07045027652842145
0.0011936291673238567
-0.034550612551665166
0.00321498486340596
-0.05918373847985625
-0.05552224405126998
-0.0363912377886504
-0.0699143574740697
-0.05724949561456037
-0.03926837143559232
-0.040390088713007095
-0.03332033718649493
0.033927530409749836
0.023654549372597755
0.038404651765160815
-0.004551453773682741
0.03407274929728971
-0.009658673067859008
-0.03031483042212499
0.00795163751233233
-0.03151823575845784
-0.038144993197667364
-0.01459798988436547
-0.004044546168060524
0.0004631942933122808
0.009580121496710352
0.00935046743257104
-0.023376576183286472
-0.0048479204983528906
-0.019303767609500325
-0.02827992993420829
-0.010329101332516967
-0.01960531228598401
-0.02544352949168284
0.006544488654334501
-0.03535597169980849
-0.015948957792089904
-0.027614440461030194
-0.020466379743634817
0.005248572908669102
0.04059463795028459
0.02396430860346018
0.05432674374948835
-0.006226987882150354
-0.03032926572689103
-0.016497153620287267
-0.05204989240995815
-0.004215459645543823
0.02596286960566857
-0.0033279069214127593
0.004810833527962724
0.007988795282764638
-0.0011534106953435058
-0.021515860546113583
-0.011913812866512498
-0.020956226265216364
-0.01593520665165559
-0.016434253928719555
0.004522581919479898
0.010714109991053839
0.0182598975025223
0.030466190949411658
0.01679653145736559
0.013908850678869178
0.017560334172321126
-0.015023573693083036
-0.005881367208714694
-0.023035903885171908
0.0033040708188810802
-0.013016757254437818
-0.000740668431785081
0.017859498105203122
-0.008680691447400132
-0.008644880201299332
-0.006793489332231107
-0.03889841163752205
-0.03561139173015194
0.01067353965711912
-0.022281612989240036
-0.017514204724669587
0.021487930787540167
-0.030863701118715524
-0.008549046202451747
-0.010993645394228029
-0.013502375627171284
-0.0006005238533766949
0.012996902772234383
0.006354338003660201
0.024236060501452723
-0.00485641412783525
-0.010739257398016233
0.0031073536255295285
0.0019205513624710427
0.002017283796317699
0.0038228983313586175
0.007236658955877133
0.015008931173039064
