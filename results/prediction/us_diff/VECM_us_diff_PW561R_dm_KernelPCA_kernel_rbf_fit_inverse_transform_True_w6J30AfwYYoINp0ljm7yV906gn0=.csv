# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; PW561R
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=14, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.031059008992917088
-0.0882322889203249
-0.03218013622969044
0.037047109248585
-0.02558680511232227
-0.0342769689068837
0.010582515050557854
0.0005934765840638267
-0.029752232381523594
-0.029308390951404556
-0.054363121438340475
-0.0692974774113012
0.046059589627007846
-0.07114640986375824
-0.013088811692271447
0.004785833282434208
0.012902590918613857
-0.006926188081383615
0.03369680345738916
0.05891259190174099
-0.022511902854981843
-0.025227617327747788
0.04999745914969338
-0.07996778760143067
0.06700947134054928
0.058273175093823563
-0.01393194721995649
-0.052128434273083196
0.02902452692465956
-0.00756563570064609
-0.07977948125886222
0.15173929965388985
-0.01873446726199492
0.054898729458863864
-0.12568085011686214
0.07124330212637824
-0.04891114672927273
-0.05002780097052944
-0.019421276915947167
0.002268581768113137
-0.06693508793742461
0.015680649514954792
-0.007063381167796321
0.031601501585704496
-0.03277332506403038
-0.03640496520442499
0.019489535596288306
-0.0071127459440655585
-0.040068940858794894
-0.006342671621110648
0.028906706259069898
0.009441402659613773
0.03420263931411488
0.021559857683402375
-0.033643179449604155
-0.01350570094400277
0.024446529266466184
-0.043814327058298616
-0.03956996175109452
-0.015896001748522057
-0.05360254978619488
-0.022000749699785608
-0.00036582537241359927
0.03526386361295638
0.020477379793224892
0.019859032545257473
0.01975425917150961
-0.04299081038942568
0.04524435267606414
-0.01047874197887518
0.0042228582332541256
0.058615586844007396
0.012564889655757026
-0.04413451915102365
-0.043613292877360064
-0.025551559921418773
-0.028929555735082803
-0.058621903047865895
0.04200108235675635
0.008601881113425728
0.04734887732505644
-0.030979739714465993
0.05472800533718067
0.014312701061716867
0.004195610176602346
0.0048843383047162126
-0.009620872514413632
0.03842299807214269
0.06728459518405883
0.03859979846208233
0.07535334888626727
0.030074885630020087
-0.013697362616063002
0.02423732173515279
0.00089773729576181
-0.06041574958337425
0.07043446984664074
0.0594178248454702
0.09646215153077053
0.14128004382283293
