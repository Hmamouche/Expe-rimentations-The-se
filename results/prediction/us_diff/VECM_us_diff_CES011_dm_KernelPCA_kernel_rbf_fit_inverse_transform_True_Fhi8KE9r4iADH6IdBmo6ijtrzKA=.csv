# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CES011
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=12, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.014207146656736462
0.045153395166391226
0.010702828112855108
-0.0009250323747740756
0.027790088788281334
0.015573474184028874
0.03162218014660055
0.004743715890720972
-0.0003869785621078616
0.016970314488933148
0.006078088457285826
0.007157143900946535
0.00856712516596482
0.008497586082150996
-0.019568264309785536
0.01656305665443447
0.02850031136188387
0.010520734592688652
0.014967033728977897
0.003583103084595813
0.025659018089908253
0.015644690867634547
-0.0030123992062572663
0.007625340593306251
-0.011606336578571429
0.005228575483105118
0.020617700268396322
-0.00988830807861674
-0.014329090519944446
-0.036869822657726474
-0.032429221777277514
-0.01749906512219804
0.00423921728279708
-0.021153541792677283
-0.021093649618970436
-0.004063956509018989
-0.0033396573702172898
0.002828751771752055
0.012955269590646211
-0.006733311952306247
0.01121927715424512
0.014453462578269913
0.01911726509780378
0.010166328001413713
0.01782211558029386
0.011665430128688318
0.020897105156230444
-0.0008790867608803902
0.007791648203920767
0.01239957816014952
0.01197609176020761
0.010181438254225317
0.011294046146969989
0.018199097391729216
0.024238443405486976
0.009816549965124653
0.02029413139093221
0.015903620966845652
0.009176064541538543
0.01867351283265413
0.018604574738662942
0.01881661272994463
0.020064016978667783
0.019914649561189334
0.018884374791282545
0.01705929658365026
0.020135414409875763
0.012181869389123048
6.938926136577754e-06
0.015233058177108029
0.0032435056947793858
0.0035561968719172096
-0.015492058456654873
-0.008850948045137683
0.017073444121141753
-0.012151943951521558
0.0017113289500911184
-0.002165433028536837
-0.008748736335672415
0.004084042639885413
0.0017126691317519288
0.010239275021340338
0.029305084995868137
0.017295387400393207
-0.0002505703139289568
0.011580673448883935
0.016621113657383002
0.025778289668179608
0.026258374398441052
0.023457315752027436
0.02556917963618927
0.010511861103936208
0.00466604024098577
0.002835896549257162
0.00685132151128228
-0.0013532026654053553
-0.013662052514325408
-0.021807541443065414
-0.014951702801305315
-0.040605017168145366
