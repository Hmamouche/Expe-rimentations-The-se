# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; LBLCPU
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=10, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.002142846207737364
0.010085608373813896
0.003228760815766836
0.013158565902628882
0.007570978140552362
0.003573684617416863
0.0013901880519835734
0.004954117323433144
0.002166886799773231
0.008643350211802356
0.001014218348237051
0.003002503756108395
0.0023005004900497356
0.01137339806919335
0.005515358147203627
0.00887365899805755
0.009569927387833146
0.004142248434090206
0.009187279345777349
0.007504387876259859
0.004609823053015858
0.002320604159059608
0.006160943096221149
0.007867008314811162
0.00176239736260684
0.004948221075003188
0.008292787073799731
0.007513555966025136
0.012106804571901797
0.01306566004657689
0.0020160129138985195
0.012434869218957551
0.010394107341654595
0.0011334917189148722
0.002157181657624142
0.0031190039822469747
0.005455935929421453
-0.003129626715054963
0.003915753388814379
0.012725375246486599
0.002694011591087948
-0.0009170279887389248
0.0031608304205041995
0.004124067695664803
0.003282327898153028
0.0003506506609366083
0.001034630758794478
0.003016315732068819
0.0038410134633209765
0.006266256864456293
0.0021537093567025813
0.0009677213696449619
0.0040490302594664
0.00621133285014702
-0.0006701728521915163
0.0040158957801947675
0.0012140648053438224
0.005002738975416531
0.0027232134165788317
0.011538376612907601
0.007319571907958305
0.0076674884084765565
0.006496089085519927
0.008391859964178652
0.0031425683178745757
0.0035327322288903934
0.012245221291703436
0.015694556559372512
0.005962976835823348
0.022383781908028325
0.0034797823914167925
0.012209848159983019
0.003126281658903706
0.0057036803585937676
-0.008649590075519447
-0.005326171424482551
0.0017422743627343558
0.0036234661370359977
-0.002621693492079103
-0.001833106009096263
0.00782149513184972
5.655706281951006e-05
0.0006195997270550737
0.0004174470652005143
0.008632860620243803
0.0030282821997516538
0.007417870697505672
0.00662117360716589
0.0037667081536346928
0.00618971475093462
0.005555231141779053
0.016728251923567868
0.005062738007149366
0.009584922427702158
0.005367224656808859
0.013341911418710582
0.019241724985773614
0.012621110107910527
-0.003573914119337943
-0.0066728974072075295
