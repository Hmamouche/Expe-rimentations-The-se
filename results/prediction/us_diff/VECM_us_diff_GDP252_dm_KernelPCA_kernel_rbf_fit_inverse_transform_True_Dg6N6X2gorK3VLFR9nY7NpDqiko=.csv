# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP252
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=3, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.003426757770270249
0.007445926226299748
0.008637778673097209
0.005388518139743877
0.00286005534876792
0.008784432543943666
0.00948099901573034
0.007877031102450908
0.007974091808113416
0.0074704268842566484
0.006927577802268454
0.00632946654566631
0.004314636530791716
0.004335933361719668
0.004313641263681608
0.004375913006838073
0.005791092316824324
0.005251216040610897
0.005453098641800843
0.008094845747331415
0.005697624805060808
0.00821559157774801
0.0053200198432123025
0.0035181834134733656
0.004895536614991143
0.00540308121194951
0.00504831039333533
0.0031185232387625685
0.0022003336409789484
0.0006100178295907531
-0.0003211378610492538
0.0026630333582846823
0.0035162708693137123
0.0028712808181711558
0.0035636640214987934
0.0025249574627415274
0.005930988657602613
0.006552277240748399
0.0049031387665488665
0.0053976368786812275
0.0049338037078227185
0.008556207161565745
0.009782058283643676
0.006186335935114982
0.006102686520892416
0.006411035553630908
0.005019591004855374
0.00634366456664207
0.006022462112029746
0.006169586200593364
0.0060693115462680846
0.005442739195450733
0.007024532189714697
0.008097189523406724
0.006933272304646374
0.007806152409209172
0.00860587569843532
0.009149760823253455
0.010969791458740314
0.009119065035856813
0.010007031663388632
0.013029989233336878
0.011468278402692648
0.010852928994496752
0.010833850923328201
0.012093594197744568
0.011999002597253181
0.012394411184831481
0.010648874809441412
0.008552409651830397
0.009176451319393696
0.007394543393240874
0.004602419384741533
0.006018044828657749
0.007463392446865446
0.010557411772079759
0.0059624967815855474
0.005107639677875436
0.0026155922506149966
0.005878846610877809
0.009539640655518452
0.01202641939955995
0.011335450706289862
0.0076052115697534915
0.008141280994280688
0.008968570804834104
0.009535012113799387
0.008512688970347841
0.008102355072482092
0.008498401302222463
0.009221579369457122
0.005980421337362258
0.006845928243616555
0.008330924239635471
0.009425873651683207
0.011275525908113895
0.009265637457031215
0.004969227063860544
0.0042133006278923055
0.003982671137327112
