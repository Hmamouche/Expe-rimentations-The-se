# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; LHELX
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=9, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.11021495743848686
0.00825619799501294
0.05812488970262563
-0.02025870935776969
-0.009817160399497843
0.07229539336574423
0.0032158657293982623
0.003729992152834788
0.008339181590369782
0.016989225710676167
0.01760306219545555
-0.0031756663363842214
-0.04104879687886754
-0.0014789856122940912
0.011438449073479373
0.030955729479681775
0.05658162744643125
0.004798486358205641
0.006465173899698979
0.025492046313868415
0.030709013552415086
0.053260188459694956
-0.0274861240844919
-0.025194266423339856
-0.01785019697299995
0.0013740907361909594
-0.02502148902295278
-0.034557862133971815
-0.07477144707935911
-0.09350965149177484
-0.05997736048275301
-0.0060988535408594835
0.01514544137571313
0.032684270574407565
0.008613188478532976
-0.028173057016000595
-0.03190274340192632
0.011458194595303634
0.014110365788791218
-0.014224682716182215
0.04060708109492066
0.03740391507780762
0.025924971293499324
0.00510094719643711
0.03611164304673843
0.02623814539688566
-0.0020159806463743712
-0.014709081359346305
0.014119927370114242
0.007258782297286579
-0.017894617204662372
0.0019280453384486265
0.016418010599435245
0.0018353261546471562
0.03633674645869344
0.009081832450424765
0.022661602794653086
0.019985424924871077
0.02542889099942569
0.012234746158874018
-0.02206323064644239
-0.01864215461959518
0.035548565312770855
-0.028075508651255965
0.014550667042120755
0.014585445296321747
-0.002617338779685459
-0.007215888087394286
-0.032894044055826355
-0.01400553266553935
-0.05363887544321977
-0.06518492664445678
-0.08161558687068972
-0.07609328850710627
0.04193800702333616
-0.03291035919723706
-0.013897076735085178
0.0035904090472400306
-0.06908101812036292
-0.002422817940909724
0.034047868853347554
0.025410600536678943
-0.013659451321498199
-0.03428962372871809
0.012686396582300682
-0.010167578182002637
0.005185900935420078
0.002269571842986054
-0.0033147988337028362
-0.009951296508359894
0.026061782525340887
-0.03596906511222061
-0.0200140373797965
0.00899174571142493
0.012166085712232771
0.0016555666522556625
-0.005475053771089049
-0.05527696326745397
-0.010489573833402852
-0.008197022689540725
