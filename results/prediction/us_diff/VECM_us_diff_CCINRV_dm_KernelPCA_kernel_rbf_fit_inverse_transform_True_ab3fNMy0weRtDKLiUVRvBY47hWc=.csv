# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CCINRV
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=9, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.006557923345592819
0.006727361972982504
0.009309865182931828
0.007764694189267966
0.00888785896758359
0.0070486751313627695
0.010833081048282744
0.009564974492569876
0.008847559099628694
0.009983742658255097
0.00788002002934488
0.006952031206743903
0.007328881098437872
0.00693723505645643
0.0031698123451700914
0.001772182643107489
0.0014730131665065573
0.0027564830712665366
0.004325403710019856
0.003978087302602236
0.005870663779446155
0.0034487615352916646
0.007817525119513311
0.006088292140321352
0.004700119932425641
0.005482670928811713
0.0023224945075312727
-0.0020930443987785207
-0.004241887579152601
-0.007212278081987463
-0.005095177640739295
-0.0019284908422212321
-0.002461841790719263
-0.005720284649011505
-0.005538668830670088
-0.005002597816639555
-0.002259108252018281
-0.0016365942384306456
0.0003224751245413768
0.0014539322469343428
0.0037071261694558116
0.006067272006200541
0.00920292842986662
0.010298768460279224
0.0099584519997538
0.016013785927006603
0.01216624471762036
0.01225364699224488
0.010930511486984665
0.011133126338427871
0.009800152895658986
0.008278484739366408
0.009311668213729304
0.005909556911379552
0.004996940610425095
0.007339581799051298
0.004994402049455485
0.00764605234907104
0.003585072092606955
0.008804686895430593
0.010448407676450161
0.010867560849992346
0.011771058658185075
0.010767023631455973
0.011662213322208258
0.014979797102860449
0.012244011831555057
0.012590065294089119
0.018901827546959554
0.021557813484158667
0.020558438998347556
0.017462425004601028
0.012375607678573451
0.019491696678625322
0.01760729943734962
0.017382085993761176
0.014596607827621039
0.013706294551187558
0.014571768794555023
0.012844595536208703
0.014164376322683634
0.01470274310830253
0.01531721416857007
0.011699027922968477
0.01116963891042994
0.016694786207766665
0.014290429345176919
0.015428758067219692
0.012999497116666356
0.009653233221183753
0.008058370981936985
0.006669515525910407
0.007115546686225462
0.00943858895794188
0.00810860803002196
0.008707448332237275
0.014242383448422163
0.009020297664063382
0.0058303470854213675
0.009318693875226353
