# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; FMRRA
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=11, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0009278225288292408
-0.00028265980953494265
-0.000597315714919914
0.0006766536236797051
0.00034780593727117085
0.0013396407044835566
0.0007771790018857279
0.001377717929260659
0.0014198730812270957
0.0020109256516328213
0.001368047337523696
0.002234401091312933
0.0030210785118878767
0.0031987329122218173
0.001873592401488696
0.0013166907560645104
-0.00014005673914389664
0.0028976926638411863
0.0003036773794526624
0.001338145115924881
0.0004419484372692362
0.0007298408471032001
-0.0007415114232296302
-0.0004938424901922934
0.0010936524157985714
0.0011462090573649607
0.00048219583864954926
-0.0006594828648745067
0.0001637637391234394
0.0011570905254325954
0.0012155462918238742
0.00021407956817874515
0.0012803846328152185
0.001849538466069998
0.0034394826869790216
0.002058381800184697
0.0020506583813931943
0.004936990011903446
0.003548613713118109
0.0032341705555646136
0.0021568349965515204
0.002729048852682594
0.0010843530087896855
0.0012753531297877772
0.0004934692834078939
-0.0018126793613315513
-0.00023615203776681103
-0.00038773037231535674
1.3049318785566361e-05
-0.001181808954744244
-0.0021190854467507893
-0.002036393999515434
-0.003432553490323697
-0.003038599970569832
-0.0024014271568144944
-0.003359886381882087
-0.0015913826473260319
-0.0009826081707500131
1.3149641162952787e-05
-0.0006884391956917175
-0.001138997716047393
-8.486205237591936e-05
-0.0010367595713868024
-0.001585017150860616
-0.0022142706513875936
-0.0009577671066365942
-0.0019690182856551023
-0.0008849947279648373
-0.000551848572430047
-0.0008821130904799642
-0.0006436789890612531
-0.001195463235935387
0.011193477834714895
0.0037100882137160876
0.0056467484467830785
0.0018424668364128171
0.0005659520784075662
0.0005865973611527929
0.00013371011307550804
-0.00256132223650063
-0.0006384024952667393
0.002633836630326785
0.0013193201566714364
0.0015875516898398354
0.0018962446003431956
0.0008486603517846956
0.00024568288141724106
0.0008778441571526041
0.00015372578155579882
-0.00023017832365357396
-0.0008066063298765847
-0.0017725462796308624
-0.0007321575636483834
-0.000656305259794993
-0.002538024098706094
0.0004923500343599208
0.0004561665899382809
-9.418271519118725e-05
0.0009505564771106311
9.521143577307108e-05
