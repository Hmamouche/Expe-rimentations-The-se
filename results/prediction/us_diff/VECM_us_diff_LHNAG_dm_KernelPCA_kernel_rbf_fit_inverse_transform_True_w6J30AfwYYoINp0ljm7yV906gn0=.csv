# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; LHNAG
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=14, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.0034042423090059823
0.006709310655761586
0.010858554163502808
-0.005092886284605419
0.002177976964085065
0.004738751338320827
0.017898168174118052
0.0037958080998069335
0.010980797422847471
0.01604746499771248
0.019996147442442297
-0.0014083975749169838
-0.001428230151528782
0.009000459673279292
0.013336407510498232
0.012976910706898697
0.008078464951848113
0.005925352588799921
0.007512940168364132
0.008962719935613329
0.00849165714314837
0.012985359372968224
0.004187311860990786
0.0007391933807007285
0.003783169009241528
0.004804516541818197
0.008457399609660137
0.007124439979496731
0.0013496778970299374
-0.00407849192704547
0.00014376198887688279
0.0010255547194700826
0.0059832947825940175
0.002119303613877986
-0.007579848654614327
-0.00015117528455860143
0.0050979410836774096
0.0060717730401496665
0.007788009707415156
0.002209771587626227
0.012096884613628558
0.00830488119159331
0.010040824402578325
0.002622720000518771
0.007101357482792964
0.0099455602919368
0.006797619911110747
0.004470508208026384
0.004960679712695025
0.001612927967530802
-0.0035656659815648
0.003798425112280398
0.010786832891392472
0.008646791696071883
0.011429442249002934
0.008662616893778655
0.009292639840008055
0.008798934740774514
0.005204377074533604
0.00469795023674675
0.00042793441060541386
0.0026953871240677375
0.008908344960742456
0.003890151887352377
0.010062827520343477
0.010148387641179873
0.010431347691267098
0.004075200914583429
0.007247382022919709
0.015448808373722199
0.007429453264674402
-0.0020563064084543003
-0.00360385996479018
-0.00404318272822162
0.006529447512847722
0.005203792948990756
0.001199106095674439
0.0015150447636547333
-0.00024655815695260653
0.003001410834586101
0.0025916940670618785
0.012576529622131105
0.009844567565762893
-0.0017980997791713395
0.005246652936003128
0.005773250744063749
0.00015878545130213959
0.004757213362844149
0.007455874729965864
0.010849027098056574
0.009738415847239765
0.0049260783535319055
0.003536637091823899
0.009528649314677692
0.008189724412680881
0.006759123730935098
0.00790591202621504
-0.008978568912606847
-0.0022876937874774864
-0.0005438790990116543
