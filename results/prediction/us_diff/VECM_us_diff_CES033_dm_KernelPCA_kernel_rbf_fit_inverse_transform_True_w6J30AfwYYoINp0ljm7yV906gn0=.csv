# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CES033
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=14, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.003207308562294845
0.061521636857233
0.03900814302969845
-0.04911583464574922
-0.0011359659616069738
-0.028514052332185284
0.0014045484679712852
-0.021164975902165352
0.03203940362479266
-0.00192027655395984
0.03015849264852325
-0.04874127533013127
-0.019075404202231458
0.010496738700604939
0.034743292708066066
0.031105157868390115
-0.0014886139627511216
-0.015013928319884599
-0.026385291067571558
0.0019829542623576897
0.02361998276420839
0.0184688346328314
0.005932331413019294
-0.007601149043629282
0.009073524725001954
-0.006979841488009485
-0.004859498230427197
0.0034504284907484455
-0.01549811328942704
-0.031161730622096373
-0.0034293247080708026
0.02121845324790515
0.0006868716062958819
0.002932349565557273
-0.023318124221403735
0.0008977354805655637
-0.004147360987025546
0.009637528120851951
0.003480958910553191
0.005741158742699728
0.015838606605553154
-0.0036368720745012604
0.019667452493525812
-0.01011296178997878
0.0007841402431743843
0.003034498075067335
-0.0009584436657402596
-0.009066426626534736
-0.0013436254773995407
-0.02400418459486299
-0.010080395077496217
-0.007555494477832859
0.0037358917524830935
0.0103171623451286
0.00029033084097023756
-0.015128631237737028
-0.0005622352835000085
-0.010023268528840551
-0.0008784344270826305
-0.011723330532638406
-0.0313905467200017
-0.02797278984567417
-0.001890230647595961
-0.013788282315992979
0.008894803634120063
-0.012412603641463555
-0.022243268965446237
-0.024322993030772566
-0.02069563252500349
-0.026205503038220695
-0.032511267841376895
-0.04280954504852731
-0.04039749491818354
-0.028290213235693282
-0.00979646025761397
-0.007272491207377577
-0.03413647264606608
-0.0517540270412183
-0.025637502098911136
-0.021209269742919545
-0.00835321850013026
-0.009591327285855229
-0.01500744667348354
-0.02284650432205613
-0.013217152873295921
-0.02343233473204107
-0.0414250206869817
-0.000365629739271752
-0.008556108124663061
-0.011206232264755646
-0.013339269548347054
-0.006560845544481183
-0.023647140168890274
-0.005541260048558965
0.0017871655439607118
-0.032863009595001845
-0.01647929710000845
-0.029284610340231103
-0.021023580891031592
-0.013915643840603712
