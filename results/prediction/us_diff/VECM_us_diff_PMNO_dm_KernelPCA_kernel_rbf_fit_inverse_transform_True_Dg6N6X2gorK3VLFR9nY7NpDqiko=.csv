# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; PMNO
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=3, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.08854781820221924
-0.18104514087179907
-0.009083249730277743
-0.19888305527714553
-0.06109384564716115
0.06020929970315106
0.1331854232355197
0.05240238108090271
-0.007447470658486902
0.06516578419468294
0.09344328336409413
0.030611844213486405
-0.056532570916336955
-0.02877235863072242
0.04503122104571933
-0.05954345589969186
-0.04300120558024353
-0.1076002716104155
-0.00446526339754252
-0.021138146500906764
-0.0255638853353432
0.06150659807258346
-0.08075434553753892
0.004495068946722559
0.04154597732776448
0.03117302709372412
0.023001310607709234
-0.036937495244338724
0.021169106471985562
0.024995194042087714
0.10231761523536609
0.09612137733964485
0.05146843502172229
-0.005456117509091321
-0.00251447255590094
-0.0017031421032464716
0.0417358285194325
0.0055945880442464496
0.0060251871689409875
0.03752101055670145
0.003034879758943846
0.0042276471966171646
-0.02269437331751521
-0.11325908958355818
-0.10224414571218338
0.018253653029232684
-0.06192099758839905
0.06778060040922886
0.026762987996041435
0.031646425736078836
0.014149711215571653
-0.04056385569189641
0.009673112837461095
-0.026210699224616205
-0.060106389885821974
0.0010005456820586234
0.008888108456569961
-0.030615497580861156
-0.0036625785500787656
-0.02297679318533528
0.0008567398233622833
0.06227259699842775
0.0016831780879296536
-0.04272375250966823
-0.007285588142565447
-0.03479273497595772
-0.01717231091927982
-0.013955730602334501
-0.02271395812446998
0.019669725836967127
0.09078477904618196
0.047809851886703635
0.03467722823492178
0.08583344067099175
0.04961381070089088
0.02537269943784156
0.090992589039415
-0.05801900577049862
-0.01821507932163299
0.09637103309148565
0.0270590369238346
-0.03318865746486326
-0.07536825451993713
-0.06095266684434217
-0.06488821921804602
-0.025681870208535663
0.03170291985075776
0.015392643721558706
-0.002562860429654947
-0.056458452157854624
0.03938219646825451
-0.08142571239889611
-0.08398233313614446
0.025004108071171656
0.039476891475379014
-0.021832852196111863
-0.006265742176202828
0.0006337867959747782
-0.010323613819211198
0.08869061607296692
