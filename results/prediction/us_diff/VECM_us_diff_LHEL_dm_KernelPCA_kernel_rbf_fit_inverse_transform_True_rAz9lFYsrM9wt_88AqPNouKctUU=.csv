# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; LHEL
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=5, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.0030919246840350467
0.02949749080524186
0.05435925136476334
0.022778111405001026
0.023994478503147097
0.054662408530899445
0.06539259022220731
0.02504887584115244
0.0008293188712214768
-0.022643947573736792
0.009625539044298238
0.008387158111243702
-0.006563190076173947
0.00014230679401484696
-0.004991902965045149
0.014127367377335016
0.03841335693826192
0.01836229577027569
0.011297786189232642
-0.0271466848389181
-0.0019640486211276297
-0.0013783087728436601
-0.023548621032197202
-0.026175215292267746
-0.021380983613092416
0.013915273094455158
-0.025240567714019
-0.07700202605115751
-0.06961206570194206
-0.1325544307190414
-0.06732450544556005
-0.006545437210257084
0.006870702369574774
-0.0004540896214081727
0.03267230134005425
0.0030981483882601686
-0.0011940743146277065
0.01839592777478631
-0.010443477147710984
-0.003862978215449429
0.014230743746312802
0.06651860092073207
0.09422797571640458
-0.018508210864600604
0.02978174845169395
0.017332788327234158
-0.015744137960280694
0.009414075971279431
0.0197115938006045
0.0015383055675931654
-0.0018455113412488792
-0.02606278974892043
-0.011907351009980196
0.0152265309691933
0.027512176688560822
0.011393753113451609
0.03444972781967112
0.005827712521671675
0.026223607582749723
-0.01012772854069294
-0.014837021558420541
-0.014227507642626834
0.027052472979101475
-0.04604531353546393
-0.007661939761211271
-0.0045912059008995625
-0.010065495499184259
-0.03047320593958737
-0.026405952095303463
-0.03127104013347337
-0.06136145848396921
-0.08883423795242934
-0.06862981499262125
-0.09287083424043725
-0.046393554340103026
0.008963360149765932
-0.04361749870080461
-0.0171646230327781
-0.0494718512326081
-0.01851863332875268
0.004377061349587607
0.037090359023533324
-0.010125297875960206
-0.019107343105682146
-0.023962023912181333
-0.000798047218727462
0.0040939630244812685
-0.0011179374506688246
0.0050405947416232895
-0.007934243955588758
0.00482891548401444
-0.0658063612067602
-0.02998833812748946
-0.008967448222865803
7.735343590816769e-05
0.008437009161660299
-0.01810562488609731
-0.05763678227336485
-0.005530127935148124
-0.03300634223017403
