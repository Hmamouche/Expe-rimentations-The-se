# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP276_8
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=5, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.008685604652906824
0.0019424660534525864
0.003923365757046721
0.005024027294888027
0.0043510938215093435
0.0031816108944783847
0.008795439732919998
0.0058570985074410074
0.0008630527677907677
0.00954094339054703
0.00663739814618471
0.00814093074857761
0.012539741396353735
0.009511941878892604
0.0036875240585503284
0.0010584291083079044
0.005518629196452952
0.001329287629961936
0.008519313351417581
0.007611030912061421
0.007318680620268221
0.005809709137843272
0.0068623036624466905
0.004094398875792268
0.0024041091865931417
0.004194657978926679
0.003988612085099302
0.01212633182833817
0.005174443114320523
0.0043150224928461085
0.01067467747421877
0.005920038843548187
0.009294675449588756
0.007095215542182969
0.012471438457401757
0.007028203137688542
0.01012176808348825
0.00689235657705217
0.004050235725388174
0.005282910762988447
0.00207656044672968
0.00228602727872601
0.002710295053668291
0.0051048455829716816
0.005717167654488308
0.005702187078355329
0.004466160811935196
0.0068619910194387245
0.007439620773464432
0.00561211626460392
0.005559623172116681
0.006576548792329083
0.006000301363485996
0.007771030004639467
0.008184829621701006
0.006648068430052136
0.005913618770623514
0.0064397341637210115
0.004345431162614537
0.0025495954238768347
0.0028962512722083317
0.005045814111517107
0.0023926901809550494
0.00713340066668806
0.002808097108085415
0.005649280760509005
0.0073280289097707755
0.0034108667381848316
0.0024272704931682246
0.0011065299416307065
0.006485385531083689
0.0014898692108470141
0.0018271793896101987
0.013507051456138881
0.006677168491941825
0.010593457808722817
0.004971154007842812
0.0063595298163259765
0.006241826276529473
0.004655103009630346
0.009688649038608662
0.007519960442803493
0.010494105631548829
0.009131758004059503
0.006252221494577884
0.007822929756726844
0.008530910010235275
0.009684158631479778
0.008142453925145064
0.009542227860910354
0.008093980339432778
0.011952868559689137
0.007345081558046685
0.009690817961121813
0.007087065656611765
0.011374590079840208
0.008678125826844022
0.011545352891944577
0.008313674960950338
0.011186260041075292
