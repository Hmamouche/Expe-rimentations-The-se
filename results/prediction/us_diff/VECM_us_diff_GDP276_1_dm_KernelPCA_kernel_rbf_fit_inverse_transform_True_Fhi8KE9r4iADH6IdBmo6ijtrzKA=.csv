# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP276_1
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=12, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.005919537364108751
0.0030467933757705483
0.007385759218393657
0.008624056218152909
0.00636592354888028
0.0084685747950169
0.006175651978012674
0.009002480531446977
0.007737386050981579
0.008013355271411737
0.008822134204910976
0.00815785344855415
0.0038042954203863686
0.008176087766367192
0.006731176641053183
0.0050794361367533705
0.005796577673815978
0.00934612265112248
0.007969314978431957
0.006248432812096302
0.007327810229154276
0.008424091229521159
0.004062366789989351
0.007178705280961871
0.007545809444507945
0.007017838373271251
0.006484134118992645
0.007304994453487808
0.011966623916847002
0.006143162600947824
0.009236182471629823
0.00360749079800748
0.0034299763305763956
0.006883203783063436
0.00535348585803073
0.003053763467477786
0.0042192844319106915
0.005788838150616508
0.004511344404340541
0.006406069137471374
0.005072568397393049
0.004180725069278608
0.0046152735328860665
0.006565475279798593
0.004289034053199214
0.005594693025529108
0.005269231046535179
0.006435724106663097
0.007459045023845535
0.007314181985289553
0.005673536430515916
0.0055156056427631195
0.005617704124174151
0.0041659784332926195
0.006082083373612286
0.007137995252540873
0.005191115692931318
0.006627201087968499
0.007090760675158843
0.006606234446506588
0.007129506570489268
0.007838273511633777
0.004423379181713451
0.006153508992032517
0.0059195044623105405
0.005952529182150598
0.007151573198654796
0.007504278585335499
0.00717274163508708
0.007563068301271048
0.009045965740567865
0.007909200327941561
0.008951775712677896
0.009227229816735634
0.0098767999830785
0.008572075283454722
0.006985936497962403
0.009887378568423335
0.005612582851222364
0.006176624866139339
0.0052914511011376815
0.006726879087991328
0.005339789533210951
0.006921834581441567
0.007260770039463392
0.006004180122604762
0.007017090992184764
0.007309032920455398
0.005559586970615162
0.006492224575707019
0.00776957645838254
0.010765545794104376
0.011235048051476739
0.012732332741646299
0.010989413972362944
0.00926611673972166
0.008756869995835624
0.007986281013746155
0.00812616124332057
0.0072133000816873875
