# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; LHEM
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=8, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.007648312687537199
0.010486667483989891
0.011046989813328457
0.010584183160468887
0.003608057428040467
-0.0027747848644192573
0.017300529622802475
0.0037245849730265144
0.005680452221279721
0.006927286777192564
0.010527385164644474
0.0038328806090582096
0.0007872447558258961
0.008357889336815881
0.01369808334361766
0.013442586209960812
0.008290913587553189
0.005678764407084294
0.010412540051571535
0.009998736011654068
0.010680747756527473
0.009748851563640807
0.0022308927612165507
0.0028137974046001917
0.003435978753033581
0.0061654852906627075
0.008991717928398797
0.0026238128027862347
0.0015605641039690512
-0.0038940318712867633
0.0006124981647156859
0.0006369216026926258
0.0053488322618757455
0.0013013119506681027
-0.0035392341867413355
0.0006515577192166143
0.0006078057109596172
0.0071549923607093086
0.009844715975447126
0.004292085789930735
0.01141336071954464
0.007663518239042579
0.008708860417800232
0.005544984842001005
0.008342806796890952
0.011279009248864852
0.007214396512889951
0.003769641381018906
0.005462299665076973
0.00011659638185150317
-0.000421485684035132
0.007032825356419081
0.011291189884665844
0.009045784011165143
0.01179481366410219
0.008889221277370001
0.008655728986987462
0.007223243920794676
0.005471550345387441
0.00659711436630425
0.000652345230679509
0.004719145788926946
0.010379079096537123
0.0030515139631835434
0.009864563088902198
0.0097797689798006
0.01039971238746129
0.0019042131907962873
0.004305469635002318
0.010314158516305693
0.003659278946284165
-0.004934400557520949
-0.0049936101872779404
-0.005475899923967467
0.01055301139509787
0.0021712620992249522
0.0012119702015763803
0.003517381643857582
-0.0016793289361070535
0.003841349580907641
0.006504151880779857
0.009643863527073124
0.0022270662705263784
0.0026111634878376666
0.006315022852262827
0.003064943647493885
0.00023140795307948284
0.007220885421578313
0.008739241675611856
0.006730498892077198
0.010820989859356913
0.003032851297481743
0.002861525508548771
0.01053664412782577
0.010781639488155454
0.005654624900505135
0.0043901570098061355
-0.0066882168269986235
-0.00462876099763554
0.002093887255494652
