# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; UTL11
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=11, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.11177117682138629
0.08416454182699754
0.0516917142418641
-0.09614885059778451
-0.06729225217086134
-0.03244221229815385
0.0651923168787871
0.05014139751763697
0.02880050355226725
0.0005238085615615548
0.12079366204996042
-0.02997149650873956
-0.030849089689065128
-0.018129654555509488
0.04890939316667295
0.07615253762534469
0.06328097393363588
-0.008469324050518274
0.012316136384251265
0.009834251421476939
0.01092207172276937
0.11575267731627932
-0.0843783013500274
-0.021603338824961085
-0.05106078873397632
-0.0051979746101132665
0.025517576883906837
-0.033629709540325764
-0.023339918412653232
-0.11582203062090043
-0.04380958079524329
0.03306295018819951
0.05010871320286295
0.0055689311803853395
0.031416183251483154
0.048462953389435626
-0.03387938525764232
0.06742827938884369
0.009063532048018394
-0.058818825431602356
0.057402530338474825
0.06010419605070241
0.07557443483222315
0.03123110780987854
0.014762400829968686
0.008839409402796945
-0.01555374670771461
-0.04532895789710212
-0.06827245856040959
-0.044199942986700776
-0.021390019853485986
0.0778960521138934
0.04561821285090794
0.05828268591116663
0.030001897117384626
-0.021776913041802397
0.042071773710137796
-0.021031653406970365
-0.00012135272805769391
-0.00779776990714048
-0.08401236768038786
-0.022648768541915353
0.03868459497468277
-0.016097488533805136
0.030376128185012598
0.032435748998092706
-0.04994484169472659
-0.05575349728295374
-0.06184473989528386
-0.06489116085751422
-0.08616063507557507
-0.04017362784587905
-0.10638600285374027
-0.09758413447021508
0.0826901088902379
0.0015368639992032543
-0.017782588528061558
-0.004647021120359796
-0.06437290117645872
0.04567826944389645
0.041174956730867775
0.08539188089382152
0.03356796844060128
0.022829273251640594
-0.00869042767284549
-0.044058317401272834
-0.01636894091360629
0.011382628187868993
0.048352240972978404
0.025105104029263824
0.060290787426930115
-0.010884536862537876
-0.062026034312711316
0.0025337600343431892
0.03694170883771297
-0.03318977767104574
-0.0069346099536683895
-0.044672216641524105
-0.05488641922579375
-0.009135416247325195
