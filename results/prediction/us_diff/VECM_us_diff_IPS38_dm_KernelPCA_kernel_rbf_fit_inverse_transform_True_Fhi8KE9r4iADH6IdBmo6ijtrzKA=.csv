# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; IPS38
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=12, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.025956296997379034
0.024671727647442514
0.003946810334636668
-0.01459366018592009
-0.002124973038291764
-0.013998436541541932
0.007889889981201135
0.018065470005339875
-0.004219732717899221
0.014882007786180427
0.019276528225760616
0.0007112480675875148
0.004127588966283278
-0.0030756403617619864
0.009828555595906018
0.027098572883273483
0.02220472359585831
-0.012191980782540267
0.008061346058048705
0.02276096271068583
0.028116560476299447
0.004175820595507088
-0.010134069330589881
-0.013864029752094775
-0.005542116459336201
0.012452272910351468
0.01124652614294542
0.002491174336813639
-0.011859898339927726
-0.013051187199328466
0.0009844099966331739
0.019949096237237528
0.011224730037240005
-0.005107906452689027
0.0035954282896514143
0.019705942174748168
-0.0004934080883990961
0.00046718727244582717
0.008823925950540035
-0.019267944329923754
0.022212390183053154
0.016098222026592415
0.020762567143545366
0.0022566789812445568
4.608199627869052e-05
0.004144609369927395
0.004968237937124416
-0.012381499572689733
-0.007631225538253761
-0.014308998382786502
-0.005308360948734589
0.03248884949957749
0.016786417210375857
0.020813843910124818
0.009057832805859593
-0.0025247175350219518
0.016546216839879457
0.0017308023835593293
0.014498097041261563
-0.006522278482589612
-0.0038507308036790965
0.0005956651925899557
0.02378745054546126
0.014174239980124393
0.016190672802197915
0.0008975922296049436
0.0011184271887140261
-0.008998859066216017
-0.030308587788100895
-0.002126248419727186
-0.0322984455473055
-0.004570129913559911
-0.020220515621249782
-0.0071746389565105085
0.03206793754798449
-0.001183646601144589
0.006835532930433154
-0.01877121061070907
-0.016102508451009384
0.02483678874846825
0.003184681636891746
0.013824244677669986
-0.0004199259003160108
-0.005438335998786371
-0.0036650035645225385
0.003492825453118736
-0.010084597330159897
-0.0038514464085916515
-0.009827002450579221
-0.0011610755952823106
0.049733750987663944
0.020457559728097627
-0.021927386221168618
-0.019765248441612395
0.03288372836528769
-0.009602616913269904
0.007991992523836294
-0.0076878070798122086
-0.012042093845140728
-0.011711183656829955
