# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CPILFESL
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=1, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.007996227240681525
0.00773281621680248
0.00826309375678456
0.007297962028752534
0.006319646060317355
0.0058815586531038855
0.005968543913916857
0.0055027734379611525
0.00573384351551101
0.006890718213097217
0.006050794206727329
0.00585360286353822
0.00586225170420801
0.005453349638964124
0.005815551271347332
0.0072520852670898694
0.006342408373927849
0.007742672025975679
0.0058998299511668845
0.008434003736781288
0.006638712736541879
0.008595844324188308
0.007250515540815815
0.006988236620009921
0.006489763981998529
0.007880897229548935
0.008495439895536768
0.009198256745475608
0.010455721712815436
0.008520440287778357
0.010155033462711028
0.008300317363444205
0.00870058148454173
0.006936953706938981
0.008106228752788418
0.006829991161526841
0.0057697638614558
0.007482367617076833
0.006908361739670552
0.00662535062465832
0.006164909154342364
0.0065172028822502275
0.005475352230654353
0.006556798451965356
0.006184646799116258
0.006128829781540966
0.006122202601604617
0.0062029255740512984
0.0065671323028022475
0.005342258698627514
0.00587145614944436
0.006278363775336001
0.005347503304966578
0.006180684638158617
0.005668337512375024
0.005764266946877952
0.004669662265409879
0.00504693175185948
0.004964106462097289
0.005111180510454972
0.005363781436481025
0.005084757933214928
0.004929649417705688
0.004505450203529777
0.0050239024522335494
0.005650243827255821
0.0059470762550206755
0.005846621781812973
0.006330788003557711
0.005462194478644707
0.005999324788560587
0.0063084698102853125
0.006398414164275797
0.006010966116565138
0.0074140767241473405
0.005178733101749947
0.005130324450875653
0.005219681323217893
0.0035211006066272507
0.002193692028547187
0.0037954783633307953
0.003261744725075671
0.004699589926808389
0.0062641517866011175
0.005217395362822309
0.006278042612780148
0.006158670547970022
0.005462505892109905
0.004889232060081488
0.0059609066772079765
0.006059164118512541
0.008758662784625825
0.007849558720646056
0.006405265991525429
0.006082034531940337
0.005860173912490382
0.005319982730415656
0.006974681396499538
0.006586406546106912
0.0062069630229437955
