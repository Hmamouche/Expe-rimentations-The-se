# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP276_1
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=15, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.007588187558851158
0.0026780984853986365
0.008727642393175854
0.007974154533700822
0.006243859496336786
0.008563948094097584
0.00567059979505794
0.009425960004151107
0.007304988971831875
0.006928264316676735
0.007177971298341057
0.007789116732648044
0.004561628793853473
0.00941879110755917
0.008543002624948032
0.004985894367493836
0.005375016288362496
0.008794443666332773
0.006238838749642086
0.006481733793456409
0.00786679360060003
0.008269197683672501
0.004203662938014203
0.007374210668935859
0.0074089939823431625
0.00712553306817583
0.006317473220885117
0.007363291640371298
0.012837104121250909
0.005934230193668006
0.01064005018354351
0.0032427412910884133
0.0028924859456901982
0.007520508592545227
0.0054426688934326424
0.0025495666454837407
0.004643150122559479
0.005371158239153025
0.00556688576565843
0.006356050219099843
0.003984224061703862
0.0044293429319266706
0.005268101757331403
0.005939584744175453
0.003948827533716457
0.005797227238191646
0.005355666548384047
0.006283366444898551
0.008031148958551521
0.00798298598511645
0.0048180733844618885
0.005864430621148138
0.006126896796525244
0.003766828528861078
0.006375211271628897
0.007286215369725029
0.0046521038017077005
0.006472557334395266
0.006864540239725233
0.006812472448394623
0.0072295129719658815
0.008196276739686875
0.0039411570176099316
0.006196051609955152
0.006640625069161483
0.006281468796559054
0.006813055071462148
0.007341101339814809
0.006605245119591317
0.008131338369538546
0.009286870586975814
0.007895872086909072
0.008949815180468173
0.010041933071334254
0.009892086233566017
0.007959583783774137
0.006326783435696995
0.009822907207192193
0.0053350175189728
0.006301729544058909
0.005194588179724545
0.007191647892461771
0.004606543773404295
0.00692888622792864
0.006946298994912249
0.005721682948465093
0.006839765649072451
0.0072040388356590206
0.006132824352332096
0.007492194945462569
0.007985078518949154
0.009959486748162136
0.01175073469978111
0.01256568077841158
0.010382112912560812
0.009468795276812844
0.008619463495924767
0.00872247327445296
0.008398218504260925
0.007480456045540639
