# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; IPS306
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=10, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.008685642608606315
-0.00984253901327244
0.0539500620541493
-0.005640491026776058
-0.007813512572081904
-0.02331342116138861
0.05725839184579559
-0.04963120986649999
0.015649848023314466
-0.018984418708657108
0.02571123326804429
-0.05230058204074522
0.0001964911203860267
0.018479110934042225
-0.002826227353823773
0.011203080009234555
0.007601872461332773
0.05105084550054197
0.017246938030879334
0.016407655903069262
0.010314505084809552
-0.0008454580929732215
-0.004875716114295746
-0.010306847372157837
0.0060523160164758175
-0.005631371142904285
0.0032801167393014252
-0.007286225390661972
-0.0012271715580737183
-0.027049248338833747
0.07174656601898369
-0.02980207025000183
-0.00479084684517448
-0.010681430176995396
0.016866959325092905
0.012120960237023266
-0.00760782900182059
0.01597865072369455
0.013818022829773392
-0.04581044588188403
-0.008366081506631803
0.01967607791636904
0.0028145916646727014
0.013124823878009211
0.012609041779639073
0.026858587634748753
0.035693251526143006
-0.005381911980608799
0.00692669399297189
-0.022831895170159173
-0.03093472520913833
0.006691233685013897
0.025845960001283225
-0.01848084416215772
0.04976904001790411
0.011165855649493156
0.004816866097419039
0.0044937096914718
0.0005270463222982582
-0.024640915058341522
-0.028819186834387125
-0.00789582267438007
0.0006332263557569991
0.024582561069677877
0.029758434438336718
0.0353962931926831
0.020726507907034737
-0.002424352607347901
-0.010480611493795838
0.012534018275648515
-0.01100779030510006
0.006369405171096215
0.012270703748312873
-0.03762126473667192
0.027599027312940783
0.023856872114005077
0.02999629615384548
0.0005282058831475867
-0.00020166225521611302
-0.029545977404187546
-0.006763041648540193
0.006112861186992844
0.035326779935820354
0.03555101958353474
0.038272261239430255
0.0036767889186278217
0.036539806087094215
0.029486595268418028
-0.007468283597194092
-0.014822677975511504
0.030125241387521498
-0.016130875702791765
0.006518562983329135
0.034519486160208404
-0.02430325958657314
0.0034533036845799765
0.03134044245043305
-0.030743086316575536
0.014038441213096893
0.035373920242956804
