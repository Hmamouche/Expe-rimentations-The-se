# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; IPS38
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=13, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.040379974636712224
-0.0015006470557718684
0.019956991393288166
-0.02348581436963674
-0.002712483278813939
-0.007008009938716553
0.005213980230933416
0.01866496085774477
0.01484272123707954
0.023075607460426962
0.03295095991804664
-0.000999827968999965
-0.0066073147624560605
-0.005750195906408725
0.0061310652467479205
0.027119804248528553
0.018436864022503528
-0.00951652625386218
0.014790361070737851
0.010026416310548809
0.026930330765784043
0.012178620844129722
-0.011287510018793408
-0.0174767617832831
-0.0037426795862738537
0.010121024710878765
0.010932013501813507
0.005748665501302009
-0.008412402602028222
-0.010430069286808666
-0.0005513872467575072
0.017707790174894128
0.007673616219649784
-0.0005997193140126712
-0.0004819227916328392
0.013577124694392694
0.009880987878054104
0.006567781764332991
0.0014191964198414526
-0.011063400598718413
0.02685183372988459
0.00664213747849732
0.01909085948103992
0.003225604452266359
0.000893889700044022
0.006273134992764143
0.01336744871685882
-0.01168514414162102
-0.00888871241015027
-0.021896886700876868
-0.008623474792177377
0.020645425520229518
0.009624861214468006
0.02066886481864623
0.009172355706846996
-0.0005931014336414359
0.02182114314770105
0.0034633469989524684
0.015343505610352692
-0.012589956923769623
-0.00566886425433159
-0.004280035782851781
0.0192495866203647
0.012374303154684223
0.011054452235739356
0.009568131120213147
0.008168609214154934
-0.006085372294143739
-0.029907657835761617
-0.005350498062099269
-0.0307810231258355
-0.012786107528048376
-0.024271926022969945
-0.007890420814862645
0.020715529988379493
0.004989083647324748
0.011393413043239339
-0.024276804335152016
-0.013501868118625198
0.025857549636530516
0.004627138732713008
0.015391388651557154
0.009988925137374028
-0.001467191909962114
0.0006560022732170481
0.01045116872405568
-0.010911906590742863
-0.007854617396697608
-0.01574479062387789
0.00045443159421756224
0.05476736087452608
0.018488684327091855
-0.020390364494199766
-0.008896232949018958
0.03178855216753914
-0.00723712882772343
0.013284084769915955
-0.008480164736602623
-0.008756412265788096
-0.013363015261489305
