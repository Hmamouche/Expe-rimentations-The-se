# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP256
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=6, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.00899178159785333
-0.007140735445687444
0.03987651542526606
0.034384454438272684
0.018881250190396496
0.01514909852549908
0.02036809773013109
-0.012878278518895482
-0.004949615228349555
0.004207939936877514
0.015102922308446107
0.0036084022994566176
-0.007298067501645789
-0.018447548800101785
0.005870967258548705
0.005369346541377528
0.001717897000090207
0.004238160345749921
0.013218489123172571
0.009718649947931476
0.008155856341866814
0.005746161270199858
0.0022611039224022817
-0.002599047336410828
-0.003628288110549043
0.0030164752016388994
0.0007371921210411279
-0.008048526022063896
-0.01578186198505811
-0.02959268830493808
-0.009788741452859838
-0.004933579854420875
0.006169055076660096
-0.005484625632450364
0.002254069228335504
0.002157233181401128
0.0017329627325188444
0.025757884316355412
0.02425100409835185
0.008632928427955738
0.01475829930587144
0.01628708573249046
0.018050328538503135
0.022775625895144223
0.02724203152662471
0.02518098949235631
0.007602722370103037
-0.0058083787256357055
0.00901221509218917
-0.004946677990501445
-0.0025301859194452048
0.01612464813816436
0.02153686611145019
0.03162903527221869
0.0267091768999826
0.015777826547112635
0.03166309147404235
0.029961370441668907
0.02262360727899802
0.025636453002260393
0.004825029356909351
0.004703142587324119
0.024249044027790198
0.022577537265790367
0.013071426820510285
0.02451442651682318
0.026726100510700564
-0.006072425345380606
0.019066599457095573
0.01218179852727535
-0.0015265151410713902
-0.007159545959557564
-0.017920201855361598
-0.03680856150216226
-0.018592267085496862
-0.02035854923715607
-0.020509813382304294
0.004833507686117029
0.0012577111653962712
0.011494621316661005
0.011205709496770515
0.042616216803820973
0.029208892063793755
0.008421638713950642
0.006603000556694397
0.022892671657295895
0.03487828924955998
0.015015800241564192
0.016139144096209875
0.0015332896502337013
0.015023798854578557
0.004208112215504873
0.012980920402752403
0.006043145552098371
-0.01447534642418391
-0.021186848789001907
-0.0315726180471455
-0.017943538084180383
-0.01690720928054678
-0.01430497742255538
