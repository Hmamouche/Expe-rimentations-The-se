# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP254
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=1, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.010120939208632274
0.007327442688333197
0.007955313428444296
0.00911761369512324
0.0017799987688129262
0.005351893304294414
0.0022165101183087236
0.0029420940740209596
0.00342610359808828
0.005187085078700125
0.006414880171445075
0.006163587964772579
0.0046690872253211625
0.007086874396965071
0.0041796754830103885
0.00606664457223027
0.0043146803225649205
0.004393003960472823
0.004255577501186051
0.005931768303438135
0.006785537774654907
0.00832111332685266
0.004540241868276933
0.003383157301184952
0.004307769985519927
0.0044772244850485995
0.004761155967846373
0.004303537421178785
0.002102804556799154
-0.0036456321348517684
0.00014317482554510424
0.0016394202140849693
0.0007282176840573574
-0.00028262493788518253
0.0071756008669163155
-0.0009711576190719057
0.006959563978783723
0.006435928105601494
0.0034356551260169795
0.008764513130192437
0.003477684625528675
0.006418753845909475
0.008555947578611795
0.006511233745897159
0.00740190548621274
0.008924542667271511
0.004586187082072419
0.004880376409654182
0.002403237371971439
0.0035537041587121493
0.003641950577012277
0.006082228877402503
0.0058906998933571895
0.00857520813887195
0.005600684345872028
0.006016375058411875
0.00784482579379243
0.0037083711909794252
0.009872423985586678
0.007208327548456338
0.009892705647978166
0.011569391226543532
0.011330175752710288
0.013094761368010563
0.009709559276561424
0.012948634984307573
0.00804604986403051
0.013208008541638198
0.008273671942853328
0.009465288103016695
0.008328737459263907
0.005149423737872487
0.003340077128674748
0.004537924343685105
0.009226495785289932
0.009800914858073132
0.007240208389033819
0.003941579248137205
0.005660267047709453
0.008447136115056928
0.012304131465810365
0.012022950575717634
0.013314509856695538
0.009770221857667457
0.00837209602356148
0.00918001339996044
0.010379256519859107
0.01082453035941983
0.01111759111294106
0.011673825221525738
0.012567405972659677
0.012231223497029238
0.01112536865736768
0.010288881287258361
0.010407126822653061
0.010092013806354414
0.008101887302228163
0.005656460913811176
0.002199385596359445
0.004155544262320342
