# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP261
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=15, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.004334489713166969
0.028289907785036664
-0.015851181032446378
-0.03802006821689716
-0.02205135024952512
0.002336099625727242
0.04132573182497056
0.05505187081301059
0.00944259096018794
0.027578247953006275
0.06306613499586301
0.03779527567423803
-0.0014323288265930198
-0.03292914529711752
-0.0022222160690148554
-0.010940319201884402
0.04492462590171991
-0.018174798951573465
0.011343354727728718
0.0048469227393011325
0.01102888451321015
0.04386397647440125
-0.02853354491512282
-0.02499943055808329
-0.009129580899619362
-0.028001282984837964
0.037108010361937754
-0.02436533983090567
-0.04605823638090829
-0.034045327254755245
0.012834952897190024
-0.003072154989482395
-0.02582754246551832
-0.016973268588561574
0.012332456588363423
0.030387252623152065
0.020134767618667324
0.01962292228702319
0.0034328284256609307
-0.006047751659094434
0.025022895963890828
0.029494611543770158
0.039274669407366805
-0.017198193629870955
0.029998192458311083
0.012238252182724573
0.0022395281098744786
-0.006645837054742915
0.003118755214034183
0.003759119619169283
0.005123731050983555
-0.0015368072243850828
0.006067413461218404
-0.005669656733779588
0.02647176911150548
0.005897672725515028
0.01958373465859815
0.008628634661346987
0.013876178769001945
0.006213203599551045
0.020601431287265784
0.011401155775007044
0.027865433375766552
-0.012737498998699857
0.005389311835627615
0.006529029928813676
0.009036913068081597
0.008244711425223655
-0.0115510889673646
0.015827217578382465
-0.0028987597983263285
0.01115507995816706
-0.028927527752447363
-0.004103240888460806
0.04465892945783823
0.03675127800065735
-0.007581596052943245
0.013190924024777548
0.016863814540718912
0.017830733793314964
0.03259552297841295
0.05667097408925093
0.02825040897634191
-0.008389638463376916
0.023180849427286963
0.015376319092615737
0.032458517583462326
0.018355458170902565
0.012274044803854306
0.0014323847368064432
0.009069604508808693
-0.040007408391478545
-0.04616101893266655
-0.03445439862094417
-0.05904332912196488
-0.041095513684322064
-0.05741647393195158
-0.08830082767966288
-0.056791200942920214
-0.056081995622597955
