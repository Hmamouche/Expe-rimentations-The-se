# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP287A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=13, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.011611868018081846
0.004706212090171932
0.01063806921647966
0.004459155081657103
0.007046571102292247
0.012903788659829597
0.00516023927398887
0.0027321252479747494
0.0044078158517759725
0.0030551691631555606
-0.007155309362951
-0.008023573002595732
0.007659891086980885
0.003331230588973238
0.005274247784738791
0.007113158700214458
0.003953085655901386
0.004918588544342833
0.0049043688396006695
-0.0011868958941294908
0.002693388933564171
0.009608254504992132
0.003138846657661785
-0.0013194186179731053
0.0030777991394651425
0.007390302910566519
0.002256352804297243
0.0008273729483937119
0.008215176345814767
0.00522119976004879
0.0015368554165023165
0.0061527501922478975
0.012376924019338775
0.004753532306588965
0.004270863016184257
0.008357608456768494
0.0031626594267989486
0.005285119530095781
0.0055890505690761455
0.004421149172873191
0.005410621539173122
0.005744557505253326
0.0014531048634389401
0.010756376953773697
0.010375712546664684
0.0012441285894201162
0.004151624760179014
-0.0013781208286698851
0.0030693530044465832
0.008017569981237212
0.002549202127441818
0.008519894563192366
0.00797223120496732
0.006732282822184913
-0.0020061672597927577
0.0012069527990615828
0.0052150506179092036
0.005257240342995928
-0.0005237755369435805
0.004194717885566308
0.002264984064476471
0.007261129394185477
-0.001453017039826733
-0.0027337715443770906
0.009000560816330654
0.012684347091574044
0.0051452756030222506
0.004279162207657623
0.0037455877099243488
0.010366686675588517
0.003914156004939391
0.007802617675813293
0.006486144495855808
0.00411948647504676
0.00462739745732698
0.002371565376232077
0.005736549178095711
0.013624462447740465
0.0005360153306268891
0.005232466369113967
0.013455793337240998
0.01841999392321736
0.002333631138354269
0.009198930186140748
0.007288062705325746
0.014761336044704212
0.013356434349845497
0.011592205449799553
0.01004490163349703
0.021489188634298405
0.0050877275648890255
0.013755407332116398
0.0029292278424799777
0.016343510129494865
0.01169240444847148
0.0029961767805400438
0.009163074973067807
0.018114197362427018
0.008244134951970041
0.002464178075508173
