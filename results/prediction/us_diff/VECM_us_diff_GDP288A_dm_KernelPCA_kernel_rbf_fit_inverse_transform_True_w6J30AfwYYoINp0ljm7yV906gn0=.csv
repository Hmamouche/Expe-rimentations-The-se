# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP288A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=14, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.003859985032002525
0.005310393095175295
0.006772135495317325
0.004549043923117021
0.007220531734887393
0.0031818676057034246
0.006617523689516922
0.005423634627766602
0.0031076217335674248
0.0032058645770559344
0.0017380602898610493
0.001231134445851183
0.005633212071570568
0.00865613945212248
0.0038624702681329223
0.005414818448068952
0.004924411106265096
0.004377163450040981
0.0056447446985924046
0.006182789000055863
0.0005962982407069842
0.004037210015630786
0.004582582992460976
0.003792353789685604
0.003682434864043448
0.007919878550540759
0.007158690059477492
0.0059400620677232735
0.006875488231182999
0.006653002267543279
0.00035251866101950824
0.006940954836415686
0.0044518113875108515
0.0020548596925981494
0.0006812459697274471
0.004862882432968173
0.002624450041180904
0.0039208538910765756
0.006496484450566944
0.0017149966426958422
0.0030884231846583557
0.0013151823556385052
0.007566284667751663
0.004020341019117673
0.007064378018416275
0.0028083640464574176
0.0035959082037675598
0.005165346245661077
0.004880251466003043
0.0022553170513108026
0.004277511579566188
0.003767361475312911
0.005098187089018295
0.004749629563292804
0.001407200269458835
0.00530463944911953
0.0036721881997229464
0.00230333595288247
0.00038497576652541656
0.003049652354570542
0.0017885045935346281
0.004805178294573104
0.005833535139047103
0.004321607837451533
0.00577564827413066
0.009439482236835479
0.008646054498693462
0.00642285273769256
0.009147643731132
0.007837863409235892
0.005224825957924978
0.007376532623111731
0.004190312930218172
0.0017699074340433475
0.001753062237446642
0.0034478884575416978
0.0062570069923641655
0.008557440617685277
0.011078807910558666
0.0061760108653872116
0.00645873464287649
0.008909718644779614
0.005260572971995106
0.01180813023751803
0.010740950246282003
0.012599894598120293
0.010326574325171436
0.013520123249106241
0.016231845678862874
0.018463792933175148
0.014501438301400812
0.016298481533180954
0.007187873211512513
0.00953240350622763
0.013905818392276906
0.010013718258978494
0.016836348595953038
0.016492507940276225
0.015706049631116617
0.016971170378101724
