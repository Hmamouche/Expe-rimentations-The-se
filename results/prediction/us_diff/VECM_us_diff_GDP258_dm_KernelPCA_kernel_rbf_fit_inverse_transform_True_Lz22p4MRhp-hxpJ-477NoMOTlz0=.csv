# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP258
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=11, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.017082583599673146
0.01609601520303286
0.01778129241918218
0.0008358364269760339
0.0115737685916103
0.0027233725565792306
0.007596001395535064
0.008278652492560875
-0.00023062633114720975
-8.450300755910405e-05
0.0103837540423037
-0.010271307048528222
-0.011007311118691984
-0.007739664847910953
-0.010104114826301198
0.012932311252673379
0.0025834726682094594
0.005560653935796763
0.006099516245295858
0.008516124178180326
0.005438360118628041
0.018647056605273472
-0.0012976526318067552
-0.0008744327101790667
0.002763661762543043
0.010712466122959516
0.0032016173188519183
-0.009938235915800118
-0.0026556882741322627
-0.012352797832934043
-0.014182437089565311
0.0018951534396441803
0.004133827428586525
-0.0033424337714933073
-0.0065302914175827745
0.007656829845406871
0.006097073517797695
0.016668259368079218
0.017577410830918207
0.0015975129284606666
0.011819179679903926
0.01358420663200204
0.019373133415123495
0.008763442912304808
0.012405616354338069
0.014098387808649313
0.016542388011960025
0.011137261575244025
0.011831536673653819
0.0033776934000238055
0.007069344560531691
0.014116204528332012
0.02123185833764157
0.015010294730172758
0.021007977326004658
0.013372897622947742
0.02962414661683276
0.021810318021077746
0.011644368335863858
0.030279491690099396
0.011723078676317732
0.016143604317913937
0.018423664984123945
0.01773336237003538
0.024921923208580707
0.02470578735169042
0.01063578718513398
0.01755586368117291
0.016421884019273254
0.01952469365732091
0.004077664997617733
-0.012917816716580228
-0.03236148973410755
-0.029307145595801252
-0.004738980955466222
-0.013695571650485433
-0.02238638156889659
-0.013889977590794193
-0.00745817010368428
0.001895685099128179
0.020569576387569233
0.013538542562189273
0.011758355773532004
0.0037240971678530054
0.009868459098977739
0.025884606787274993
0.011562420262313878
0.010910196946621957
0.021582956714748944
0.012946981001726372
0.02167647066647477
0.017506222727718318
0.012409776850057671
0.006853856697958474
0.007226930811887319
0.014387367855120356
0.012831957994973626
0.0021886226093811687
0.005716990538763346
0.017330999997018176
