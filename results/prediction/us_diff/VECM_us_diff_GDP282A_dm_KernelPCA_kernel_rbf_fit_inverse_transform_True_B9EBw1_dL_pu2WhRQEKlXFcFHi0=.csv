# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP282A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=10, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.003914569083412588
0.00563255135365719
0.0034207212168870637
0.001744293732560806
0.005499092032152173
0.005666263400371889
0.002758463106797013
0.005209525965033221
0.0033508047146146172
0.0022323092834918784
0.003827733756887542
0.0035123470470992345
0.006522296863610166
0.006150772298510699
0.006445361810434379
0.0055647082877866285
0.004221848823740797
0.00610381586492658
0.0058481892005768
0.0063169145550065415
0.004639915422369889
0.0073870825233113965
0.004590851862416635
0.0051054179157099915
0.004761048547325051
0.004484314694275372
0.0037677096618768534
0.004190447112604306
0.0031176190402676285
0.0022884145207506088
-0.0004546350565702408
0.0029510221248526584
0.002983778466154324
0.0017135443500530723
0.0001296709745923666
0.0013501150971354106
0.0009335794048409194
0.0016261310775965445
0.006681464896915913
0.006296559171111872
0.006515552329410485
0.007185885282408735
0.005615508023533503
0.004052175182075546
0.006263818053782497
0.005994730694100754
0.009444784041627031
0.008988119087468525
0.0046419884841489316
0.00495198718820309
0.0030221554983252755
0.0021569869572830923
0.005196326665456113
0.005132250340425848
0.0031012099051186274
0.004681948883153913
0.005481806247461051
0.004500649431447976
0.004162778106906913
0.004654977158063261
0.006163893141568348
0.006285376832648327
0.006431282210839313
0.007315712093720208
0.007443079812771093
0.007299883751104128
0.009573474045631133
0.009148382507720897
0.007949591633758649
0.006591240179778816
0.008882498206001028
0.012301329541818163
0.011398297237261115
0.0079775855541987
0.003928544736663867
0.0054634948783375565
0.004450640999739828
0.010780919479994228
0.012298291947002212
0.004705883538284343
0.004524827007319979
0.014251956882313784
0.009442524385530381
0.012572058617932423
0.020612547342862476
0.01756481226292428
0.014361496501626887
0.019514085756348887
0.022396324904828645
0.017473207039018217
0.017417683128822813
0.015827545159202552
0.013705464442147347
0.015214779550897083
0.008413114434401216
0.0020229850308463547
0.006899138788065709
0.00033688374526542105
-0.004580600229015095
-0.007223592564298202
