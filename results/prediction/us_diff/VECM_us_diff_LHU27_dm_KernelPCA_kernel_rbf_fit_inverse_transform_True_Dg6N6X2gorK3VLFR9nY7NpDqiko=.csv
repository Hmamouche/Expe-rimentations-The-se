# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; LHU27
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=3, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.05379653054062641
-0.12306034165248975
-0.08428434762265616
-0.04250403866508048
-0.027414336751225822
-0.017075050084931175
-0.029985402003310135
-0.005457251498961603
-0.004019586977430624
-0.014226895851672482
-0.036788909071720007
0.0014605291787486404
0.01373584293118749
0.006217258456364394
-0.025190009181214647
-0.02574155241535979
-0.03445338733404385
-0.030617769029074673
-0.02597001428741351
-0.008381541889310472
-0.026579492057942702
-0.01970806482225376
-0.026168219659116206
0.0033939720402135776
0.016266189229051348
0.01934720169830217
-0.0012749134028525481
0.007662574981776669
0.03768820401849345
0.0648857405101756
0.05373859528130912
0.04543115581905378
0.017005966213283354
0.04655506353021374
0.09957845807263135
0.08161211583299603
0.038764977058612204
0.008265805424225593
-0.04483260340446692
-0.023280120088356008
0.03555543147667531
0.005336285322563448
-0.04802517708334736
-0.0632695586032334
-0.0415852860742944
-0.03475434968554572
-0.05264219779022008
0.014507080200885737
-0.013041928770641736
-0.004974787961683597
0.0031737635679885967
0.034914382511875355
-0.031404140663374075
-0.04854578782947595
-0.025576242243849846
-0.0059901307335682285
-0.016780713744610563
-0.04364627845671762
-0.02031496428258986
-0.017130908832199594
0.008003992856372917
0.009442840494513154
-0.032794893319560404
-0.020132814562938875
-0.005293546207742689
-0.020492555799240423
-0.0340518659124362
-0.0015233872691896052
0.0234934067975232
0.0030487597114264844
0.038537482619497215
0.035359029383580515
0.05648806631384079
0.09581695611535238
0.0690043037636962
0.05333128301539138
0.02220469826120134
0.04753259520362149
0.035452930690700345
0.05740112488001545
0.010177701722969902
-0.032401516487855206
-0.034803512074121454
-0.02151058377518736
-0.034992862314031925
-0.012990975382995037
-0.007314160617883708
-0.03006593037028038
-0.04265367911182171
-0.016440477192095276
-0.03694578723719691
-0.012521914319276324
0.013769044100015084
-0.02334960346784784
-0.012561452865692501
0.016004639796122173
0.03739869648488067
0.028775908604412013
0.028904427333180938
0.04914523905792616
