# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CPILFESL
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=9, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.005238119144953404
0.007564260031078647
0.009767451416405691
0.009012066657747213
0.005344142985266516
0.005634347485199436
0.007572981770546441
0.004244484283241596
0.005880457678491528
0.006301517597202254
0.006904626748556433
0.004558737399783591
0.0056770188699402134
0.0067974941684898595
0.005409794403488342
0.006792674223338929
0.006835377905994753
0.00793027357515267
0.007038210893013051
0.009042098754738053
0.006573300663566053
0.009791840305313257
0.008033221750363119
0.007165868379632999
0.005279870699781243
0.0077250792424766075
0.00829627010116891
0.009459357819082753
0.009801630321566345
0.00927658326543854
0.010561732981343159
0.006423788830000469
0.008744814768103047
0.006812483318564029
0.007869934992287941
0.005502247356068451
0.0056723136615868365
0.009590384444483341
0.008024447621399063
0.006419691651991068
0.007367566090060975
0.004326130959882309
0.0058066098173670255
0.007145212501432148
0.005440853245226827
0.0074418514665313806
0.0067713038809575615
0.006315794164999097
0.006854155651592748
0.004363593210201323
0.004930768685746979
0.006358791237571301
0.0050684687275522776
0.005844894777155867
0.0060839892836401085
0.005156901375282504
0.003948771524019183
0.00498461990269013
0.005041208789130119
0.004784298425749905
0.005045943081165586
0.005121865038494505
0.005844688021402844
0.004161627178396227
0.004719077270356843
0.006496154888328206
0.006066093738939155
0.0067800108208328725
0.006158189287179215
0.006332115008886443
0.005025453165644881
0.005680081472006445
0.006369919729049592
0.004736370353941913
0.008462676287622848
0.005020668735799804
0.006313595354582732
0.005868091950539009
0.004068700165431747
0.0016005690106426695
0.0026169459705594573
0.00276707104627928
0.005125011577978437
0.006948909850691945
0.004899010110506984
0.005720816736629728
0.00720736926184487
0.006016480190481642
0.0044587487808709185
0.0058006690944977755
0.006777918808992305
0.008630924307662
0.008467984628833341
0.006137925804033681
0.0057505750410434065
0.005670746193079978
0.005375719130045036
0.006597843869447971
0.006358803252923136
0.006793073720531371
