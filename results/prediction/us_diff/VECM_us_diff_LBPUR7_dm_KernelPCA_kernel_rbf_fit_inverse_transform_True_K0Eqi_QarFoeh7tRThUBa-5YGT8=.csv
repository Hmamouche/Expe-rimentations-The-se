# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; LBPUR7
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=6, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.006389026912753331
0.014793161892423025
0.0005887274772053597
-0.008032234520124538
-0.004201509104836781
0.004883695245311256
-0.0035516506417343626
0.0004671794095267058
0.003509755197609642
0.007651290977111419
0.00597686270337238
0.014402724838244374
0.008145049218119102
0.013080729590621464
0.012779056021282811
0.0034658810968818386
0.002115842365844503
-0.0012699734501339863
-0.0016304997279224798
0.005126453915448557
0.0011664631687055911
0.0032848527530843787
-0.0033227729053176814
-0.013759214930401152
-0.005051768101815888
-0.003302448388895299
0.0006041978577544054
0.01180267297459904
0.009282744400587642
-0.001129254117375477
0.0017812749317462741
0.014868542441858944
0.0027478916988796396
0.006172050080629858
0.0136490457228963
0.010820996437315187
0.008389696055476164
0.006299718005193022
0.005128551924110774
-0.0023360495786812815
0.006628359126926723
-0.002226089028732513
0.0004362894197116919
-0.010295885742311885
-0.007914560957879811
-0.0048514996263469765
-0.0021926250128791527
-0.0047666192125190975
-0.0006152294600410041
0.0033356571257116907
0.00761115670884465
0.003410307376643952
0.0027094678356934113
-0.0010973056652404947
-0.005211846169449788
0.0033761475313836093
0.004643492700944809
0.008836279942997939
0.017930786507285804
0.020858307241324727
0.01844000494759436
0.0179286604735734
0.015470582422144651
0.006232002806173318
0.0010689401887714162
0.009389152212123438
0.02609486415728047
0.010292144982359629
0.012751944919453615
0.014453121029706167
0.01659329150616961
0.00887505213733624
0.0010852687249011067
0.00775561431671509
0.008063324580473794
0.012488138697722004
0.009413412643877048
0.003201267999642508
-0.001027700675992366
0.010409445772179537
0.014193003431600496
0.0049500150983039
0.006516318910874445
0.003170298395389283
0.013511239643595054
-0.0010542639905885406
0.001906087383625681
0.005248421346023466
0.0013282152843864434
0.00043662807322779307
0.00034457171163200756
0.00034103540052872195
-0.012832947363129472
0.020577681683034248
0.00287932856222201
0.01002052897482443
0.01257805258829591
0.004791100225337045
0.002014327497115092
-0.0037546403144749925
