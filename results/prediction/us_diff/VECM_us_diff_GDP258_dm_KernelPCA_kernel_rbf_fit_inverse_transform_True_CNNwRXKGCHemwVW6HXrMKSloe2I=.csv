# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP258
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=8, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.017792100317524907
0.019639750011369143
0.015033412262371048
0.0036908641604708435
0.009703982944173012
0.0041045592532272385
0.012182235682211344
0.007915291902144435
0.000807092203141322
-0.0016265066933975007
0.007543011213629099
-0.010132850022852077
-0.011871322315867173
-0.002934265378569829
-0.007653997227490101
0.007436250760033171
0.00509736510222011
0.0055452480574478685
0.003805470147477198
0.005714885592567311
0.0072338823039739195
0.01787461978325436
-0.001509973509253435
-0.0006465195899551081
0.005629093734334466
0.008397531642752564
0.008662028836077255
-0.00790905957759283
-0.00914208692644098
-0.008205255152968289
-0.010057173289109036
-0.004114655871751566
0.0043042379189626185
-0.002576012803257177
-0.006032489018299192
0.004705796923850721
0.005372494490288036
0.017154466269595346
0.015914485934654943
0.005395519959923543
0.012850277081263316
0.01619781196150939
0.014432264003385122
0.008643442133698288
0.010917604426583754
0.011646383099629537
0.015082554100112193
0.012245628354852607
0.010317910988956586
0.00906107764196651
0.009338316552864002
0.01853288708056575
0.018889386151472825
0.017698441780633904
0.02237773308648308
0.017783834822324176
0.025019180519517077
0.02286870045095065
0.01429311036688837
0.02827769885242441
0.013736649011600223
0.016707760386469917
0.022886538480799117
0.01681850082902208
0.02270579623020101
0.023805099250547333
0.011388786737418739
0.0160086518947294
0.015168496353080822
0.018291872759568614
0.006682238726483502
-0.010594711559096241
-0.02825893339503288
-0.035901464091474045
-0.011380646378773547
-0.018463944834262475
-0.022033544611303107
-0.006894149737650853
-0.007044522416136915
0.0030055640507379534
0.015271183964395028
0.020305265697517574
0.008791609057623523
0.0076356186685605345
0.010723587239830953
0.02020360226868798
0.014221534464685328
0.014234602392087702
0.015512037493232886
0.012590227266984218
0.023180899985768767
0.015017875609228527
0.015012397681447517
0.012035590601874561
0.007727747172250144
0.014959660367679666
0.01564638978845484
0.00294935554588485
0.009007828363944991
0.017551192062105585
