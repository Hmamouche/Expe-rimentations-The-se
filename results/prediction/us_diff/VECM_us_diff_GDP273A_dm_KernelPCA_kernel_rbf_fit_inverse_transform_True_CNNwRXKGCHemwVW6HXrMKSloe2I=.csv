# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP273A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=8, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.005205332164817393
0.004245428138945689
0.006771080607214331
0.0076414895053810725
0.005030003697277528
0.003925804915763207
0.007710356402584856
0.0047585655562260906
0.0046538593814180965
0.004639777852294796
0.0047262072065961435
0.0013825106039575363
0.003977446373979634
0.00210170651023527
0.005719703148359508
0.007338051662515223
0.008538930855808185
0.006960170071641472
0.006479014153315374
0.006817722704254996
0.007600839254590784
0.00801570995024003
0.008734475824664205
0.009508381799912235
0.005849850573857043
0.007017671515095798
0.00828335892569181
0.007765512509987692
0.010972793080602434
0.010729923659096677
0.006875793853434115
0.0057486453886167405
0.005489054965908849
0.006078404466793685
0.005143499685654481
0.00663149387250089
0.005930610803016636
0.004507575178007225
0.0062915716103407165
0.0036500104388914496
0.004024977515697804
0.0034255407091670605
0.004174581172747411
0.005325179467462733
0.006530480019031707
0.004545168092853809
0.005802452456819759
0.0028420468735801093
0.003451141422897072
0.004934993999865103
0.004359879254695401
0.006392084001948155
0.004540633293682455
0.005114721889266406
0.005082341415643058
0.003787442294040051
0.002451865461554394
0.0021600940610067404
0.0013143374695795058
0.0015941533557508292
0.0022815132867338257
0.0026041050463290554
0.0037561740576292184
0.006166880744898792
0.004040116405103386
0.007122679734165135
0.005950009301538503
0.005644276763059407
0.005327813564218113
0.004576079759334691
0.0054661261285399295
0.005100615922289773
0.0055775915244384725
0.002071457349594963
0.0034523430554774825
0.005175650498692527
0.002533263570261667
0.005673673151719872
0.0057474375916930975
0.0025815456932973564
0.006233321360503822
0.0041562493920515664
0.008195269792823439
0.007647205302742489
0.00694898008844105
0.007813604361506825
0.005757289458339322
0.00770539264472792
0.009223496163708537
0.00987447901005673
0.008180079807989857
0.007620658104507924
0.00735514169956313
0.004216804851271011
0.0077517380737934915
0.004121987524105015
0.008891761807395256
0.010295160761916961
0.008809438500029984
0.011923940073115338
