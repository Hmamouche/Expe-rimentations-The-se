# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CPILFESL
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=11, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.005980826234557898
0.006542395659481315
0.010481780331492259
0.007598017679287317
0.005436225647502447
0.005985748316324558
0.00890891745940081
0.005236463317806205
0.004568256522308299
0.005821492091077412
0.008143449401369397
0.003976034410736228
0.005923248035646757
0.0072642877161259115
0.004839543162855096
0.005715857548243435
0.00692790568931608
0.007602939181484599
0.006880723313153781
0.009145158486089376
0.0054811334954292905
0.010463744199140423
0.007709952641612416
0.007443826194795402
0.005400218200574353
0.007707798147573534
0.008253086437670424
0.00966302817215569
0.008484311909449132
0.009881543731566434
0.01129427929220253
0.006148111445176985
0.009235028763028827
0.006021486873112937
0.007616688964553602
0.004712232078681851
0.005656116683039885
0.010054479845244624
0.007351395644507797
0.006514335623466604
0.006128579570771826
0.00434352952526459
0.005659137229853525
0.007127599412855526
0.005294074831342017
0.006776017215217598
0.0061602185668898244
0.0071305679176160135
0.005593716468738712
0.00472704094233679
0.005239947859054218
0.0067641393041213875
0.004878529217390957
0.006744045881148703
0.0056962799583337945
0.005753541648471862
0.004080063767189613
0.005166605500415746
0.005190328564715405
0.004865850032380482
0.004948323516557466
0.0046659904674095825
0.006652292222556945
0.004847865839958468
0.004657046360877934
0.006550078319509604
0.005422161374427702
0.006717599055306971
0.006163517420991808
0.006150497226213451
0.0056407490601024955
0.005705141522722324
0.006446648835423807
0.004497883408348341
0.008133491367750018
0.00557604629490381
0.006041224342515571
0.006281234949409199
0.0038498410536770265
0.0025947653624726797
0.0018561298038742029
0.0026017845888291332
0.004333696679733394
0.006793638231700338
0.005779332973155028
0.005792163891727065
0.006262163874150868
0.005516563248690843
0.003985203626960137
0.0056659106840025114
0.006219522046331997
0.008810459189080766
0.008731705056565165
0.00666307508510129
0.006542964824069772
0.006305068803046139
0.005744595835855488
0.006129859437150871
0.006840001255316953
0.0076761272208953355
