# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP272A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=5, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.006531372200169218
0.00542940037467653
0.008496646587259142
0.006838495689926434
0.005831938186364278
0.0036422611764370906
0.007499885027743198
0.00409150206040465
0.0035686110934600784
0.0038302275712990956
0.002459705660046944
0.004009683147902944
0.004810324108881001
0.004681739878074867
0.005383188839443873
0.0038878573134359844
0.0064233397260744065
0.005805707560743143
0.0053953854188021795
0.0064409920102634875
0.007843691876114797
0.007191057230501831
0.008232716974564923
0.007377005550185863
0.005826344880260974
0.005798714072871098
0.007413879144818621
0.008174036647686499
0.00761429511531376
0.007271281821573262
0.007778806404487538
0.005560442638491961
0.008037465612668517
0.005757540498055654
0.004166027510661077
0.004785044721015352
0.0036257764222015734
0.005219399614918402
0.005374344145782147
0.003983977192798239
0.00456077987708848
0.003937078730181651
0.00503876755578299
0.005232511123623397
0.006055652400515879
0.00464531288030883
0.004578112191760278
0.004585771324772935
0.003726780506273895
0.004436082453952376
0.003960922259774101
0.004122549485997301
0.004208010519126782
0.004778231445540144
0.004120529248761152
0.0042915405204558615
0.003321867026326277
0.00360171524734216
0.0019992198885072764
0.001843661104848097
0.002781688060089362
0.0024709121820717535
0.0027357042142121613
0.0045193724417809476
0.0036393172525171326
0.005135066274700279
0.0059918336856211105
0.0050462671219568345
0.005621344255479663
0.005569089541578708
0.005063285422877893
0.006397020373195031
0.005013074479404632
0.006113533640701916
0.0054154210910587995
0.0029366788407205803
0.003556097539894512
0.004959284756805222
0.006592298776182559
0.0034056440834774565
0.006597103328548522
0.006046259084111927
0.007298763335742654
0.009469784799127818
0.007609802966020658
0.009085647995913073
0.009412052363225414
0.006199039805683041
0.009917225204093931
0.00980062801613016
0.008720225620076055
0.01081288623183617
0.007956215321385608
0.0077472938788887
0.009371792534737468
0.007509801640938943
0.005868367803145018
0.007900592730087298
0.005866547726684953
0.004762253880385154
