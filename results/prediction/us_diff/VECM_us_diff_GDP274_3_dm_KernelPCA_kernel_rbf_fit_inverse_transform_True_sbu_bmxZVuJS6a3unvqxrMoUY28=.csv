# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP274_3
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=1, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.007101944416105385
0.005873631809333072
0.00031039207900470387
0.007735855412161715
0.004889863161365072
0.0055965836361353384
0.004453306497359412
0.007014841571609578
0.0038252724794704514
8.257919350368882e-05
0.002680543079126921
0.0041795720814883485
0.012294687311386852
0.006334662555328424
0.01555394122474149
0.011309496997688477
0.011119874614531783
0.013291356943247422
0.015151976247138451
0.01188039400180243
0.010190313152591897
0.01708815305585686
0.010992860007994508
0.006394970067700942
0.011690025012002477
0.011244097112488633
0.02156941012509683
0.020492819042266953
0.00739885542403356
0.003508046255625166
0.019440672423786963
0.008569811824414908
0.011680100217564578
0.012914940642111593
0.007226035091342077
0.0047848431795369465
0.00339922248440173
0.004280525327642212
1.1773125441835708e-05
0.004666250325494685
0.0027696291484302295
0.0023712497842861627
0.00359577726189656
0.00464170767821199
0.008157252418320696
0.002813100056114792
0.003965867224999826
-0.0018184946033180931
0.0055061902412590815
0.004469439036429817
0.0035326891951570527
-0.006505448204997343
-0.005773152577156132
-0.004074345651381448
-0.0003816107866352234
-0.0063694029269917634
-0.0023136647007716902
-0.003465261896410167
0.00024556150391908017
-0.002896290687069156
-0.003102144371880089
-0.004322694436853853
-0.007987086032365559
-0.002502101133747955
-0.00681033450630978
-0.006512545776495932
-0.004498676022747993
-0.0012487584846503363
-0.004537079379333537
0.003021003269188365
0.005770959524736009
0.00014591828313806343
-0.0023592825743080285
-0.0009894268248945132
-0.0010155396010681995
-0.0039078203434448075
-0.006195245345890754
-0.003566659429038702
-0.004947665360082255
-0.0067981281501580445
-0.0032001756813736077
-0.004010034039219816
-0.0010536440798693389
0.004308330916566873
-0.001167962305935885
-0.0043601408509985045
-0.0019184786529266374
-8.828650931950077e-05
0.002936149616054892
0.00024229652814824337
-0.0013479905463198423
0.0024038253659234843
0.007084407071208908
0.004487828629081152
0.004536931626570806
0.002687380537747788
0.0006910200679164466
0.001253593876520984
0.010727079007524447
0.014321639026571202
