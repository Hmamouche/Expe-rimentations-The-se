# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP276_6
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=15, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.010609811866289925
0.010831998506596736
0.01164794964058405
0.005532718896521293
0.006216422751493039
0.005626555245242258
0.003292281553672359
0.004766974067261363
0.0044894776391571824
0.0035348187310339997
0.0029903287233721087
0.003504523660295555
0.0033141097259777714
0.005004444572722464
0.004243925995214126
0.004758236533686792
0.007887533583458825
0.008277671439932115
0.008445523127612483
0.008998541757491832
0.007930888090509146
0.011962852382778763
0.011740179250404575
0.008405757259547533
0.01087189496954899
0.010179447010326664
0.010751976530106677
0.009790160145697285
0.010005378217700884
0.010242090049246332
0.007499605325103383
0.009132887193429896
0.009609811085573971
0.007241848364178797
0.0063000951389128226
0.00933239444151482
0.008773235710313675
0.0066633438391533895
0.009285391258931132
0.0061070011256032335
0.007389995811582433
0.007239809073392966
0.008533012789966767
0.006947967026131939
0.007133451962816585
0.008157380558905213
0.006846539172833906
0.0053015469956454835
0.00441401247830202
0.00528995041481103
0.003102742228236892
0.00850488350439122
0.0037207083210809007
0.006602014030459775
0.004206218587022456
0.00478487132160161
0.00371073021926847
0.004150300395635073
0.004278967070294642
0.004473000294265204
0.005222800931107611
0.004361458948132402
0.004799384952292664
0.005651702716288948
0.005421338301378742
0.005836119980868176
0.003725675206791875
0.00677098357401159
0.0064625223909318755
0.005526919474862129
0.008504081152778313
0.007401936518180929
0.009489976043288328
0.0031475888356444996
0.004652312168712997
0.006045937718148637
0.005873988792141733
0.007422346496379889
0.0072065483436962825
0.009063300520498469
0.008059890570632795
0.010288459482974037
0.011677488328298534
0.009389785235550497
0.008741348487598234
0.00757451347880575
0.009734427097242388
0.00651602269984755
0.00851600793542279
0.008966696429839828
0.005418375262369633
0.006805618045416399
0.008686511752079573
0.0078055702821630425
0.010237302954457538
0.009444975985206964
0.01016890981019461
0.004242805132373895
0.005618658176378377
0.005971810346519708
