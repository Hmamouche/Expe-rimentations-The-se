# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; PCEPILFE
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=3, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.008043069321036413
0.006586833833170847
0.006132164767038745
0.006976175083978938
0.008454574305281695
0.0040783313647276545
0.007661636017731781
0.0060438862096308735
0.006054811497677906
0.005018481284258933
0.005744108436649865
0.006821005362737753
0.006965441164613845
0.006578092810809542
0.005999710799746011
0.00654327696750106
0.007137376055891262
0.00688243717404438
0.008720761625398234
0.008414404185835299
0.009772090586645896
0.008656212299413456
0.008651861930324443
0.007618832214627602
0.006275125809066247
0.006344311340358292
0.008094606810666094
0.010198705595139334
0.009295156273335917
0.007627061411005661
0.008549323436051581
0.007605777392168654
0.008338851837746668
0.007450577988220059
0.008102961156646877
0.007814222922421347
0.006505956113648062
0.005686968384601647
0.005445601222594611
0.00590912355449553
0.00512782042549455
0.005011041869240402
0.004902114026481837
0.0053451296398836666
0.006823973870908077
0.005888087542919333
0.005492918716333937
0.004575141050813844
0.004952656002815021
0.0052997416094675304
0.00433655498847262
0.004371168353631601
0.0042268763632093125
0.004247592052758129
0.004449216625794533
0.00468805567099039
0.0032507762016631024
0.0028740700417791477
0.003341803563702641
0.0028597632116758045
0.003438521442327246
0.003603749551601403
0.0037890535787709345
0.004086447494755386
0.0036212688622653095
0.004140195726028264
0.005610087091704869
0.004386653959934123
0.003155628483676844
0.0031776025591731226
0.0053652002790433775
0.005475774839329921
0.005090407646847736
0.005861092880879288
0.004451978183224599
0.004795882400519646
0.004533134396911612
0.003603126604873122
0.004163196944504855
0.0030504096898859153
0.00418464248771903
0.004528034413844866
0.005408260894704931
0.006458714676648838
0.005808956565455843
0.0057316945003566995
0.0065152205122372695
0.005936610317840965
0.005372237453767365
0.0063111030869751
0.005798344645111388
0.007006857063482048
0.007267641475949999
0.006015437280157209
0.006722114385542268
0.005882628498202861
0.006232933819248551
0.006259976803413232
0.006693732979407138
0.006811207802214834
