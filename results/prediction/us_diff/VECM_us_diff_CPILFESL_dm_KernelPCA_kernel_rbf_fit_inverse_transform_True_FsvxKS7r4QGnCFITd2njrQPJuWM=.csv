# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CPILFESL
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=2, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.006875331902071193
0.007472951465689624
0.008575885902054966
0.007812896950213966
0.0071724781490130765
0.005344127125155709
0.005703584159096673
0.005104154227662799
0.0061856000640421165
0.006883090944043946
0.005820916446836936
0.0052415845764604875
0.005962850938854891
0.00585934270869348
0.00620708742103911
0.006504768999587249
0.006593091368541894
0.007096758678598344
0.006695189652163843
0.008593954853341667
0.006784428787966005
0.0087504645525722
0.0073569118687733335
0.006931277751521437
0.006437643744223501
0.0075311994900797465
0.00845598187254506
0.009280685804968096
0.010781822203250512
0.009031705160872136
0.009595683014387478
0.007818015891779736
0.007866969543609974
0.0064493600482360795
0.007633014814849138
0.007020646223841528
0.005847604227809589
0.007912423378157729
0.007503454388088309
0.006845596678856818
0.006395802993582038
0.005303915104765869
0.004949702712092594
0.006149620013338841
0.006101620699998844
0.006670294547729823
0.006499407756598631
0.006684941068108522
0.0064305415876894
0.005154283807631211
0.0054378264171361925
0.0058683956930686105
0.00485852890440165
0.006331792730657085
0.005456973108065026
0.0054812878681381825
0.004663438934961812
0.004735387244731457
0.005034337902954783
0.005235117280710711
0.005427469413591212
0.005220914389873698
0.004867147232031235
0.003998600683714519
0.004935044504402893
0.005659645213352489
0.005929859228275393
0.006352341646869133
0.006910296030484107
0.005816134442226126
0.005598508785490918
0.005520642538219301
0.006132074422798796
0.005742720180689801
0.008136339735011941
0.004827207871656078
0.006489382102887449
0.005022518553788188
0.004356492775511344
0.001374165788460426
0.0031890308768150405
0.0029235306422014783
0.004599006537951552
0.006366393080308707
0.0058875533766113465
0.0062449470920089446
0.0065993770553357395
0.005569414132572298
0.0046166937218387865
0.005819479951831646
0.006104407760645111
0.009081647731844902
0.008165724421131504
0.006215830931136861
0.005938303243168079
0.0054477108454743725
0.00514093532413371
0.007499169886301527
0.0068486242327510626
0.0060959842881481065
