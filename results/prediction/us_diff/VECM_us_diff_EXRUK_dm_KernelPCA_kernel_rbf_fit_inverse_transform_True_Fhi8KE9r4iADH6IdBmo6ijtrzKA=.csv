# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; EXRUK
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=12, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.005454721111858261
-0.022481156315358047
-0.14494151244095196
0.010757083552178637
-0.1459307753291986
0.07188404699260709
0.05934605329140811
-0.03630858659475326
0.03069222856653192
0.026326247329044643
0.06855642347119938
0.02843819370266598
-0.0010118084357824946
0.020708508488020257
0.057054444774402066
0.027101771652931442
-0.016369170257894354
0.10957933512419626
0.02735575709867988
-0.08478759411963255
-0.07869995117573132
-0.019980736861720676
-0.028545035611405943
-0.06696797580137037
-0.008665633245384786
-0.005637658605260613
0.03506926430839631
-0.053048787666233485
0.07452506838948206
0.10270198501155392
0.06022050787200616
0.01902446180392926
0.006276125202839763
-0.011166703798382315
-0.09863391618559997
-0.01422622451624991
0.07850015413232034
-0.06223791813311178
-0.024613365475030256
-0.036036243524706676
-0.07954408217158479
0.016072244478546223
-0.05845712457973541
0.025378570070186714
0.033299342221169786
-0.055892357308719685
-0.007893269477229863
-0.0011149976526862197
-0.023074054456849104
0.006577053168818202
-0.03546378723873131
0.08287059099828595
0.03557711219431439
-0.006507585259553465
0.015504368387829157
-0.001014637748705239
-0.010795060638007534
-0.027575517961867305
-0.01969693383226498
0.02233166762250436
0.015109062184463538
0.05473658157415025
-0.0036959339534098877
0.0076659731406832805
0.006799258028824279
-0.009193630186457843
-0.030154044275035728
-0.07448126538686789
-0.011273068198409985
-0.003105589006070282
0.01706922397758462
-0.0024700513849852876
0.017813050996119538
-0.037423575568315305
-0.01603704868702282
0.012730286609149303
-0.022534219125855855
0.04344701084803461
0.08471853080907547
-0.08260235731286306
-0.0004867165787777461
0.06070492828341512
0.02078116964287184
0.05636081236039166
0.006965817025750123
0.011898545475647494
-0.026731266141198223
0.009863728756691593
0.0347349297855036
-0.012054658002071481
-0.005250963392336898
-0.03280345124133699
0.013844515473404376
-0.011031875785315606
0.08371951700393829
0.04077605831867259
-0.00018516517532424486
0.007048831911004607
-0.02035107968391659
0.02915544286110293
