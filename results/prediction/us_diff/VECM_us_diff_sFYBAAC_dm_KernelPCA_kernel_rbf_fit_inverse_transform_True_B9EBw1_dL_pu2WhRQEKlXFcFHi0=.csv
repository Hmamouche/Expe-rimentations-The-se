# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; sFYBAAC
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=10, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.02294913441013227
-0.042895264768209394
-0.07052037851977669
0.09926403997676926
0.04520185741351439
-0.0209806314853231
-0.07015804950029092
0.025728907843652664
-0.022694820002611277
-0.041576421806907446
0.016280420295729577
-0.0011301438803438882
0.07938433899537889
0.08396700267167187
0.026394536822792095
-0.01535482696517943
0.0073280813993202
0.06615592685625354
-0.06197531945558578
-0.0009552680713525025
-0.05203736301439899
-0.11286835467449405
-0.016884797825761286
0.04582492883219954
-0.057466891858144784
-0.003528752584046023
0.0008106270636641447
0.02950024520493652
0.06998734615626731
-0.008767177673367509
0.10808931201168617
0.018185800430156746
-0.10721817809326273
-0.12386166455938509
-0.015040928008427006
0.012612245540905963
0.0697288431866782
-0.013085632385378472
0.021770454152877275
0.013461467546694798
-0.03325086359563141
-0.0483386641529776
0.005116208269261055
0.02816874448740574
-0.05358383712232005
-0.0034070946257503
0.03398478237714167
-0.0760642733772276
0.0322692100278134
0.0064985515513795375
0.03449633479541167
0.004823534804682129
-0.025164778418338953
-0.012783947811805387
-0.05819682087196551
-0.008773637377614371
-0.004614236440721856
0.017890287697884838
-0.0016932126943411466
0.04595042603967374
0.02596669134491031
0.09069397770680677
-0.03367221423886128
0.0395514560911856
0.00792469783613707
-0.017358526323641377
-0.02374983927594425
0.09295171031399187
0.015877424055692264
-0.01013476011604516
0.10452815182006486
0.017373282858431312
0.09800885377209831
0.024926247888303617
-0.115386557627885
-0.030458997415379288
0.038889166158304594
-0.036051723336439745
0.12755559535356126
-0.08946072822676121
0.03536776648630644
-0.11226263292405154
-0.06519393001841295
0.054434900524664306
-0.005934626212694652
0.0021263280951912163
-0.006900496347103824
-0.02346170675749777
-0.015608244657931222
-0.020405938365803795
-0.035696930985123734
0.02923345129054847
-0.00793752023623373
-0.011237293605845538
-0.01827802585742396
-0.021419629831166433
-0.006094668153495311
0.10647703940746328
0.10682631355818752
0.045146544633994014
