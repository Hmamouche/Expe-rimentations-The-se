# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; FSPIN
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=12, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0028835098657486995
-0.0049619480187848165
-0.000786926599708246
-0.009103435365634405
0.0039095016754296125
0.0007438265986269435
0.004193322637584265
-0.0029733305907919372
0.008222826727909121
0.009782677898056752
0.0153908038965228
0.012749878944267688
0.0011212209214869714
0.007638769361204813
0.013527789979607983
-0.001754455604216347
0.0019752445212465673
0.0011923794095880218
0.007649437494808937
0.061435985962691814
0.01616219027063775
-0.034942359850724254
-0.001274980975897333
-0.0007975425470463679
0.008395200241129415
0.01679771786035133
0.0065827453364493286
0.00620878497379476
0.000522611562149871
0.005383298392194308
0.01391753156686533
-0.007712454926540374
0.002376380613189907
0.010726670246653976
0.022296235334643026
0.0012137016111092081
0.00665196021971942
0.012981770026823406
-0.0019329604523264509
0.004245976819025424
0.013081830798261546
0.002549636338686025
-0.0025690826268831655
-0.009242446016220903
0.014515901309930981
0.005020295692905644
-0.0042184707315892425
0.009509160234548572
0.03561252547993786
0.021122409631232235
0.024018927907704823
0.010345029563346767
0.014210654123063774
0.018846108940127667
0.025312602294762274
0.020795155532463642
0.039233619439211234
0.03818356815283346
0.055288691931287465
0.029391249297554312
0.05510005866996972
0.03740749353346173
0.007587698461131219
0.03276750140212642
0.050607493949261007
0.05081233514370121
0.05723875915430421
0.03615449734492418
0.03446910736488169
-0.040595080078427576
-0.0382467497155745
-0.05386747667756003
-0.06087222865198654
-0.026296944754342966
-0.033375184190411925
-0.028801489613216734
-0.06042058793933891
-0.020562521396253697
-0.06568660519120709
0.00594073173115911
0.004232594582914417
0.024035667022999238
0.03916385087482395
0.007226929925840085
-0.007793018240368708
0.024047105201037543
0.03802605314337977
0.026055844386885532
1.0722641426916257e-05
0.00489660996349665
0.03317939869293615
-0.009214667849326947
0.005637460578651338
0.051045774232519
0.006028266924688807
0.053804922359116554
0.029053156470916938
0.04950681908820334
-0.05630921571766699
-0.00295826270770975
