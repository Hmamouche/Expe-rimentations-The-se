# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; FSDXP
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=8, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.016754431815172943
0.15233554716529238
0.03386217218738451
0.1130323162627714
-0.049669185247815134
-0.0016110181529320634
-0.09351059302130081
-0.05029447822517317
-0.06367570008022445
-0.03928456167925953
-0.07345687479642021
-0.06967590333501363
-0.03696550313688953
0.020843654756308186
0.019200662944585847
-0.02265502357006553
0.013633186425911081
0.04840802000781609
0.03209067076345144
0.012090255853263386
0.029234316569513384
0.01859347459922831
0.008047909806927331
-0.01693238748395985
-0.04167087705459939
-0.031489534746665104
-0.017863553751530706
0.017700087688334358
0.0018069066520403653
-0.03425685504263126
-0.08318922441245878
0.035844628102707464
-0.018444439099176008
-0.012649165650480122
-0.012109126857514094
0.021233090140389564
-0.019379654143795676
-0.008580210558947764
0.02601448933316603
-0.07376581283227326
0.0017171842897205861
-0.03935908564197362
0.042493962477804834
0.0635315037448816
-0.007736519738378174
0.0050601531836872654
-0.011269861337144128
-0.0789407665393907
-0.07450045727827077
-0.03537230947331081
-0.003021163621260074
0.04472153165597577
0.05736174352749446
0.008367348343061774
-0.04030602524356674
-0.004918078878968146
-0.027634257742916543
-0.023799366850221194
-0.015808352537844378
-0.011133705771799531
-0.008930197215845176
-0.03313888670457557
0.006119212320892863
0.03812491931091791
-0.014215514652683517
0.012959424947776906
-0.048688926812754205
-0.015062734706523957
-0.03182538245877673
-0.02977504257849893
-0.05577786747718508
-0.03352140143921751
0.03666622577947547
-0.010928304035953742
0.05150711702682329
0.03254443487934753
0.027552536781196346
0.009431942463982561
0.012084438511420988
-0.012360577538053846
0.0237181415352914
0.005898063842123327
0.009573924828705897
0.014087254146008758
0.033674691725111824
-0.044288396909805676
-0.018865409012913267
0.011500956294165235
-0.0011051250082216389
0.003101543951869077
-0.010390957849263433
0.009247315329550455
-0.02277661460126151
0.015665400429643914
-0.007850266307994984
-0.03441646260701401
-0.009427561543682149
0.005642299321015738
-0.03444786240107611
-0.0026731557228621677
