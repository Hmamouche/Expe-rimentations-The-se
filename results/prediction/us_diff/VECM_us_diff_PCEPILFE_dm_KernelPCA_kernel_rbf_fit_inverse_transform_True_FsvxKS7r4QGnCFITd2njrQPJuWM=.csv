# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; PCEPILFE
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=2, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.00829507699857003
0.00762464303849424
0.006513637036376368
0.006675612926456892
0.007595684505341635
0.005514886290544574
0.007172013431573193
0.005786729197952012
0.006341818281422955
0.005274306847920124
0.006087243865228556
0.006819313582262567
0.006926544839610593
0.006704378499228476
0.006466666598344965
0.006627580966672214
0.0067097802872033915
0.007235924276129696
0.008087387666208973
0.008621579907588517
0.009334203109275515
0.008841277751002966
0.008596427162399485
0.007571812716915795
0.006476282482643021
0.006426276685990812
0.008134607036601647
0.010233380385850907
0.00936137558905289
0.00781561454213062
0.008420584528975272
0.007706086913753867
0.00824477631080768
0.007265100194206121
0.007952668376026796
0.007933959277766398
0.0065000623101422374
0.005886694625562036
0.005388575595734581
0.006067612470373891
0.0051792443926864115
0.004954628012506511
0.0049148503945299635
0.005125336215113145
0.006900087764972404
0.006018371971445848
0.00524441084808056
0.004649695620401246
0.004830925357036015
0.005150653333891806
0.004400796867687872
0.0044764094071562035
0.004296028852382062
0.004346422261511629
0.004222731222543904
0.0046402008398455305
0.0033454816721140354
0.0028445757726449266
0.003167475966681101
0.0029190911203657347
0.0034010359303267607
0.003882611705061655
0.0035805387630035304
0.004086826950414685
0.0037256796201607855
0.004197841745689067
0.005430259066866349
0.004458458702714739
0.0031735090909546394
0.0032440835146870218
0.0052557943258857215
0.005478150958155026
0.005108254395858242
0.005806227031887855
0.004309944803231617
0.004991958276925635
0.004452296338980685
0.0035630883752647714
0.004177709928313456
0.0031287572863898236
0.004283632329683748
0.004366241259561092
0.0055426238642970384
0.006257361552676065
0.005933053200346727
0.005840526916691567
0.006387560794027511
0.006047520824357621
0.005390343445191276
0.006321305825292104
0.005735599662173604
0.007168276908409603
0.006894312158299769
0.006423762450101311
0.0064559283894802914
0.005888849905772059
0.006256054931549582
0.006177059596010548
0.00662526447642805
0.006868961587800847
