# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP274_1
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=3, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.003583899346314126
0.009245353825747633
0.0033656280178318834
0.011406457251855651
0.009282436240910656
0.002420046724560481
0.009802127358938477
0.009118164521794293
0.003986830841349773
0.0026241544109988483
0.005950012259925093
0.009601330517587969
0.010823879309349412
0.004905481053441765
0.0036528970551164414
0.01570333193563028
0.014672950380928248
0.009196020854358115
-0.0008976707223462713
0.010874942138976676
0.011950931808078661
0.004824781157935807
0.008358809199232823
0.006942214396376855
0.004480007156651837
0.0076806523921444545
0.0027580723870485914
-0.0028950641518458316
0.0017288515055379598
0.004974300213841308
0.011519164963159731
-0.00028303930884950143
0.009754920822311539
0.009292176031309315
0.0048775410878829535
0.008822140684587448
0.007257816451775433
0.0069780486339070715
0.0069477571636284065
0.014465307596869785
0.013914254933591913
0.01235170053670105
0.008347770767515994
0.015522212145766262
0.015760432771224322
0.018855428247944724
0.014466458632106832
0.014268333507009057
0.0055285839150986645
0.01329845615967808
0.01367723046065765
0.00036171179445130836
0.005887962654994647
0.007592703939971239
0.006921238773970852
-0.00477069293130279
0.001317233413469498
0.0007350106489142403
-0.005514108573688779
-0.005872946170077118
0.002602142221827487
-0.001939423135631453
-0.002653342357864031
-0.0010442543360647755
0.008191227662693477
-0.0008097213210804175
-0.0014584112093202956
0.007679378127532901
-0.0036673115363133795
0.006052665874962171
0.0029151351429565495
0.000355006222459388
-0.0015112334455577119
0.003995945452327394
-0.0026202738032784917
-0.0014959647163774485
0.004090158995913486
-0.005354590561259238
-0.007833867975509886
-0.005167903259102027
-0.009177699985033747
-0.011997752628625286
-0.004735341259929502
-0.0033744272596107922
-0.0030484292837752534
0.0059415862967048955
0.008122217330634177
0.004138595362100258
-0.002142045889180765
0.008612269443520917
0.003945723963608791
0.0023358752938944854
0.002312793487038155
-0.005404291718018053
0.001228117848070048
-0.002568275703605397
0.0028668860990961843
-0.0007082250796164964
-0.0035285292665534927
-0.001183550615651929
