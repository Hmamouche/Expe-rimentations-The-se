# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; FSPCOM
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=13, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0037479331872412483
-0.015090712276759718
0.0011177125931186378
-0.007398420496966008
0.007156651710095843
-0.0008331088512522535
0.0014760504833423527
-0.001590279282550781
0.005431689747442196
0.021080692140796695
0.02452632061531583
0.012984157965975563
-0.0006769853280399505
0.0037139421337427205
0.015544893941227371
-0.002138060488507946
-0.000402676541739302
0.013193226849086848
-0.007642021331240041
0.04980443333432828
0.008842446338912388
-0.03496018331395865
-0.004039461565567689
0.0009747926692935646
0.010936630041392923
0.013596673940138736
0.006220323564083871
0.007509322504822293
0.004726681273331082
-3.413685937683937e-05
0.01361223573701602
-0.011679874187834465
0.00046682820055330126
0.009797281231744942
0.01697993032619434
0.0008332156500837154
0.015727120829230862
0.010513091987428773
0.0012506798738046165
0.012288083605969832
0.011855768288842194
1.6672697240786502e-05
-0.0035111377809435157
-0.007593964592217806
0.010023811289641502
0.0023561933843889056
-0.004070222854937254
0.012508623309321064
0.029610789438729128
0.01970972696029311
0.022548221790239156
0.00649198160145908
0.015116681272644327
0.020081128787039222
0.03195947158115149
0.018604085032019334
0.03986854154344191
0.049646204761513775
0.055142190983256206
0.03385312884542864
0.06058675275611637
0.035629206949739894
-0.001090683260933407
0.02702465278534445
0.038854977392115686
0.049376637172361085
0.05031564875650861
0.03999112122782837
0.02425386081928292
-0.0027648752654049844
-0.0014962844303577291
-0.03517983922717362
-0.048729986753978854
-0.023894306185051305
-0.039425396346527974
-0.019960952342060932
-0.055079744755770876
-0.017668746565262183
-0.0782720037249698
0.0020096074920289957
-0.018297144514677195
0.013929300420844205
0.03689581151019499
0.006376538109035277
0.002907422045575621
0.03319868737872836
0.045224434212510246
0.01489101045517664
0.003127391026368543
0.004624072063074184
0.03748813817889698
-0.007662778070862432
0.013373777149496783
0.05500676147937978
0.00018117402233868264
0.04803900918760867
0.011899184403671978
0.03616732389174272
-0.055435620563867756
-0.013732204971108688
