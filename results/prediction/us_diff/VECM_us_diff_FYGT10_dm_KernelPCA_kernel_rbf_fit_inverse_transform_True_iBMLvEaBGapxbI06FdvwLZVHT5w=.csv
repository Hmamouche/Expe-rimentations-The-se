# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; FYGT10
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=15, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.07863360026889099
0.15425545054251916
0.17632215097320875
-0.08910907214177397
0.03791621002686616
-0.024894028174666377
-0.055096438548306315
-0.03474872953257023
-0.06321326852669215
0.07489823341552647
-0.13862580844339964
-0.11746801948051562
-0.06117939917722923
-0.0699799264208706
0.0282651591172335
0.023711477615415887
0.020025063038024343
0.09570112747202811
-0.0010153595716446695
0.09800217899390791
-0.051209090156286274
0.0266735584363785
0.039769969617164475
-0.07707066920968123
-0.03748432102005786
0.045004992633774825
-0.011269165129372965
-0.007868453426405336
-0.026207923303752836
0.0384618014730124
-0.07199651739443363
-0.023176486254671835
0.11038381335258561
-0.05135768740741814
-0.0575987199277806
0.021465763860165542
-0.08086731689887525
-0.03615380066901918
-0.03590946370768807
-0.06277275080194233
0.02705867669918486
0.01686671627153924
0.03290514764738274
0.03285989314835087
0.06093182469020525
0.09648131988613926
-0.05212279527339461
-0.008525497330940362
-0.07661717340962634
-0.016358590059705427
-0.0714632237426831
0.08380145508187911
0.04516267812363094
0.008391807027240138
0.009252841737440665
-0.029840623507978094
-0.02155325477850806
-0.035395802732681794
-0.009625764538704479
-0.05609591673270636
-0.05748289101774346
-0.06214926548931959
0.08615269585391348
0.07929957812971317
0.012038242184712257
0.09374358520142845
-0.1179890657005024
-0.006052648564226465
-0.017733858670805333
-0.04224907415105965
-0.05803772843056701
0.04684564866401944
0.008359032843811728
-0.029867146249588552
-0.017954324188324426
-0.0012860137589819059
-0.06225929571226936
0.005822726885974086
-0.07656924579317145
0.07796833086730531
0.0011484967806824134
0.057864942767036444
0.01838788013592218
-0.03264922696163373
-0.052215234267906085
0.013515441513487169
-0.039743712493609896
-0.02032881726537183
0.023919318855659216
0.031103769505988046
0.044587782421677526
0.05522540925119067
-0.0062740416254875205
-0.012638491581902783
-0.026542876955198927
0.013581970207408043
0.047244103458390856
-0.030013989333601172
-0.08044794003828536
-0.036445985278091196
