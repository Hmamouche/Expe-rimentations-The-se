# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; PMDEL
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=7, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.10617945663541917
0.041775633544147206
0.10741385196276902
-0.11490038514299203
-0.03959086143434619
-0.0022088023453240777
-0.02748879667051686
0.008468250771290098
-0.09119888103017905
0.03188445160806169
0.0470637655312144
0.020675346394586687
-0.07480640905110848
-0.013762781535265474
-0.029833324505597197
0.06142650651890379
0.026779371339195134
0.018012768061649514
0.017592338166783777
-0.046076145118394404
0.018506245289300838
-0.004535587206941791
0.015291501636496355
-0.06888439906683408
-0.003021145931068423
-0.04489175861345322
-0.006840229504486345
0.05110385801146101
-0.14474988991318172
-0.02521710693109241
0.13814922242295
0.09854544484104942
0.04452607601370577
0.03498482854631192
-0.03991647099539043
-0.035127326033837156
-0.013128784549331293
0.062836818207671
-0.0033929572048574767
-0.03949361174619108
0.0851853256312396
-0.005512467355648169
0.070051778382183
-0.02974107385435443
-0.033679664187231034
0.0447675231108099
-0.0314047241174933
-0.0840630703004267
0.0016110900693382681
-0.009326146615085795
0.021407744917937954
0.018893079556397525
0.025657716810397312
-0.0011675552923073613
-0.05608797817218826
0.042645142307603794
-0.007728379139342588
-0.013285263929854157
0.010412844787144063
-0.034681918015962536
-0.016918324543359554
0.015027172554075402
0.052933789168014854
-0.07856231151951795
0.025650011908550527
-0.0019627856140458123
-0.007211693385609811
0.01654073184415666
-0.05191027800355519
0.0009770704099840467
-0.038400764601468164
0.07728603787653056
0.019617034044100402
0.016102362645644006
0.03723676138403883
-0.02609831485319301
0.009377660291962513
-0.020965847512791742
-0.05183350603100387
0.04750105162667249
0.05837192118321456
0.03042662567276012
0.053071641821786676
-0.036199408024778994
-0.04519624454691471
-0.03936566642184622
-0.02374854524494234
0.027723776260875906
-0.005961425452663576
0.01890555387786578
0.007377663571181931
-0.04742142639148969
-0.058931717281988996
0.05209760750601613
-0.04190486229130053
-0.020156816430556824
0.04599941260416532
-0.05127402687182465
-0.008185472921323935
-0.016429150282604752
