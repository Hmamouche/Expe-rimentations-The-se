# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; FM1
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=14, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0062283240274945
0.006101955188097988
-0.0017936803883845413
0.007898180308799744
0.007398039339410568
0.006016164948573299
0.0074899485936047745
0.0081316674298639
0.0111984012804316
0.012160051504370672
0.014328151205222616
0.013935071638826926
0.016108587923399746
0.016364082410353042
0.00957220262520048
0.011567691808982596
-0.0024224708562210675
0.01258143313788542
0.009682168363982514
0.01019475970090089
0.00544094055341207
0.00660442466467601
-0.002016785135814823
-0.0013086240174841222
0.005235407864878243
0.005930263733349706
0.005475689432826169
0.0053181038668901415
0.002020474284648036
0.006470059763046362
0.013538584265009986
0.009519160228967724
0.0056526022807083685
0.012530528231790313
0.021267640871785894
0.01867292324830718
0.01756462805619709
0.023786689085084817
0.02058694347135738
0.019235482208171516
0.014645486849874665
0.02067519634858117
0.014584317876760195
0.008447040584820096
0.006429605351138446
0.0014135163302343213
0.0034965852302752546
0.00024398067060995036
-0.0007378422084338857
-0.0036886498441507883
-0.009477636440547228
-0.008555696104221633
-0.006824342655162169
-0.014258913466195549
-0.0076485387437757076
-0.008172717924514008
0.0011081331929951013
0.002300412865731174
0.006171066865813545
0.000768571302829099
0.0005548544841956755
0.006513324446595003
0.003929057989346736
0.0026155887406485974
-0.00470986133587702
0.003596920759754933
0.002149102815593624
0.004226994641199669
-0.003131850920233514
-0.0035127137182737887
0.00448701004122227
0.0031156086920078215
0.030599515528844767
0.016940408971378457
0.003010214378160415
0.007056875605785663
0.008272697069899968
0.010312932394303316
0.014940474288322235
0.011850182893265589
0.010603727298237513
0.01298691754348674
0.016462633659904916
0.013675162287365962
0.012808406398113176
0.010724168723489705
0.002063807954799526
0.002910328474473438
0.0012930261437315805
0.005505918650401378
0.003032564831551032
-0.003208791101257018
-0.004909667945705468
0.0013459815079734498
-0.0020779001879547166
0.005324590826222269
0.002151724642606969
-0.0016347073649870063
0.010435503399236124
0.00018256195841153539
