# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CES033
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=8, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.022700911123658768
0.02618025159298683
0.006373366293094269
-0.005205382537346436
-0.031103315175223807
-0.01631591148095465
0.008316177593870738
-0.003511055927016514
-0.00522646007701499
-0.001044602804727901
0.004033304181888261
-0.018642395648906497
-0.02162735298031443
-0.00014367257354861666
0.02181556837362361
0.02524368390550928
0.00845185644268933
0.009168588400290088
0.004447913669757434
0.01209943156168016
0.01559818282230681
0.00921677309860416
-0.006633971839751426
-0.013921710403561601
-0.013797534895143102
0.012147394508180292
0.005289081795596886
-0.012191809557973755
0.0003044943068815876
-0.03546586949176568
-0.026630487112301357
0.017524436276694918
0.002803727713024725
0.012056906352714796
-0.009927079312608028
-0.0001387508618797763
-0.01702829667672253
0.01837851674323857
0.020041448180579992
-0.0055067496255422725
0.01649357338470022
0.005069715552523028
0.008981488345156465
0.0025072095085449334
0.011893735320725043
-0.007460995827285341
0.0031994991633629427
-0.01888784323920921
-0.008453398280726093
-0.03256644693218093
-0.02093522089337608
0.006505728612264559
-0.00037533668359414785
0.010313847972299775
0.0068046002885932075
-0.012693911083910148
-0.0037841008037880304
-0.006926653680180139
-0.008034645202304389
-0.012750731800800509
-0.028875292445366706
-0.01923452151143709
-0.002799835089992315
-0.0159206412849091
0.010216249489356961
-0.006891616479767002
-0.015811202195802572
-0.03153035718701708
-0.016527852666709225
-0.026526410776615852
-0.030744010402732422
-0.04738312102323984
-0.05048303306718287
-0.04504548898832478
0.0008482698994489394
-0.0251984171965869
-0.02057705227150259
-0.025085883168302164
-0.032814417574476756
-0.03507306781228674
-0.007056741945960365
-0.011568198252366897
-0.021292430760737214
-0.002551614248562117
-0.01766828483111523
-0.024372307389833606
-0.03537671503620518
-0.009707233309556786
-0.009709409508858794
-0.009178205246228265
-0.0032250653507677855
-0.012626093940073423
-0.025685551677575042
-0.015629351293374914
0.01115358794058149
-0.027196584778020262
-0.009466851458614263
-0.027834743185781812
-0.01872699576751326
-0.008055309599735177
