# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP276_7
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=7, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.004747363833338705
0.006275464639150104
0.005834074116006857
0.007065264321189273
0.0052799861695678124
0.006975412944058274
0.002163264214261799
0.007353567702357412
0.004150771037417634
0.003870381356788955
0.007185070182886079
0.005429053787047212
0.005113053970688697
0.005075258133565946
0.006132001561392755
0.0061497598025341835
0.006344509817373126
0.006680034566472324
0.003755530526603167
0.006484759081238972
0.004712087101136478
0.006917185923141691
0.009942886016085263
0.00621992039027611
0.005343947334585907
0.0071990552666144295
0.008807978429213215
0.009128119380252247
0.01128908059180861
0.007371195701294247
0.006449482221227692
0.010120131221575644
0.010153285503027784
0.006513504601291957
0.00515380793349773
0.0077841771180165815
0.006745678856199259
0.004350814657399516
0.0041133031349258956
0.0059360997577732055
0.006490192079784407
0.006242600490576587
0.004898788873400225
0.0034037350040502616
0.00326104360479283
0.004199294092390562
0.004204770470389011
0.003951388547515355
0.004211076891556431
0.0053133115208652895
0.006195424913338662
0.008314698277904055
0.007877606312530044
0.006142998561883022
0.006239632191343217
0.005810723831157818
0.006721791182782717
0.005262850174829197
0.0052414562077339405
0.00622974786565506
0.005370030078502487
0.005248136051367475
0.007251850798991946
0.00805284175858419
0.006704364262979703
0.0073032178607873605
0.008109352911741821
0.008169227337418032
0.008654818666114058
0.009123597147605045
0.007389684799430137
0.008287987538990864
0.009593835339670863
0.005040853909373996
0.006957090320975112
0.008778012028939347
0.007265132216246693
0.00845655140543189
0.007743218221967074
0.007365875899771853
0.005482392468500743
0.004901850694000009
0.006296775508080667
0.0074761593273836476
0.007508307093331709
0.006770277397582977
0.00748840329512902
0.006432947682085412
0.007779311044724719
0.01064071729149935
0.007896388770997041
0.007100898970367914
0.010346147801117797
0.005778941959869073
0.0016197693468270984
0.0036362774992224544
0.005187825101706311
0.007296325335363021
0.0072303481547782425
0.010921104166518737
