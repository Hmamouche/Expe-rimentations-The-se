# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; HSWST
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=13, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.000387572842527828
0.16873091250940592
-0.35547026235566964
-0.03391035640925626
0.06470906807939586
0.11185807230899657
0.015909111596112024
0.04863732047423916
0.1579538352342041
-0.0757370717909382
0.09160469560173147
0.03619886281811704
0.04441104260667243
0.08735852945179527
-0.12261373016394639
-0.046729976437215145
-0.04184135196816693
-0.17616262426879048
-0.14379314142947575
-0.15166655980183247
0.035122363892984176
0.07095501963110559
-0.03648881945526143
0.020056148454460285
0.02267354920193932
0.05040460824641699
0.029385319444884355
-0.07456680208478654
-0.06737163342159808
-0.09184670522609815
-0.16530223618512732
0.00918642475102707
0.007528124172991521
0.09028517818789197
0.024058892384209232
-0.005002301610593576
-0.11099016102071545
0.10514185051662632
0.020526645760880896
-0.14055675671856852
0.08423421547770438
0.01350522957858126
0.011685153312690018
-0.008200338502581284
0.016440321026323458
-0.1230551320848246
0.08952214834292731
-0.0656107999415189
0.14116838526655923
0.0610053839226907
-0.07032995137708861
0.033469771535225706
0.05906284654252075
-0.08883225856236462
0.005415532825110089
-0.004268001503354494
0.05839579122207691
-0.028047425308995667
0.06348313219258965
-0.010915088513968326
0.04113848954885022
0.060421342541344174
-0.03387749296353598
-0.08349238896566319
0.014257636297190502
-0.00309723582499917
-0.01951979773614739
-0.034646104940579486
-0.06267416694341583
0.06953658772363397
0.09858973815574323
0.01624043734610247
-0.01638791671981896
-0.000911439426332622
0.10869173916675123
-0.00892841572434521
-0.08384524352755153
-0.04744066204884441
-0.04757147157621503
0.024374684535593126
0.20947642432752878
-0.037335689325088406
0.049866288722777666
-0.01885813068718535
-0.009812123129580384
-0.028350839502331603
-0.012799804115759374
0.10057464675279501
-0.06333354490277401
0.00647206420088987
-0.025314284840386194
-0.029402775063393026
-0.08636263332814802
-0.0004877685248625349
-0.04557274549888024
-0.09906776299353708
0.03267829502358904
-0.16187884175362427
0.0029576278400488785
-0.16716792732458138
