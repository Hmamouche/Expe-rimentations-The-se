# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; HSNE
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=9, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.180184741982092
0.09678949342651676
-0.12009283680344998
-0.10324176163702287
0.1297619755257201
-0.09164920774782653
0.11216709833287984
0.016293543940051322
0.04224923022013168
-0.1723372876055407
0.0823770027886126
0.15845916928869958
-0.01109604885083674
0.021171162163754365
0.002843262162155611
-0.02911465827276989
0.08837836890037458
-0.05979454290058292
-0.04959197052270318
0.02698732687097003
0.19470274024350936
-0.00979876086567194
-0.07287616508306777
-0.10105137635404504
-0.004992231814698357
-0.06306187851795945
-0.048578859147306155
-0.01136094364248208
-0.13871054012639328
-0.16242207571961806
0.04061421300677543
0.022533079269659424
0.20573287188742262
-0.14583278778908926
-0.019017134577104307
0.02171268602145522
-0.006362884386074481
0.062081249760624194
-0.04109779148421672
-0.053940087551947964
-0.027479962944463393
0.059732199266197064
0.00019084981172775087
0.03988272505657622
-0.02742817599045767
-0.07040657618612858
-0.05389327898377125
-0.009340104960494493
-0.025692113630952404
0.027628846220732924
-0.008774273223192762
0.10222083135430138
0.11889317025661664
-0.007804368259727801
-0.009481143736775638
0.004257531222996283
0.006309273020329102
-0.02255135295671457
0.000489750025454704
0.01304435402416831
0.0636277871460075
0.040459391257238686
0.009131844882962273
0.013116160441746415
0.029264093050495127
0.024257229198777108
-0.10219640214525594
-0.03270132971667227
-0.005598890889080537
-0.06270811038608741
0.08307315783377593
-0.010302067000917629
0.020418951317862612
0.02824710594673878
0.08940709654876516
0.10896079773441782
-0.09147855078543782
-0.0034277043094829334
-0.15269602749259753
0.025369218333722944
0.030801742524459847
0.08428988745632025
-0.02718824422099242
-0.07753605731884235
-0.06850108543341274
-0.04789220312310749
0.06805482197789699
0.035125971320577876
0.031218053327793482
-0.008821222899292602
0.014153127643529348
-0.05980961987962943
0.008985442426182436
0.02438018730816796
-0.033355539961301625
-0.0023546655589940044
-0.019823377916022452
-0.08600075302300197
-0.04532175326662617
-0.07531255548112939
