# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; HHSNTN
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=11, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.21071549157720287
-0.31180834934587776
0.157361156225103
-0.08051504292793041
-0.052230884499860464
0.07124697778652543
-0.08166037131459042
0.005893116630033883
0.18561317044244682
0.006824601508606067
-0.014556402011227428
-0.030292981612908863
0.009301619322173096
-0.02854619428809533
-0.004286054795634233
-0.05371490525738688
-0.0934987027145839
-0.020850372023586198
-0.0224118353011592
0.09309097099107132
0.0013214869491426518
0.07146451122867702
0.024038766551713074
0.03249314968524331
0.015272578348437406
0.03290156206293001
0.04527846738576854
-0.05224497852070408
-0.07235445296755726
-0.02523830419373124
-0.11169674640630026
-0.20404491455615706
0.04332620106904331
0.08031061436864344
0.16491026943481799
-0.11059265196312708
0.024864689964650674
0.0496805661937057
-0.09454599719911749
-0.04783378131209144
0.017173571430105894
-0.02801522573896789
0.033340340850180866
-0.002215418114298179
0.07040792139536503
0.06874711349665558
-0.022574139605167645
0.031833809928895646
0.12151032594917276
0.0006019395761097945
-0.08705633639417672
-0.08712168158930078
0.06645099212876578
0.06591610938654571
0.0578678387154378
-0.012832622667843685
0.0585964462351372
0.055218770911262066
0.06460620904893839
-0.03548183531101948
-0.02066234504036532
0.05585685973488064
-0.01191028903318575
-0.14599114698822038
0.03443305901994901
0.14378163617018375
0.030947922199414057
0.005416131548265783
-0.033556872012788425
0.01817737094048399
0.0017118988132530655
-0.006629097161969404
-0.10314958229333798
-0.02822565438695083
-0.004984360854629034
0.07146617850543469
0.0538547823604852
0.06366472629781308
-0.2115569100396007
-0.1130145872372331
-0.003752479128162012
-0.037200312733299476
0.010131394438277569
0.07144823001367354
-0.018649623004458733
-0.013701405893881302
-0.02764755413346427
-0.08738842845502282
-0.002337523876486447
-0.027085620442570423
-0.00273001833498781
-0.009982091424272366
0.008417724166996834
0.02214404052097285
-0.05706936977218119
0.10273196429035367
0.0788261884637435
-0.02703027184877925
-0.006839351382657923
-0.07232945979459726
