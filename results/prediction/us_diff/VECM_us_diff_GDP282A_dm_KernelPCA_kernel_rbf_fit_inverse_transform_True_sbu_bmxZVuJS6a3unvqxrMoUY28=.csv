# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP282A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=1, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.002646589331232766
0.003669871045761525
0.004635033301960175
0.004055035447500835
0.004682777808563493
0.004245033967272265
0.003424699344372305
0.0027200585646320907
0.002038394384212351
0.0032891003305833806
0.00447881706726494
0.004991110708442412
0.0058468164756914085
0.006637434192053844
0.006156155126541579
0.005886885192511188
0.005516549498824285
0.00552957623683254
0.005386376393640454
0.005182572233997312
0.004939351058953596
0.004685310649437484
0.004960929338718812
0.0051096219765192335
0.005010029023979398
0.0032951883649212166
0.004292289771788773
0.0036813572360703604
0.002906047652150502
0.0028213971347422965
0.0016859011879835563
0.001682647192691058
0.0022843167555918874
0.0016280188945284057
-1.622344957220273e-05
0.0018637754093900056
0.0024597455943907273
0.0030902548246753755
0.006426382929773387
0.006558124396802387
0.006485696143075132
0.0059172988500885695
0.005775740139056188
0.006174814066639242
0.005690023439391999
0.007691473542707994
0.008275568937916948
0.006670556426653319
0.0050788225546903295
0.004598189402542658
0.0033920430332972686
0.0027866995891543144
0.004609880163519367
0.005242000566599526
0.004226190239303755
0.004695757246637742
0.0052143259487481275
0.005385475162561359
0.004204508200006824
0.004275115037797454
0.0057590247832767436
0.0057942529621255985
0.006200388218194435
0.007428198428896954
0.007656919270986378
0.007298929571697699
0.009449758919373802
0.009708161234486873
0.007907096284713845
0.007972071343650836
0.00845969665542422
0.00872528474403897
0.01021129611431141
0.009528026551381876
0.005870804731331494
0.005822581515103404
0.0055444876016087635
0.007715770157700452
0.012521331975790247
0.005447426598263574
0.0048435877003525085
0.0142360460938466
0.016363317571542354
0.012398000701244034
0.01722172931735957
0.01808528730285077
0.017461394946114213
0.018005825475258884
0.022677273517940046
0.017802349338084784
0.017038294860545384
0.016653305377655636
0.014381669094629995
0.013925735107806548
0.00990369628121869
0.0018678637579685803
0.002035399509034861
0.0028317210238879803
-0.0034114345546110833
-0.007367959121386066
