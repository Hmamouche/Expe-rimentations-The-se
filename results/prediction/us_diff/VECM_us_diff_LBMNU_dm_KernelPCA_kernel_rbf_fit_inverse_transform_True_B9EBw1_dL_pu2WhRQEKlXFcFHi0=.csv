# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; LBMNU
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=10, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.01174756699525387
0.02158529024303666
0.016924492676882952
0.0013362479433692512
0.0008310759391953757
0.0026066612969724828
0.0374840709164035
0.004988132729330967
0.012364155422173884
0.011290994144111185
0.00875021342472117
0.00035015950288695957
-0.0032610123842568986
0.006585993666290677
0.006915801824783887
0.020501500578136374
0.016722175663291285
0.01325983823695281
0.012523089528785133
0.00791119458228848
0.00857184570881708
0.01852194656613794
0.0074042540084657115
0.006541179669653118
-0.0009177259012142086
0.011668008690413009
0.006418300132344004
-0.007461574140740739
-0.004864849293737333
-0.026143384616259122
-0.017685804954691634
-0.006432948172714302
0.010443357152774512
-5.523956439574054e-05
-0.014611094009896616
0.0006997612253354787
0.0014233352292221603
0.01233092137578489
0.019147469985782293
0.0051987391462763426
0.018554099469626238
0.012831860761713925
0.01654779723256755
0.012745034908634576
0.02858602124475641
0.011905910980178052
0.02047638489428618
0.0041258091438148865
0.002012866448232658
-2.5577282705458153e-05
-0.0027428381047797205
0.01691947913940108
0.0168880853668009
0.022131055597888184
0.024530940601355602
0.006827376711744009
0.018811167763466603
0.012022405330596484
0.002036430576527688
0.014734851865922851
-0.004068496808219687
0.009974032956270093
0.02216590815384979
0.00783675609529272
0.02339308783588623
0.012883063534228939
0.0023575400641440425
-0.004343899528720153
-0.0016214679442099478
-0.0020722876947104935
-0.01387487993387074
-0.009398412726072482
-0.024061214784493575
-0.02454146454130739
0.007083038082565371
-0.0007688691588050123
-0.006045680965293918
-0.008215136074465865
-0.010633189892872742
-0.009681953059070353
0.004521123516796103
0.010621024377736805
0.012434674329781478
0.004178946243704823
-0.0035660708175003913
-0.0006050515311758061
0.0019341331353770717
0.006400334459251462
0.016446154610109658
0.007408387855153131
0.01949569750912388
0.0015216829269430131
-0.0004158795535586259
0.011393549770088107
0.015783572241669576
-0.0006690221456164326
-0.007984878847053872
-0.00928225752349897
-0.013877938625452158
-0.00834557790461975
