# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; LHEM
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=5, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.00287860679271434
0.00764378207240729
0.017673408254994655
0.01448012064475237
0.003510585247049662
0.0038403774803864956
0.013844792701178811
0.0027980361103021123
0.005553773777671447
0.008521123496762711
0.009788230182823501
0.007013927055591052
0.004548796149923349
0.004895950941456322
0.011946787835178187
0.011052854308149784
0.007375286060352314
0.009257805053777149
0.01042136659178042
0.00683729551746789
0.00982018937345955
0.007615093397334327
0.008549904298576303
0.0034311314822000234
0.003979490374597953
0.0053486714666325695
0.009049983019788292
0.0025650699072173877
0.002813170236164627
-0.0011813747955724371
-0.005590554712658741
-0.0016626466788952497
0.0025328557273742226
-0.0013615962039039372
0.0004311359663874805
0.001797995997975495
0.0016687032796469936
0.005187452460439238
0.005639692603905428
0.00377112793814348
0.007673889273645589
0.009893140053851487
0.008606477538345992
0.006520247383456438
0.008283375498809429
0.012320102766847313
0.006300865343755719
0.004933316455780275
0.00550666157624892
0.001267430488129466
0.0008230586333882758
0.004921965099178585
0.008095230459711542
0.009411344885446489
0.010079718755605354
0.010244118992523976
0.010033126426259779
0.009232597543585299
0.006585648975651192
0.0035913627303550653
0.0011121433307577841
0.005769310261033704
0.00909493981431434
0.0034654118390728683
0.007147997079130461
0.009066922874105345
0.014739387347351722
0.005103126564305573
0.009972662268249203
0.009230890891931288
0.0010453438092258016
-0.0015389084306915391
-0.0021469430898584264
-0.007290298391543745
0.002625838619388376
0.0012818577028877113
-0.0001539313639803198
0.0013756029763421732
0.0023545953023457462
0.0023015178080100095
0.006863696410102765
0.009909282986533815
0.0035001686571015695
0.003336768231532746
0.004644658234703855
0.005973651934426672
0.005110824656991506
0.006888382571382799
0.0078861087601085
0.007680176461443929
0.0109747020910334
0.004059869230814494
0.003931525595280661
0.008563201937361587
0.008437913430056732
0.008173937712229854
0.003583938755214276
-0.0025703544691747485
-0.002395677839538287
0.0011700382650656044
