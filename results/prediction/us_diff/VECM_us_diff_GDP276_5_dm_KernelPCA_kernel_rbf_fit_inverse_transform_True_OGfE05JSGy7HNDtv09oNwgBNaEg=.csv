# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP276_5
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=7, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.003579988856509579
0.005864562118464353
-0.0086597503741789
0.005011148080570953
0.012905257834068208
-0.004231771195760199
0.0274974574309699
-0.0041126946316753284
0.004704941900848681
0.00597507354088299
-0.002545124530162204
-0.0016255477210591605
-0.008759159210273388
0.010663441619500388
0.011863634122872588
-0.003216235610205196
0.016223068951468744
-0.00558235650074964
0.02169591120796529
-0.002400457229475383
0.01889766775286552
0.004371327834637866
0.006560672595775896
0.008710693336250236
0.0044469964930245335
0.015258772082034619
0.0006154144625019672
0.0056337896755266955
0.0057607991856918365
0.0071049032622721095
0.0038516751177521563
0.01421462029389011
-0.005629958107674019
0.013726998401324738
0.004765312431960897
0.004622908172239608
0.0067317429078059265
0.001062172960651503
0.02006793718850115
0.0008042735157282518
0.02178450122613331
0.003935274993751649
0.008332533474676104
0.0015874257091755104
0.018013615147715052
-0.010393161019846706
0.010864591690642104
0.002033388220871672
0.007517628364650109
0.013697508916350406
0.00035007131810532374
-0.0004738713095484657
0.00289888200017793
0.0009536567357240441
0.0066656351583657385
0.009854848990747634
0.004171039800428825
0.00023901752593968395
0.008490605364587974
0.0008878377129297619
0.008219910117000613
0.0008190441365857537
0.005083709428041707
0.00011335937485616124
0.005875462700351078
0.010986502628144598
0.0010877337840022503
0.005511216791140016
0.004215271964113115
0.010407019134150453
0.009735357888815271
-0.004763303117523106
0.009196872813803365
-0.002931317262894523
0.01441308792591675
-0.0002543774573366643
-0.004183154420631836
0.006375899059720235
0.002223455308092346
0.0018177220753830357
0.011947779642120892
0.004631534762727909
0.006088986158495799
0.005468575998902076
0.010226934821456445
0.003338620882857048
0.005871247795095567
0.00823648688660452
0.007484097392809874
0.006305862648004172
0.013363273537999692
0.008563670452840066
0.003947525306190585
0.0122796416677038
0.014890200172049272
-0.003884332908272652
0.006988931409149928
0.0011704857777692327
0.01082711394234105
0.013286989457834962
