# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; FMRRA
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=4, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0009228890502406737
0.0003556201861721682
0.0004403971294284426
0.0009757792942168668
2.29100730078224e-05
0.0009798148169434756
0.0010208718178336942
0.0013409601370432084
0.001660294191378945
0.0017970765590079314
0.0016830737985441995
0.0024531738492700288
0.002484340499754093
0.003620953752593435
0.0020244636636778707
0.0015941594339930047
-5.887127368601466e-05
0.0023253442425419336
0.0005901048217968498
0.0015196572206365258
0.0005577229561071245
0.0003654033956365102
-0.0004464309334047563
-0.0009226098294629413
0.0007213444969142774
0.0012501888981074005
0.00043007493536126426
-0.0008506350012640568
0.0002162452407875039
0.0005607990658574216
0.0014985179198360118
0.0006772682202768664
0.0012252540842307108
0.002500270892305165
0.004303390433516468
0.0019933801530524157
0.002103204019879889
0.004950420119138193
0.0025976316450267325
0.0030938278186508975
0.002203251295987109
0.0035956510744784586
0.0018041904387098785
0.0009626852486130685
0.00013157035492629562
-0.0011544327515682709
-0.0007555476794625139
-0.0009066488988355523
-0.00019935988280180762
-0.001458694158284485
-0.001811586106382242
-0.0020926456897621642
-0.0034903080723748332
-0.003534872685555184
-0.0025607079408829676
-0.0030780225983301234
-0.001252981229301198
-0.0007762289923022225
-0.00013919189941508236
-0.000835962300015232
-0.0012027014636749023
-0.0002527949948573731
-0.0009206656219677671
-0.001654146309869879
-0.0021475571031630827
-0.0011590801072287036
-0.0009864044284678317
-0.001205306308472643
-0.0007619718080819687
-0.0009332543303670673
-0.0011402927612673588
-0.0005298249276819208
0.011579586009940112
0.002691279327861015
0.006514365893287197
0.0034147571384097754
-0.0012651548761301939
-0.000819418686554196
-0.0005291885205861442
0.0001800051241858798
0.001399536361744899
0.0012183115498997032
0.00038221563044433263
0.001537106468550849
0.0019348933112801798
0.001082123756856269
0.0012574612762952552
0.001128738331040153
5.639757648984612e-07
-0.001229714943503211
-0.0008031222888365186
-0.001267505094771131
-0.0009369723454731829
-0.0010793213503715643
-0.0014368451020465999
0.00028196868589667264
-0.00035426634777084207
-0.0005148797716876244
0.0003254119381943217
0.00035201183538788214
