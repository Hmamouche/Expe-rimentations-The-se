# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; IPS306
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=15, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.04723010816278135
-0.032083325374446095
-0.029536419351624037
0.05437018276309863
0.015969603583819783
-0.011359339177453867
0.0916197554008524
-0.008656676946048991
-0.06069820304444314
-0.010444622761682957
0.05713048932719976
-0.06651429972785453
0.036914437789522296
0.0027349494957148723
-0.007064596932581185
0.0007364968832188415
-0.028112353211523985
0.03970470452707993
0.07555219875761601
0.02734199914307078
0.012572899578099307
-0.01310865099192663
-0.052096133798895675
-0.009340831014427373
0.003875492006345011
0.009203227800727484
0.0054033018056002385
-0.0351362431532283
-0.0015270569579941438
-0.022393331710759894
0.07188116761467693
0.012730252522395534
-0.009191883684626343
-0.031893892649476056
0.014147960592965997
0.02932934810985978
-0.056093205597006625
0.039489785827632136
0.01119861086498206
-0.06446216300119331
0.018382699825476804
0.010011512576247968
-0.0026813942745348863
0.015534026749469392
0.018719342157211515
0.024307439172825025
0.020845405258534254
-0.01846225915502992
-0.016972818579624717
-0.037192834054921006
-0.027759240345369147
0.028752188379012174
0.0450927628712178
-0.023158031140987183
0.045260854467149836
0.002827672603238159
-0.003594572912050815
0.0035031798201452585
0.005703871253706404
-0.04562335544069364
-0.03305987296147252
-0.004088971299738379
0.0031167876439526284
0.056590777260149744
0.04258535163480819
0.03163005075799097
0.004974142676732621
0.007190808499102997
-0.01541564089017173
0.025059953747444928
-0.025717958855189682
0.028643637911600885
0.009732784897487131
-0.03572485818337355
0.04020080492679588
0.02116277317557714
0.04786805439664384
-0.02466881628232235
0.00399052634606646
-0.017397820971330663
-0.019517665957450844
0.004277992216819605
0.026105086385779012
-0.008637396830519
0.019374366515602665
0.003997757826657185
0.023926122109382806
0.03865045870791937
0.009336055707516142
-0.02371167776762194
0.01970226659526506
0.003562218178335568
-0.016350032990150122
0.0373347404924632
-0.03497860695750732
-0.015032993627283388
0.042849470404224266
-0.06117127756582698
0.02361303147176322
0.03178479941005459
