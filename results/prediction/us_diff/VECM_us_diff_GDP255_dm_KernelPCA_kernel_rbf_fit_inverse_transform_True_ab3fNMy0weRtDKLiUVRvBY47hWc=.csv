# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP255
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=9, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.006334576528801688
0.007520860189669383
0.0022965924786205465
0.0033998055860850816
0.002651904980811054
0.00562276006621966
0.011071122756740642
0.008054689773060317
0.009663384426181225
0.00802736505667863
0.004701753586761484
0.003918683639905388
0.003604300558802441
0.004381105847526411
0.007048757846809352
0.006197042105530313
0.005884396100009771
0.006547186810714749
0.006646230267479935
0.006388029900053717
0.0068613658533094
0.008209342847614499
0.0034398731912249807
0.005135636676512649
0.004640278503256262
0.007001316413898732
0.0036677191884167287
0.006264836404857916
0.007118707641963424
0.004529161564518679
0.0028849928649407196
0.003437035381723602
0.003498359093635347
0.004903073423826827
0.006693467280995682
0.005145705679540792
0.007853397526444195
0.006114089350239644
0.0027439578645559667
0.005151092385029365
0.006443298821099054
0.005807098380296562
0.006503095007663669
0.00520195360417313
0.0036576752985062
0.00529673972410011
0.004935608610836681
0.00542422663736528
0.007628869770493223
0.006649605999783752
0.008555332786958563
0.005041712324352062
0.005110536184787904
0.0040372326955854815
0.005812070323326793
0.008262653237012316
0.006901658047151749
0.00969321920097263
0.010485853145057239
0.009498066647947159
0.010209435815301277
0.006926524039365361
0.008444260867235627
0.008805001398559614
0.00983167256812846
0.007547500872992311
0.011597312482323471
0.012328637291009189
0.009067232108478275
0.011961351095997799
0.009757121320785617
0.005907583914937096
0.002237413920563782
0.00551703290277614
0.006422438180743439
0.004201928780365156
0.00539510794532462
0.004605281757492424
0.0013967975020399807
0.007311424026255864
0.0036859770988205845
0.006908870755132486
0.010240989995228315
0.007783944312224527
0.007876409991698901
0.008869828583901548
0.007063467466504488
0.006802920684149689
0.0061466147621082904
0.006995248752943163
0.008102674761737559
0.0055768006860191345
0.007247390328799759
0.010484701171355162
0.006352876711324812
0.007062537974314239
0.01000748107444568
0.003921985966557519
0.006925016302577086
0.004558268299887253
