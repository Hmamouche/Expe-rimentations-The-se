# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP282A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=3, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.004112777249404199
0.0031222689793710743
0.0045061812948826154
0.0038911988259515305
0.005880073362619955
0.004817369266089282
0.002202853774134092
0.003498494236297726
0.002513700607961111
0.002626890600547615
0.0041634794357491385
0.004269659298000783
0.006162526013999467
0.007077277364923451
0.006058195243409843
0.004669573809779714
0.006093349095984631
0.00594939762351556
0.004972061461263099
0.006142082244189658
0.004260305233124726
0.005508684057485129
0.004631515576797925
0.005265762351659138
0.005186582519098399
0.0027757067049747767
0.004342428920994972
0.00407130224409844
0.0028995950197536913
0.0023311887022574684
0.0010040785202778198
0.0017373355404210996
0.0024581034787026323
0.001749934464242521
-5.034846142808755e-05
0.001764626394774584
0.0026469673243309432
0.003163406574292839
0.005960429583895666
0.006876071000747788
0.006229625976419474
0.005493134983516916
0.005730040522719826
0.006442095993359219
0.006395449595052967
0.007331348766820252
0.008324423832715847
0.007023216663495625
0.00452827192941778
0.004623599548358413
0.00392659933049877
0.0029727650062023373
0.004646605271235856
0.005369402460689949
0.003826393841482233
0.004737395082946943
0.005534827362877327
0.005096115618326127
0.004048842007826712
0.004437885198442043
0.00597361112702578
0.005917549115455477
0.005773799555895583
0.007994865025867083
0.008100250358566131
0.007140323628830605
0.009030473798529708
0.009895447112195602
0.00787940027388682
0.007683228992521793
0.008015924062552521
0.00897244519978124
0.010829913973235667
0.009508272815374409
0.00616130195006713
0.00582732782891224
0.005080115422035363
0.007244605315715416
0.01323391274034931
0.005331582963390688
0.004240607688713571
0.013636664046694159
0.01660175200027796
0.01253981055453302
0.017478114729917386
0.0175447176974418
0.01739240069278004
0.017983342540832423
0.022678661398150685
0.017553899332386665
0.016814126934985026
0.01685193895232239
0.014837322067817073
0.014153531119464153
0.008992909430159195
0.0026659477604893253
0.002169995414288997
0.0026688418028670874
-0.002971973089424643
-0.008141095579694231
