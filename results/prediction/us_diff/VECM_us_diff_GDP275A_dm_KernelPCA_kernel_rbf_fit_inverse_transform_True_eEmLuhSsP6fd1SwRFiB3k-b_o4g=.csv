# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP275A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=4, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0031421841254909476
0.0018896208067907773
0.007886850636350879
0.004941431901309877
0.004939469147986896
0.0023933689460488177
0.003563839542455284
0.004370689115984
0.0027211222910436188
0.00344869859385719
0.00035897715106642946
-0.007480673467319566
-0.0028273944210695646
-0.004426604812434721
0.007254568259109822
0.00720134217953972
0.007892798428623565
0.006248352608249603
0.006188558347812758
0.006340750829715393
0.009300560483339701
0.006135424084112262
0.008420246698308822
0.013484126249758126
0.008171809053089665
0.0059737370999127706
0.008714710056512762
0.008696687799625829
0.01182425471014673
0.011221204439958422
0.010161516052753347
0.005763559925965796
0.0020550457155797744
0.0071249858430775595
-0.0005496955007073391
0.004468361148448542
0.004325319759232722
0.004061568418824392
0.003522510123726352
-0.0016065313959342136
-0.0021592520777903583
0.0002740287741528258
0.0021440806864033734
0.006014265514212659
0.0032072698207818873
0.0033773117116800144
0.0038388900589782287
0.00047491522452387585
0.0030079910829649945
0.0024074187644942805
0.0031514750065786117
0.006116720038348016
0.003853533156806045
0.007256198245120059
0.004173574875764781
0.0052990996706788075
0.0010956572293954027
0.0012776400948170171
-0.000513973075910251
-0.0009142442525115646
-0.0006491822461258674
0.0013094500223301748
0.004614353330738514
0.00760689281135292
0.00813847587229645
0.010666492447742619
0.00890118944353046
0.008796747094303083
0.011224853557618398
0.004684811302628762
0.0028387404024442847
0.004701991925422978
0.0028129138920645557
-0.0009172800707264432
-0.0019299380683623973
0.002273781825489584
0.001271549832995255
0.007047544180206242
0.004648260626534792
-0.0008004422309133222
0.0097372621071081
-0.001569944393150319
0.012210137200868817
0.009067505754295775
0.010348780840991799
0.010368891762778902
0.0038207361009788706
0.00899094901612324
0.011874618552506471
0.010844850026047521
0.015305197250811423
0.006229123712758112
0.013063190620337652
0.0023331950500508876
0.008152106280352681
-0.0040271986121797575
0.011230098991510203
0.016352692054016713
0.013488861752700022
0.020129217128397867
