# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; FYAAAC
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=11, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.0038398640583943225
-0.016123898845960508
0.05025164308660083
-0.0414520189177429
0.022225787179323497
-0.04178974581024016
-0.054027687533804734
-0.017881920729764827
-0.036993599976238814
-0.02054228087038979
-0.08850095232891342
-0.05095562195050413
-0.05620853437815891
-0.014290694425158536
-0.05595958672384484
0.03807086235230557
0.038234412696489806
-0.006198604189506634
0.08061431939329047
-0.02116872783750688
0.010336384846203632
0.06837265674410538
0.014240365779576217
-0.08923395685350408
-0.03444675318999385
0.009061440477053822
-0.016997861109787286
0.011971296363623539
-0.04094958562456524
0.03614917474880312
-0.03585288864675537
-0.03651490876603168
0.03195218982932756
0.004840202967533895
-0.017930343625611037
0.011917579784382442
-0.05436984163088854
-0.011825296253954162
-0.002333711470788251
-0.04998867712132607
0.014586951240427132
0.006819549552085694
0.0379371723385816
0.030066073709465877
0.03956199387227577
0.09603630171609652
-0.05610539201933841
-0.013314143108787521
-0.048482908226677376
-0.02750016786132333
-0.04855602070628508
0.02515549248363563
0.017791098321738443
0.002188973060950474
-0.008954876901146604
0.014074993674475143
0.02403932504070737
-0.038374174902951336
-0.03627939844281416
-0.04109375552646623
-0.027594297915981118
-0.05394778161520335
0.04638037075701809
0.004941652987456659
0.011159843071319857
0.08095243610002911
0.02028276023444111
-0.025602410437953096
-0.005911976213257674
-0.0317930939984232
-0.03397198310738386
0.0004746259246396576
-0.023243349509364554
-0.020442264833496995
0.02094380718941148
0.02684031595394034
-0.08817055683009288
0.033323720761461686
-0.05679014366162408
0.011912139521272222
-0.021360940333078695
0.016481251546979502
0.025132458446768688
-0.033812768049087796
-0.02397420122761619
0.008151028619028888
-0.03813353287020035
-0.017553072267164124
-0.019809657059516886
0.02975970134643454
0.018648515846845647
0.044566690876633536
-0.014126450614350382
-0.021697917699310416
0.011830251938168293
-0.012611475959397364
0.020262512130690823
-0.04034800935294315
-0.028080555117913256
-0.009615137518268427
