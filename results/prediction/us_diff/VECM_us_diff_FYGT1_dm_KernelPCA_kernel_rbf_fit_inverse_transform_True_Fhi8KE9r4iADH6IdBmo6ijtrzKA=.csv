# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; FYGT1
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=12, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.10594880919661209
0.07059340699504496
0.14905529704818693
-0.08986349399764038
-0.06487193482782061
-0.10340898750049199
-0.007590504632153633
-0.0519771302589079
0.03470333517803938
0.062406594277620867
-0.059525898597077465
-0.11946517697796455
-0.04683915596093494
-0.006256086823946766
-0.028700904548395665
0.12688823084358455
-0.005277466265760885
-0.10248139128581753
0.09331482878586221
-0.014154184169893308
0.011444838747196436
0.0908166934826926
0.03196702847958788
-0.04981519687705705
-0.06669522430337149
0.036674028733835316
0.005956208919490384
0.04039936130374394
-0.041871612289145696
0.04142882244742548
-0.15210626365132912
-0.11016528107857679
0.0636419611485423
-0.001175313310482054
-0.005235198274950908
-0.016411563014448453
-0.13682111723619278
-0.03314861002205426
0.04446907503934423
-0.05683213748164617
0.11303177824333296
0.013345346486613334
0.02844963079853111
0.013757647580481001
0.004223448868085695
0.09999228952370334
0.0011662686148257162
0.0478456258196325
0.015410747100892772
-0.03628281112859976
-0.03798909343807941
0.011515939553215967
0.01902069202174289
0.0016169684911421056
0.015673193347562165
-0.022754469728332172
0.006048854751434286
0.007737732415437265
-0.039510330976865043
-0.005343716650599486
-0.027794424581171435
-0.07085154205830915
0.06789303716440964
-0.00598122880719092
0.023128440321185446
0.04535996496567097
-0.004249095453454872
-0.04660723775907831
-0.03136510521685699
0.004076278960496004
-0.04482126794655014
0.012993456264460563
-0.07643186838983668
-0.10865321573183925
0.0984012144463477
-0.0050442481187240856
-0.05095957564412195
-0.044595380346666706
-0.06941000065732653
0.0782464061951011
0.042950282159258016
0.05076220680883637
-0.017876364645197845
-0.049544533969072435
-0.01534590716865597
0.014764014962366834
0.01909770588479541
-0.006847331142207604
0.029412875314915453
0.023636591169086396
0.02724080504641783
0.03900320998258534
0.017271819486409073
-0.02986257757484532
0.026558943445748218
0.026075763591478035
-0.013726934602109744
-0.06146956203708192
-0.10400216584299596
-0.008783446720829972
