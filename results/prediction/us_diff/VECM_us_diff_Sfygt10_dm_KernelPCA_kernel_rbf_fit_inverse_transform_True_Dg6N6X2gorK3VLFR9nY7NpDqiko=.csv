# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; Sfygt10
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=3, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.028070769380275806
-0.012386896313149293
-0.040541816653268475
0.0791211898119765
0.13774651732398038
0.1556054197220065
-0.02973056210942064
0.032788536765873635
-0.01984699312835586
0.08909662413386668
-0.03136832047051641
-0.05439172689855711
0.0004291415400641714
-0.03892150592846732
-0.1689297260981249
0.07764640975947897
-0.037262888064493016
0.10055273699774861
-0.0017897706514855838
0.05193369387224888
-0.006671242225923652
-0.125250615783713
-0.0506913396097602
-0.014379731708273025
-0.09552474570982446
-0.09949424685994979
-0.05391445234478576
0.03718265966389944
0.17769746543100032
0.13406675970686316
0.1611997871978825
-0.0627537259499568
-0.012139356063210954
0.02780745486729449
0.021341230914384876
0.11971725782682446
0.06885379893684426
0.04352494401043659
0.08756125642448487
0.038604206831521076
-0.07484417965010123
-0.062254373777591826
-0.15411739985839512
-0.047326823384285295
-0.017011834489993844
-0.050583878038079476
0.030624575295932932
-0.04806334475484077
-0.11729442312199717
-0.08457929383692621
-0.052205826742779175
-0.026986871816874404
0.04844977538831992
-0.06364463967480266
0.07110536009624599
-0.010482020572259165
-0.06319706645389939
-0.06958641023471449
-0.03577520557550824
-0.0012858856034241167
-0.010338992977159445
-0.02887666462110846
-0.04456554328564188
0.05335892450200809
-0.010335159663014553
0.01400027442941091
0.01085780868172694
-0.00817793559866653
0.01382591160621276
-0.03262080310202942
0.045649573032048286
0.03437223549884249
0.034682623986857765
0.21827022588790385
0.061803560925132346
0.21637091195638364
-0.02926576019816029
0.13017814876770642
0.011495430094703829
-0.03800450208261645
-0.08254742219695052
-0.09621925649973812
-0.04439328496373991
0.02219809104814935
-0.015341036256840905
-0.03284338589027282
-0.12210305011021427
-0.035629027081677034
-0.14848417699945266
-0.09902905292145647
-0.11580147771891922
-0.02473631487250651
0.0025624832286600813
-0.02535504270337096
-0.030567242493228158
-0.005241955043479324
0.01183209137132947
0.10473639153593867
0.18368773587125714
0.09109414851130986
