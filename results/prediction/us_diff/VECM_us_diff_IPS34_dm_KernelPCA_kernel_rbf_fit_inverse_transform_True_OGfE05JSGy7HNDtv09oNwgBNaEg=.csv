# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; IPS34
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=7, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.004796520904899418
0.007488895529695632
0.018393791640378104
0.0052476687280280584
0.0002416355603098901
0.004819505180465981
0.007169384717600326
0.0014439300533196913
0.003612729767462072
-0.0005253966097631909
0.006057862259152336
0.002182179575932905
-0.007395720717128178
-0.008542008442359151
0.0010135535617367144
0.010135465306152391
0.010124144312656241
0.005489219406152984
0.007132353536210238
0.012546157992900145
0.009313427150143055
0.017708611096896282
0.00030625581542058095
-0.0025785787826990685
-0.009534925122857741
-0.0026227285606582576
-0.004196544898401672
0.0027897282159553044
-0.005280364286587571
-0.010585807948402892
0.002392889165208054
4.3220455902708444e-05
-0.0001408587888101628
0.005131513334342416
0.00896679741108457
0.006388259387578121
0.002719563191175338
0.007074934708087212
0.007226633423494795
-0.0012160840761038065
0.012784808590510887
0.014294327004236312
0.015104891878999169
0.012059690015845897
0.012559494561520702
0.013963687383886364
0.012725723156558325
0.0037776948124264085
0.010569207609314794
0.01102333048639435
0.011533997752508008
0.019410868902453186
0.019570878859470637
0.021460521811296273
0.020033884622705233
0.01977121111836442
0.027478220009461117
0.023923082930444334
0.024296829366253485
0.01942735050120504
0.014588463336925171
0.014074779740255467
0.019486383356001252
0.018597263492362875
0.025101994290325665
0.033761536468650453
0.026476730098753492
0.018571425775516574
0.017921567334617
0.006190411499947212
-0.006316015278083753
-0.0029627891703402705
-0.017209774605043603
-0.02649148488281844
0.010569313831570816
0.011651250329073326
0.004301639723338541
0.007229593833335691
-0.00234031286819394
0.007409871148610262
0.019971474205467743
0.01921365220306826
0.01654555224606096
0.011045851096613594
0.004388405083444957
0.017051721496492374
0.008106258804338004
0.007005882319612053
0.015846111065115583
0.016162745735138182
0.01896618309667333
0.004395501885865567
-0.0015697105504440278
-0.003554261627925718
0.016670110262624053
5.9469168338348614e-05
0.01972370745908557
-0.0023464519182607255
-0.006769925319998524
-0.0018402187443795027
