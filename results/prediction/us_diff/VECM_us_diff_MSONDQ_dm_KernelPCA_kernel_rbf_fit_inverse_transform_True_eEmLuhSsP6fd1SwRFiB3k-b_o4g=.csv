# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; MSONDQ
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=4, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.04094857407018824
-0.006549125408309481
0.018399311391930143
0.055828260759054366
-0.01710112134276938
0.003311563304679372
-0.03483124469677908
0.02638533448207253
-0.005630783247758414
0.0011816666030617382
0.01651594321968983
0.017470663207123885
-0.038897952084481054
-0.05113457964645944
-0.0010372895945831365
0.024823374028535496
0.017856869718007234
0.02130406917203425
-0.008048102930200933
0.06142222041948146
0.008629154829336499
0.05390862240407911
0.004310885814909132
-0.007859947730602234
-0.011838827185125085
-0.012036301753495569
0.02101785864920474
0.0030739128225287255
-0.053804763554960465
-0.04671049426581429
-0.008844815682637928
0.06323382742393421
-0.017414192844812937
-0.03123578328972441
0.0013378077833448212
0.015210737574449911
0.014943632286047184
0.012855580721969035
-0.020815149939126965
-0.0011601913029114508
0.002415945749331054
0.03203624291152232
0.03816576221723845
0.018236615888262683
0.0015592931451081154
0.017746347251011648
-0.0025250635046518283
-0.022836537766291423
0.01816769082246121
0.015963050272069273
0.06126379694381981
0.05005543607394365
0.007601126194678887
-0.0018747777506139453
-0.005684111686146779
0.024799187520270737
0.030454836611712867
0.0644288206136572
0.060190099655842155
0.021080596977614937
-0.009762392379280092
-0.0009256064647694437
-0.015428672381811148
-0.004130886943087319
0.002432136454699762
0.03357396200731709
0.03344228886232547
-0.00015041141983171847
-0.0028400625619097817
0.014230645450396606
0.0036037644004596053
-0.01428480956857016
-0.06023912877664635
-0.07991357006355403
-0.07144600650635431
-0.04380773488209089
-0.033844862859467556
-0.012254136903197923
-0.021554826534599163
0.007268244620887649
0.029610451407157734
0.04268823158578919
0.03891290127100981
-0.0003059054528066693
-0.020427245029637386
0.010190782658151067
0.01504721754129351
-0.004003271152819304
0.041357017852154176
0.034175053752349076
0.07544793935183776
0.023689486328908677
-0.03152802915941445
0.02082764028994586
0.010483273000604514
0.016388816083411216
0.00868341059127926
0.004401807709650738
-0.00956292782911996
-0.010101067508707593
