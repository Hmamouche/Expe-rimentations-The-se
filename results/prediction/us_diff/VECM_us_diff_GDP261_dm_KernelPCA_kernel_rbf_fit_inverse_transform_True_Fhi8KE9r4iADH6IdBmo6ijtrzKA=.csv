# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP261
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=12, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.04773906347046221
0.022275515408430938
0.021125333943725854
-0.0429494368209841
-0.010651666240803624
-0.004616938689230424
0.03955904288959953
0.044619345822442306
-0.008539255132273441
0.00655474249993789
0.0261316442252899
0.021965230887727213
0.0017763336053836431
-0.0008246490703847495
0.011071920050325283
-0.009300664092832192
0.0278789173409072
-0.020135220473118293
0.00555475283393049
0.005816988310639096
0.021602338294139555
0.04626032511273043
-0.017956291215176758
-0.022325950537336933
-0.003912297458355238
-0.007740048294057536
0.013345599760900918
-0.027602913846153865
-0.04269678036770388
-0.03447248582167993
-0.002642860661498335
0.00672629255492874
-0.025452005764103322
0.0001522206912462614
0.01882809058069545
0.025526429908316633
0.01796482697941526
0.016377901161295536
-0.0043642913152625255
-0.010187341880552172
0.03143695283687922
0.02946133740391214
0.034889823509013894
-0.022065400050467004
0.030566255197224113
0.00315334361954199
-7.697318413307092e-05
-0.006529276303542178
0.0035923135487463875
0.003618895824095469
0.016713515301891243
0.0013481147535312071
0.005720442535583123
0.005664715882172996
0.022025885758567215
0.0007901919768215514
0.02133782112290632
0.004965501569804213
0.012446500157879146
0.006325536780939512
0.021222776743496118
0.014675226739246686
0.023050490893618054
-0.0019083016685123022
0.007344471921608038
0.014241095697819513
0.01160077402552447
-0.00010751180046945398
-0.014876726946725403
0.014133932389310386
0.0019680442671907395
0.018356633226336967
-0.03394353668577217
-0.006586031654207229
0.05831720613501563
0.02542541738360868
0.0023924835358626797
0.012178582996905007
-0.00012888327736455991
0.013154780680017615
0.03268200215123887
0.05994603380757681
0.029732378370498132
-0.009441083259530846
0.021290767636415093
0.012674946878795851
0.027088758483517408
0.02321252646578851
0.022306723786985498
0.0021498547739687984
0.009691101495923893
-0.0334442923655958
-0.05983755689621095
-0.04334517198736352
-0.056140447345951236
-0.039768330806782964
-0.06337914804435124
-0.09069266718828535
-0.041329985161897745
-0.05674373151429931
