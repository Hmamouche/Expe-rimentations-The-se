# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; LHNAG
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=1, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.011207123923829084
0.00992187747355701
0.011911689494434463
0.013431568916469721
0.006307200881151203
0.007473408319880578
0.00633389968579191
0.004396448117623416
0.006672548316806706
0.008010088411889806
0.006733968813350444
0.006704671292263825
0.006994697957738017
0.005772086903509948
0.009806036072798322
0.010065593330021109
0.010149032972276918
0.008768722813355775
0.006449851857322704
0.007832907699750018
0.007208647268153653
0.007576573156318991
0.006883391481187069
0.003386670702304667
0.00272195898345745
0.004734898159078909
0.008498547917564506
0.003719700176862878
0.0050144378039902095
-0.0007015403397031925
-0.005668883419280735
-0.0009360732475657959
0.0011087218264714998
-0.0006100337312787064
0.0005647413903210855
0.0023593646579694286
0.0023853283148817734
0.003408412425373836
0.005570792295766727
0.003999931802524996
0.005328151043052079
0.00845697582032651
0.010327146201652738
0.010206994911429176
0.008231777145963848
0.00969592228707956
0.004555817643425152
0.0016721218361852967
0.004035017550704893
0.0014976306453961892
0.0026206018487110027
0.007583089391436307
0.007226364896819688
0.00785955933608532
0.008994373395488446
0.009523214375874207
0.008954927492276549
0.008414656969390748
0.006032628968838112
0.004669233590413997
0.0028593438062210394
0.005013887750821491
0.00676595262112875
0.006762260320272644
0.00925353717402234
0.00794072993402684
0.014456286508512325
0.003136688162210775
0.009492342125359841
0.011694857243337993
0.0049462553730580125
-0.0007779274989523736
0.0014154130799720098
-0.0028087170347566776
0.0016606937166114128
0.001338600607442703
-0.000604402841274472
-0.002334495684447889
0.0034490822295035707
0.001224108153131595
0.006390711302144091
0.010567369763611365
0.007270095124856228
0.005379887154047019
0.004191033539712086
0.0034727176102696553
0.005216095792493269
0.005598659181723458
0.0076339213337199615
0.008554136234491484
0.009938228127228034
0.006432064432827378
0.005369840397969488
0.0049770582649737655
0.004752630538928993
0.0076546074493504
0.004564369688846283
0.001202916351944226
-0.0012957597765409017
-0.0014466309174835934
