# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP255
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=3, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.006122515669216157
0.006476069248185611
0.005756221927466564
0.005133416969821925
0.0046990234864990365
0.0062136126209347544
0.01029334299424546
0.009153119235602135
0.00808265465677286
0.006773465493944414
0.00453348060573418
0.00505455096957171
0.0036400296048008643
0.0034398518469156477
0.005763312070537289
0.006592488801245007
0.00676400216196169
0.006611672723360446
0.008283366087637824
0.0063445996594827655
0.006621570540346739
0.007522702120529764
0.00524154533417912
0.004910789837922634
0.00454165051689845
0.00582869991221514
0.003910034800726178
0.006087771510695671
0.00625852759467457
0.002845730112336193
0.0014780572336458185
0.0053002660239403945
0.0024808899010395156
0.005632183158204757
0.006912492677139051
0.004531513572373044
0.007568568575688153
0.006224505610953835
0.0036150730593828076
0.004365108454837532
0.0054629467468054445
0.005622693821327054
0.007811889571630387
0.0063121216110989566
0.005085431580488646
0.0039027729628166264
0.004569416982009732
0.007673412728229993
0.006057283920846129
0.005859994798419579
0.008309060120440918
0.004211658208071912
0.004985605461441454
0.005955652787072645
0.006382935587850515
0.0073855521606933676
0.00835083902779944
0.009170938936176414
0.010286244036223866
0.010241861717300467
0.009590995427784443
0.006991817707347546
0.008482743016012219
0.009160094260271683
0.009030223789916594
0.008720754899952204
0.012204687280178187
0.011524776234864031
0.010416972249074096
0.010717657527171577
0.008222767650535676
0.007010669478551747
0.0038659691094543014
0.005779115917933291
0.0032157859045061216
0.00424410986394631
0.004676329030101323
0.004716978785281328
0.0026074263472083557
0.004705322301846463
0.00606556413877599
0.0069126180333047805
0.009394006131166555
0.00922038362215182
0.007291311818029008
0.008847898543664188
0.0071642520953508725
0.005931399754073485
0.00738974422128077
0.006375021053836806
0.0067905054697112955
0.006880724475811592
0.005487802083113992
0.007475222893040238
0.008255155478970974
0.008447749114071246
0.007466936220931929
0.005910443308964056
0.005582749074376732
0.004330888152015034
