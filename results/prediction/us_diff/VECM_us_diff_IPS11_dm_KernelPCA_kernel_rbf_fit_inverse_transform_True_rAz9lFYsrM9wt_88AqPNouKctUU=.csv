# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; IPS11
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=5, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.012382429552680329
0.003623193820998582
0.0209124314562573
0.007534030478135058
0.004740725261552219
0.0047596707176588374
0.011772710669760218
0.007721834193898342
0.004488701378768924
0.003326272917494856
0.007219473003949102
0.0014889599793833138
-0.0011443939734715881
-0.0007519520948876423
0.010902915448543254
0.012418018247709306
0.011154153746908108
0.011811936242878603
0.012327701527304856
0.014258593283607757
0.015013705935828825
0.006256958461466424
-0.00018361241257541057
-0.002486786195911128
-0.002933002766860502
0.0004169112137811082
0.00349193226224546
0.003909384740515106
0.0023994326494735305
-0.007073204231395248
-0.0040816609374926234
0.0010312839194193744
0.004442147010245504
0.001032407196405645
0.004206837566609729
0.007314994404207105
-0.003825489752318492
0.010548133346842731
0.01133810452198003
0.004891474141870063
0.005006143789231049
0.011670320933323665
0.011241257167543968
0.010178915451968156
0.010778545384593333
0.012764833290774607
0.00282689991195531
0.00414231258820177
0.012437985548605424
0.006870357670625581
0.009698472699953435
0.014541091011613664
0.010100854026026767
0.017173078580378684
0.01481925912593652
0.016445907885224122
0.022829294224496553
0.01802680599892427
0.017393266837453472
0.019619127865278342
0.011215711536817465
0.008153390610525212
0.014715941377276533
0.009177737064292226
0.013100114963475205
0.011815707304195058
0.006783069559217997
0.007849491064411919
0.005607728720640201
0.004394197711888663
-0.0032305078803459668
-0.0017034690797914464
-0.010579627717679688
-0.016052709855994912
-0.001969929675140118
-0.004544390209393533
-0.0013802241541850517
-0.00150015030036474
0.0012745801150906328
0.005503352816971003
0.012142501367421536
0.01414339714665959
0.006343871913163333
0.004409239901099738
0.002432074657884737
0.006249858956093276
0.0048310695511472315
0.008107993646756616
0.014654364588388221
0.012515334824780726
0.011380211988225766
0.0021383930594395316
0.0061997776589833384
0.00260189193188019
0.009070949383970496
0.005468171603044815
0.002882698572446699
-0.008179963384516955
-0.001220814348684004
-0.006835731369152432
