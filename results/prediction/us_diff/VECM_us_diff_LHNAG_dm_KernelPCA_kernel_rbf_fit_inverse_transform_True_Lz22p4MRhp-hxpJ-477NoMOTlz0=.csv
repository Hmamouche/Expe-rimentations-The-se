# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; LHNAG
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=11, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.004387555349639609
0.009745277790573648
0.015963481389834954
0.0018440120655184543
0.0055090661978898494
0.0015939099907538823
0.01434782570671029
0.006305025790247995
0.005425547630905676
0.007507882233968522
0.013717790175973833
0.005524476055398851
0.002449361784982399
0.00658308422655746
0.012028882766842244
0.012227991490417367
0.008488646780894081
0.005047353176106686
0.009165462360364102
0.01168552753417269
0.006997425983893545
0.012165273658021811
0.0030297087562203198
0.0006042871852450513
0.0035831123875404948
0.006826061102188075
0.005699259068030689
0.007340781064865905
0.003050639588597169
-0.004643501715707295
0.00016428127101267113
0.00029833765979545663
0.00445421681502415
-0.00039505578493598086
-0.005194001897793659
0.002181423198734795
0.0030205782012087882
0.0054151489157297835
0.010402010337836921
0.0014376141598703407
0.011126302760380534
0.009523329721870075
0.008432791165591346
0.0037640153675877032
0.007722620149762294
0.011352975167691567
0.006321786840195487
0.0036858047047125843
0.00619315697031973
-5.394140381227404e-05
-0.002560881064381972
0.004293716505184054
0.010597686042916736
0.010025024874740864
0.011614648116019876
0.008051549766859756
0.009494352982947993
0.00780406517339182
0.005903150754216541
0.00551080066545777
-0.0013832608860676514
0.004343969870619944
0.008858547874266895
0.004149885029878326
0.010433813940860926
0.01020428966613952
0.00914500485492092
0.002064075402417317
0.006577135907775478
0.014207613838575711
0.006971861981182345
-0.0029561810426734746
-0.004652026876513417
-0.0034700124496912306
0.008833265027173092
0.004488284507597795
0.0006563244145137937
0.003600145793768873
-0.000461266615366265
0.0033198070539999028
0.004504448356510425
0.011948156712146676
0.007249879083217842
-0.0033305528959619688
0.005461674717769014
0.004243612609567984
-0.0003761508568417716
0.007293820071698522
0.010430962354159539
0.007195638828961707
0.010034196328940028
0.005439039395284407
0.0030323833062218895
0.008732070240220796
0.010286679471945212
0.005598348123546933
0.00483542494334567
-0.00545564646144024
-0.004691118630496814
-0.0015316208568547634
