# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CES003
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=15, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.010373086382946928
0.08724917239233694
0.05216511783429709
-0.08660331825172121
-0.024974925131618662
-0.004435077020872563
0.05124118823380962
-0.012641582143215384
0.046444691219515125
0.021437465011863298
0.0488296067707054
-0.01600490314371189
-0.0640690683978196
-0.05369549224431911
0.014317898895385671
0.04247219771303218
0.01914228773214285
-0.013992698688629797
-0.00406050605053054
0.02354228744900213
0.0029514633042997864
0.05015301993126725
0.006832399632015722
-0.009431611950978363
-0.025464798443152036
-0.006161316667108229
-0.0036658188528218396
-0.012402700053690556
-0.049518843010585636
-0.07047390867125904
-0.04284284431306526
0.004765548012449586
-0.0009867298363681375
-0.0405230503010589
-0.03364298517260479
0.0045726959063740755
-0.040495535173049935
0.026817007908117495
-0.010191097964981851
-0.020458323752846
0.05419653560886982
0.0062223596620054195
0.0349699760765245
0.008269638777241925
0.02207697847178364
0.030921092979791287
0.016137353019908346
0.006992619135126367
0.00812881066604424
-0.014803475153491244
0.004013901655177489
0.02719651256364922
0.005304773842688643
0.03504480524559994
0.03082442688479952
0.004469163838776924
0.030011019854692265
0.021900983996555344
0.021728421025683856
0.012025784192454113
-0.0181813853333557
-0.015625520153065706
0.03225294410942252
-0.009468152590518161
0.03169271507311807
-0.000707387278956033
-0.019810872359635672
0.015305725129388667
-0.009411210962232224
-0.002264397171181475
-0.0360848328511541
-0.030384636412574408
-0.07150154265816298
-0.07947445506575733
-0.01863467254516607
-0.0051716262856902895
-0.033113063440922394
-0.06805632979622175
-0.044430507330529244
-0.005383026786559583
-0.001966547669489116
0.00044374077651783417
0.015823917619786864
0.0041625486401445574
-0.019280529718609073
0.006279208831629576
-0.0015646855330410285
0.013874670550237249
0.023913876940901954
0.010340166394122536
0.023184441057290173
-0.004327373072597252
-0.002080174456287418
0.007374688668668609
-0.002179562365340109
-0.018883465763940562
-0.022196379322117196
-0.045193889824922305
-0.048585585764468364
-0.03345171285511776
