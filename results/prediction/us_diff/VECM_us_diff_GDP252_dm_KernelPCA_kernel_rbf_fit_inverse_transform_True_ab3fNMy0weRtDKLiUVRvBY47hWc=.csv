# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP252
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=9, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.002444156289889329
0.006119625463121422
0.010793410539561099
0.0037602702268114013
0.0023233662444666404
0.0059391940891789455
0.008625317210099325
0.00588997584836727
0.005676982303594952
0.008983011150095355
0.006967172035670974
0.0025561417833305693
0.0011922301171249645
0.005687490011993004
0.005391082179389265
0.004221300974528457
0.0072644194990062775
0.0070070913685569055
0.0037224083275666127
0.008894793727514148
0.007867222846282126
0.01070062336044739
0.0010078378376047628
-0.0004078733845685651
0.0027822741070494443
0.006372374506700872
0.002361267046678515
0.00341501024124441
-0.00024790853623126254
-0.003986350637629115
0.006742828126363116
0.0034172014972767284
0.0038376877366693074
0.0024824671713605164
0.0012218853611747817
0.004607780830929598
0.005008165777994942
0.00800887250760108
0.005624551116644804
0.0005453607527076938
0.006717632137503637
0.009204782694808497
0.01022079695051013
0.004366242537427722
0.007817017032218342
0.007808503435339105
0.006385034644987349
0.006935810559156073
0.00604703758833995
0.0055821068436434085
0.0013950179502749667
0.0027721361467345365
0.007048798528826891
0.008704349411284739
0.006842776013635252
0.011285982824756832
0.008005433917138748
0.007518783291392827
0.012682954912968811
0.008334025700133486
0.009667563814886421
0.012050733869883465
0.010932039573529157
0.008484672445545604
0.010068886180631655
0.015456935570824696
0.011293693008817537
0.013221867902505943
0.010145062537607493
0.007467957740222295
0.011141651725166957
0.007286437882839502
0.0025228893864802154
0.004768712849029143
0.009585613974597219
0.010437313982128727
0.0032033400189894743
0.008219149043772318
0.0007717725715489564
0.008851135933725485
0.010370473594934959
0.009527740873469685
0.012509843453124397
0.005145899196268469
0.00965544397022058
0.009389199682183595
0.008170226793860088
0.009340557633742362
0.006653449323481891
0.007920155263709407
0.012000570097145589
0.004292816840012275
0.006325162957284755
0.012917415504287674
0.008595146406633905
0.008452567433455516
0.012642288401132653
0.0015472349028424891
0.0020263201826618395
0.005032279360592499
