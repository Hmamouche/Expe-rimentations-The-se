# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; IPS32
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=1, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.02308347917675039
0.015572621948123061
0.006968170088405382
0.011480386272148774
-0.0020196607975709697
0.005139114313542304
0.0013231561841699924
-0.0027224585246961733
0.005825382035017883
0.005637233091230634
0.004065502599306301
0.0062620912282546305
-0.002972592033088836
-0.005077331349178702
0.007993719607740642
0.0036883625226357677
0.013158704380391172
0.0067972764973992204
0.002424550667008383
0.013953613085105251
0.007861561665674088
0.014153784602217343
0.004804152951253924
-0.0062564121368420406
-0.007960202352419652
-0.004820907357604649
0.0031541290191920515
-0.0008130138602102743
-0.006230031576169982
-0.007967549433047982
-0.008827285388902026
0.004999772731930828
0.009093623485408566
-0.0016738344630442556
0.008363657361557086
0.0043885149769939975
0.0017468616616031414
0.007336603039240051
0.007083857054519095
0.0033959399445877485
0.008892308183896604
0.010783294049983638
0.012512054409636944
0.016927077879333462
0.010589009634090457
0.014469376389018447
0.001730205259710356
-0.004265932671926414
0.006224128525688058
-0.0005268865906759472
0.009047150757033266
0.019546881569063385
0.012000225174535249
0.01824363520429221
0.012742094614001234
0.014497273120841075
0.016689539028224135
0.018112588564577793
0.016273547783785234
0.013965675314025282
0.01088419783763795
0.00820199334309973
0.01739923799940398
0.01531562019307644
0.01983508251086455
0.02199764857883423
0.0166080667573291
0.011620625678670907
0.01188193246459953
0.0034941112245948256
-0.00507245854467605
-0.007303263216192005
-0.01287750071377922
-0.020469200382735305
0.004581533307634273
-9.278354693902915e-05
0.004587082679412358
0.0033254513378015004
0.0010988460169040707
0.007176261120960946
0.009564689386748789
0.01569599689432199
0.009908045903706713
0.005016116367865486
0.002162648818511569
0.005443783092942019
0.011532257202634483
0.005060288144469326
0.009953690610940018
0.006353921348714197
0.010372592835414175
0.0031464186747572546
-0.002418985704497045
-0.0004138800819691896
0.006948168271579587
0.011535906542592204
0.0011904664837803416
0.003459389123589132
0.0008085943889006712
4.494268404806132e-05
