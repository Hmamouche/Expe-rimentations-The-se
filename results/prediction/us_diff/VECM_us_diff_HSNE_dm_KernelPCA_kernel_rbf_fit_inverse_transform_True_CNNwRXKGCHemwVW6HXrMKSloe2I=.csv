# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; HSNE
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=8, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.20687659906028044
0.08352667071802092
-0.18135683360392169
-0.07681292356222183
0.12345827580120594
-0.00037654249112538396
0.14346958987257377
-0.010945779077690697
0.010065617371510797
-0.12402230820433076
0.11219323764859494
0.14435085891861693
0.03056972606309583
0.03037916064153988
0.024274936318565168
0.014544319900410767
-0.002195818213489277
-0.03639340988573757
-0.06352648053296178
-0.03266746604916074
0.1004166858161168
0.005859687198996558
-0.0885690439259762
-0.05079007604629812
-0.022184569529513067
-0.05842750600063683
-0.0657461109653508
-0.023689430669628135
-0.10864409276844073
-0.1297552433198032
0.13264473395073956
0.06942502539028333
0.19683010829872272
-0.1432022217181777
-0.06917541745562857
0.023522063140300427
-0.013565958496739949
0.06387111958683837
-0.018875044102115966
-0.08814560822529388
-0.05377552216368562
0.07572594443172478
0.023771780043628496
0.013558479257141362
-0.0535383901256249
-0.07884516529740779
-0.041142961613645196
0.009311726873210274
0.02592216642721846
0.015297814184258197
0.04205790037917901
0.07031318239961601
0.08613941633000319
-0.03926605379719551
0.01672041005769248
0.0027456730478167615
0.021971423115234284
-0.017157985992855916
-0.0017328413734858583
0.03224360206127908
0.04258213877463522
0.04789494038521727
-0.018192986822880265
0.028527562147423087
0.018805302661017147
-0.008717995961784263
-0.08198893518106148
-0.0345387229360791
-0.019971067982899812
-0.029254613035551845
0.04888967967728512
0.044263429926801046
0.03704484181041347
0.042062035883180734
0.05609384546164428
0.0671969705431429
-0.08909229799206987
-0.04653149001997547
-0.07618623581697778
0.013993344310070968
0.05105871850504876
0.061479329203592344
-0.004751001959506411
-0.058692649413738064
-0.07328114875775224
-0.03519179719935972
0.06014639795463076
0.017604542061796142
0.03832748053874922
-0.010532477176534131
0.011184646657449669
-0.07889031875720998
0.01635089174877821
0.02600079500897368
-0.04098290674441331
0.020761605171696108
-0.028848297478567916
-0.09488635435646997
-0.05370369997510226
-0.09457616494886523
