# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CES277R
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=4, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.01818059964418526
0.014429406777326846
-0.01074194722652858
-0.017510866318905402
-0.019435060552189465
-0.011816582062237345
-0.022517351482998292
-0.017096565984183073
0.00036675006940213063
-0.01210573679113601
-0.014398710296565878
-0.001916765086780792
-0.004367856218290207
0.006197951798113615
-0.017177777715571572
0.0025717987095228868
-0.0074965333453313465
-0.008004943364097556
-0.020538709849983926
-0.005494579237524772
-0.01278028338956385
-0.005834328805417892
-0.003445524867213148
-0.00941237598591194
0.0033925526836052905
-0.006887496120577286
0.0031614319903530276
-0.002547270971867831
-0.0006973752155164711
-0.01757968377939492
-0.018408681778799462
-0.0020386883821616837
-0.02054160401139379
-0.004707958212487779
0.0057639190291904575
-0.013957515190808975
-0.009637490529672313
-0.00954455038039754
-0.015518896105826855
0.0035088930238605345
-0.0016359177359368082
0.0004966595490105987
-0.0015285336228528662
0.0029478629522651477
-0.001709633147529466
0.0006037841346164452
-0.0038420746353011203
-0.0022230438333075055
0.002844562049548545
-0.004759304870702741
0.006854667011484817
0.006850931856359829
0.0051069776390506695
9.32507446705208e-05
0.009261791510645963
0.005758343740738816
0.009433311586579974
0.01578587620068892
0.015919112347280967
0.015412553782102698
0.016581793506186673
0.011925568859105205
0.00249819795244584
0.01089025911102551
0.012958067447352001
0.00460571518491123
0.007593581681826391
0.011349099179706092
0.0047514498156241685
0.007666640903589063
0.013400230515779456
0.008550093572648233
0.0036936870633811534
0.007210663365675256
0.002145251809843915
0.0003479710034523034
0.013181169194789306
0.012217691844030397
-0.002917994409223703
0.006477950218005594
0.004279539466861716
-0.0020543320912675017
-0.007683267216171048
0.0012602222064579524
-0.010131629445795856
-0.017488802085700812
-0.010176076007042316
-0.013225897116240774
-0.009389616584972588
-0.009867224381650785
-0.00864289567845326
-0.003987722368035916
0.0001028601482591018
0.013564928899173719
0.00847183572123968
0.01577393826784684
0.013483012576557693
0.00867110353591196
0.0032351712352406197
0.000477659320246341
