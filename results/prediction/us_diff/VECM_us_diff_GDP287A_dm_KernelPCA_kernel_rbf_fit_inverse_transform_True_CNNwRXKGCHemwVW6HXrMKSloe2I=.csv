# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP287A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=8, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.007867285257368965
0.00694760752785837
0.007270553425790411
0.006329225423228823
0.002761134985758859
0.011032911162376799
0.004387667414939249
-0.00026468245204481003
0.005393316123972021
0.00641072650100154
0.0037608058473963396
-0.00296817297392748
0.004684736400064046
0.0033417439820080386
0.0020895526988824143
0.006610700916756133
0.0022694467985132907
0.0035390275057650853
0.0015075866397082172
-0.0012445977729041231
0.003589899935937079
0.006559540541585914
0.004345454952719898
0.001018468215019189
0.0021610399464839277
0.007144684172033709
0.0020096770972607633
0.003124758394850863
0.004812259087346504
0.009321105427947353
0.005682603588005471
0.00707768129990202
0.012086937612502997
0.004654463908075244
0.002905359862321584
0.006144804958427495
0.004105868605011751
0.009575622615303064
0.005356934619014798
0.004526028391819274
0.0053822732124642544
0.005190738880615235
0.0025281183372775876
0.008184728692924529
0.010459323129295787
0.004930684082459615
0.0042658442750344505
0.002464592916162577
0.005485340140203084
0.005710872597290582
0.002988638079651814
0.005946576349736728
0.005183034015550648
0.003253319303289385
0.0007091698993953448
0.0016051941384896454
0.005994354571483175
0.005985039189138218
0.00035592231331072605
0.0035255199768576663
0.002077249845128421
0.0023350860526433295
-0.0026033544250268145
-0.0016932384290608811
0.006573178492923115
0.0114320227662512
0.008655975649575907
0.00591752625356371
0.004606572871293303
0.012345934016191024
0.002118525378987203
0.006862001571176652
0.004174600469411962
0.0023701379959733815
0.00517941371789199
0.004134533071707594
0.007143276066560874
0.012739529166662154
0.004754519794429739
0.0033944620512765073
0.01436337594316658
0.019023963226940572
0.00046221574924831116
0.0067922558307994705
0.010249098330997693
0.017398643930098566
0.0154116060499054
0.009052392137298911
0.007795794316685187
0.019738001111660734
0.005852895232710612
0.011644856175163613
0.005221257808199645
0.019235592254039733
0.010889627810883106
0.005085536722101196
0.006642561528344515
0.01659575113268165
0.00948896952101673
0.004145642637267506
