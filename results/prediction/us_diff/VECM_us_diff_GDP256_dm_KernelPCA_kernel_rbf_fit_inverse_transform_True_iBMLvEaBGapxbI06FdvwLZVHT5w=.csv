# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP256
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=15, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.012668470276613473
-0.0050984766891259345
0.024598564185363513
0.0009921789631812316
-0.02136669054642481
-0.008579177388222812
0.039106726397887606
-0.0199096157761734
0.018967231158395194
0.007123611263649434
0.028249012941723942
-0.004296141263104844
-0.003603737491391423
-0.03697887575403659
0.029071133412315514
0.02021705047413062
0.018038492771973128
0.0116495678212112
0.01963481050866914
0.031525325599350916
-0.014802487835004114
-0.007917245076788221
0.007854685469433345
-0.003759099166773058
-0.010766272712182667
-0.0026222699015418724
0.018148058966800995
-0.0061692865566466875
-0.009420743056230798
-0.02596601304776268
-0.01703724476427654
-0.013503336946011666
-0.009736184438298408
-0.0027730648778825813
0.013852911669096395
0.0058122602627108146
-0.028312003571504693
0.0282016200744324
0.01370026912655933
-0.005033270979876799
0.031806584376583985
0.02474179030972975
0.02270037507503138
0.012124844981497108
0.012812040231217195
0.014583489216089108
0.014799481548389327
-0.017961061822010876
0.01651007599554034
0.006155981770482939
0.0033453799643657573
0.03731035967971204
0.004294250367902673
0.020043126292807276
0.024361992367715097
-0.0026241079621574185
0.032401596164622536
0.025587662769976198
0.015699340122840317
0.029092662582437784
0.00611326508196636
0.003160300778779555
0.03291281101843685
0.03534093850055454
0.005144970977008593
0.011440277392877292
0.017837051751249673
-0.017034667598369288
0.026989496070395837
0.007845228942900663
0.004216056172643177
0.02133814086423471
-0.010513576535979764
-0.06145252751983503
-0.025732329932169073
0.0022908614108249296
-0.04227531713654967
-0.009509622779082776
0.009712359895076043
0.012167370588266203
0.013389949177131258
0.03902216946397481
0.05110890713325924
-0.0007359961985833469
-0.0013810086715234562
0.014379663605601604
0.037167187037622014
0.017940080240529246
0.014744110291686825
0.016876018200765806
0.004214506205405977
0.010443910477582252
0.00794794165464222
-0.008525116185080886
-0.01653783191516395
-0.018312517077478028
-0.02516699920233628
-0.034643008624242105
-0.0027212485426428446
-0.014553342351906693
