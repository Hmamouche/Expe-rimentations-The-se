# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP273A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=5, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0051535025705557415
0.004086549216314047
0.0074670270587332025
0.006460921550913247
0.006686638440624694
0.003991928620960938
0.007017499836382944
0.00495366431847066
0.004322243007533054
0.004620711865858811
0.0036619307548355928
0.0024469634877192278
0.004739888871049285
0.00212297355317661
0.005985208861270726
0.006158959259490771
0.007495962686148492
0.007247517789576768
0.006810109762838431
0.0070304351841467255
0.008278685802954709
0.007892405814969744
0.008941338808069963
0.009639001306564018
0.006799692406521328
0.007183251278399283
0.0074318422830268425
0.007111174976271584
0.01039387020978346
0.010217157167434895
0.0074282578790167385
0.006168863574155827
0.006283329649817583
0.005509292197806397
0.0055692902448266956
0.006093404084870395
0.005934987596384106
0.005385040027351882
0.0055984152835376975
0.0036600720730719806
0.003286422206712436
0.0035873996556098076
0.004098895170617295
0.005995822441003975
0.006689828375484234
0.004816427213620819
0.005979610907275428
0.004058952441086058
0.00433144488616701
0.00455855098083348
0.003992469793579451
0.005238941914736499
0.004541282732213156
0.006046260565219859
0.004885045723150976
0.004083047471202874
0.0029255868217923607
0.0021667778046266734
0.0017772608214074595
0.0015313525656469962
0.0017278507588514424
0.0025016487547241772
0.0030849124556502614
0.005866193375133632
0.004330184829136842
0.007042792356962661
0.006754201560526696
0.005895147407838655
0.00626258552093318
0.004184649353391197
0.005292684733264334
0.005097347569836436
0.005128507397660875
0.002739811756621104
0.0022007093149970037
0.004574854705118058
0.003043238586523758
0.005239766794818038
0.005763844574005634
0.0024948624337464476
0.006911462860654672
0.004196565465372613
0.007677516911311988
0.00819981566811942
0.007307441455290254
0.007638102757267105
0.006396608961252585
0.00731092570791709
0.009150056598284027
0.009468615256999477
0.00827086775577606
0.008374937680092408
0.00817655484818704
0.0042987248141261635
0.007409314505039839
0.0047197384203362764
0.008784505452948004
0.009933714529461275
0.008446768016097096
0.011689292514952512
