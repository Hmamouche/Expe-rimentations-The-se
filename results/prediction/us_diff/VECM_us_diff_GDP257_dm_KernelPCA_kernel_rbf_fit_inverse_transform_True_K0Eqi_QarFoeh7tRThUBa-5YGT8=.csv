# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP257
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=6, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.02083870569224589
0.0077577502105804635
0.025960906653548957
0.011048005671184637
0.012539447202640564
0.010997980234696565
0.02173351012801187
0.011202516860137266
-0.0027520701729750376
-0.003796731710601968
0.009653177755827977
0.0008439004547780098
-0.0055334529683953365
-0.005508586015952209
-0.006282288194836613
-0.007572081461908579
0.005598976851603663
-0.0005377493491639889
0.00812642738829575
0.009792653647508323
0.005249133039126517
0.012763662325196323
0.0035016791316349236
-0.000990007934125549
0.003405392356206185
0.0035350523277126907
0.003368999545535769
-0.006015192265843456
-0.02598558778152501
-0.016175229834084256
-0.009040310562252962
-0.0046459095474259875
0.009956232232159435
-0.0009795515393347942
0.0008785831311782016
0.0038799897615658845
0.00597941653789661
0.016237526667746537
0.013603659941094135
0.005859669584489111
0.011044657833485886
0.019636877706380493
0.01927736404991885
0.011462286672798607
0.01947168801995228
0.01143986923447973
0.008345664948676843
0.009047566880878738
0.012397164140313308
0.01208698644475084
0.00854400526567891
0.01311996784112784
0.01864047329965772
0.019921539806010975
0.019033953738287476
0.02173320168630198
0.023347367284479094
0.02233833108024046
0.0171892936929774
0.024462101518747507
0.010822919471912325
0.018082368348097046
0.027005035461437243
0.01019735488405439
0.020002937742396112
0.022748577535063298
0.015135879032369893
0.015925754135823617
0.012838143039423159
0.010699054174365199
0.006453680919109727
-0.0018791937636669185
-0.019344941006420948
-0.023951362588592942
-0.01195741621706103
-0.013161502419167992
-0.017680982739446037
-0.0018769428255468374
-0.006649553459675031
0.005741575305308274
0.023836354471203226
0.031164997415750836
0.014301297106453887
0.012180247009095825
0.01753667889159099
0.018191261612666768
0.021374154275572564
0.016543207613061873
0.017818445083486626
0.009042809980431676
0.0211281465080629
0.0007431509341249352
-0.00332505576034383
-0.0030968719420290712
-0.01669998320512528
-0.0004466906692270577
-0.00699985581937617
-0.018733311616943048
-0.013534501599357205
-0.006858738870006609
