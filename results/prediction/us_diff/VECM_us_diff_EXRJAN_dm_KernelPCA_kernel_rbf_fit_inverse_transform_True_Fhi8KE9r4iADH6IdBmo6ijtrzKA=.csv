# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; EXRJAN
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=12, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.09746677883570433
0.013085005895039001
-0.01215550757210839
0.03965207794301833
0.057925502783236715
0.008437765652596813
0.03975872472552451
-0.007221496609933872
-0.02476821447560879
-0.09379847061505933
-0.053131272392786394
-0.04447990187006389
-0.04229215443403575
-0.03807341972505566
-0.04142593705047933
-0.03942910915303535
-0.003299640255882138
0.005061994706361017
-0.016162845575181346
0.007611937545107646
0.040624059213139864
-0.04641883686837783
0.02086730914009439
0.024485990675982408
0.04802940191139715
-0.016066638934494164
-0.0021489396104390425
0.05266502991309461
-0.07285639510885965
-0.0004211426814162596
-0.008279576170515841
-0.046989681000787153
0.0027015541070352384
-0.018229830636521803
0.03200250974842704
0.007174236666505924
-0.03638205174832056
0.006375529785276186
-0.04759335309947824
-0.046126274629770106
0.017125476033815083
-0.04259900651841717
0.016853202015557157
-0.008517711891221035
-0.01297784331066391
0.027381038921614215
-0.002056947675305447
-0.02125045873635475
0.04586532708904661
-0.009636018302053934
-0.012216576935405912
-0.02691699940488799
-0.01558148478057432
0.04756595091177718
0.01346260037847353
0.01882855802776827
0.007596246969013283
0.02397124678204531
0.011961553012192833
0.0052114189563608766
-0.02079767269337389
-0.05262810304974719
0.0007115149673839229
-0.01926487984670247
-0.03202476708500319
0.01542865428973355
0.0026497879475440612
-0.00428150073554797
0.011599368375266712
-0.006661745370801398
-0.000366831166080227
-0.0026241264207596936
-0.04215125797572129
0.027841795220039295
0.012673808789131834
-0.031115174113077005
-0.010054111318850655
0.023366867331836363
-0.04604205952197976
0.013341133571117927
-0.0235786670040208
-0.0074769996522993055
0.01564974463785142
-0.002016545098335402
0.021552587355354015
0.002083531297936779
0.015711235765335504
-0.0030223917556280646
-0.015443394544225754
0.029345187544643277
-0.010756038818636803
0.04117207788597652
-0.019322950236994155
0.04414679716621117
-0.016885191189255678
0.011047430379604047
0.009195718961174828
0.02234305638857884
-0.041749513722321656
-0.030830097455045828
