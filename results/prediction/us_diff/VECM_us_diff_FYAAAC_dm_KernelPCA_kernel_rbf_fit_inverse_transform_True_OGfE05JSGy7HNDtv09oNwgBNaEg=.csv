# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; FYAAAC
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=7, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.04360729607469739
0.06641673533603934
0.08441068527325782
-0.03320888782135328
-0.01452257123165128
-0.047101466542780294
-0.03214747827869001
-0.034937244631107305
-0.027612033935909216
-0.041101146367929914
-0.04589318572738581
0.006040758081743002
-0.07261208103916504
-0.009590078037224893
-0.057009050553199325
-0.014484407478014272
0.05641919364184918
0.04862031292506296
0.06037220224003045
-0.03341208773158941
0.019539117806952864
0.04476447235239315
0.003197729320982251
-0.03723070134101149
-0.02701637035813929
-0.015627124124211272
-0.019221447489292692
0.02236307777626951
-0.03468116667611229
-0.030199928086428046
-0.008054587354531559
-0.030656630355971354
0.012238975348442812
0.0163486563343611
-0.010243308302474014
-0.009147549087205723
-0.03974875660924095
-0.003916754034084834
-0.007601195187121126
-0.06639633494652865
0.001547239526739106
-0.0028979761998117505
0.022974001416468357
0.04478904315241187
0.02725978672541754
0.0625417341134201
0.007386826817953688
-0.02308455838086344
-0.023742376096677037
-0.026839400203852504
-0.019237433579747294
-0.0037451953708801658
0.01693931180320317
-0.0025344453152144047
-0.002941015857830284
0.01607420161633113
0.02635818379114861
-0.014165717573274773
-0.014872441171197369
-0.03719975509445486
-0.012461147283295589
-0.04927553840869444
0.017980573412515913
0.003887479067936057
0.008081952446908605
0.05417452849073495
0.03227264118744165
4.1242307329387995e-05
-0.012016524892063262
-0.01182971417934681
-0.02643745823866015
0.00030443554122913923
-0.003015042148818629
-0.06016150980594492
0.003767967841530672
-0.005685258780426847
-0.0389050408442713
-0.0036573934737374244
-0.02907907495019138
-0.009212411119730209
0.02240597614338206
0.0018939944584740395
0.0566230143683977
-0.0002490029668263116
-0.030820670870267193
0.0046696785974078454
-0.021036959195022444
-0.01506325239378696
-0.013929800846543989
0.01943463114085581
0.0229763383572202
0.003531081311394216
0.008999741397342075
0.0017927500793662038
-0.011163624586676866
0.02032776702397967
0.03395903389611635
-0.04583184899988812
-0.03875713235871521
-0.008364510310857273
