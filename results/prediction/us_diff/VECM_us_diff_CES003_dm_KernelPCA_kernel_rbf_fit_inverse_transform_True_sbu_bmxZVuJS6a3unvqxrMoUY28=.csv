# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CES003
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=1, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.06621032624840728
0.05458572975171039
0.039435460686573415
0.041015651301207615
-0.0009535204554677393
0.00842098242568404
-0.0007039720017601205
-0.004695798244201285
0.009767571203039487
0.014117617995657469
0.006244179672925259
-0.0038139564630647405
-0.014997392401349206
-0.008282467917847425
0.02053814197872341
0.011778310103195218
0.03114091966495023
0.023087664323783265
-0.0017584366116566263
0.023253247373603046
0.008935444223219041
0.021712728027626506
0.008394744718316902
-0.021443410103460576
-0.03015095314725437
-0.016606220122935965
0.004941666987564609
-0.005896613384002127
-0.03209566889887852
-0.05182411926108067
-0.06298797670293196
-0.02300088394507176
-0.005426454395340924
-0.028252837189153605
-0.004793680515450871
-0.01617343959360926
-0.01989563132630016
0.0009836108221823008
0.0033471335790527593
-0.00917128663907049
0.008853621188717742
0.030493163178534694
0.03200174191773837
0.049438857401397744
0.03291911692524187
0.041909803352196726
0.001921484368805398
-0.018891475363531283
0.001996532568723385
-0.01984524387500683
0.004238175879655318
0.034423612449041595
0.011844780201212182
0.030446006952514287
0.022863726906613858
0.022056823884338828
0.027262649429251398
0.02505583912868004
0.01445010070973303
0.005110751075781756
-0.0046380983508079975
0.002197232951699415
0.021714600185002632
0.010911674893418313
0.022177149672713673
0.02725945459823815
0.011857403619793157
-0.005684275262964426
-0.011388070623115478
-0.02580096944339847
-0.04189561528858388
-0.03643840687732982
-0.05290838815123303
-0.06012191061851913
0.000492800044861021
-0.037398909835698685
-0.03306115187124352
-0.030839330450036388
-0.04802641199272574
-0.03263069047903672
-0.0011331954726337672
0.01942300775945166
0.009986398936816052
0.01589790691154908
0.0023680476595822376
-0.00200947170079785
0.004747320870298236
0.0023308461900219822
0.022088955113513685
0.016065924822795563
0.026258389555120724
0.007636557162221176
-0.010120626953040134
-0.01678491583882706
-0.005581966394934619
-7.125025572028189e-05
-0.03192120846754988
-0.021755419951827233
-0.03649359494889707
-0.04353811552729025
