# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; EXRUK
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=2, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.02107418287413274
-0.005518172572528977
0.017750446037231356
-0.006468061585428414
-0.03390753135361991
-0.0258981155676819
-0.05868524728630181
0.014613359466777788
-0.008637752487996824
0.014136185521158324
0.03402139363942356
0.053289272508249885
0.011071732773772432
-0.012601022873737981
0.029155840630719514
0.036239094694911364
-0.008252941644413604
0.07536553504197155
0.03266455331796832
0.0323334570096131
-0.010199823352102408
0.022382087998068904
-0.005616272995714377
-0.048007320443429036
-0.003792492761399712
-0.022849451234064136
-0.008404404552612649
-0.005393851804405523
0.05240971694152041
0.051186355753777196
0.03081224841340447
-0.023950518787075197
-0.009227735491398957
0.0017599860355200446
-0.04419294285774573
0.022105456529379456
0.04443238067153276
-0.08790673485936326
-0.03441215984657725
-0.029776938259103426
-0.0629005144885692
-0.008857000242567001
0.00257198290820467
0.0018108924976925084
0.013845599935122466
0.006911060793037185
0.013106792429567932
0.007993616590219441
0.0014121825365077554
0.008886434400558179
-0.018462162607083787
-0.007863453038001799
0.012939369300969034
0.009095906277359183
0.010194271006180311
0.020788010337147125
0.007195833803191114
0.01474687883278699
-0.0029374007225492216
0.006356496957096292
0.0017106325052540826
0.003832376010166674
-0.012064293653752365
-0.000845689104861064
-0.007388108205990571
0.0031435108510376245
-0.006600667742350954
-0.02218919902908807
-0.02545668466296657
-0.02547959896614787
-0.011208075009473208
-0.014957306258957775
0.003954172426730736
-0.004918473423543965
-0.02488980656888727
0.022619962786329634
0.00253524904011437
0.01867177484606833
0.025370487829276773
0.028148100868057836
0.005311253564200368
0.044038244931954074
0.04177244405915969
0.0066110913577663985
0.027693776309984354
0.027010816027393657
0.006894383715449768
0.0010447806617654145
-0.01627274915913637
-0.007709882922525266
-0.010911226892170745
0.0007020404291393869
0.008137193113683383
0.018767644473927265
0.027069077530221454
0.030389162610153047
0.027933586163284105
0.009068689665145017
-0.007603740580741247
0.0009623183829999659
