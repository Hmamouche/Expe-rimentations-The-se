# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; EXRSW
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=3, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.014757401846070831
-0.020497081971343763
0.001984719262552958
0.04481742270490674
0.02787676578669175
0.02066954714087496
0.049436767767965156
-0.002015081952169019
-0.012389244947887158
-0.049302330162687834
-0.02883821301122841
-0.03745198349883713
-0.04990247314695824
-0.03195538410395846
-0.03747953047498872
-0.03236408790635256
-0.015557301344729556
0.0005124571471631703
-0.026304764267458036
0.02611508246321761
0.008591755646108703
-0.014253240317152315
0.011243580346248946
0.022919412432209522
0.003072225633451201
-0.013234568646545954
-0.012367791401513608
-0.01165300588199852
-0.030958757482420114
-0.01871973767782873
-0.015413303880393123
0.024506109021675344
-0.001853147100966514
-0.01600202177289478
0.016876269800200388
0.009468083162098458
-0.03275586968995689
0.02244775231447635
0.005924356907245677
-0.00841800626146252
-0.002612348494169631
-0.008468216793738359
0.006350970230256091
-0.0018612604792162596
-0.016165177422453613
0.011471679251118777
-0.017485672681140915
-0.007744037032385449
0.0030136524750915186
-0.02522885376052436
0.005923427451758562
-0.0035639679436832057
-0.02337973488548449
0.029275790419106242
0.028122233252816743
0.007287595727451592
0.015605018875191745
0.008232937943807405
0.01398287655445702
0.009666609560809778
-0.008111795953293002
-0.014029428362591924
0.006461884917278078
0.00363412912254793
-0.0025249706520024755
0.007442790543889088
0.02076781656253713
0.020556625610295816
0.016173962903434355
0.012399087492676096
-0.01758308365385413
0.01377543203305524
-0.016186459372692353
0.002809880913381365
0.003680555413586431
-0.03133424490306001
-0.012303318437752283
-0.009189076829596715
-0.029859236115131086
-0.02182301800796983
0.0018130378517622154
-0.025282002807521287
-0.0028256326135484037
0.004709424833627477
-0.005487521899341704
7.030728916695029e-05
-0.003125557657807132
-0.0013310088051484339
0.007326111321897396
-0.004041059340228595
-0.004894840739783897
0.010143280138795658
-0.013736362354746371
0.008075809734780812
-0.002560840854710868
-0.010512098094855904
-0.010181919302792528
0.001449981047510403
-0.019695286940657593
-0.006446083147046786
