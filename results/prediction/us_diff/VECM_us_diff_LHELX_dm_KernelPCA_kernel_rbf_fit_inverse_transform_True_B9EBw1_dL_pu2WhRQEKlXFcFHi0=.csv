# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; LHELX
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=10, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.11767251277354025
-0.0051400997627574566
0.06994788230922439
-0.05251149190941376
-0.025471267012325383
0.06470642434187786
0.0008815845574602701
0.0008641829538422185
0.00581698829257463
0.01638966432219922
0.03519046378233418
0.006581310604531611
-0.03872054042030309
-0.006338451042718083
0.032223386885428945
0.021995253472216834
0.046216964645303595
0.007170298005274195
0.001555962282188711
0.020082616739044212
0.022243688115028568
0.061031380987682585
-0.02636652641984509
-0.03415609646077847
-0.015371009106873168
0.0011722995181841019
-0.02810341934331324
-0.02664415951980201
-0.0764743281733805
-0.09285754641133194
-0.05844179621483075
-0.007679634240566988
0.01736355479560639
0.0347591196730451
0.013522767706894624
-0.026723235778392113
-0.03494553681901158
0.010227978578576
0.005857004718178534
-0.01733570891891992
0.038045326144742944
0.04218633718558994
0.02830806163757496
0.0037868606499702083
0.04003015660403485
0.027258759589862597
-0.009502671443965018
-0.006754993742529424
0.01000867572796332
0.007120305932633032
-0.024230525496090994
0.006947191886282185
0.008166261848883105
0.0062486410415578345
0.03805588677984574
0.008957884283031112
0.02293175903970585
0.016335127698107445
0.025402239477569373
0.00792321779723579
-0.022898455641353507
-0.01891033256137529
0.03476562020343856
-0.023524968988228628
0.011507937088798235
0.021871971039560754
-0.0031992495314942734
-0.014505770781910395
-0.026378547826808735
-0.025248796081832392
-0.050163745710492286
-0.06367662546792814
-0.07940763755398929
-0.065455183424497
0.04202713394636443
-0.024388663315175058
-0.03251779652051637
0.01175694584785554
-0.07015153656461316
0.00294273256267469
0.025359720706974585
0.028260902271412754
-0.005637127664851775
-0.051841970853994016
0.016149356575499128
0.0004863813867472394
-0.009942362360357171
-0.0019418647816350759
0.006132247782827045
-0.013268511404345347
0.021431287882261917
-0.029768957998634042
-0.017672893411300017
-0.0009222904068108264
0.01911451615901385
0.0011966143819482104
-0.008018294712902187
-0.058872738207943656
-0.018403052130121153
-0.011288108399326601
