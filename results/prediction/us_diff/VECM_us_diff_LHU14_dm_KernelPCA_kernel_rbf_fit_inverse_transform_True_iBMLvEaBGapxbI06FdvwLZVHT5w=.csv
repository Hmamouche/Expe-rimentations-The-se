# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; LHU14
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=15, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.11392348499548446
-0.14334902799482704
-0.011220443695171497
0.16929286799168722
0.05364953953887422
0.004214257199656873
-0.11261214000305975
0.03029538247511439
-0.08161297028887582
-0.027731799598340323
-0.043877578822684324
0.09766458846796695
0.08031479935251148
-0.10495808870393984
0.0024900303099903327
-0.04814517408824522
-0.08256694081181544
0.1437046459415445
-0.05451718338288128
-0.042918899207490493
-0.015865707432744715
-0.11305506961966338
0.0008803980701405471
0.03895377399234044
-0.042387461422519784
0.007468134455141881
0.052407299817200936
0.0025085923662169184
0.05944906443831222
0.05154460289347468
0.0003665044746119575
0.037741696714319206
0.008036339804755743
0.010499069877915448
0.0002200111982545959
0.025245243599310702
0.0944944901245102
-0.020777441861516012
0.055838894558763015
0.012592980741256754
-0.08107888225054122
0.011164140747540824
-0.06147565826075679
0.02262758026609722
-0.004986472757993662
-0.03361642331297843
-0.006879260473277398
0.019446820923850625
-0.02345868594913522
0.041887958727352174
-0.003271749437537312
-0.009467165526796259
-0.02231896873341036
-0.04139637078239819
-0.019518260002833035
0.020890816383651804
-0.06184132467797615
0.009720122968684259
-0.034448096799524354
0.02308510900214114
0.03154281509119856
0.02380946769409834
-0.05954783186671153
0.03288729783605276
-0.031989389412608704
-0.012668488297913593
0.013432287264762439
-0.0014542531665491312
0.010435273644631936
-0.0013195876632896147
0.06852300260754883
-0.01894313867626743
0.05498945745532166
0.0885403187183264
-0.049823210512205944
-0.03976252316679297
0.05830332882300814
0.07414025595979488
0.04839942762217703
-0.015740132775378314
-0.05238490851319706
0.008869180522970704
-0.04961381388314962
0.05228700715677445
-0.02395408713045339
-0.001876781406159364
0.012029588929189622
-0.014831125966399808
-0.004273267157998426
-0.01963448350987348
-0.016349978705303414
0.006563256396717052
0.028756020202388335
-0.07403536228015399
0.0012072743236086116
0.009339287791233327
-0.0032659744397216407
0.08301176950316452
0.05503680602152367
0.031234331009815
