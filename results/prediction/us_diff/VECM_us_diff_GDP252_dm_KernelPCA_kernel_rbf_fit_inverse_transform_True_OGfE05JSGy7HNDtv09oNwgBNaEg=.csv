# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP252
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=7, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0011675680215921646
0.006611122716366363
0.01101428735511096
0.006210974654098988
0.002768257474141135
0.005931870636435024
0.009756832508740383
0.0073488282359013
0.004916934146714759
0.008331305188819397
0.007339347232074963
0.00411146623962468
0.001212665619495326
0.004056072238385663
0.003999466889147719
0.003975564756005692
0.008503796674680498
0.00622108396196241
0.0032435970782023933
0.009434869284231668
0.007029691933986907
0.008629172548260065
0.002368568843445718
0.0007374362128441334
0.00343194908515081
0.005988797188605476
0.0032373360258120083
0.002854817279082489
-0.00023843936465326945
-0.0009684614256790175
0.007445843141817242
0.0021691445949886673
0.004785860592138171
0.0030042047950303886
0.0003876076759831062
0.004884131748351599
0.004289491370368684
0.007828015997526494
0.0066812827708049366
0.0015708847861526994
0.006899641069828094
0.009622338110521636
0.009804719539106665
0.004035243005013624
0.006372933109313507
0.006558096609509682
0.006274220212790644
0.005462221217639166
0.005620688490132527
0.007216190875235986
0.004546866909177175
0.004258212359824001
0.006948194557529108
0.00855047469376044
0.006340403477076611
0.00993043654635209
0.007421525878209914
0.0072158261535698815
0.011807247985903518
0.00884149770376469
0.00985039135296922
0.012319553289080592
0.011809538355192627
0.00903619863373984
0.009914925277505175
0.013908440955722487
0.010286143580647247
0.01277053779492051
0.009920566605275113
0.008333824763522731
0.010400587310109692
0.007574743567957143
0.0030448985903327366
0.005174450006731701
0.011261999956625498
0.010745553041752893
0.002755880066666244
0.0073096254342690705
8.644924604309318e-05
0.007883657685298383
0.010775854101058111
0.010259270877170773
0.012858489433757399
0.0053040344615632
0.00928676289016892
0.008658816246689058
0.008983508491220645
0.009373445177106334
0.006227775481112382
0.008136063918748855
0.011248457935485347
0.004834642467428112
0.006655375417476274
0.012958707606586142
0.007948869571302296
0.00927553571857001
0.012296964284566166
0.00224110654373842
0.002877404435524273
0.0036346528994281955
