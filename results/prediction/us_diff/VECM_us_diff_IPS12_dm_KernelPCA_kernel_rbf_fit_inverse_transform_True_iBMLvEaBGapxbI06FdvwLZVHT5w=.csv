# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; IPS12
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=15, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.0259332732685419
0.032105297222580986
0.05234941346223323
-0.003309379779435365
0.0013853513613978543
0.012890405920903847
-0.002063311324998089
-0.006857047671349452
0.0120000514149503
-0.01180746371999042
0.02452927455807986
0.0005227228442040203
-0.024749252320533332
0.0005405273173768946
0.013233267620256438
0.01655200885128803
0.009305385470749949
0.015678235385982415
0.0024470425127117706
-0.0016825243634104783
0.012780945013850499
0.030231558019284177
-0.0022550838300738995
0.004212200449603656
-0.0029150763029135137
-0.005056188545398791
0.0024933537999448038
0.00914590865344403
-0.02283537956188613
0.0023604180487648216
0.006353075913720211
0.01694163660197972
0.013298574929127414
0.0006053431905443567
-0.0031144693206538662
0.012483657005464374
0.0005035029968168243
0.030026789307992675
0.0010849183037329934
0.0035677668407081723
0.017635070660240264
0.004015372402232196
0.02679485179312267
-0.0037709698454088504
-0.00025407717823821034
0.015804805405566346
0.0014041939956393145
0.0015369431885648988
0.012821039367430556
0.005733406759332551
0.00840541922373346
0.018765545461219862
0.010502023786926131
0.007223297224802002
0.006955920999840099
0.008877555770443543
0.008003367520422052
0.0065122156717387514
0.01564521478254684
0.013108529405240807
0.015157862728588743
0.004528552913258297
0.017307860518399873
0.0011324796375304794
0.01335801113129606
0.0017007739638321764
-0.004755080968428849
0.013749918608223692
-0.00045847964775269385
0.0026330711207155147
-0.0039074965462227
0.009313026956828254
-0.002004424798762468
-0.002538787588204768
0.0010099961558763092
0.018397826000869207
0.0084042809921583
-0.011423563602268105
-0.0039894452509436325
0.03228298882578542
0.0093401734274634
0.009318040505000302
0.01241161243110098
-0.0057712791528991446
0.008794247896504293
-0.005469720367894431
-0.007830118423838964
0.007078844141011993
0.00563393048055866
0.01234208838677519
0.003979018882278039
0.0034959265543185788
-0.006520847754491277
0.00822377952897156
0.00024823813107970223
-0.007079349294587924
0.008956585383655858
-0.014117724158812428
-0.009493380244217173
0.002376598203340493
