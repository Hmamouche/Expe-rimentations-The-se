# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; PMNO
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=7, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.10459235317733595
-0.17391762805088284
0.0535826782962098
-0.20636362237238987
-0.036018090103955
0.09016430530796585
0.20867390620604018
0.040739703185135534
-0.041835333421819526
0.08182573013576022
0.10707511907339338
0.0500637930421249
-0.06894284351178216
-0.056167277126415505
0.07468324646085123
0.024750400634066014
-0.02880624835552211
-0.11832856791792724
0.026533310872937532
-0.025292409620926118
0.02788491895101307
0.1446129288257743
-0.16272627239566573
-0.006457086320656868
-0.01346637998064304
0.0190115554307089
-0.005099356780757
-0.0019563856094697712
-0.04392562018193144
-0.006631090613281654
0.24091363703830124
0.06222043988909545
0.05826257584968765
-0.006808506503431063
-0.012073611610864447
0.02167007224515803
0.004075662940072611
0.04884953924363833
-0.041910881641528716
-0.08148147501691236
-0.0019184295271420584
0.013400163971810299
0.08930927551634754
-0.15483725132230275
-0.023927628629912788
0.06458166935020723
-0.07872751029743398
0.015345370489466631
-4.731382582336997e-05
-0.025475387206117306
-0.020402190550739954
-0.06567847851545996
0.035718415676660675
0.006237775711418002
-0.013269535841047016
0.08152236517153288
0.06778523625603317
-0.047006450973353216
0.022699831556139118
-0.03974474197695411
-0.074510403685707
0.014837634704144682
0.02844460661062912
-0.06330792799138396
0.033225429521162336
0.02952539058092387
0.03410645041792862
-0.041505405416419616
-0.05285497592913829
-0.003724086139598057
-0.004606750480441749
0.06820350308164724
0.024761042312155146
0.05887331981412508
0.16258841782061936
0.05137214988794068
-0.01661986590324464
-0.1195115448765835
-0.10361493282974994
0.12949323209912747
-0.07202847640809233
0.01164080780939741
0.057941263262616755
-0.042260095594961966
-0.05021819174741484
-0.005559457106055675
-0.0005640701451519528
-0.023527600234907055
-0.05295617059211032
-0.05782856847381695
0.10604991435588584
-0.14441437283288514
-0.03480120406859037
0.10797015719715115
-0.02916710660275982
-0.0018526278652531147
0.08269747070495292
-0.09154796465936255
-0.036505901119945325
0.10801553129637942
