# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP259
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=7, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.020120913154988727
0.03671343976822719
0.015987228234434357
0.02626087630463281
0.02900284662723549
-0.01559211498960452
0.05087716671204537
0.016655178235303186
0.004606402221136483
0.0013705992876297743
0.01763553808794681
-0.05867663373524129
-0.06972289355313607
-0.03650627045065732
-0.04984401869927933
0.029093500548305375
0.0008660904634028941
0.04694398954325424
-0.016539444060271115
-0.006798636548530952
0.015984899262753056
0.01598612909272915
0.006978126885075852
-0.01387164888274843
-0.010546260637875091
0.0034621908005075426
0.017534638135351492
0.005663499697658892
-0.028939011309139097
-0.05193675187931276
-0.011382997317704067
-0.04723756006581591
0.005713489489457022
-0.011291294809078305
-0.05974127381570915
-0.026182943966487307
-0.01086396599646049
0.030689099829046926
0.023699708796459964
0.0038956941359651566
0.0233718177395731
0.009513119415184368
-0.018864517147182115
0.019033977835838524
0.01389104912546837
1.3766084664986085e-05
0.027027965472956335
-0.003971781829450526
0.026148394805969463
0.017765345686622594
-0.010110793955130983
0.0009047456683340706
0.01228722742890225
0.012690438232091265
0.033335762310204665
0.037779136861447925
0.02115544879393396
-7.5503342013848e-05
0.01653083591805921
0.022729091414346883
-0.002343642201482562
0.007349458265290223
0.002420992299690614
-0.024349864341359793
0.011980063699286
0.015240020711033413
0.008082612896974784
0.010112112427916025
0.01524006658422598
0.01813688690101065
0.004317436899582499
-0.004241415070054991
-0.029792445313102683
-0.06741311157069282
-0.024459243638182866
-0.05065918803160328
-0.06778070883375534
-0.03244815373512412
-0.030363870369462503
0.01696039572163299
-4.599830172613301e-05
0.023347390507214634
0.010742888426362177
0.0041249270472544855
0.007364889526756396
0.004467985546982259
0.011738987676165002
0.013490815828648355
0.004422426370004897
0.007963760167242488
0.023580638651302863
0.010488507069801846
0.041538398376692494
0.016303601402338466
0.012446198651597757
0.031048339901669084
0.04173980629229912
0.0011603329447277726
0.0031958229485360163
0.03245065931522677
