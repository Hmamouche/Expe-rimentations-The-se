# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CES002
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=12, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.006917666201680594
0.02098629155434071
0.005945075762426054
0.00012033646988156808
0.004402549389025907
0.005894558774173426
0.013995822468017073
0.007197741783455636
0.012309298321347802
0.008911721460349752
0.008242513478159592
0.0006851775778352259
0.004855576229494833
0.0033548679808810566
0.007807558608914293
0.01539850161104622
0.010321515141868447
0.006193188927906066
0.010860357898774837
0.013868330570573462
0.013095440798529345
0.014754368002676108
0.005160219686052913
0.004834116441693528
-0.0005469240454089338
0.00713597573694906
0.008151792174259466
0.0011397332339116307
-0.0034543558534881353
-0.007595297534918205
-0.007429513806636174
0.0012953218023398316
0.00471826150081601
-0.0013083457097396757
-0.0021395824241201766
0.0030608214174542864
-0.0003149180461084726
0.009072787940972946
0.008396700630734099
0.005131073538623283
0.014243622147612465
0.01031462940536372
0.013807623118269646
0.009996818626208288
0.014750409629416778
0.01276195658197922
0.009127858717805998
0.008876161505883943
0.007125309916784225
0.0036042275407579556
0.005072824379280645
0.010720019202055755
0.009738493330216758
0.011921677491198672
0.01129083831485699
0.008982490079166192
0.013420591265443971
0.009163282160156062
0.009677438713666685
0.009608906422751275
0.008730243325490007
0.009690969324964788
0.011478977303515742
0.007784472190381114
0.01219905406822913
0.01090013993492464
0.006689265521048686
0.003931080103487873
0.0046945447447064165
0.007364537988226956
-0.001490065916941525
-0.004299144923380187
-0.014425972284420835
-0.01176723400346425
0.001008646947014307
-0.003165136179399607
-0.001132561007318509
-0.0033254067783026245
-0.004414568476748861
-0.0010868296533789814
0.004321773590574887
0.003634797387418035
0.0041607132166917886
0.004992487647834629
0.003840702991210248
0.005389971129453804
0.00571906904554541
0.005492302684350622
0.013830536035484068
0.006353450234114683
0.010608346691581387
0.0070618562444506984
4.898375568554046e-05
0.0080223162318511
0.008041027584779002
0.0030954120787977015
-0.001442333131216745
-0.003992764292610857
-0.0019945683916141907
-0.00924587985691608
