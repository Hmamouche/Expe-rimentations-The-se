# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP266
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=12, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.024853041322469214
-0.0272725578442277
0.026833312651836333
-0.027399242541272892
-0.0028901517679580085
0.01593659843078865
0.06708664406191184
0.008359289506857739
0.014221709772214809
0.0029859396028378265
0.022815720304933233
0.014016958415736008
0.045355775579273006
0.026577966868757047
0.012018484394084681
0.002026473683079323
0.011559017051808267
0.019220352706492656
0.034430542010002216
-0.02566233503636879
0.001431283377038523
-0.020092260536463038
-0.012783998267947239
0.003764927634083954
0.02537868243169285
-0.010057062120543542
0.02682340911496346
0.015690661416985788
-0.01746720776035797
-0.0019856633901268288
0.03133338621710737
-0.007290746569999388
0.028235316424268207
0.005754329476723384
-0.0129989977384239
-0.009247795043849809
-0.0006454941082338446
-0.007492648708922664
0.014973269379588207
-0.015395493967420355
-0.02800180620743864
-0.015766291634025997
-0.03480980962498242
-0.014149126410723209
-0.007355053877168747
-0.01330222393391974
0.010267330046603879
-0.028514023015459574
-0.015352228994625697
-0.023538490641802082
0.0009555095352198686
-0.0027742058829776095
0.0018543059203808832
-0.011672726487835067
0.012296063051643113
-0.019998967203044365
-0.010423259149320433
0.004121006971942988
0.016124020421568314
-0.01142307997804098
-0.0031740656089665606
-0.014172398827128745
0.006477208752401497
0.01491872456137084
0.005869643123107551
-0.018817726690229842
0.025119182317749386
0.015419653234805843
0.01249901268698523
-0.01680733801580305
0.023558618099090496
-0.01530550931345465
0.011478960939068712
0.03543863333711755
0.028822787440403813
0.030977936092935587
0.034240140251434875
-0.016753965568133328
0.04779395268905118
0.0033672531466159474
-0.0009794384831280844
0.015744101902661685
0.037925001465369715
0.014490984608950751
0.008322046196939785
0.0017412728960802867
0.020605534439189995
-0.0007784416325250293
0.0037862408471147843
-0.0044942448676903255
0.021466393433654737
0.004341388832026536
0.01539933704659081
-0.0077213716163491534
0.015000986835375547
0.006662284114025055
0.0014430147094829618
0.028514543766312392
0.0444575627496658
0.031608947345137965
