# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; MOCMQ
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=4, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.008649487879478345
-0.01999771194284754
0.026364261217429436
0.0057082574259347315
-0.006263467926533499
0.01091290219851744
0.024755867481928713
0.004505393004630978
-0.003762211730387197
0.006097045341910536
0.028539591021405457
0.015729303130975213
-0.01801111912975941
-0.022091120026843915
0.014446021576657106
0.006037512119259566
0.02047826707620181
0.007061434907771426
0.014834706691910312
0.008134820160890024
0.010075602311400813
0.02405512897671066
-0.005360631611087617
0.00031041083007718375
-0.007339927715335758
0.008301959239376332
-0.0024459407277922724
-0.006723914297126609
-0.026464395483443127
-0.018630117473392292
0.004848179173518948
0.01923986083061647
0.02523363556910868
0.0027606204046760896
0.011516645152040416
0.008915264445408393
-0.004517615687891887
0.018149064350475745
0.013982897039683638
0.004304139232415571
0.00605436106569188
0.02956349367620755
0.021414421797102474
0.0010768241226170932
0.019629965610382938
0.022980064883152598
0.0016538003079996106
0.010421346980943762
0.012525924621536552
0.004402839298639348
0.005827285150229879
0.0032624842637038872
0.000918589565091996
0.0339379510326205
0.011162296683436008
0.022318303853146634
0.033195818306099856
0.01123361310215582
0.02193767675309114
0.0018762620697695717
0.00032690024714869623
-0.003366376640576858
0.007778786339165291
0.013240450098158798
0.024211341641433286
0.022557256310041872
0.004124418221425908
-0.008665849529947155
-0.009079301104484227
-0.010440124444684461
-0.014349043447924047
-0.0040496812722779045
-0.012885061953087683
-0.025710764609163807
-0.0039189572351545285
0.002571748988305292
-0.014719602466140826
-0.010127916468785856
-0.016341944633991634
0.011185889310246618
0.028109146950489806
0.024454295177391318
0.01714790645372135
-0.014649288962264626
-0.02036503123864925
-0.009791875228224731
-0.015579902319787073
0.0010075445208271405
0.01734134927420338
0.01471957456284461
0.027145374361997918
-0.006997863099022528
-0.01162135023244009
-0.002702591326531608
-0.010813360647427198
0.0002480885027245413
-0.009478276918289716
-0.025567156097167594
-0.014883656224599837
-0.01108553272336173
