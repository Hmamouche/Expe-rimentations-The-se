# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; IPS34
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=10, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0021817597932725632
0.014537355277980373
0.006348824477656959
-0.005333067179338418
-0.013190841825841293
-0.003636908203334791
0.007863010106205395
0.0071023565066503395
0.008511326360535589
-0.0004294098340383531
0.006529870570994526
-0.004553113475305887
-0.003667899635288347
-0.005054814735980401
-0.0013695701647168912
0.010008513398720983
0.012333125263286894
0.0024860654610761555
0.010984025032870324
0.009822391433486875
0.006045720068431572
0.01752959686597455
-0.0059397728732250585
-0.004919119322606734
-0.009443787981393255
-0.0004097929142677179
0.00038742311640552543
-0.0016197759286407684
0.004467864386038858
-0.010791776765047438
-0.009941579653248479
0.007113499586169082
0.0023279186075552023
0.0018680346119040758
0.008657791743222319
0.009769668015100253
-0.00027737516162279865
0.012525126675999615
0.004069179594995068
-0.00010298048117080168
0.012426944671134053
0.016231514542756124
0.015217722797791282
0.012150309623796462
0.01552104133901034
0.008686893052314652
0.010253612920622294
0.008469222210606125
0.00229788049194244
0.010061976187357324
0.009232348705426404
0.02245605640844841
0.01536529123794556
0.02802202391030137
0.021696320449666115
0.018171008606847533
0.027699119542962898
0.022250116043070645
0.021530619687299912
0.01997308218454403
0.01257804683676729
0.013836150378253993
0.021694781866216317
0.01957858559254495
0.027806388807080022
0.03316073569975146
0.026840105711794748
0.01574528687855309
0.017641972272016127
0.004498821933682498
-0.007242226592973503
-0.004987680827766849
-0.020327100611049986
-0.024795439145789886
0.02059380432860658
0.018544948287760443
-0.0023954603022669062
0.008637805930189845
-0.00732557508881319
0.011816248654887363
0.016064986058282278
0.021701971471559695
0.007582187313299007
0.013904051654386577
0.004959152167988329
0.009998243666046036
0.005182081568728518
0.008863787862650716
0.02128955137471883
0.017800996931395873
0.01745020958117447
0.01046607271556186
-0.005265823053432895
-0.005798470130026153
0.024021316352221368
-0.0044506261894401745
0.011849558192932281
-4.753617847937184e-05
-0.006572870650828478
0.0008471891123010985
