# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; LHNAG
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=8, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.005299936889438051
0.00961637576206853
0.013378276975597994
0.00895931023235203
0.004274926497224387
-0.0007233073195577699
0.014969605821274929
0.0041544537647199495
0.006361889980424228
0.007188330034209807
0.010639714377341897
0.004165191848205176
0.0012386070352069893
0.007744246732320589
0.013230919853230591
0.011733970723584184
0.00972666837702593
0.0054275993153871105
0.008966071226157467
0.01097810924397824
0.00938670796474271
0.009782747770776022
0.0017927780001892194
0.002631370416397625
0.00230982068840317
0.005724050396972612
0.008986675036182144
0.0029811011164797506
0.003280182726802012
-0.003123042399347734
-0.00110321125977226
-0.0001835817364681312
0.004834168667100057
0.0012189963962601106
-0.0031786179952781207
0.0008297984804775844
0.000880828525227687
0.006293443271650616
0.009186227918188206
0.005042175452384914
0.010613276978635313
0.007996840226785195
0.008224014568945455
0.005112805647125435
0.0068452311691639305
0.010473989987990097
0.005753393036062225
0.00369997022619788
0.004937003865916939
0.000252051796183074
-0.00046758099097896967
0.006836366954911814
0.010120583519284592
0.008278216367696557
0.012333512822175673
0.008405578031878618
0.008646771071248895
0.007890291094716433
0.005710049722886631
0.005758161676662625
0.00048327830160121055
0.003835689453496662
0.009120313490462072
0.00374277968616013
0.010798927905976164
0.009023392527105437
0.013393552908266881
0.003493074135365007
0.005503066349188037
0.014869368024540924
0.007706859290890377
-0.004474888870572621
-0.004657643363811757
-0.0051492137120503125
0.009814029934317747
0.0035707020220370035
0.0007349501419848196
0.0018741914696158496
-0.0006882507753475143
0.002943443263529697
0.006785381626036641
0.008694633999153616
0.0050773761345315515
0.0020379903298627213
0.006300171524788871
0.0030207714834083986
0.0007223478219604146
0.00597111741672025
0.008502849528738303
0.006739122696435819
0.010324915489543448
0.0032487861026986938
0.003100083080468575
0.009226326824109557
0.01015199240667613
0.006661001755156883
0.004268937244807268
-0.0058648805463886195
-0.0035893706075499784
0.001513470584884353
