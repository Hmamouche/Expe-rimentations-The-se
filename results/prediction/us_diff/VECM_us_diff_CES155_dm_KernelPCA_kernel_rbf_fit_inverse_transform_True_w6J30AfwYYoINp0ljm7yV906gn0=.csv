# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CES155
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=14, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.041243609012287165
0.03904044567560221
0.04637157217757401
-0.18488499101873515
-0.18613234520616906
-0.01052208912502249
0.14851561551001613
-0.03250688837984374
0.09096863324072026
0.045618808813908104
0.12811667321214437
0.004467966032395392
-0.006030695646321818
0.00271708096603834
0.04409525912526242
0.07879593622949664
-0.052314070688668037
-0.022787823032125024
-0.10057428463845237
-0.02269372139717464
-0.03153166324414976
0.07631488853337118
-0.005130920455453648
-0.04641775145421328
0.007043070562003349
0.021960445047057735
-0.003310843960994441
0.014446763850235272
-0.004465983993251223
-0.02592270401064347
-0.10722943366518863
0.11175975940716451
0.1380046156597545
0.08819133850572433
-0.03626087066104158
0.019381350112043234
-0.01048880904574094
0.096132597871289
-0.018998884455303473
-0.00917263156360854
0.1101299320852959
0.0077444504639400304
0.07830977469560443
0.021849789896277935
-0.0006336608632844139
-0.019476621320298912
-0.019943976486974976
-0.01444966868144813
0.037080742317023366
-0.009725079324886164
-0.020853522592753616
0.015187862561167954
0.045519863594503586
0.014799541724033222
0.034054332093953484
0.023058376456119335
0.03949129989493009
-0.024359036737445654
0.013411592538564885
0.032088207178239576
-0.04953559538547126
0.006952246259664201
-0.006724875983707579
-0.0026359369530827223
0.03112180445423987
0.0223723045472786
-0.05693105266137903
-0.011389457558664544
-0.05943892775108843
-0.012158913567910556
-0.05329048298243466
0.006862666343843768
-0.012938455742701173
0.034994047203934814
0.02689357549100317
0.016019023209598957
-0.01403580999750987
-0.06445194345582682
-0.0048573269138093705
0.03959768358022012
0.07522963363802565
0.011094145387522672
0.02225938340518975
-0.026487734743918905
-0.04164113713609445
-0.010700680540706442
-0.009387556257996602
-0.019732857289263394
0.026954857331207453
0.016019022081336858
-0.0252818287622482
0.044272071255306314
-0.08739857448659535
-0.021748778223853533
0.017042887890858553
-0.02395289491675607
-0.033377687457961304
-0.09131359455157853
-0.045050826723557875
-0.027051132573285723
