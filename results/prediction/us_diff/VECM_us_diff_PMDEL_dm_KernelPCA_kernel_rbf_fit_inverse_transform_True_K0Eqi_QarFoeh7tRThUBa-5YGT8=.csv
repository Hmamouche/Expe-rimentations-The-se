# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; PMDEL
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=6, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.010496185998544336
-0.015486401918448064
0.08792731590284467
-0.04950592971252556
-0.10466917583336324
-0.01064472985838788
-0.02124631846791733
0.006750206610385404
-0.0666450397165697
0.04537015242407692
0.023716416753629562
0.06474997197438731
-0.1208289603747093
-0.003565325379051569
-0.010604557785253172
0.05968741971042732
0.05266665152496554
-0.013426217086123765
0.010847582774389564
-0.02072333579115699
0.03062053584017563
-0.002689879828752715
-0.0041882029936414645
-0.0761539032269061
-0.037076819532095934
-0.024056355592127612
0.008444925212956561
0.04566687970134364
-0.10487756740940814
-0.04822887000927649
0.08718311545302845
0.11963526538607189
0.012613239488890857
0.05518681169749171
-0.031385440632389114
-0.03298693933048595
-0.011780617166303055
0.01980060827107521
0.005037606825628267
-0.04603289086952332
0.07609114165843228
0.013490896026527227
0.087371344145037
-0.056035310048398485
0.01990846674974272
0.011210163938873518
-0.03326870488037006
-0.06293237354634676
-0.023739537413341137
-0.0070177357362011805
0.03536939737756058
-0.0016121289111237988
0.01785082877484659
0.007250335065629266
-0.04998378219371207
0.039846789597785814
-0.001162260928314219
-0.011766985238095407
0.0013002568490693943
-0.024399377955628476
-0.0075061826820264355
-0.016304107670315555
0.06966886075609918
-0.06027028322133206
0.011747161251664012
0.026297524148768514
-0.016452605112563412
-0.00024243156286913106
-0.044859811030489895
-0.005006618773573346
-0.012264698576245334
0.05102345766348195
0.02630843390886818
0.017847926623350215
0.04282923769724245
-0.005581529682238762
-0.026308278548194848
0.0038247388867888796
-0.05734491413578222
0.03559004002606235
0.06368224332484843
0.03754045704498968
0.04876009550058692
-0.034584722785135996
-0.04768529416513291
-0.03248471178977504
-0.034697667835101254
0.010567660517271345
0.00566855716010603
0.004230344722114868
-0.008094881383912445
-0.031325325877381086
-0.06691613929138879
0.023644062956806017
-0.003404429021537137
-0.025885823542781794
0.0448642778068654
-0.05030528871159926
-0.01476732543562852
0.0028311179226032396
