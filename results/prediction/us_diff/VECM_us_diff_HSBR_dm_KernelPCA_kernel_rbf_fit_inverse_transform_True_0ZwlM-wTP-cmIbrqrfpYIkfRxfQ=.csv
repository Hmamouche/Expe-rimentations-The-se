# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; HSBR
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=13, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.052599904740748965
-0.09078330421080069
-0.15363937703790764
-0.06517637764018916
-3.043926550952078e-05
0.021608773673463547
0.01706630138230575
0.04083406289275206
0.07014680830093278
-0.02010283884510576
0.20104946404801777
0.1315850270154701
-0.018351989401785868
-0.02289609769024785
-0.13923622984913286
-0.06467615491415993
0.003460939119877115
-0.047879526185293786
-0.06557202211697467
-0.14717700973140807
0.07825816579787494
0.011366047163722085
-0.0068622567641982825
-0.004370181816554002
0.042405772597912464
0.04671744453153731
-0.005510533424729465
-0.030384359841263614
-0.13532764199541938
-0.07527469671537218
-0.04266339025847828
0.11499215091424901
-0.008758379302846734
-0.002958634893267172
-0.006711319924856223
0.016731493193706454
0.010851324108757152
0.01624853635622445
-0.04504240634196048
-0.0817483898387449
-0.0006009255885156602
0.05646344224541295
0.08114904613950333
-0.11746989255501533
0.06048753739369262
-0.05922509680543371
0.024120231148518256
0.032974627475530496
0.07793256760810047
0.043399239134452976
0.01923474170617668
-0.05012545463054252
0.03502805344901485
0.011631380201251703
0.026967904208817624
-0.052970983779636674
0.04235418767175136
-0.021541904113993246
0.04883974415105768
-0.018989711074192034
0.0616731930113225
0.028085709526766808
0.03226828844469301
-0.015012752351670454
0.0100095047003537
-0.04447966539257825
-0.035589751625988174
0.03943066141194138
-0.022172560719852
0.03764377565555951
0.016317609314975688
0.02855164810769803
-0.004283206550582484
0.0747204993265619
0.012838934035418713
0.017164045330640875
0.020821042642023654
-0.009049396066655339
-0.08343685548343109
0.03148325389012872
0.07689129256862137
0.032782318030783235
0.046493349067632
-0.03216986912530358
0.01221242532097392
-0.0008381701642180134
-0.006990125777749457
0.047870689080563814
-0.017541867231857616
0.022865094904526796
-0.006216509485300688
-0.02590611691581285
-0.048970458556993376
-0.03104079229368812
-0.0711540334203605
-0.05537206456672466
-0.04125492171988404
-0.16141594976409052
0.04114129294290113
-0.16311050683779643
