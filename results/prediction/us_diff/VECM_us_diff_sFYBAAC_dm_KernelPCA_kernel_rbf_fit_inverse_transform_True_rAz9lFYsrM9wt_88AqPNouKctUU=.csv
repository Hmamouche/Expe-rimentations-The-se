# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; sFYBAAC
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=5, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.06380036539621572
0.007620759347971712
0.016088054791498444
0.01856103315825234
0.002615505146984356
-0.04504092783268608
-0.12788554429423815
0.07076950078714853
0.04635730518162934
-0.02770996753693923
0.004908329124921525
-0.0018285769214456743
0.0798789254603072
0.09167966781321017
0.001076943842658361
-0.02591115909696631
-0.006459151925559679
0.04053775189080124
-0.07377774218674685
-0.01772839892610369
-0.03162094790194454
-0.0519433462265609
-0.052296743040653196
-0.012213303412638932
-0.006781778234106523
0.02744930163177764
0.023405236690559137
0.010510786358343974
0.00672710220101482
0.02382149514757052
-0.0043467555039653615
-0.011386013962127274
-0.02106327255059831
-0.022218200107260628
-0.041821799960112
0.01842547970367422
0.0340842870682743
0.040601114600852535
0.041327908516290805
-0.009913499510368448
-0.019790647977010935
-0.034584386255665
0.020008569693976526
0.02913770559113316
-0.04280027143712064
-0.013999370429490236
-0.03738938386384007
-0.06491055040697807
0.010856794055248342
0.02937755417479504
0.003138716749947198
0.04656395806267638
-0.0035831710703614944
-0.031110829773502744
-0.012660382879721403
-0.0074033483939299006
-0.026011552562536594
-0.011422237519182615
-0.003992510980443608
0.03808067799322174
0.030489816248541877
0.06910792489537168
0.008769115425793981
0.03280628560302558
0.02719920646276816
-0.0069842189944418955
-0.05597465296557489
0.04961492807109441
0.013966496026647696
-0.00567184142277274
0.03920376549688441
-0.005227791178152971
0.060625567859451904
0.039612892811510286
-0.014971133108159526
0.004098667272738131
0.012957012431421989
0.017950048396082746
0.051567526538319156
-0.04442355202766339
-0.01210377851762006
-0.05747996701685493
-0.05650431251026523
-0.015506137024377972
0.013962125463819959
-0.02926090562213578
-0.03581705475578494
0.004101933133236148
-0.011772216081905845
0.006432879556582361
-0.03212649825664803
0.02089205993179148
-0.005327023365717415
-0.0016636873359777535
-0.020151016203626634
-0.014192855658790193
0.010371340295069418
0.059735936366282494
0.07301977255205802
0.062414302861037996
