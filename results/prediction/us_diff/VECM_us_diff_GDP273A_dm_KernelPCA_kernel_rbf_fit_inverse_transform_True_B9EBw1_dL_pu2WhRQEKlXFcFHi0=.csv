# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP273A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=10, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.00435067818015152
0.004693051720713779
0.005382891768750375
0.008846780821226287
0.004970379822817301
0.004726550737639225
0.008461459639453252
0.0042164657429358205
0.004512428105525688
0.00639612472376606
0.005342079314251415
0.00033366643515021126
0.003950640077226323
0.0034484417391259774
0.006321089007702173
0.007419515227914856
0.008971722188212999
0.0064570034504114245
0.005917499722907017
0.007009739496075771
0.00757655095037417
0.007570035467608463
0.008731068291465298
0.010098649185053868
0.006064481479107507
0.00736020351353283
0.008441138061275683
0.007690779961581306
0.011196649029046811
0.010932464364365244
0.0067344628548656315
0.006227131009625347
0.005675521745148078
0.006096834993745566
0.004238739125440477
0.006708038966179044
0.006021996157114551
0.0041409252578137
0.007335751856919617
0.0037790704731179335
0.0043392034529552695
0.003320184544728791
0.003920548565466159
0.00510096560120739
0.00633349783532016
0.004410614638621463
0.0067353575979738215
0.0023167509415864874
0.004671449640469133
0.005026379680313739
0.0034009219309189503
0.0061662374559731045
0.004830359651613757
0.004803630665778488
0.0051603410440918115
0.003851238337753528
0.001939852485729829
0.0024187058307525767
0.0008277992884634023
0.0012022365177621658
0.002277081121587282
0.0028011028214786
0.003722946421022358
0.005732459427026391
0.004296960627103076
0.006739226817825285
0.006114891597214008
0.0062879462785155335
0.005092806640727593
0.004756709069274887
0.00577461437510823
0.005361555566023292
0.005710487344382986
0.0014188657489387104
0.003621617262685303
0.0054314628898525594
0.0027086696161118984
0.005038767298502779
0.005558168723734222
0.003539611212325278
0.0066303304920642524
0.00441320068543688
0.006981354984512254
0.007806773548665822
0.006600514197391906
0.007635233756216037
0.006563361074899384
0.008036568356219685
0.00916953613615214
0.010049169587054294
0.008471892016149663
0.007913857909106658
0.007440465883069538
0.00436237632652642
0.007752467569273268
0.0035450748461146285
0.009090253902634123
0.01091631014131534
0.008750124172602925
0.011998380695539143
