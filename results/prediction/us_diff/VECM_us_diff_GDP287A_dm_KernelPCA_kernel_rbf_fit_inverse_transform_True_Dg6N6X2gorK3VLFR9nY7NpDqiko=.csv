# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP287A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=3, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.00826266038472144
0.0025842130055952167
0.00489564858425947
0.007646912739601434
0.005719700026855198
0.016972377293194087
0.007238912421278842
0.0013236602492845214
0.003064601270888072
0.004906723997255106
-0.0007556634188125001
0.00017771898456966348
0.0036357086574901718
0.00027732255148589947
0.0021194755117102545
0.0035120386527483565
0.0028508765105043233
0.005097379291649666
0.0007865659064402719
8.130574890722816e-05
0.0012030165788884252
0.0035776385625164945
0.0040708242530004685
0.0016910701489371443
0.003772130058380759
0.0073148255287703275
0.0022726396629323725
0.005605640674888905
0.004201756140360903
0.008296364724409836
0.005305430443624223
0.005655469603891563
0.009303428932816014
0.006245541303002008
0.002673628053095914
0.005584388926028942
0.005840911124356969
0.007285140563110574
0.0031832066069385433
0.003442164188459451
0.0027633496461522606
0.005090275609727807
0.0059292533980481385
0.0075279682128110825
0.006156282461627709
0.006172979584129195
0.004717589355395672
0.0013068368468149745
0.0035771163902673093
0.004178009937658812
0.004379370569997586
0.008060411054438029
0.011462466117932243
0.00781875633202567
-0.0016384211541345974
0.0020658754736957194
0.004941631450411379
0.005236246630505055
0.001003610783860421
0.0021726487384212886
0.003048746929302749
0.0029913810119587742
0.0016694936420005245
0.001999392790520631
0.005085405675707656
0.008822454109182167
0.005508793322406367
0.005322066757330775
0.006443350183355033
0.009110551952220517
0.0021006058521237866
0.006842625803479102
0.005116104966167474
0.004633428714408143
0.0034804924681893713
0.005561612778062641
0.009103549324239955
0.01081140633778009
0.003690513243513966
0.003893318723873
0.013112375087965741
0.01579676749166397
0.006254752797279014
0.005059629693812706
0.006488160548061193
0.020047400145306392
0.012974279040325488
0.00741779963007962
0.009425263268525306
0.02205352723832337
0.006194079598281135
0.010601213631911466
0.006020808661364388
0.02057525590176607
0.011981741079115718
0.00306104429241114
0.005541728545874275
0.017889412974736493
0.010500657303221052
0.004517414689554137
