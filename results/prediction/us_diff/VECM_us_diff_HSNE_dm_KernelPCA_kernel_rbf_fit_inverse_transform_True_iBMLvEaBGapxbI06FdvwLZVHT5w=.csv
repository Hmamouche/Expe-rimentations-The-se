# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; HSNE
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=15, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.6401426913538364
-0.5581154985294516
-0.04151512928261446
-0.08744532968865452
-0.030892279017335336
-0.047368270912592075
-0.10399446545521307
0.19719092995804888
-0.004018846784559157
-0.17690491186869772
0.2779168370726953
0.15270217500520927
-0.020540086507563966
-0.10449865642908315
0.052361101006924766
0.04135552566926634
0.1045115636956061
-0.1381038950018694
-0.31181475882762255
-0.07281339424052774
0.32609767580721255
-0.02510539884466919
-0.03275268524352336
-0.08174205410988573
-0.08109932637494971
-0.16202314160679776
0.035238348149317075
-0.07836615392539314
-0.10872880052616296
-0.22898347666412183
0.09770326796754503
-0.009344241702005165
0.14424691677478363
-0.0943163960800921
-0.050241582107489725
0.04198899571746799
0.09102082187243868
-0.06995293409494942
-0.04343370337505517
-0.006328860719456044
-0.08327356891568836
0.10173854659553216
0.02059429486890503
0.009468798988756907
0.0023457458605497666
-0.045534877008992815
0.06157489575365988
0.06211983208369021
-0.07023155669253633
0.03128834493663445
-0.0936890979425855
-0.022665869251892633
0.07049013716348919
-0.0035761090260036273
-0.0185860047801277
0.05179077731625407
0.05230265049953657
0.01771525394752319
-0.07098341137772643
-0.021065486996995928
0.10367655486306399
-0.04665965803042805
-0.015308096831397226
-0.07251208848022207
0.07531729821148359
-0.01618206111856696
0.04855148314634607
0.023954916702137816
-0.06067226407450574
-0.03850373078865675
0.07642724484529094
-0.08578421320824274
0.037758205724611096
-0.018842844962505993
0.05130593998509646
0.14349692006792333
-0.09930752007626645
-0.09231143041818782
-0.16736218309878514
0.14438475599729425
0.0679278605509355
0.032466528225873176
0.03944562265671189
-0.025839069531926207
-0.044720855014864586
-0.011862318029863754
0.07860700499037931
0.046641045411855084
0.007308351499649538
0.019241525854996465
-0.02531094724155913
-0.03293225167111068
0.03382537146726
-0.036390009876096654
-0.03493364031305531
-0.042016778301686764
0.041192229147341684
-0.06788477284296576
-0.023552332165336948
-0.1314275977437795
