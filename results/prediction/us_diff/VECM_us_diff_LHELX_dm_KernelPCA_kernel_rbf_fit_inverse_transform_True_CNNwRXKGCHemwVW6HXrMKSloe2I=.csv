# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; LHELX
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=8, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.07785083217039399
0.0008238469898551488
0.07303271371717776
-0.014906251478963087
-0.012747296206657432
0.06377794661814185
0.0137636588839447
0.015066214621334534
0.0041515471962079754
0.01203379675571855
0.014711689348110365
-0.00021270854802085898
-0.03564020748170183
-0.011606015372870856
0.0032892712120590724
0.03331487844975037
0.05742424438286808
0.005071314757307852
0.014109092859488023
0.02285243039864092
0.024100908131645886
0.05415123262293023
-0.026607629037427905
-0.022366447861378407
-0.02087158436721811
0.005653798128955241
-0.023550706638798994
-0.03566440718378633
-0.0741867294839634
-0.10222099033878138
-0.06631117200867814
0.0011388208589932416
0.021243042022008735
0.03304945784700497
0.003652655215468936
-0.03406220756225957
-0.03729430929529973
0.016997658506061733
0.01961399618327228
-0.01181554226392598
0.040458967497559756
0.035455002895938524
0.030168615819886956
0.001750766459952399
0.02946153197956657
0.027668286034506932
-0.00012313072669645903
-0.01446685347093379
0.023909436385989687
0.005656236607649715
-0.011882500688370275
-0.004461523148619421
0.005655317658319793
0.005452252477122025
0.03867883044754193
0.007924307113985958
0.021008785276952872
0.019774595517483826
0.018864222099509016
0.015267204417176434
-0.025341177170826505
-0.01262671311271894
0.03395147921505902
-0.025324676997045548
0.007679759639587136
0.009517192116921626
0.002989262538953444
-0.008271499586105248
-0.034409864334499
-0.006650470164392248
-0.05955130463634448
-0.05234483895191494
-0.0711369795544236
-0.07468903858447826
0.023478057085091257
-0.04630676081589765
-0.01813669703053499
0.002708151170332136
-0.04493442195364257
-0.008198173782937327
0.02853475835447674
0.023253821614229425
-0.002847143179697558
-0.031294592818836536
0.004645579104121519
-0.009835702274643872
0.0037185898571987525
0.004853392874201486
5.139988040107641e-05
-0.004844796585799528
0.0234585103045632
-0.03862220534881402
-0.0222444017718091
0.008886187032527106
0.013432482093559645
0.0017689314354316192
-0.0062402467436660876
-0.05213529117731935
-0.0071220410156348935
-0.015244480513493237
