# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP276_2
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=9, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.011130608052187442
0.004672225855727863
0.009414011344646728
0.00545423962025423
0.014253797169505169
0.00639902773238445
0.0044538240010231316
0.004384188259441648
0.006855076372927118
0.0024511136948532223
0.005276385995667101
0.003258335586465377
0.00223596995514192
-0.006080426403878446
-0.002767059755204398
0.0023872794667415473
0.00199997083378359
0.0006785321618464671
-0.0038138510363373212
0.0034347228160874106
0.007353213635860822
0.002977317712004191
0.006152076737849487
0.002947450585002906
0.004465577599714811
0.0019167490353592129
0.005096566751528799
0.00306128822332979
0.0008163616042335732
0.005650623457737824
0.008523206849692318
0.0013756719112526187
0.00893510898191886
0.006818720759521776
0.003403441237670419
0.0015986766457132553
0.00473838365604587
0.005073228598532825
0.00550474714356637
0.009659000625772993
0.008182804127222401
0.004085143710475762
0.002076533628468274
0.0035629335117693967
0.005310253401341296
0.0032097904991709204
0.003169801532982069
0.004266196960040584
-0.0007734871187880083
0.001503713123260471
0.0021680852177457595
0.004804917070825853
0.005211581988849469
0.004251200129170885
0.008040065876175248
0.0013731835516216022
0.0016793409689439054
0.0011327172482426518
-0.003585069568337554
-0.0017106497342055916
-0.00038503737643089586
-0.0003546089712960557
-0.0015983946229289284
4.240614016784948e-05
0.0011452203391726392
0.002618063741945071
0.002873303324284968
0.0008560612986384124
0.007092640780891652
0.007715870879212332
0.025486062620827914
0.012117234337062693
0.0014481975689800686
0.0021866910272795134
0.007098903247954157
0.00199883385908737
0.002976171579155715
-0.00047893723011908874
0.012185722874214199
0.008964575788058413
0.006129058746820205
0.004098612534555835
0.004706101555587476
0.004750647086992615
0.008153978002095167
0.009308973706929943
0.006448827808710456
0.011181728003303214
0.017270426624011535
0.0304657222686513
0.020928329808417866
0.0026736720388545075
0.009894587004332166
0.008318843629740596
0.020347801688571313
0.008356100615390275
-0.004560828343457331
0.00944898117258493
0.012075984583000937
0.022542701063638003
