# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; EXRJAN
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=4, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.03504102872753994
-0.02499165199245778
-0.001241974593258829
0.05224024981060016
-0.006154856853181529
0.010997219338764108
0.0247192641258946
-0.022461056661294186
-0.02822586409930876
-0.11057433802117406
-0.061261423741894735
-0.032739432208919374
-0.046675120212722444
-0.0039142036927113716
-0.05124312672429144
-0.030312328247507993
-0.0030943325476058513
0.0036491960690036573
-0.013940299251421151
-0.005356912177840831
0.02101162450534773
-0.03652269639918167
0.01764958229500583
0.013858018758348238
0.004258748180838904
0.0037864536727472125
0.003645247456242385
0.020933218132208962
-0.04762830186189392
-0.03331687557044469
-0.006704469257038279
-5.432517403229729e-05
0.001543168556886217
-0.0044121722958923425
0.009800985928173581
-0.0027401571863713576
-0.012233327786330456
0.009108580966147887
-0.026023119312630877
-0.037664594051211774
-0.01938437622359907
-0.014397186948330918
0.011968587027907741
-0.00982650202719175
-1.8476165263451487e-05
0.0013320538283271162
-0.0008377767223199887
-0.02217065820041626
0.0322907142959497
-0.00426725904236553
0.007062696116920085
-0.014320643102262016
-0.020717778914773045
0.03468503325455073
0.024159957719263672
0.009664070666410271
0.0044473926646086
0.034142630846737194
0.012477409479159879
0.01905498346424196
-0.0004389330914521374
-0.04953723691934454
-9.738718990787111e-05
-0.01275309892239696
-0.03202894433625765
-0.011043370262425946
0.009451594902299434
-0.0015810649081360005
0.009147872044785598
0.004430440658300502
0.008603954289446457
-0.0005242386496346018
-0.024088643528124537
0.017794492352071686
0.017485659595130248
-0.02839646478111802
-0.012955736761607422
0.023662998164726425
-0.03139648310798613
-0.0021923703806563085
-0.0029942638009866677
-0.023940160282004103
0.019185485126456337
0.0077880611274284885
-0.011581723702899381
0.009955884039357495
-0.005794144854611508
-0.006958981851238012
-0.002033108132155741
0.005753055007925776
-0.007439834142696897
0.02292422463671701
-0.00599485664836186
0.009267392553026249
0.015263385874436906
0.001000966376471177
-0.007049950487707922
-0.004481287697998862
-0.02337591258878564
-0.010118854191076634
