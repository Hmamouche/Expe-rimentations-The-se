# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CPIAUCSL
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=12, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0030043379904070426
0.007549974246715324
0.008943664626939993
0.006368426348701852
0.005477489376651191
0.0034780532244438043
0.006184296857941461
0.005815228208337383
0.004216697728682434
0.0069865570835347095
0.005760888998204022
-0.004655471245663923
0.0018385312645692216
-0.0023074567740599804
0.008923807063168478
0.0046560399283260044
0.009110748239192966
0.0058293713094174845
0.005062215322264599
0.007125823618910313
0.0053901991233237575
0.008871185816061413
0.007011314425308782
0.009557449215818326
0.006169594185790125
0.00795341756752634
0.008346942956949585
0.007609433643237311
0.011829242853504209
0.008285594800500264
0.008934682146310388
0.006024298822539474
0.006729150939685737
0.006250446502859721
0.002621536715817571
0.005552426395174653
0.006149581075515912
0.007328365872146985
0.0078268800541695
0.006474491730625628
0.0026281743904012903
0.0051197494502755415
0.004599108244521694
0.008059599009696107
0.004568911461130812
0.005123163497233909
0.007791225677888187
0.0036664630939065575
0.0058150051355341775
0.004068346410282203
0.0048788741351872686
0.007918720881780724
0.0059327089218778745
0.006234207215975405
0.005052579366463055
0.00434963231343085
0.003523383769730286
0.0039915321016295285
0.0025936117909536234
0.003290427653406617
0.00317177070693653
0.003884865548588429
0.005478437512337304
0.004694264056759148
0.0047737386505754065
0.007638945632443245
0.007046491140300365
0.007394304129509393
0.008309854172508659
0.0076674861965542115
0.0074967749109227
0.005873231660190477
0.006736363041554126
-0.0012381889358626366
0.005252283752883901
0.0039602636565836645
0.005065064120343648
0.005675477909069855
0.0077639643169344135
0.0030855956046960467
0.007878344586509772
5.044681299772632e-05
0.009350340923044565
0.006204694738519812
0.0075434188039776185
0.008316393624198393
0.007395971085841808
0.008787792311109778
0.008283111650444132
0.010634061693498974
0.011649054184387556
0.00916583331030481
0.008096522591342954
0.00380204139127868
0.007983975515755668
0.0020352397837042407
0.009780553478513468
0.011636270887815875
0.009633104689861595
0.014081776310716282
