# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; PMNV
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=2, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.24765248629954806
0.14493403894993245
-0.08603757521193733
-0.015190618334918134
-0.20171781390776433
-0.007777550492840924
-0.1098240955500295
0.021080784720399225
0.023158888958778222
0.010616166650224518
0.006936946914336515
-0.006715543260678601
0.018298640179039444
-0.037084856932262364
0.042569408805347236
0.06199199135925561
0.06452932773168402
-0.006333282633422414
-0.09586758366339222
0.06177329067559021
-0.06594802658888346
0.072113468631299
-0.0567330010115301
-0.05913197544088513
-0.04457277034373924
-0.03080824919587308
0.0033328903181293577
0.027217483181625292
-0.011812038916783035
-0.09723671674712188
-0.05713282726726053
0.05598647245708014
0.13560138128717622
0.05485731383392097
0.11798151278837399
-0.09293792654440575
-0.013046444977232223
0.008438799140153646
0.020442694884394912
-0.028935061692176918
0.045949699462064675
0.021279844008600918
-0.011238965481819338
0.11762602150202087
-0.054730478879531926
-0.037694070351344186
-0.12061497024702733
-0.08768353148796668
-0.0330115028383389
-0.04080810002855608
0.07795360324758192
0.08276147195961914
0.010242848517241615
0.024498035670504917
0.0030839097817859235
-0.0481416515684329
0.011855676242801679
-0.009683793433455445
-0.027283681417038207
-0.012209930177504283
-0.03209961197465671
-0.011705141406510678
0.06491876441397817
0.0314757107068776
0.033190673147777495
0.07181180575804288
-0.05357134160180945
-0.05434295749073862
-0.04375901124940644
-0.055533695660272095
-0.05516548775044609
0.006944737126102458
0.011025041558590104
-0.03475436616286471
0.16010177688947294
0.008973727558309691
-0.017958028794130568
0.050719248225672454
-0.1054656150254126
0.060403101803264435
0.07642755273906554
0.10553679758190912
0.023665210589600704
-0.0029652703957266137
-0.05149141186057621
-0.027637798244856425
-0.0045605110174703894
-0.03494746929269556
0.07118723896286046
-0.0046035682127452855
0.029768126280655522
-0.05307823553245414
-0.037640425803515995
-0.04705382801853902
-0.017564024244024874
0.05311172569109475
-0.023266161819795503
0.033740845112340684
-0.07833713255870547
0.017820689701483004
