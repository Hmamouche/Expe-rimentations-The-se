# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CES155
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=9, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.06500909485417655
0.05930764902202293
0.03869140272517042
0.02946802743910107
-0.10612536844458664
-0.0021105948265463742
0.15000376799188925
0.008582508533149728
0.012442717371259855
0.03850823385852043
0.04810507293676829
0.007008461346103972
-0.020637161750657034
-0.0009001571949374615
0.025491825239792695
0.06640210353420331
-0.021417648551056014
0.045731177057275224
-0.017688580482646786
0.041324905533828275
0.020737160262483033
0.03459839973771013
-0.018047726459310753
-0.029292519686943887
-0.0371503611409552
0.015085217122996906
0.012781721254444085
0.015008516801299129
0.01073989809507481
-0.05099802154231917
-0.04759501747856748
0.05045596510711001
0.11315652669761324
0.04114287850670185
0.004426209816209954
0.02219234034784425
-0.009273527819437476
0.036835399182669426
0.022557423310360265
-0.039133467999050896
0.061957624960266765
0.04235983245758704
0.07242859976343581
0.04471075601801239
0.01960147217151253
-0.007413058113185433
-0.032601118299367154
-0.007700438939528431
-0.003825479220379671
-0.03845536953911765
-0.0030202828377072083
0.041105642092812394
0.026906954608826694
0.037816587054914835
0.06179769537641589
0.014307754547093064
0.0419083711533664
0.013955607870932333
-0.0011622981962985772
0.02578737782919005
-0.07113554195703262
-0.006131974064746186
0.008712929120959906
0.006877841046989446
0.029993778141257036
0.009121633372392312
-0.035732110181649256
-0.07407583507738902
-0.04735717312634386
-0.03118363947561191
-0.07947918762970989
-0.008157816108194958
-0.025697274196017604
-0.01179171296297437
0.06571033779455557
0.005090793089132975
-0.01292992114973681
-0.027506537293383537
-0.01607142884623341
-0.008894221245142591
0.07167310811753044
0.02210086576310727
0.0017545483312989725
0.018123057075002807
-0.01703512172338749
-0.041151034421929286
-0.011484893737837683
-0.04105035524842201
0.025274143984483844
-0.009251671318304306
0.009484442678407673
-0.0016570029110648532
-0.04541971524980653
-0.004548262625347183
0.02484306840007532
-0.01130435535840104
-0.05054889746159918
-0.03402464867631182
-0.0654190297162181
-0.0044299027462966715
