# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; IPS299
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=6, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.011353017160586542
0.004599188575292309
0.01955614385808307
0.00653153602306099
0.006852626666292243
0.002326525738941902
0.010186516692203003
0.005419023744379663
0.006996277892291928
-0.0008895030573384373
0.004188616595652511
0.004030333776992322
-0.0032203281108389393
1.2779982500819072e-05
0.0070946555156839765
0.011349953103269528
0.011277225364708992
0.008296701141938105
0.009355867039134198
0.0167588025418812
0.0184570620928611
0.013237879284682806
0.000889876980403788
-0.0014593990911986085
-0.0016866986341226204
-0.0023225333842113657
0.0024586917248140294
0.003207895029561941
-0.0016651959971366336
-0.008422108695522332
0.003855586733143047
-0.0015259953171529801
0.009512485493279153
0.001894917841829984
-0.0017758227017376157
0.004834727771112232
-0.003068983392699063
0.01258736472184382
0.011813549574003233
0.00695913087046972
0.004054194748001742
0.010277788802938061
0.010010875274669692
0.009799613700195739
0.009462365771769364
0.01229121493535753
0.004086156055270055
0.002678450800760387
0.012848830460996436
0.0072058676368847675
0.009448257976106645
0.01349980316082158
0.011727138191658753
0.016285085845199266
0.013529465274188955
0.01633206205195838
0.02008910226487235
0.017320572585221978
0.018405839639863197
0.020927752260921008
0.012296214491823717
0.007814865561372385
0.014296507385862849
0.007438366400687615
0.013245936500935177
0.011923164225398885
0.006340259934087725
0.0060512186991770675
0.004940522746643801
0.0025167855839443643
-0.002151498021781173
0.003910654663486297
-0.007631469564444345
-0.012389271381180596
-0.0013903633460886026
-0.008504724171231064
-0.0018071562311763852
-0.0027847762539913137
-0.0004925467224533642
0.009208861425524023
0.009529025665533843
0.015769149818393165
0.0076858188959528905
0.005257351026657907
0.0050071008268664135
0.004463470331291706
0.003521688687011083
0.006979618089149164
0.01417710462391237
0.011761507853266597
0.015082809831534705
0.0017101301218472884
0.00756556918925702
0.00801648176206061
0.008648228569309297
0.004298593396974825
0.0037844471011212774
-0.00651150634708257
-0.0010702407718995836
-0.007330593032422927
