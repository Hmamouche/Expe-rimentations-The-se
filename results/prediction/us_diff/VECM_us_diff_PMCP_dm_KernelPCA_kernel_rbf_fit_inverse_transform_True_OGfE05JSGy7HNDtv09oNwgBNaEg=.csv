# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; PMCP
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=7, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.10352661921947746
0.09780514868998114
-0.019628220267117226
-0.08136150276360624
-0.07478980731734035
-0.04914665416489136
-0.004531370888556506
-0.031160253504881805
-0.04105593184703056
-0.025924186776453736
0.04886695723771414
0.04153066786044934
-0.01862544402837399
-0.07872192494220351
0.04171527980657596
0.07703459797745546
0.08221375809604826
0.08099881635966386
0.01391642873914863
0.0788446866528922
0.08347190091360601
0.10107342921068806
-0.08193243450772465
-0.10829107916371693
-0.1584550751057095
-0.07943650323919585
-0.04970892831103668
-0.021729426513077906
-0.01444524810157251
0.03080965653819414
0.044541761582517075
0.05125902402832463
0.06738058216120235
0.05134933550780063
-0.023442787272312145
0.04455651071383378
-0.05924023894281016
-0.04654945366552948
0.011239866389865351
-0.13649260185425505
0.056331233119796854
0.09188539934111767
0.08027010383767617
0.09713523057238513
0.060533546863497045
0.06513027023376569
0.023288892875330633
-0.045136904882937104
-0.0335372710706148
-0.1568089453109654
-0.16064283756061043
0.06521712863290019
-0.038338250264180807
0.0028237778220652275
0.08290764479609715
-0.010818567267266772
0.06603515884635006
-0.02777144994823839
-0.04683507870235549
-0.0768398863785614
-0.08839807745005603
-0.04835980002484505
0.026451707816672707
0.05342739155980661
0.15406231772384898
0.14376526797111028
0.06717568261054316
-0.042358911577094954
-0.04057765075312579
-0.07326272095267862
-0.0349546003412707
-0.012028941102383818
-0.0562166177286489
-0.0959053137787954
0.22094527906699535
0.06061151234849384
-0.0383231547236251
0.007271265251477907
-0.03575499626774793
0.04418197000132931
0.06462545261368034
0.13591758406096005
0.097548123214933
-0.02995418634761933
-0.019783319622657967
-0.017516928345007454
-0.07016308107862385
-0.0790845661704026
0.0016552564198519196
0.04092694408668232
-0.01236835387341995
-0.009109102235797951
-0.014090954869068712
-0.08818005913181522
0.013856852193510127
0.015799363140335372
0.025511706398083048
-0.05963727199007538
-0.006275179869132737
0.05418376352810789
