# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CPILFESL
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=8, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.005751720254001914
0.007942083255878578
0.009457498310995849
0.008839066383946433
0.005302302744972368
0.005580635255450641
0.007194965397525895
0.0044264023676417715
0.007033267083788673
0.007417991998796709
0.007680956791460982
0.004828776247403963
0.005352705689961971
0.006576207773743249
0.005364874609641319
0.006477275401272762
0.006786188582957421
0.007646606805807662
0.0068137754320702
0.008934871269904785
0.006667966238724907
0.009325763159783862
0.008153803874067882
0.0069799119331249
0.005502690915151594
0.007524833641385252
0.008287218024739442
0.009477616169527442
0.009776126688489567
0.009189314199537287
0.010603560023938365
0.006226438542817378
0.008650750019005964
0.006835247331700963
0.007939719041310935
0.0056467492592531445
0.005665022375768695
0.009419849852738388
0.007908564031774291
0.006554356518289218
0.007301103959476591
0.004465001109741715
0.005745905260326383
0.0074113858177511545
0.0054758572681902155
0.007440630950429825
0.007126331592862318
0.006293859330336469
0.006769212451406398
0.004354125978682822
0.004735014468306374
0.006562531792976467
0.00496562571704364
0.0056047763753165215
0.006294454090193212
0.005262495115985413
0.004014918596246657
0.005071058383880305
0.005033040207493605
0.004696638471152677
0.005067853422747529
0.005075873449414516
0.005684330568326295
0.004217218727511076
0.004906557512137006
0.006329581601612143
0.006015878149082241
0.00684901746123707
0.006155161700409157
0.006366288786019756
0.005174029965413515
0.005367109828643923
0.006282466558899753
0.004879299419633882
0.008886004732953869
0.005079366223499965
0.006093082073515183
0.005216777821691517
0.004064243755348162
0.001749617257890862
0.002997694508498346
0.0025882861249503725
0.004979416501264869
0.007222552962492708
0.004661976310924811
0.0055616257937655626
0.007339095567191972
0.006136293726966825
0.004301991403922959
0.0057884332875772935
0.006768317245774339
0.0086571971169069
0.008628056774303694
0.006198469584993717
0.005467424393876382
0.005853453353923293
0.005378974349195612
0.006542796984628861
0.006579902683190803
0.006174852668516116
