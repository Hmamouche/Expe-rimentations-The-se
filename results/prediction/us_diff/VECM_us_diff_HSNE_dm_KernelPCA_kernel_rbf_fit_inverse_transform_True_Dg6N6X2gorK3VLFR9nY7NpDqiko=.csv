# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; HSNE
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=3, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.10971155396946146
-0.06269670472678718
-0.14744991996599704
-0.13174843960643945
0.029554628905909822
0.04208832841070626
0.12614440961736728
0.07198962774809957
0.08878374073089687
0.018825780194301013
0.03270548795244769
0.1324828659801997
0.03345948718069999
0.0362322991937036
0.003499986918215299
-0.044308607738147945
0.012981413172204444
-0.07443214145376474
-0.0547875906165408
0.0004941852671856845
0.018150237493751203
-0.01744968375319426
-0.09742501498187062
-0.051136441628069046
-0.0036070169959977155
-0.024889820897062705
-0.06660487747980215
-0.014361842230936103
-0.05090581070501399
-0.10333376632457332
0.03732643231752892
0.015120106562957508
0.029500847438146433
-0.03851399203588703
-0.0076413976103532726
0.041359600928188536
0.006967444655801874
-0.04493070720771014
-0.02144061835505642
-0.0425765760544
-0.028535480803666725
0.06385168752974854
0.03203800475893902
-0.055189313705923504
0.0019136243310685095
-0.04629218238878627
0.02012191843752814
0.017485440848629713
0.006943038012087802
-0.003203171953897902
-0.025768014689063826
-0.008743793427257372
0.04417302158198547
0.019495138490643427
0.009878776856950223
0.024245873200323145
0.003355829863036108
-0.013682683713509477
-0.023592322061446652
0.014934265718404532
0.03888398066999971
0.0008057277639455973
-0.00043505597798156395
0.02532667412194075
0.013604995427201377
0.023257159348061045
-0.036773865189899856
-0.01704032756879533
-0.021467691424776454
-0.036108319187157
0.06551139234252593
0.0536051523310027
0.0491538160493089
0.022853026098089643
-0.012225743440363864
0.039463792451115864
-0.06619814020437455
0.011788995847592415
-0.04757283329322697
0.008195348477990142
-0.0021164463952872067
0.05049561136525215
0.018520090413137836
-0.04907745095683761
-0.030895792823956596
-0.014285180744377617
-0.005442859002172718
0.025680664979298273
0.020084458471148606
0.03842700104277211
0.015507350125512532
-0.04880082164380032
0.008109076841869279
-0.020045226870457802
-0.0325554674046436
-0.02770291941579162
0.03944259476667293
-0.03628598168705832
-0.0206465156517846
-0.06575337709196494
