# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; EXRUS
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=4, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.0059506067566731935
-0.011060568035843401
0.003881592763786975
0.06704503340532952
0.033780540783618855
0.042473307123194685
0.07723402110294454
-0.0015577096497148696
-0.01843081514114882
-0.10355693753674251
-0.087970249293768
-0.05342399269927604
-0.06434182881650898
-0.021715866126832344
-0.08579987185386809
-0.04583406779349543
0.0034485454440501898
-0.03784844176179101
-0.048277139754894866
-0.0037328457235834447
0.0360096450873877
-0.04267225705705879
0.0038691120598605667
0.03932045722857941
-0.004616585032299104
-0.00672553377861804
-0.013685953556535266
0.000419841387166134
-0.08389341950672466
-0.05510527152444089
-0.005291579626718765
0.04532613523513671
-0.0058303928596062015
-0.022491962179580827
0.04852573616145529
-0.006804934530482282
-0.05496349026721056
0.06891832102655858
-0.008792952540773837
-0.018189349597833457
0.03663417670867174
0.0006599652848892864
0.02815001938077939
-0.014453027522762063
-0.010516021838003566
0.0030354562019845772
-0.02380514609237394
-0.02631254355396201
0.02497778920218608
-0.032601923574407526
0.02496576124852375
-0.00013909868185205468
-0.0338529547715742
0.03976428884760672
0.03200629255358396
0.028922344831846615
0.043876213243788056
0.030690063572303465
0.03306558934071867
0.020621811960127717
0.009280531051772869
-0.032120923526638416
0.010826057187843893
-0.008281252781172827
-0.03000494903970268
0.00636696066331377
0.02510397060130944
0.02217704197255763
0.03137458957116376
0.04584499671510677
-0.008314829845241305
0.040142868915484936
-0.02310866474219088
0.010798941488056718
0.03422623446407072
-0.037745873603081743
-0.02938498421679155
0.00028571253724440915
-0.06723656024168258
-0.038687704856136186
-0.01716798799862672
-0.07700772594815632
-0.005548388624663468
-0.008552872396512192
-0.03841074564230387
0.006107912546456377
-0.011023639939727756
-0.02269476968754914
-0.0019408773231191475
0.011921927271307297
-0.003069763562096792
0.007103932043512902
-0.020410308342950767
0.004808288341018738
-0.004953874327370647
-0.018381712603217457
-0.02130112309208311
-0.03977979992540575
-0.0338859528838709
-0.031169018046908605
