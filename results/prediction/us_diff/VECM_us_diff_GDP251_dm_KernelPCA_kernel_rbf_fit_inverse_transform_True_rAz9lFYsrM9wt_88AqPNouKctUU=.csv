# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP251
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=5, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0018876203940920698
0.0033623782846032894
0.013087450780683976
0.006978675829677958
0.005787328303773234
0.007334460684765806
0.013371333512472583
0.0039845358561982095
0.006606202128666054
0.009679944168557289
0.008733180606554935
0.0061248250922123805
0.0021270065224489815
0.0029210622550355538
0.006488813943126267
0.004934647679508339
0.0037992642979970256
0.005946576489547317
0.008632228753654436
0.008270298975106151
0.009433003717968342
0.008926604152936826
0.007660758230031704
0.003568552877160483
0.004834804608514629
0.006590331007602159
0.005631425877324918
0.0038816247434137314
-9.028705922194732e-05
-0.0007121481013272852
-0.001476807789869984
0.0008518296414189447
0.0064643718256000345
0.0029524074527414955
0.0038201904547477917
0.0030558339740179873
0.0027207653684575856
0.011051563684172708
0.008450129438528024
0.004457409812123612
0.006515729211233212
0.006488903043903514
0.007504169421326661
0.006920683051350926
0.008869226713319828
0.009902144067409835
0.005124904567384612
0.003115856009142913
0.006601984895240078
0.005096201959364746
0.00459373177130059
0.008830250170647116
0.009037335477231283
0.009837149465084386
0.011418309822086619
0.009286679020078303
0.013498384160202158
0.011492369602751932
0.010469958633989446
0.008136371513936185
0.005955487706977058
0.01020022526548451
0.014453763209470737
0.008453983843985019
0.010245200340324752
0.013282204831905238
0.012253071189968268
0.00812120926501233
0.012360237543996013
0.004593304330638576
0.004670888831928986
0.0034722778702747353
0.00215081047669426
-0.0032732792755234795
0.007766028106079707
0.003981777704326232
0.004795001740004142
0.003966466665505819
0.0011140835907048113
0.006122897473364328
0.008204954969868512
0.0164816130460556
0.011511568329989712
0.008994867723845303
0.005785587815804896
0.009309584136003482
0.009857016076448597
0.008047333620023356
0.009438978788563571
0.008718513745455469
0.009727483209878604
0.004506964782532668
0.006103446648371669
0.007554320800446506
0.006429192965664705
0.006303257165464107
0.006067520100665701
0.0017620302745115324
0.005411723465258466
0.007550480389424697
