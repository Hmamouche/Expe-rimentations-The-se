# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CES015
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=7, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.04684514353426178
0.02228254728694494
0.029790716671522877
0.012391068115021752
-0.011586410368465448
0.015721101481520772
0.03982714222298523
-0.015508063650486171
-0.011778275556994223
-0.011207428707742632
0.011364076704626249
-0.0037685618174574283
-0.03993545660179013
-0.03173190958890595
0.01828049428461788
0.014469375939038742
0.020079244197000284
0.009119738845462655
-0.001953296106303527
0.02344930701444398
0.01734636556675009
0.04470586713801691
-0.007974499320501663
-0.0195880127049465
-0.028132879144588424
0.0022210214647170566
-0.008590770877685908
-0.008371905674573805
-0.049985609802158826
-0.06306720436319524
-0.03206331481191514
-0.011465445290793269
0.029571015206640298
-0.002565476521698258
-0.012682433822631563
-0.0164814141161016
-0.022033471543742182
-0.000988345720323889
0.0073759470841108996
-0.023695829771260342
0.01911198834010576
0.023219126709294297
0.019054125176348864
0.013509545191504255
0.005826535503844862
0.027134579547818477
0.001547374991474746
-0.01748933247449172
0.007642752054327387
-0.012308857072398436
-0.004789996474084918
0.008983949718865191
0.0037151936520310883
0.02197156795102999
0.008928068736061607
0.011630874099978504
0.0214995644204867
0.010579352122259529
0.010637183118192119
-0.007252070788065806
-0.021633988422724907
-0.006725575665800428
0.006238281942282912
-0.02248860978833776
0.007246458329146492
0.011767787658144176
-0.007816336801578372
-0.01604552288914614
-0.015054586492244013
-0.01872665938658334
-0.02869849420280555
-0.04494774357827809
-0.06112638463667137
-0.07639961069071033
0.00041307334664909823
-0.03832169753819894
-0.02834356066190759
-0.04074159213355556
-0.04657853606342657
-0.021418888484612607
-0.012299630219806418
0.005132752287408066
-0.006803159843383422
-0.014797079250526835
-0.012233841221223021
-0.002645252233188398
-0.007650459854481791
-0.006567120039531877
0.0003558914330818513
-0.006239747888287448
0.01776666901488199
-0.016627536422921144
-0.0245609304675383
-0.007534957354062173
0.0002905381341314125
-0.013931324547246519
-0.015019911602189597
-0.03133026278635077
-0.03179174158009055
-0.016714779223513398
