# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; EXRCAN
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=12, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.04566252901182753
0.028262079830520488
0.007410476446851567
0.03914854671153833
0.023369123923886213
0.021031713814274856
0.00035617192098547773
0.042218090084858204
0.024352419455123335
0.03381856192215334
0.024756548489841858
0.003962020436470204
-0.035476979221342575
-0.013045718161746399
-0.024209711752226738
0.0037601283998307637
-0.03437472309376028
0.0014362774632258153
-0.05471915355140435
-0.04742665345032124
-0.05343482932441934
0.004592722261431601
-0.03312942912381394
-0.01520362413900777
-0.032492079768621306
-0.009038219162677236
-0.010409002428064048
-0.004770179026161479
-0.030534696469724565
-0.034431556233456985
-0.021330434552588144
0.0060460724689468375
-0.001332656476446037
0.007249379490581374
0.0200544687142304
-0.0036275175800282995
0.022104818628841102
0.04600908608034944
0.025873508005613183
0.06975848826609801
0.07762237280106542
0.021704619534138565
0.027962033224469635
0.04452467664317401
0.013630330995089751
0.023021155233857313
0.011372154956658697
-0.023727265274402137
0.04786934006260624
-0.06320636682521226
0.014878940209671898
-0.0012329334755746895
0.02080703334581726
-0.024321754083922002
-0.034891473958941766
0.003788080528235244
0.013711799971094688
0.03808308456193994
0.012901226429467475
0.030984489947217465
0.07224155942337067
0.05950053253387794
0.06044124692609557
-0.035416315218828126
-0.019834052745208566
-0.01736976572769391
-0.02957382312047532
-0.00044377232605411626
-0.023679627425826227
0.05194406242966913
0.012659232032218085
0.028700175347303552
0.018871435776099937
0.04173803818592484
0.02957391845988297
-0.0030625451579902154
-0.0072777379419717535
-0.0345267038279429
-0.01217882542731662
-0.02139134664611194
-0.02198521286114997
-0.13997296895113107
-0.030045512868393458
-0.06584434642454157
-0.02992353810409657
-0.039996305434827996
-0.025782241198018533
-0.03271403846674384
-0.04820399693645156
-0.03939631719537976
-0.049611614247103385
-0.04053074075941507
-0.013710962775418768
-0.014727928183666354
0.03521034089014308
-0.03001509512876088
-0.007224049099017677
-0.12405401856130924
-0.03690807470234824
-0.05607814350218832
