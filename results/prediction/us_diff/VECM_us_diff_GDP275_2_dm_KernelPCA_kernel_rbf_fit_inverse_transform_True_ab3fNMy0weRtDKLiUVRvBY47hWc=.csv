# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP275_2
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=9, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0035734708167077687
0.0026410247235713526
-0.002454949064124934
-0.0036245379710401976
0.01323344490712809
-0.0010434898279048433
0.010471971280962878
0.00593004223761632
0.010335017938684453
0.004488798635382232
0.0023907633344948977
-0.017250500188698222
0.009756112370744547
-0.0031712916307986296
-0.005008816443624263
0.009146116532407877
0.013902120906492104
0.014682883202584327
0.01751430065036845
0.016329929083853254
0.01754659577470374
0.009501043661191304
0.007735408285695663
0.00869222758378716
-0.0014698500046139138
-0.004676991948715044
0.020422199818314946
0.021458838071965365
0.0027820750603174274
0.00035442587314782423
0.02352680131249644
0.010349539373166312
0.009517308800658089
0.010249385288013486
0.004782860183423557
-0.0003890363250828128
0.009836847199452707
0.009641581828255806
-0.005066836293972065
-0.009734586643370974
-0.003848809298571077
0.006695418191378578
-0.01344745054233862
-0.011745112499661897
0.00163013181536291
-0.011994057877649912
-0.010637577794020098
-0.007694747626973496
-0.01065324946145867
-0.011706342289520954
-0.012221465598028102
-0.00577490740187693
-0.016361844032974696
-0.0025316415112844994
0.007073931573036086
0.0041892680555887865
-0.002606716442266304
-0.010401056578155241
-0.0014316925539930912
-0.013198962191959453
-0.0032962402627381066
-0.012253155368147117
-0.015863672665698082
-0.0023880282533470533
0.006141286247472213
-0.014184054785577858
-0.0010667249796427053
-0.009932935408234783
-0.0011753841478839987
-0.0054877704066394715
-0.010840454774246644
-0.012533184408411585
-0.011470048471217336
-0.010097727914614973
-0.002042811385683135
-0.01382819126683332
-0.012972409722268695
-0.00918421782939842
-0.013183434606664855
-0.004583008396055204
-0.01583970063665087
0.0026311982230538557
-0.006943230689102042
-1.8677582139084697e-05
6.245117105310293e-05
-0.007301152221429376
-0.0040386722346536785
-0.0049894292620951105
-0.0066007662803573616
-0.005611414506839953
0.0034005456727751234
0.00040356870395265093
0.00659370415159575
-0.0006607491796026899
0.007381354186625816
-0.011492302572215405
-0.010511247759100022
-0.003107132161286088
0.0009690479072200753
-0.009981699370744859
