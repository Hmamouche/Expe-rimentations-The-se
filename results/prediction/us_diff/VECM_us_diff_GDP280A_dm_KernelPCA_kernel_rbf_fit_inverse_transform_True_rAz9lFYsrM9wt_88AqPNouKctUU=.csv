# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP280A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=5, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.0008958614045275772
0.0023126877994484128
0.0014467574920605313
0.0036948126498193732
0.002298002726586334
0.0016203009766376343
0.003380802299668743
0.0005633660321741693
0.0010421367366291348
0.0016066961528385768
0.002364621498350321
0.0021645841793586176
0.0023358832808677127
0.002573472253004309
0.00035861691751065444
0.0009492959281200464
0.002511542535368051
0.005068805530835818
0.0062793851789490155
0.006190130564731792
0.004472629281072978
0.004698105525020288
0.004475123027025624
0.004447202266054697
0.0038617265908494312
0.0035740034875990905
0.003914563257964191
0.003128144094292219
0.0031942751627360775
0.002166958860606726
0.003075648455396434
0.002471565335076952
0.0012733930933863488
-0.0050766579667737306
-0.0013683257336933449
0.0025766211115523857
0.00254641188177864
0.0037966195634252823
0.0035443553593299927
0.0043575780511741205
0.0036318720750704876
0.004489327356986856
0.004604730408302694
0.0046235877100200135
0.006533029861571287
0.007784541890644187
0.006868426761954946
0.0034233290147016593
0.005384687858308708
0.00475005104267559
0.0005956092906582604
0.001971197524336823
0.006405484895389376
0.00494046925111396
0.0069442980733740705
0.005893696919191935
0.006513907939510173
0.007368331482980912
0.008332399113677719
0.007042991710581564
0.004942202750324601
0.004755239183935981
0.0038402277907123267
0.00433762610588043
0.004828245705385332
0.006146496195261044
0.0071414941126586974
0.005717428117604254
0.006670013473615686
0.00792679827383286
0.008134525987286962
0.009877684566069472
0.01049785864548892
0.005038298115669258
0.006689382377271139
0.008537385186512824
0.007647570658126887
0.010186365502759087
0.007988614211053133
0.0015937797433203547
0.0038488120801717166
0.00708620402816272
0.013118603330443106
0.014747281475145221
0.01789494757289023
0.022182399585665875
0.023523856119177792
0.020662033791105202
0.02912030946947095
0.03553942163529306
0.03335751027259739
0.030388996259004406
0.012446155407111052
0.017653083440724776
0.010532040790783227
0.002952244474934366
0.00019770298137540787
0.009144279973018286
0.007684395307252519
0.007102314428163152
