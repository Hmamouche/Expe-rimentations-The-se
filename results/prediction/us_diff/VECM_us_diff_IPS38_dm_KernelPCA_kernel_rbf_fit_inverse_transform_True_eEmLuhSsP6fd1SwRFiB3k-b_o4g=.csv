# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; IPS38
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=4, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.010582170530833625
0.0068353892558218644
0.010401256959531691
0.008562752195315416
-0.010603257676956173
-0.0010492097446977169
0.012388886099139743
0.0051712477970604406
-0.010035756612724569
0.007376460455719048
0.014453847569234216
0.013048292981873781
-0.0021808862496426897
-0.00604828664679217
0.01193566261357331
0.021603836968771196
0.023287186214015633
0.011362622329832832
0.009609394750535393
0.00845001769714004
0.021186780311621786
0.011952250915960732
0.007555546039967421
-0.008015006680134117
-0.007808988383938181
0.005544172649241918
0.009000319067754987
-0.0026834002259895056
-0.013525820632058304
-0.015300101194870883
-0.0017856084035345653
0.01612176432660958
0.027072169321781123
-0.0033684681276338227
0.0005183406857556232
0.004289904191670489
0.0010505503480405746
0.002343836849078687
0.005710665318625612
-0.006319761604175132
0.005864942104550754
0.0184536716032392
0.014605760259763952
0.007370585873336481
0.0009334370664622043
0.009061627340343359
0.006580033496053709
-0.005975709041314852
0.0027431267987850037
-0.0047986655622259105
-0.006784052376805783
0.01574250365375792
-0.0023503826560561337
0.013597489459189926
0.005759437083807251
0.010846582025104856
0.019372935363934314
0.010777750005506386
0.010579734291110542
-0.007640047910759562
0.0012079608427725168
-0.0021915196855913054
0.01887165301995636
0.001784311587862318
0.0039096120851313055
0.011995969994502772
0.0014009352690938456
0.0008106835155643306
-0.024564854708865387
-0.00907867769851596
-0.029872310685199056
-0.009597809011645857
-0.012534276524365288
-0.016871889284795414
0.014191642025546732
0.002844460974749186
-0.0017685837063779446
-0.008509767524157236
-0.015429161641011395
0.008561225401647212
0.008294324191406195
0.01969886558755563
-0.005055911778541663
-0.0037238836571532453
0.002151591732542666
0.01808462786947464
0.011667375551967002
-0.005425906163610064
-0.014079475734543616
-0.004646151837417522
0.035215108501859146
-0.0008654449290563036
-0.008916719905180958
-0.015230482120930665
0.027052135530524605
0.009733122332075232
0.0017959031038688273
-0.002648340507577528
-0.009404884849670368
-0.011304776098734573
