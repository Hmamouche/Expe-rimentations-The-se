# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; EXRSW
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=7, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.005103251128213707
-0.04590153305850412
-0.009459484618713068
0.03918497768496242
0.03682560802396783
0.014119625194920214
0.05115653748696687
0.01452791271757433
-0.019746632846665967
-0.06307982433802334
-0.010627721443929265
-0.010613115935887303
-0.06961133610484135
-0.03763073928304047
-0.033922791025728524
-0.03384506199997097
-0.014599057254656763
-0.02009879520819629
-0.020767307953020155
0.024203242385778718
0.015310648275290276
-0.010701630441520598
-0.01053789287982856
0.030100855353239087
0.018762705973557482
-0.011562577883261108
-0.029805569880846847
0.00548793156527016
-0.052247996583562974
-0.04726576918546066
0.02153752820685278
0.023132511225074502
-0.0366962360187499
-0.03134126722334331
0.031954615068229546
0.02397410536368836
-0.043564898714304634
0.030386546012985353
0.01046277158920528
-0.019749314561411782
0.003925006029191866
-0.008345781771707573
0.013991025767783575
-0.010946246640181114
-0.011915700585226284
0.011897486474090405
-0.0063792799082131495
-0.014040433939541307
0.0060487236052785154
-0.023743125083417287
0.003128739827017165
-0.00900318106781483
-0.009844413206157204
0.035734273926005644
0.02171078048751749
0.01636547834740614
0.018091360404892936
0.002406426434544507
0.02074956214613086
0.008904992263315703
-0.015843661487823603
-0.021206811941350937
0.01996533022939774
-0.004659333400422217
-0.0019086782311900433
0.012391106781376521
0.015417752771809913
0.017026790421395016
0.016153613573200207
0.00872709001228884
-0.02464124358553481
0.01562977017270894
-0.014596603644887945
-0.003783425956827109
0.018064757550698935
-0.034789651533237126
-0.021801103982634115
0.0001357842427487238
-0.04161758461536564
-0.010067404200361806
-0.00829930882924648
-0.018756585908245197
0.003650754569685272
-0.0029176845444256884
0.003850804068296744
-0.003936591616935062
-0.012689385973522298
-0.002035995497440825
0.0028277713609183887
-0.0034044847533324734
0.014368647517614833
-0.003360182422156616
-0.010457812694889539
0.031086659573424047
-0.016247868066148356
-0.018598411680786762
0.009953149886098786
-0.007869075158228048
-0.029364335919746166
-0.014939863691965812
