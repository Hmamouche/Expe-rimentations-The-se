# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; FSPXE
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=11, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.020565340764303382
-0.1027519663689889
-0.01508637899365295
-0.06304861715725851
0.022428523254939124
0.028000599819888627
0.05549702032965756
-0.005002243417947912
0.04592418737206159
0.037624091510438606
0.06693697610535818
0.03821660661336869
-0.009763570714691161
0.020847582095877466
0.042817595276611796
-0.006878056295018554
0.020343983212723238
-0.08204477137602949
-0.048180801357672796
0.04603154838876829
-0.04149074890200635
-0.03149565274706763
0.015685061194588797
-0.032010716043649134
-0.025519379151466293
0.02934892819236087
-0.010122216090077841
0.02592306122656525
0.01182240805205264
0.002348595328042418
0.06983669093660624
-0.012552670791179488
0.030629781400997414
0.03574531712721327
0.06948710791506049
0.010097490648647161
0.019335232522209648
0.030331205079155668
-0.02838817701930963
-0.031020708645691234
0.0020248893864429603
-0.006687776235569364
-0.059600697560274855
-0.023286795790320756
0.004460332077956323
-0.06263470632519232
-0.048199723114092784
-0.013030453952847035
0.04354507361704882
0.0069743005068832395
0.025365213939781528
-0.008461551451806056
-0.008728797225541124
0.005633622166177698
0.03625860414052405
-0.015034204333179197
0.04131707898336931
0.02503491252384652
0.040264211647766904
0.06561504902706343
0.013027854049708399
0.07349294089601296
0.05734804442111433
0.014409012629481176
0.0034229157906599792
0.02029244998365968
0.008575865132194976
-0.028365315960052692
-0.020320811715945637
-0.035255228023755976
-0.0019389089744489092
0.021347305398743223
0.009698817120104314
0.08642498160989938
-0.08201293421587952
-0.09697261970375175
0.35002925385958455
0.19485877880961297
-0.04486937177792515
-0.0055590439391997315
-0.017700116974206242
-0.030828677368294526
-0.01102497458964265
-0.09867682017165068
-0.1336835116405082
-0.04525763171882262
-0.0051431878814402095
-0.029768523006419304
-0.02536137749114259
-0.020774078339735567
0.007603967088693387
-0.07585625996757303
0.012330493697279517
0.014345292155449002
-0.0326769171709039
0.010607665222000948
0.033976487640284256
-0.030384733299887286
0.01132128723835155
-0.021959319013264693
