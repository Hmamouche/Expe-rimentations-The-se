# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; LHU15
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=7, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.018109446812617433
-0.1363943463951735
-0.10421446543156712
-0.007956210036235648
-0.030177864706528664
-0.014431309660012435
-0.018725264320373147
0.002308431545641282
-0.0009200162593970048
-0.006712179118048838
-0.02433824977177321
-0.0061938529990231694
0.028331609662119207
-0.0016087460341267902
-0.01068854516867804
-0.019463912898073563
-0.07003019170982308
-0.0269704604856712
-0.010897006504066815
-0.03688371977956615
-0.033850983782516934
-0.07124192479192076
-0.008110570509920922
-0.001027953907055098
0.03390648606105991
0.012830841956481126
0.0026210764328120743
0.01748675121465863
0.07472274758788089
0.09592056401653283
0.05358854453642177
0.04313668575747688
-0.04220437750916435
0.05360149569328683
0.06252296193041208
0.0669931173949368
0.030826968807512727
0.020136658609709607
-0.05101878970267325
0.02168824063235125
-0.0066491264592081975
-0.021217674888441698
-0.030437247968351105
-0.07794289720843736
-0.0027577401927275647
-0.04175784655803249
-0.047460174298868306
0.015047053638766749
-0.031545096386441325
0.030426859736863984
-0.01625283287062456
0.027676170276621184
-0.038836800525464926
-0.029232843725138534
-0.028537403948255553
-0.011873691505010407
-0.03840943440084519
-0.04424692786165624
-0.01893936501341658
-0.026952796801217673
0.023469044698017305
-0.003226260658923192
0.005460177454716903
-0.02962321845670022
-0.010944917430810828
-0.03525188269157982
-0.03539171008789061
-0.004480477245352774
0.016742361665964083
0.016220902980463685
0.06152192774487198
0.04421417268473519
0.07117889740234792
0.09945394847846764
0.03895079851491995
0.029496372163563933
0.0018439397750515084
0.06410881883407207
0.02842976694405507
0.04488480863328719
0.00935626925716227
-0.02344237795614562
-0.05075960344015696
-0.014890534044413838
-0.02262884488492488
-0.019221364500947916
-0.012701974191679271
-0.031142171814501633
-0.03264800108354087
-0.0005510894965982446
-0.033083985125889476
-0.01665400158231581
0.0042178339243779915
-0.03732042290963013
0.003370557499912958
-0.004636279165247503
0.04222652599129885
0.03594861778302011
0.046759239501533836
0.07797107352587923
