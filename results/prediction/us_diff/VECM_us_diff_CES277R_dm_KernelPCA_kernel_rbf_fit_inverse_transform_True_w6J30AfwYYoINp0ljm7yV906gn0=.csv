# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CES277R
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=14, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.0006303920110764562
0.0119095422530423
0.033234834738308766
-0.006228886581097659
0.00022979059925325174
-0.03262248721722512
-0.04575141816691959
-0.029750735655735768
-0.0194410654248851
-0.029744174773577606
-0.01976083256308557
0.043994517723721344
0.00674363920013471
0.006292765505580611
-0.03415605983251882
-0.0036393143562898243
-0.015439698477638245
-0.005302015865151284
-0.031527332090775115
0.0253577296931946
-0.009497597682733495
0.01512603325303008
-0.021864370310576114
-0.004742669610245434
-0.0011208176749770253
-0.01868466359854741
-0.01382147790467449
0.007838294977435909
-0.010192412384344448
-0.04446923334629459
-0.004064494139998003
0.014802855511443563
-0.0015813424497355226
-0.014176823622936058
0.008656355103964827
-0.024466776904899283
-0.0217021025189476
-0.0006324431627378049
-0.007436376282212477
-2.1238457095043052e-05
-0.0011040830182286621
-0.01760828819461016
0.003771088711153555
0.012646957359618384
-0.007120170733978937
0.008865285813992412
-0.023181901963563775
0.011714654461784779
0.02121213615971774
-0.009467846142683452
0.007540326035985784
-0.003437872838515054
0.0055263938276906965
-0.004076276350736963
0.0037497652952029905
0.014475813094624854
0.013867757044926115
0.002641040439535422
0.028262057866511415
0.015263361377108531
0.012246650698963983
0.01091112124170645
-0.006361998888257252
0.019543077240445784
0.006024893628388467
0.013237241885362518
-0.0040061614552260524
0.01583757296054511
0.014891099738783815
-0.0010567151969931052
0.008453124104829854
-0.004626270382220758
0.008589323396533252
0.02118301925344867
0.008329777816807025
-0.0003150512978154123
-0.005705470572624551
0.015711600857710888
0.0032721416193520975
0.007735283313024777
0.014703463592009136
-0.0021164592967227473
-0.007620575233421781
-0.016756960990769138
0.009457419505373287
-0.009940407188122521
-0.01423016812321148
-0.016863853899434695
-0.011901171913889548
-0.016101593177440983
-0.012494372234914489
0.005955178457088995
-0.00044492182277865167
0.019759429914607593
0.009301989483423657
0.016076975337991607
0.0070329198094730575
0.008437195084341124
-0.007108999199884713
0.0016795541608725804
