# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CPIAUCSL
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=15, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.00587137437969181
0.005865904213835044
0.011408219642820815
0.007926780561330197
0.005362169017158962
0.0041759516699950506
0.007237404908762329
0.005649487384695314
0.003837827466282329
0.005251767583469567
0.002167033498381327
-0.005378626206674033
0.003963415385096937
0.0013692424393536265
0.008209671758771835
0.0068793725493824925
0.010159930932291937
0.003878185562073418
0.007133613179886368
0.007145489135096154
0.00526811918239058
0.00882305262577148
0.007169495952822146
0.007115956423361703
0.005513778237482184
0.01034078812961136
0.007634829685125911
0.00576684853496128
0.011789285097461388
0.009101249391653023
0.005338219769437522
0.006998162646171328
0.00613962183823464
0.00973312767455477
0.0030861108770708847
0.004962746258680009
0.0031575898118508163
0.007268421253754761
0.006384227224047271
0.006261004115868405
0.003677143346007765
0.004728946626689052
0.004945505284839605
0.009047932666418453
0.005740232268163482
0.003966593425713529
0.007676237371079143
0.002368398023172448
0.004301279934669179
0.0040548499521315265
0.005687223122231532
0.008962292625120076
0.006649830196288396
0.00848040011572827
0.004323910018832766
0.004002191031727565
0.005254630992929568
0.0024721417915817244
0.0027168426357169224
0.0028954467948072065
0.002167071685631756
0.003627793339390166
0.006015174793872196
0.006309238491360139
0.005681192992844492
0.00851564830189123
0.005704529408099315
0.00430556849275981
0.00824840706739328
0.007072676458631767
0.008688463689969955
0.007360818417868388
0.006525651408253751
0.0005680545406119527
0.004028971472238294
0.00206842817709649
0.005431639976268863
0.004259281156511342
0.0065910507564423074
0.0035820279457850898
0.0070661655429982845
0.0008739810930962516
0.008928956747522922
0.007482007337701407
0.00713898643987036
0.0070804271370153715
0.0071448382539620265
0.009123380448435548
0.008021080681318947
0.011262731938223414
0.013004017129331583
0.011326949119114157
0.005823162177386106
0.005030472066060493
0.007240629501887824
0.0017873692943136646
0.012212845472702747
0.009740059115840364
0.012700635094812517
0.011427073807861711
