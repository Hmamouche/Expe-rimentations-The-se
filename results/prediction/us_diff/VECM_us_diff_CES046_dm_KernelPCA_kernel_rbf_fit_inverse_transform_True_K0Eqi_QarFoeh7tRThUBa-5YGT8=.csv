# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CES046
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=6, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.008770638724594075
0.008170710540815302
0.009873437945362946
0.008650102851664686
0.00879165232505139
0.009143442825040994
0.009441142052962077
0.008780245924429681
0.00897950602443169
0.006281462851369209
0.0064093861654769685
0.0059189271437589935
0.0059711387863403366
0.007455433108217836
0.007568892026258444
0.008206331841991822
0.0074241843712498385
0.008872059206618198
0.00901660957700922
0.010400589653295038
0.0080055636949175
0.011288667348568192
0.008346977712751743
0.006584648140928388
0.0039931989907981335
0.005993625319594258
0.007759607396054252
0.005636579499433558
9.538624983524129e-05
-0.0023249762178019755
0.0028025405381116564
-0.0015381253447856948
0.004133404912724168
-4.43448486157626e-05
0.00112980375155732
0.003997408105504682
0.003368680603814389
0.006019726449479263
0.0064317192016641375
0.006051184312823761
0.0069988967183388495
0.008572982801099728
0.008796754478431328
0.010485164061567461
0.009953518667032032
0.010087199753288444
0.008455486254942711
0.006781687126957082
0.0064946123374147405
0.0058263831556507285
0.005179334308156613
0.007476489350131404
0.007103379748067901
0.008629074212784934
0.007852787307969792
0.0089808969501223
0.008421029690172013
0.009165013430335694
0.007285099145031901
0.008104986765879361
0.007634296242536851
0.008140533965587959
0.009491746298148909
0.009286634952057247
0.008896022642136204
0.010532717964272643
0.008785597376622102
0.008587903981277954
0.0047701949194369955
0.002341013187418484
0.0027832813182464052
0.0010330685456055215
-0.00015353861141956585
-0.0038198745764453953
-0.0005376103959314051
0.0005105344219468906
-3.256788523402828e-05
0.002229758795444098
0.0009746637074304291
0.0005284332346931718
0.0018782253040968843
0.005252909586830257
0.0037775565448244014
0.005465917186132222
0.004259113197525837
0.006147161476212575
0.00536153723787448
0.005855719489409386
0.00833414033576856
0.005012930875487871
0.006854393258378831
0.00515347221790421
0.00500260721785772
0.006951003242297374
0.007539315613010081
0.006025840952717661
0.0013958240324165086
0.003416002823175468
0.002094972721597049
-0.0013053915377083409
