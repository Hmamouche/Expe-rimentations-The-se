# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP258
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=12, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.020594911557099152
0.020605088773453028
0.016227073893980398
-0.0008520411789556797
0.010666027860598353
0.0026272278347815705
0.007213963720979523
0.008682368315144646
0.0010803244002742726
0.004259595318913659
0.010629268380870624
-0.011719661428296403
-0.01216591594109342
-0.008052679087892835
-0.010201710820121746
0.013339500566343313
0.0014229893447643277
0.00393481912304654
0.005549547799541138
0.00895964988316868
0.005516294080831641
0.021087807032010956
0.0007950214076692212
-0.004015211967039271
0.001345510343647027
0.01146398136653559
0.005709784198808827
-0.0103410348621894
-0.003951171617263901
-0.011587647023313361
-0.014075919321272716
0.0011133758488743768
0.002733778333156207
-0.001379180456399524
-0.0062617586277848546
0.00567318886205838
0.005429735954634437
0.01860897567018422
0.01618664142366827
0.0021945805925573476
0.014616644105154755
0.01250619626428277
0.01800848235089157
0.006809963794695688
0.012267961042400483
0.013750808370987777
0.017323723756259506
0.01132487149349823
0.01233086510949233
0.000494443295670729
0.006948928903022823
0.014200457388825426
0.019235962665024836
0.01290484804058948
0.020842834303814832
0.014906415000708221
0.02922771901132065
0.020511975658586114
0.013900243400527664
0.028583400257048416
0.013778885197269098
0.02070122047333656
0.016506530301047255
0.020143752271951313
0.024445162535192813
0.023897343445791183
0.013403149843703412
0.020154100839961712
0.012891894038908227
0.023101252307726597
0.0046220438947887936
-0.012811847980359805
-0.03174989566171425
-0.032142586313068267
-0.008534546711699623
-0.01291614898542754
-0.021399171283456194
-0.014097338216814411
-0.009297918977931283
0.004732860174352392
0.017032512037995447
0.01695782338377841
0.013316008201351445
0.0016113936191334594
0.012769596804389723
0.02886439126375227
0.011280711627168337
0.010182408740153543
0.017549652383539328
0.015361231171777642
0.01929489946822238
0.018769499758069116
0.013567684748956473
0.006212898330486404
0.0071383284971467025
0.01364949732300386
0.01710261680412395
0.0009471956792496783
0.0058950306508972795
0.012807230409871615
