# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; IPS10
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=5, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.013204985621719569
0.0034518713846054382
0.017275102602277596
0.011274014175133643
0.00014247295877486163
0.007000259782309617
0.010606898054620848
0.0016448043753320356
0.0011267608959460228
0.0049340860637947645
0.005609272246346105
-0.0001465569208397115
-0.00516977228803231
-0.00537136829211137
0.006794607714818251
0.01158440721723124
0.012633632650395752
0.01028780723913424
0.013142182137610455
0.01486908483755043
0.013971787125707763
0.011357869843311098
0.00018345830728993748
-0.0037495066907426086
-0.005686192587446497
-0.000689066886497519
0.004526545229511606
0.002364459151185777
-0.0012996164181765238
-0.006680207464673151
-0.0059451442706089565
0.0012725496049538231
0.007935977696178412
0.003957721563889882
0.008201144010146124
0.0032937769264260266
-0.001987735687739734
0.009784121829333838
0.010188599454029886
0.004241520383789807
0.007802353004288486
0.010296028814526844
0.013370692891309465
0.011505951901863973
0.012686782046306685
0.01556457901946832
0.0031313329792012875
0.003995792168092255
0.012404308475167634
0.00830833664548361
0.01055918501918973
0.01639645410149554
0.012117828147932979
0.01857117770847613
0.015278877384558956
0.017405070289061332
0.02304653212151388
0.020208321406547033
0.017969949229767586
0.017054885753059763
0.010328473698662388
0.008442056297376998
0.015991200017559683
0.0107574047882911
0.0176335543804485
0.01743811599466141
0.011387748179134195
0.00883987648834612
0.008780076438031293
0.003486771979748642
-0.004624241541998749
-0.005711098126529339
-0.014201831796145889
-0.020431276140442583
0.0030983066186151473
-0.0013046506673140383
0.0023315867444456597
-0.0002654971946176349
0.0018079934756452137
0.0044809464450272125
0.012290489956547012
0.017608127423841328
0.00763383971739752
0.004571605358635799
0.00018871382858399923
0.006595066135486834
0.0076710608193076854
0.0062043610437955725
0.011342254020936672
0.009722062552727617
0.011313556785141381
-0.002144717098371968
0.007030735784201669
0.005218691462673711
0.007852821417581736
0.008988589955571443
0.004266283888240162
-0.0032702437907767244
-0.002450951161345834
-0.00286429417718163
