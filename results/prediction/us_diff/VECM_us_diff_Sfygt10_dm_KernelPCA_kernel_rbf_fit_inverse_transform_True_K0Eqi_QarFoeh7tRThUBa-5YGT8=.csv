# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; Sfygt10
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=6, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.07572465759366825
0.21213235496161048
-0.01392673964051424
0.06671289977621236
0.10682066679191768
0.12478354282610706
-0.1417205075759197
0.04035008470475093
-0.12970548304800222
0.06530475719243509
-0.10694234346116697
-0.022291375436379796
0.02906464257283706
0.020727171688426284
-0.19118549769898535
0.09490050276288198
0.14752484159530968
0.09384061584594022
-0.10347080127421723
0.10122633373276477
0.05142427085419789
-0.029961845068737995
-0.06088425765325728
-0.057527299675014965
-0.11812000933816344
-0.14341614061027233
-0.08019616458337893
0.058505678370069286
0.10969033633360854
-0.07258702386653273
0.1690181198890126
0.13293143973860494
0.049781510479699156
0.0195563601972195
-0.1388058603851034
0.10929609720158966
0.036368953218384466
0.0834350198447407
0.09550149809675407
-0.05838749288359212
-0.07985636390081824
-0.043725831884045045
0.014709362944972201
0.05303330989328142
0.005139397364564452
-0.06603851486342577
0.027584985404231096
-0.0858043701056547
-0.12134663792788326
-0.0914608594480738
-0.06439121301433698
0.03390979070610894
0.08581292227561971
-0.07450673592970478
0.05193886855463503
0.01390686544742371
-0.04274114117080369
-0.06670636025422245
-0.031146868439391844
-0.01886715709121129
-0.007378447872843766
-0.08046205129345303
-0.02751048640643559
0.12772927490063588
-0.010305087797824068
0.027579864436920672
-0.01491300422204403
0.016461222878148322
-0.016244252609406547
-0.040197592027136936
-0.02280507843193058
0.04055212708766785
0.07615703897941808
0.1589592176321911
0.051306750534718074
0.18925571940111255
-0.13566022344794493
0.087831034589943
-0.04013211351521627
0.02290909545409604
0.06872494219930872
-0.06485318736369786
-0.023004772703865247
-0.019080187926197457
-0.00959238249381629
-0.05780841406551644
-0.050986351762018836
0.03770846844728404
-0.1513535332011868
-0.05456259566727095
-0.060068854211935835
-0.038194702645226786
-0.03570872555279189
0.027728823690160394
-0.11946541895547388
-0.008719282739531951
0.03804493237780018
-0.030732076196509132
0.05904257383200783
0.046967309049576564
