# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP275_1
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=10, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.0019479436116213566
0.009813045147774702
0.004198651957248109
0.00598646054967678
0.008035071867949706
0.0033177838189508606
0.0035638702598641513
0.0003338894153120577
0.004215437457101077
0.006590247724270437
0.0031133066458306807
0.003826451188646296
0.01164768473475198
0.00490609338393523
0.004732779075491884
0.005593200549934331
0.007634428429995219
0.003987321835528576
-9.207761925767095e-05
0.007479139976921122
0.007953094666814908
0.006899342188371907
0.009025162443086324
0.01006643914756689
0.006081066276300032
0.009659090326086042
0.01201020925587735
0.0028063521997712107
0.014124528158987935
0.005220877468767298
0.005298399687505501
0.003928266204542362
0.006067431483903334
0.004046872473657606
0.0028888869011812067
0.0044782664885033244
0.00453187754159616
-0.0022167772629817957
0.00379499990604148
0.0010495047588908088
0.0052465053872019565
0.0037780108852072496
-0.00013281008051194102
0.004553111937331321
0.004915902332810059
0.005443568239707314
0.005406582109335232
0.0015896555056565754
0.005818780848547486
0.005078295051408322
0.002822296170303105
0.007131040351226361
0.007452199296697134
0.007524388888369008
0.004824122587500351
0.0038992887950106917
0.0029438447393459674
0.004977359996134696
0.0028925574974689302
0.004838173772930892
0.00495159450192861
0.006433963127029874
0.003890958972517626
0.0034109975196687653
0.0034185318604307447
0.0065484338506570025
0.001335176739168266
0.006486897748589919
0.004238977909209463
0.00735217662611269
0.008594834487213425
0.005352636612964954
0.006761854490762772
0.0045104382924174525
0.00925534544852706
0.002936303417509921
0.0054270707398874915
0.0018738521994931085
0.004029963732485256
0.0015619577404892538
0.00559250334576434
0.008471478175120669
0.00699506921738367
0.00922857893211664
0.005448986878163043
0.00698418723222039
0.005888989601305218
0.008070302946807535
0.0029730525277768343
0.00845319837351271
0.004969994361520263
0.0044089689574709
0.007233351601633317
0.006213598837202105
0.006644809352502817
0.011117563100590287
0.013908235648246527
0.012795832750379396
0.01201965852014882
0.012706012782632885
