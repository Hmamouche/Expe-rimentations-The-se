# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CES017
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=6, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.04824220304885273
0.047679758475118114
0.05203043611581931
0.00940931925589162
-0.03746329221802187
0.0025266958367677027
0.02246952924670165
-0.00975656719659251
-0.010399820519193796
-0.020981512610696796
0.004671164274974544
0.003966927182626489
-0.04343726024673236
-0.04157272682030328
0.002214412005638354
-0.017029194986337794
0.00646172098013786
0.004990581118854875
0.006837754661257508
0.01942117408015937
0.008669947319468423
0.03963640314921595
0.0007958726066128819
-0.02280827016948003
-0.027901702720142342
-0.016929182720384663
-0.014130364497207084
-0.017919495766922318
-0.05982672774361062
-0.07831324504634077
-0.04092344503629167
-0.022811393708363686
0.039009975708476766
-0.011538429277039975
0.013629915519629117
-0.019809746409022073
-0.021044267915105233
-0.0008552489885333718
-0.004330035739211137
-0.020026599604876825
-0.008811081207442194
0.021857236048819166
0.026514087612291435
0.01814226757049848
0.017378195341063055
0.04217695448152951
-0.00851876546642125
-0.010394097572566215
0.005140437083524525
-0.007398285754335209
0.012865023552511252
0.012998936310776213
0.022819347525313987
0.04516254258274099
0.004837990211884018
0.021505831729825925
0.03539513550038082
0.025184346002309666
0.01941370353531486
0.001358159150714275
-0.021209519020894334
-0.006795355875727122
0.024262295440316627
-0.02494739800496373
0.010100523613405594
0.01817394451173944
0.0023742272355796244
-0.017713018121037902
-0.011162346532817452
-0.021143395701254394
-0.03640371625544218
-0.035490252190976006
-0.06831772371786991
-0.08145377473286505
-0.020535016327672267
-0.041827409564410147
-0.023914864844532733
-0.04767021531163888
-0.053336967076969444
-0.02786865934879862
-0.015582954389441158
0.019484122941442937
0.011427703811848149
-0.015259717464716525
-0.008268013475117197
0.0035375894488763396
-0.004217071935720964
-0.017145267107379666
0.006206692941594296
-0.003632669026417966
0.023016204741888237
-0.013089242045260935
-0.022517356761248792
-0.005675429585627494
-0.0025675626564382673
-0.008708935220827793
-0.023264400765115562
-0.025156613227032366
-0.04192632149468053
-0.027533599995539344
