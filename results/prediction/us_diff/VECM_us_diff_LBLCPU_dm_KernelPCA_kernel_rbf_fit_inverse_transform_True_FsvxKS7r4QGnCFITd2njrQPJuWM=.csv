# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; LBLCPU
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=2, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.00044860119338970515
0.002932338952878878
0.009789385683186923
0.005398880054629181
0.006132854262699497
0.007086912044292404
0.0038116440459742126
0.005213842265148924
0.001544422869629271
0.0040227351791541225
0.0050975470635062125
0.003633737295901268
0.003375946262998713
0.007011741395553973
0.00461480305663525
0.006170057462344393
0.009829863386629358
0.008951041065842913
0.008008695602011201
0.0067956409399213165
0.007442043044503281
0.005869998919136261
0.006229881168299907
0.0046287218405366955
0.0010738773800448647
0.002470417278228896
0.004384369955550287
0.007496841938925715
0.009750914594255741
0.010454732311582586
0.008672462286172026
0.005304064719174304
0.005647527326953722
0.008020883634385877
0.0038360591488749594
0.0019034667005832354
0.005480477423490336
-0.00030214019173082794
0.001107738518241895
0.0065272480464719125
0.0030919495546172663
0.002611839319517276
0.004834859851042792
0.002673990260403526
0.004471992016237457
0.0018956036231379944
0.004172233620998122
0.005667667573557323
0.0016472427287390682
0.0023638848098065735
0.0017784543749843453
-0.000791064253430286
0.0021005937506598437
0.0034261473568932307
0.005274509816402968
0.0043391715144378
0.002354997951834624
0.007017579780110934
0.0073184358928885095
0.008753538475138855
0.009240935388664653
0.005715937616087073
0.006101644959719075
0.005361560504852187
0.003966445517865291
0.004815942782780661
0.016677110974729525
0.016127436238757058
0.005955249723443765
0.02287261421558606
-0.0032139726944517165
0.014051079238957452
-0.0027432815399253095
0.004586705854176802
-0.009004087503185808
-0.004475635542496342
0.003143710996818683
-0.00084053337282401
0.0014499572204598275
3.29388835358707e-05
0.0010255610390508111
-0.0028157006265325463
0.006235072229830721
0.0010272173400922278
0.0051817849410877165
0.005320165456099462
0.007863625993037538
0.005629869075553499
0.006307917034226698
0.0022844567267831864
0.008436235919865783
0.010059966655562386
0.007227247554760254
0.00647872767811465
0.007544220724902304
0.01155107551966656
0.012645613463884561
0.009164011317872584
-0.000262626656324295
-0.005651564611310534
