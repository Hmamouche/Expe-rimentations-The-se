# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP278A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=15, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.0018305577323147063
0.0008128961629310424
-0.008811927997877974
0.007134937065843165
0.0050130912817851515
0.0025376330454172855
0.0009323271988512637
0.0035408100606027443
-0.008394276504041611
0.007137425955126165
0.002417902642191748
0.01681893049125446
0.006595203202975956
0.006357380311017857
0.002330320526695506
-0.000541726153802783
0.0025900578492712473
0.01309844616910096
0.014255673351050008
0.011908100532770636
0.003894535001388874
0.009932966656759634
0.005920745096729806
0.004587701056146233
0.00021819409729689852
0.00816113656874579
0.0012066248148859889
0.00698926399206675
0.0044077024914998784
0.00534041634288206
0.0026846621223656974
0.003968801647671745
0.0005185583832067198
0.0007178596916139165
-0.0020390756619816253
-0.0020571756161576237
-0.002522969797947352
0.006221368237292146
0.00539069327895781
0.004126226758659113
0.005643404094195851
0.003024654272895249
0.003278026925981213
0.004367648206339048
0.008050068450197583
0.002003410035501615
0.00503336820300541
0.004253029765633959
-0.0016348050740696124
-0.0018868427117784774
-0.0018822522339789409
-0.004964314254157033
0.0035476470049150373
0.0012649927951166806
-0.003029235188617312
0.0011083054858836137
-0.0011723898112649316
-0.0016899476126594419
-0.005819781899699316
-0.004807574650276271
0.002092707204952295
-0.0017993954002577604
0.0012303472675855142
0.003302703732461789
0.0020056695241104563
-0.0012624740135492181
0.007111104509990218
0.0029176037433198644
0.004490713372250763
0.003087013647128019
0.00047236785529724797
0.004139584304309909
0.0038738673766462147
-0.0038728717561569625
-0.00039176368431508533
-0.0003366151949064128
0.005487406563336954
0.010873424259915181
0.003040342473143188
-0.0009209420189823971
0.004090212528667451
0.007558979135128473
0.01031563851266001
0.015426744538314541
0.013302298739845708
0.012673653010444562
0.009353422297767266
0.016373661994128746
0.013245616361410088
0.018042240654007873
0.01288166848072428
0.01722117449317863
0.003642227340374932
0.0058168942122987476
0.007525953649807629
-0.0006927975381661234
0.008468762535057794
-0.0024445621617800637
0.001608984725868833
-0.0013027119425890361
