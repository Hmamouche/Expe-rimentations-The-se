# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; PMNV
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=8, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.2169868854249557
0.04786294283954373
-0.03986657454661552
-0.23661328972931822
-0.22453776670242392
0.0872756360283316
-0.04548285193880468
0.08203541755208979
0.12165971776018088
-0.026496944796373885
0.03805296540292365
0.037872167743935876
-0.0113975223032033
-0.007632946455634865
0.05566211825176482
0.01366615204279851
0.11412521076593059
-0.03048528092216045
-0.09245222878232658
0.08385555022216944
-0.14138714303614947
0.0475590361334533
-0.10894257978772501
-0.07725360982835315
-0.02031895086872733
-0.061261024716888754
0.02501876925419629
0.1042332077525939
0.07946010772995721
-0.15146971505000725
0.004269075346764711
-0.0943318725945417
0.030228968446376576
0.14153913577479738
0.11632886655993079
-0.025439482819590693
0.012631099444341286
-0.06751428591041447
0.08576690642401683
-0.06545243296757575
0.03469939314062427
0.030874648677686703
0.07473855366882687
0.08422915724984045
0.07574723088925163
0.010019790317283409
-0.059846136071361106
-0.03306828353910813
-0.12153210021881458
-0.09942197275518826
-0.05511762724371746
-0.0010092222909341437
0.01659601894257546
0.05750912491812213
0.067149421579884
-0.00530456393268057
0.04162751440119712
-0.02031701149317701
-0.04093764698609595
-0.07355964422195978
-0.08683658774929968
-0.09903392617465978
0.1134024514641263
0.029993003596921634
0.08808447654424732
0.11389689484562254
-0.025159719450255393
-0.05383102250385205
-0.04875056992153955
-0.06863430747673964
-0.032680357567940965
-0.06797650910288953
-0.005359757968584546
-0.08445967192230536
0.1753889168861032
0.022223656573201363
-0.04212310521202614
0.07828937862198425
-0.0863976471040023
0.06443241656594927
0.023879865501719652
0.10840354735879579
0.16405110828277902
0.0015843020776785885
-0.008455110491592383
-0.07740106749882228
-0.07726644251016093
-0.05353506621546818
0.039087856420632464
0.031739011960004976
0.10931679252478488
-0.021817849777332185
-0.06625377793269874
-0.06396676129243346
-0.02958620668665431
0.03076169220773073
0.02569683574885589
0.01036859830053457
-0.035396204061796346
0.045122432436562304
