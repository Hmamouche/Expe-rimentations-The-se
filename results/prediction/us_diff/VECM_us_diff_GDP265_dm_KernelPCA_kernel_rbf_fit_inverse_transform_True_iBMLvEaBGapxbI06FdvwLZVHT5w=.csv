# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP265
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=15, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.010065931224839779
0.008951162649544313
9.609462368446358e-05
-0.008754583609329375
-0.0007495534775967001
0.0112765872567407
0.02544270143015914
0.00651063841128559
0.014946714858255918
0.004900930518650336
0.030155010853028755
0.013849172095053553
0.004864468846281385
0.00518945841525374
0.005220053374927715
0.006218525619559387
0.008463927792367846
0.02145067914157626
0.019436580086729993
-0.022745854074817492
0.016051683120012684
-3.307288757865303e-05
-0.001970227359885903
0.005429962266960133
0.014256920620627766
-0.0030148996032263323
0.010924592596756126
0.007429302980514155
-0.003897165182407506
-0.0005056821300264682
0.02238153920225894
0.01126318474999151
0.010755278920742937
0.00040922188492786057
-0.0023615128772325675
0.000488999637725245
0.006886447361581254
5.8212990624622023e-05
0.01812677526956425
-0.011043398175239097
-0.0025902012932097393
0.0024647842432706586
-0.012261352834933023
-0.0004122416544906011
0.009270665649646386
-0.0018808814172475952
0.012963682630020987
-0.0041067544834982915
-0.004422237659186319
-0.006776449126185955
0.0023801802823115717
0.006557364968248625
0.0019838097834635506
-0.005438295673980765
0.015104271076136827
0.00249872097234916
0.00499976341581014
0.008934813748603528
0.006620639856863893
-0.0011260599036855279
0.006120275450222638
0.0027577880308284307
0.00846524510360364
0.017288346721893683
0.017324993711671344
0.000620773492202964
0.019037959837633612
0.010491999949338172
0.013304687380281871
0.0009956810257310846
0.008769674529971544
-0.006370884815645232
0.011455626244391226
0.015829170906469445
0.022663036082807852
0.011381963020386784
0.022990263026559012
-0.00574593083821239
0.022089251352277087
0.006641430415816434
0.006162974669812218
-0.0029553187634595085
0.020435442720021325
0.009268402617394662
-0.0001394448417717676
-0.0021961222982632826
0.00818063429748355
0.0035369966436668513
0.0008533185529780741
-0.0009300057206209963
0.004180322394787764
0.005194557371654385
0.0036924348189069514
-0.002709125913588151
0.016460980363387365
-0.0038096707936662306
0.01557901276472119
0.012408541813602132
0.020007787668323663
0.009135334439264993
