# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CES015
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=12, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.02933538699496395
0.09475795818541553
-0.015047961197793294
-0.02222210348151578
-0.04921224636328346
-0.02433084722486929
0.004189921531674929
0.0038827526834650985
0.004988727691617449
0.000767176868435886
0.005852037064421514
-0.03470134862661685
-0.0290669972807821
-0.02011947106516231
0.018993985483135745
0.028215798695771104
0.009032242878301695
-0.0038280251653313915
0.022846621940892237
0.03870829450885891
0.015632897021378066
0.028395364814561702
-0.015078573627967983
-0.01944607330785829
-0.038274091876318764
0.003470622387391856
-0.008474593730125057
-0.009514528599229802
-0.034811492204391045
-0.04938636999878099
-0.07221447643687452
0.0006262119488446537
0.05883370489389713
-0.013831663042763252
-9.085079597845498e-06
-0.017250732259531925
-0.022466985435710466
0.026811401835896455
0.0038328373238958793
-0.021756561334194693
0.041427371540246165
0.002470793284857116
0.028685018275564765
0.0029857363833217755
0.01864449642075391
0.022263467341207443
-0.009566036102333295
-0.003356669146628297
-0.008806737153086747
-0.03604031531026379
-0.005710255676313012
0.022904953061096817
0.00802949269356176
0.03145534562026528
0.007325198079126245
0.0005022531196957423
0.020416520055108307
0.00627629805597084
0.003002015744750377
-0.005219511890944661
-0.02311187079171864
-0.014198157748150433
0.008318655263267638
-0.015165654082958328
0.022256307419069858
0.008025615226095689
-0.017416588082629414
-0.007905246907170602
-0.02080473441793012
-0.004728440991586484
-0.040270781510709716
-0.04803182126452419
-0.0772201508997159
-0.06925873922532619
0.0007823821570369233
-0.022258205555349794
-0.00988697286566076
-0.04759123553199221
-0.05828241161563374
-0.007766886929919281
-0.02611836383583774
-0.005693067426952572
-0.0031219137288916845
-0.008123167842140634
-0.009410496514834749
-0.01448644237437096
-0.023071176766123202
-0.00776262731571506
0.0072848158299850235
0.0006782300007944632
0.005854738564030792
-0.0019534110170675604
-0.03641204899273199
-0.010070357778944682
0.011556866845898323
-0.022064968895652574
-0.01569340810626833
-0.03937973503044856
-0.016117596026264218
-0.022756946164427683
