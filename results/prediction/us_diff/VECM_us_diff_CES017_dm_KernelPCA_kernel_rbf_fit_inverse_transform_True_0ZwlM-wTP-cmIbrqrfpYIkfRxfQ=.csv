# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CES017
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=13, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.016313596626465483
0.032055335927443446
0.009520907370220474
-0.02212527216878827
-0.0712700834217283
-0.015357974256769106
-0.009651803880849888
0.02877817997315769
0.031186099563796876
0.030778148186126578
0.04499717786324392
-0.025562774573292653
-0.044177928414636684
-0.058213672062350966
-0.00599755687957439
0.030833088506835048
-0.0013853270874405622
-0.0047331647894771605
0.028516954184345827
0.03617888916677361
0.02640722766244777
0.0451851784528001
-0.02515920971071736
-0.01199784512765057
-0.052754142742358644
-0.006670801470268901
-0.020187172750772354
-0.015381031606518344
-0.04101983158329085
-0.058017673521609754
-0.08368692953311166
0.005342207153951889
0.054714007543924595
-0.021083621829268283
-0.0022492891030081123
-0.029966360228381776
-0.019570577810399864
0.023130281232651703
-0.00504486039393864
-0.020080981557618734
0.03827291743248252
-5.1296330263117355e-05
0.041759757044027825
0.010845587392680343
0.021292935903394955
0.035216961585869996
-0.011269588424629013
0.003824993343129827
-0.011650044751426072
-0.03220138148714886
-0.0017835247408789622
0.025435444785475984
0.023354026962549956
0.03326019139902534
0.009724307748765532
0.010559890034193312
0.03126286642207399
0.018396808932423972
0.01355441462011706
0.0008141456942636722
-0.022776967880696254
-0.012932848845536643
0.011008782416937693
-0.01789148595359621
0.022310174367172007
0.0066228591021549425
-0.013438825802696293
0.009167555940039564
-0.020688453612744212
0.00199008759242081
-0.04255244152373866
-0.0564947631216437
-0.08210223798096121
-0.08841941368441085
-0.001869456317221005
-0.0071276737448641055
-0.003555488275312796
-0.05646990929629164
-0.061456851113226435
0.0017415636232860354
-0.02341326131598935
-0.004082878372426371
-0.004914965775179352
-0.015611901810621512
0.0005003557410231153
0.00037091386123673173
-0.013242563977189863
-0.001296558571819418
0.007200797799299052
-0.009298185630261305
0.009180001620751181
-0.00033915089631698274
-0.03434298397203585
0.0005224502625160573
0.01364728234909368
-0.016251613642708617
-0.02240000124632021
-0.05172653115685434
-0.030770781982193473
-0.02543712828292328
