# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP276_7
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=4, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0044550321891214
0.00580553003651193
0.00552473055189309
0.00625105274779226
0.006610403302222249
0.006793606493891503
0.0033357247802226486
0.006716706092084499
0.004880198386173265
0.0038222714721270314
0.00662904893507363
0.005229799008168367
0.005545620706981173
0.005067052142554175
0.005799852628061034
0.005630583775894785
0.006046862822482464
0.006523615658882115
0.004037086656029958
0.00683441403802926
0.004973779435584302
0.00706298526304351
0.008146099661107204
0.007138970998695808
0.006089229122937209
0.0069361060865042595
0.008346873160551892
0.008933845428253704
0.010871214054897544
0.007335357892352239
0.00872665691311346
0.00950969876642908
0.009766996093486356
0.005515797945765724
0.003473734430383797
0.007303422637473457
0.007168919281076359
0.005065660823834788
0.005107490064590814
0.006613027743847175
0.005806114579095277
0.005836817845960916
0.004768182756863181
0.0033294473319363024
0.003015862815033167
0.0035734586076943044
0.004584406221510578
0.0044936852355278575
0.004648950571172435
0.005664054454122597
0.006259334736877198
0.007399157142261512
0.00750763748977604
0.0063564764128772105
0.006050520258963245
0.006229877342553529
0.006604765401710684
0.005314505071791774
0.005229011063789795
0.006308598643682795
0.00566749116752011
0.0050618796387511865
0.00681327252292513
0.007264223718270329
0.007022445041889549
0.007192400175131268
0.008179170954514014
0.008310717390880394
0.009207653634270018
0.008624929323327955
0.0076615010409736345
0.008322035075441625
0.008859738263622751
0.005913022870657449
0.006711433835800605
0.008504766463068846
0.007582967887551139
0.008108812967837865
0.007823048585283095
0.008016548760787421
0.005101690956887837
0.005266833401503082
0.005793523492468235
0.006945735177034357
0.0077387739662631
0.007153286614870521
0.0073770227048798424
0.006497798934380066
0.007785270232883014
0.010079035471323078
0.007817602051091579
0.0076175773935723695
0.010748578661219536
0.0055120700864986286
0.001674334536497423
0.004456434860174104
0.003983151017191524
0.00685136404480736
0.007513792334603726
0.010347501869297457
