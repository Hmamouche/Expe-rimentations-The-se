# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; UTL11
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=7, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.09269363216379808
0.07280473601087384
0.11064899509683973
-0.02190928807379882
-0.031672273961813505
0.0024358284019628685
0.03427623045207914
0.0004698684242736024
-0.008501783394294088
-0.020601717139141062
0.04804944575345714
0.014903428802294977
-0.06349553631880865
-0.05394266144243707
0.01342649949510561
0.07283714278094189
0.06471594597675168
0.0294498501515775
0.009170208481300911
0.04571017725767362
0.041887288951991605
0.11662868072714838
-0.03797853658008815
-0.0472360443554445
-0.07193825913401646
-0.006929739480788781
-0.020999238596871667
0.003168231333237615
-0.08856167213954398
-0.15168366589559484
0.0004521561550746827
0.004656132782096506
0.02676945514419676
0.025104812336241338
0.019454426085905578
0.02932253447532337
-0.04190703222076423
0.01410540017162033
0.004687038037701302
-0.0616427435309722
0.04234785662762551
0.07971889853916098
0.06827930648944551
0.04075832596135356
0.023550998596393098
0.036602245374319255
0.006725204625250553
-0.06561803848677822
-0.0026127253230567183
-0.010352126343583075
-0.036019678778721434
0.022331684893682095
0.02423203219329354
0.02358036795383252
0.022758601707791867
0.029226859372374035
0.05614354831371186
0.0015049991263838625
0.008590577067395853
-0.039541132102860144
-0.05957081240420745
-0.03272943708865764
0.008204267081835824
-0.03448130871831362
0.016256524560145078
0.05420714392935073
-0.009508915857975562
-0.03314365965322617
-0.06893709215539709
-0.05620273315238991
-0.07425181542685966
-0.034177519512825674
-0.06530673179057485
-0.12809089503253313
0.04980905040237266
-0.007469174389379725
-0.026563032286152227
-0.022661126950961313
-0.044088175972808626
0.04411410591973272
0.06976830572112905
0.08219857437562282
0.0678290459059478
0.003350339438385622
-0.01037557744570822
0.008854466120596033
0.0013946017872792844
0.004366061255679639
0.020996344020842
0.024611690606096158
0.07546328133755827
-0.047586086557833696
-0.03734257871894046
0.009688732439475616
0.009387018558555334
-0.014784660953504584
0.04230673011538903
-0.0675689627352388
-0.05937638360410327
-0.02921208810312242
