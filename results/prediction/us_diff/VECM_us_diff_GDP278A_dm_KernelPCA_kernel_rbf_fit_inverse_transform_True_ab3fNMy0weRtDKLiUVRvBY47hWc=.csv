# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP278A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=9, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.00046560347434214475
0.006708844548686054
0.0011888080221181588
0.0029963059036724627
0.005348036626692617
0.0017165503600549289
-0.000724821047813027
0.0018431382592888435
0.0012870327777646992
0.003948844187254785
0.004882748391171558
0.006297298533831617
0.010117128532697507
0.007652342498102971
0.0024225388447537397
0.0022067292452406786
0.002288281073609154
0.010047847215262614
0.009812696995282758
0.0074469343860015585
0.006033146664086833
0.01336074806025546
0.00811299570676313
0.004674863737980309
0.0037105100743433715
0.004042672554255878
0.0036161736802311495
0.004660926623586585
0.0035723016486699467
0.004669368962782132
0.005224174341235393
0.004310359617391445
0.0009599741233556069
-0.0008807804314817766
-0.0030315225290460436
2.666856162286094e-05
0.002530933515288481
-0.0005489551055137929
0.004621508804832169
0.0028238261288012303
0.0006980224141407685
0.0024691815266339057
0.00537141576793954
0.006561590525837759
0.006960527803784983
0.002222182354106491
0.005244200807951423
0.004886518716970378
0.0008461328092467697
0.0007545895307628975
-0.004794282211709572
-0.005247092318930964
0.004243882170496772
8.059954074420624e-05
-0.001481181110060471
0.0001986763872754868
0.0005291188979383308
-0.0009855778854556039
-0.004309708559237808
-0.003879208943040617
-0.0014660311700276261
-0.0015853751255055862
-6.57689601971154e-05
0.000842017290121855
0.00011438035482400354
0.0019574595960991635
0.005373506576741733
0.0040902923249596206
0.003637168049463018
0.003222277110497744
-0.0008269445833022893
0.00437438112320369
0.006444646864093734
-0.0017017710869241312
-0.002512264625215603
0.001680441360661619
0.0028776003055694306
0.006873022119009286
0.006401272896771519
-0.0014669512262599383
0.003825717155380369
0.008534154953111776
0.006747493534803185
0.015120033386917402
0.014273747003367174
0.01137318601928199
0.011234839461529469
0.013465258272178543
0.013175793797933938
0.015821826165624768
0.016206794544509837
0.012377863591015963
0.00823400060893846
0.009653706185309776
0.005028306337775548
0.002624741119187284
0.0037574807621881747
0.0006701305079936976
-0.002271399263357091
0.0017085269112237667
