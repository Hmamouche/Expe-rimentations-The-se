# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP263
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=11, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.008889375895511755
0.00027432013599876606
0.007779322740922816
-0.010303525643295421
0.006034704918846615
0.0048244435006358395
0.0007376619082824381
-0.004759912907538172
0.004045036622010913
0.0012678474193283983
0.009756043722056462
0.007488360797736598
0.004835156898748002
-9.423171306926093e-05
0.008548290664527993
0.006915402033648587
0.00332035134206786
0.009779620009745051
0.00420747194315824
0.01131677382557513
0.017609225650423777
0.010146275035493705
0.012898192334370671
0.0038604649502512202
0.006248341796866655
0.008873467000655229
0.003358149029621106
0.015003085632527322
0.010381154195430491
0.005793909577827203
0.0006537573685646519
0.006973493540084875
0.00954924890081299
-0.0009442672984509189
0.003934938289314684
0.01200563310769568
0.012988291093405904
0.005842718572574665
0.007860459338540897
-1.5281220837195554e-05
-0.0014871236810258745
0.005352595857978929
0.01060286323270454
0.0061361338585773926
0.010640696055004045
0.01663605318883265
0.016786227159726642
0.01252793972537944
0.0064315764137343814
0.011283059163805797
0.006721728153741615
0.010044405722779235
0.010221464170980698
0.010161632700703378
0.019023269326763605
0.013489153427212635
0.02333304670922496
0.02160042050299122
0.009791356834748466
0.0031122308524588155
-0.0019449568491666386
-0.0023967660631759547
0.008545555484930347
0.005091245282035733
0.008110300317909979
0.02076293895860761
0.008804011923054732
0.011325545503043292
0.017701082764365633
0.008543140470603148
-0.0003222444177040655
-0.012309519752445975
-0.020226036036766246
-0.024524643703471172
-0.00021922280783437387
0.018687480400391112
0.0014054407979076822
-0.012198944483335476
-0.015035104537973975
0.008323685819658581
0.012855717977386954
0.013886402227280922
0.011983587647315962
0.0066172574752031785
0.011521324847662027
0.024770530105710047
0.011539567428452902
0.010546008813374691
0.006614990595163887
0.012177507398424835
0.02410152997012731
0.025454570366099796
0.023583323492561564
0.01893549294925877
0.022167921482016215
0.016999863909270316
0.013593538643833517
0.007306374302923205
0.016975541549622154
0.01773027431574358
