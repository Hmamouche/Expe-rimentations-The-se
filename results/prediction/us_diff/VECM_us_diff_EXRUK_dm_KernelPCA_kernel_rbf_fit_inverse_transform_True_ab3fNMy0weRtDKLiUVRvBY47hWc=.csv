# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; EXRUK
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=9, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.004266594474021527
0.0336183255427479
-0.001874385447483265
-0.07163724925723089
-0.07560557853890414
0.08112516980281184
0.020618573115098425
-0.03524286856280598
0.03787491624052278
0.05942896547890629
0.08496949233950361
0.018750163689699548
0.03218794374020224
0.03086455812301777
0.0766723367045172
0.02084876778972143
-0.05219378397425267
0.0874070300795757
0.00873995905225556
-0.016659673516797365
-0.07746654400143314
-0.02816355620874266
-0.011098223706667378
-0.05725469642056673
-0.01754244378338011
0.006210874756680945
1.6286240281835132e-05
-0.011622506416504585
0.09519539059003596
0.07796574277095192
0.054874227147987974
0.011544853762238294
0.03039777234889273
-0.040473212591555716
-0.09935775037299494
-0.013834791575131743
0.09649493553471361
-0.08671535639665304
0.0177688224979867
-0.07489357673136601
-0.06913194552961109
-0.006750280882150666
-0.03515185069630691
-0.006073093962698645
0.019367324346372863
-0.022000155644655992
-0.019289425796113254
-0.013958223392482368
-0.03487299324490322
0.009797350506567604
-0.0016042587413138219
0.04010951742892925
0.04710671263590397
0.012316381651197172
0.013114065033548075
-0.030449040415944387
-0.00387247591988925
0.0015472334640089878
-0.016880059304471673
0.0036824199536493237
0.01609198547485159
0.03484038057649167
0.01696700353523961
0.018902359277517888
0.012841067341312597
-0.006157835420211772
-0.04584140783625572
-0.0601592828720072
-0.03120629599089137
-0.005582420658575089
-0.006811341520105489
-0.014164661767936893
0.029088533644537833
-0.0012784894156286676
-0.008918046263707353
0.014676295101343759
0.023754951116578486
0.011402770932545346
0.028397372196610773
-0.03711044549113535
0.011500606780827179
0.0437256445505649
0.013344004383656549
0.03510111795755137
0.003449161004397532
0.00730719846428312
-0.026432046788980146
0.0059614238645256685
0.024225977724058455
-0.007710232801825843
-0.020094383921210317
-0.012062793717506206
0.021975802040634256
-0.01903533271430385
0.09126904862417615
0.021844104849170792
0.009629914570586384
0.008949253966071699
-0.0037409876551543
0.018639684839525463
