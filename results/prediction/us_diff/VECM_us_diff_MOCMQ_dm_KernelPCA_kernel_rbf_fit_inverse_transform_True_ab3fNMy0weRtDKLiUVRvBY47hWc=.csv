# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; MOCMQ
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=9, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.030894993396368396
0.008864781702296893
0.04003901226130814
-0.020443973061884634
0.0013013703274738916
-0.006017493244300808
0.012496458034183148
0.02463312310673635
0.0011705404194472038
-0.005616609238083528
0.038349900079434195
-0.009538686656326097
-0.018671867788362388
-0.016654465100287928
0.007643098257466643
0.020854174591585353
0.024585217911704267
0.0008944283292614355
0.02292795006504288
0.013686017609767807
0.01941218591421863
0.05085730985887309
-0.04196891531375117
0.006056856619515638
-0.014035970361942054
0.027056533482511504
-0.004437369807458059
-0.02645507950636864
-0.012747546755596348
-0.04016174523834342
-0.02195343116861397
0.032020033992050737
0.0277594367272729
0.01875030790758413
0.01170817717534262
-0.006214408074619128
-0.02212424124066218
0.032233788216647734
0.03287057082567254
-0.0038727068119777603
0.02994157668739962
0.02057863954500111
0.02010763112654803
-0.003183031327124209
0.014924820706176064
0.008685780425822706
-0.002103563210425116
9.638149237643084e-05
-0.0010314312474392555
-0.015945528330517635
0.009285994579997096
0.021402726927308848
0.015559439179875366
0.03343405816047984
0.02798103602273161
0.011336725285969056
0.026003981879780296
0.0022992902568628563
0.01290739445462801
0.022007232417947404
-0.006638235907798819
-0.0037414822838390044
0.01258837752937099
0.01488197844647452
0.04143833674461382
0.024459223169201842
-0.011244994543545484
-0.029795629628283245
-0.011736267546429114
-0.0009646300887732051
-0.018653696101991114
0.0038925358726360363
-0.020310688789730715
-0.0254326605548316
0.041122300194463904
0.007303897097610476
-0.012902920898088083
-0.01852861173356772
-0.02365354089862614
0.019329041314927232
0.020340901186157265
0.011654331563252535
0.026482651586713445
0.005665585062948146
-0.021753843641889415
-0.02045722773456612
-0.03012580733661393
-0.00247698163043316
0.018451714909793172
0.008023739424423929
0.03461534682458366
-0.01455180237004014
-0.01371153046491448
0.01129432695947774
0.005107864101016392
-0.011590321524775956
-0.009678489503973509
-0.044683097142174485
-0.02500094044292411
0.007087513500676468
