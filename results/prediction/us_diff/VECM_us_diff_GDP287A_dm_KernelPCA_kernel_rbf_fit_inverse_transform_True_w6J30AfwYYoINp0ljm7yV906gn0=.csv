# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP287A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=14, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.006909377903592857
0.001962122806046864
0.008805779334522007
0.00656227472584686
0.008680642504283458
0.011526900093514621
0.00549565632754242
0.00455282218491585
0.0034133809400603743
0.0033372260539241234
-0.003656508183116941
-0.010284442048162378
0.007414677281452741
0.0007466695077139795
0.0057992771393381186
0.006069191328243616
0.0042119098459568955
0.008316416773673644
0.005055271720676985
-0.00270714885501944
0.004566522020001284
0.00818256095572514
0.0005537208980583306
-0.0014712956571733726
0.0027052035300066044
0.006023482274623157
0.0023512945661177966
1.0886670785780102e-05
0.008142819013816804
0.005630156412937894
-0.00010687333730817288
0.0031838865496162053
0.01497065283385657
0.003417994544396551
0.005215328691785042
0.007974194721113867
0.004445059389926643
0.004344878960920362
0.005106202253176435
0.0040364158333537304
0.004527508798191093
0.0058577597483994775
0.0022025196948984387
0.010609419460996928
0.009543142312559628
0.001788625751689735
0.0033141862868791582
-0.0011160672404900353
0.004010159110431712
0.006383304875797222
0.005007865139335144
0.008419541116451138
0.008303513418589549
0.0077967325090329415
-0.00024793022948408467
0.001445100584152877
0.004939441731281189
0.0055294773275972155
-0.00041641147303182627
0.0031108381762570626
0.002483998608354355
0.008045135305724885
-0.002323808109721168
-0.002518927948260889
0.009624247907135097
0.010981447242443178
0.004541437044699283
0.004666337421971372
0.003696003697865213
0.009329029934367936
0.004356754408402845
0.008113607736758394
0.006587320489500141
0.0037590080636509
0.004330542066182767
0.0028755828677293036
0.004736504530309252
0.014997889703616362
0.001114433092354584
0.004150749071966541
0.013407639063022255
0.01713773781225332
0.004207511956359031
0.00960919112364658
0.007707294073461161
0.013751522823444958
0.013962994296803031
0.010599074600678287
0.01024813390225655
0.022337443952971096
0.004473524328448326
0.01380743427759514
0.0033589437090199015
0.0159411938299014
0.009555150538121487
0.005989922518900524
0.009332600317026266
0.017333886096590395
0.008807522732416957
0.0022077665151656505
