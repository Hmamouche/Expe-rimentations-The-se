# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP263
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=7, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.005261082584420101
0.011314491821515971
-0.00036077588988354383
-0.0010448842506614112
0.006430598258983631
0.00029715000458398113
0.003946572811174554
0.000580166487354605
0.0036233938908576168
0.0005711651135607229
0.003419122057790264
-0.0008442452839505501
0.006756707480900756
0.004714586112331157
0.006646062466085714
0.007505909597434171
0.006243423952859647
0.008689150293221043
0.007365374985831056
0.010599004818154515
0.014690128497347943
0.009346589035444542
0.010605033114116105
0.00560766976800723
0.006595831741665138
0.008684576431598054
0.007246210904030816
0.010191637234882247
0.012688691672668668
0.006012387977005891
-0.002427749921670992
0.0050665908465778705
0.011888230603600761
0.0027543484374861244
0.005153623328396266
0.012776748483198779
0.008013934257108666
0.006000151424275286
0.008406535173811649
0.0028736495581946366
0.0028503423600269384
0.0035311674640365097
0.00809661639799137
0.006034511059887445
0.008584394130147095
0.014147255055719187
0.015999074738259733
0.009315587135292142
0.007879109419042456
0.014234241798445832
0.009546137341909329
0.011438854173239464
0.009734679054918052
0.00810418785339866
0.018532997990040666
0.012640702163234837
0.02298556701639064
0.022999120045277127
0.006348876807157431
0.005644030142965155
-3.675814672357818e-05
-0.0005303984210654434
0.0077983538595499495
0.0022969731248512703
0.007096721624622198
0.01619692000228893
0.012833269447134015
0.012563035275224056
0.017158156808253736
0.012482341826938272
0.00030835339901072825
-0.008855189560201347
-0.018594828863810225
-0.027554556632282956
-0.007949300867797621
0.008939357778718312
0.0009878737401245964
-0.010179182018466286
-0.0042699214460769404
0.0006017492196789169
0.009021002946452436
0.02354874923149085
0.016162254718307123
0.008814032615820333
0.008282045575594553
0.023242547486418172
0.013869381555467474
0.014759293453257235
0.00676714068429843
0.01360150860559934
0.02614316725140815
0.01855318344169264
0.010558176251062434
0.021072750187191805
0.0263466857404516
0.012453010930420706
0.018927296748333416
0.016124627417047614
0.01841113089028262
0.01757994398798834
