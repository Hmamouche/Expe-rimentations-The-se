# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP276A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=9, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0071133663017623385
0.004992553194408023
0.006030794032234206
0.008456309589615388
0.006224334713185014
0.005734048352981554
0.007676931873758256
0.004208367749302526
0.0056430429539956455
0.005545200093621666
0.0063796273538866514
0.007328795604117492
0.0057075005421266655
0.0070773602669828035
0.004792929926954073
0.003714198111219093
0.005793683662184237
0.00547207261540051
0.00813030752304627
0.0066200398176078454
0.009110023223724804
0.007445719742867679
0.007777285652795034
0.006775358311499235
0.005892569891360606
0.006786044334767354
0.006852169185280548
0.009915645200352964
0.008479911823457151
0.008364149703326914
0.0075303708234031016
0.006031968546993036
0.00709868452564754
0.006587795888015146
0.007950412087569046
0.006179851191868888
0.006277806691581162
0.0056956273894329295
0.007862870261256979
0.0056400492321456676
0.007372833183178617
0.004447164024177307
0.004669259038277465
0.004933092574557432
0.006747063845095771
0.004979500902884891
0.006813280199910338
0.004623906031158106
0.006824230357666343
0.00662337223836097
0.003902985384163513
0.005442522568298941
0.00555651563407052
0.004897975675674324
0.006058197499832094
0.0059904492427293185
0.0042762776582861185
0.004910452616806778
0.004382354248204512
0.0035581609485612464
0.004700645425985774
0.004373159469423321
0.004187400782559453
0.005015650065682051
0.004039438103554075
0.006155725950207085
0.006387886228501153
0.006410732694229542
0.004244886210313688
0.0056908569955790335
0.00870496778924218
0.005992315081774554
0.006593724071422462
0.006680897108538481
0.00798573724457184
0.006167329106300442
0.004895923587515101
0.007038241607989321
0.007259806446689642
0.006131418995155582
0.008297628946878802
0.008036683269065937
0.008473550387432548
0.007260826630787977
0.008257523259359176
0.007577082263981224
0.008413768351310446
0.00875009026302372
0.007900444755361785
0.010501859334186578
0.008282349236334982
0.009487554075673955
0.008611461822600322
0.007866986573172205
0.009704916029774614
0.008935408569815714
0.008607141721020463
0.008574657866594015
0.008612020374448217
0.009840668935033388
