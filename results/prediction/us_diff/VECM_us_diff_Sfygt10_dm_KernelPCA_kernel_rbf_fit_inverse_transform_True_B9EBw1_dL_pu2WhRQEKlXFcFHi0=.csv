# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; Sfygt10
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=10, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.009333194285964012
0.03055375386701066
0.06451102017748933
0.07857167859697889
0.16066914453179462
0.18099774984064781
-0.06410180611725036
0.10154261284967835
-0.19944145514491066
-0.08093101727090612
0.02067806502650335
-0.0019479835735414378
-0.026333852088844048
0.0009728494323458098
-0.10287086912229723
-0.08736901917516682
0.15031517859953272
0.22487910472210695
-0.07542657463483568
0.12628342879731852
-0.045129605162573194
-0.1249462676107061
0.020004554742815123
-0.08467254795599102
-0.04652801621196077
-0.22113302133429502
-0.09272265075157682
0.12784375358728936
0.048290531282096365
-0.1098373759376035
0.23334534933398376
0.17102007208500863
0.11752218349006045
-0.04771895676133683
-0.10459586921455787
0.08787732333318107
0.010381028964085881
0.1644144018145332
0.05865508263878848
-0.02442267891659188
-0.17989242579487294
-0.020897343251477466
0.06523407784577176
0.030043944145354808
0.015194184789805217
-0.00010169890869796833
-0.07156406103511465
-0.0031354816321617768
-0.22798861301827406
-0.06455883816224098
0.005890430055917586
0.09111101626805347
0.0314157651974793
-0.006649257527682595
0.03670955506938307
-0.001757109888877653
-0.04502799297851894
-0.06117713334110191
-0.000456134300323964
-0.037686287766830806
0.031742993818049854
-0.11098880392111943
0.02830710846791438
0.1763128084259337
-0.12022163599265483
0.009988559318636271
-0.00439605811190177
-0.0474811517246343
0.05232423222871348
-0.0799788525797834
-0.03773514143024421
0.02867710433261486
0.12082201283563243
0.24570837958981362
0.0029179926827315184
0.16082845193999618
-0.29184131057436435
0.1877181379314422
-0.05389115514753016
0.003097636221015058
-0.04782763352427278
0.013291672061712228
0.022165657760057963
-0.055965889644709194
-0.036926946432302946
-0.040511967155178574
-0.04278511929185963
0.056836392702556186
-0.0670529506971582
-0.058867968957104305
-0.040218209703991786
-0.04473201292014446
-0.05298755789033491
0.0356404160161895
-0.10032649961349215
-0.044908166689447936
0.002922337475938286
0.05160833910980947
0.09732792121205394
0.02352584211077648
