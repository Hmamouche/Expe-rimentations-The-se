# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; HSWST
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=4, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.04574387304369629
-0.012695091832953698
0.01006638268506517
-0.003036149856555849
0.05097821570556671
0.0510678480664213
0.048381465555386347
0.06139234948780015
0.050208574169342386
-0.010501258138291128
0.07876818524172195
0.01992872689013121
0.015656343160544147
-0.1002512858183019
-0.07161868745903453
-0.059606576327479247
-0.09243163784900263
0.004238277962590558
-0.047273719941941905
-0.045319975715052814
-0.015843006854302746
0.011002339352567735
0.08155831867268355
0.019000711088773416
0.02626197683016142
0.017879128786880805
-0.03285606662564369
-0.031481086879996255
-0.07170049685281948
-0.08464682216082578
-0.024571778492842734
-0.05305970095367318
0.044529660571484254
0.04828752687385105
0.028490031519150694
-0.03502720236484863
-0.02646807845077253
0.0021771930416190615
-0.05623590498643863
-0.08632613791703192
-0.02086911426088322
0.10290858684581997
-0.008210876959921794
0.0197876466010814
0.03492184879940663
-0.06924491550903467
0.019463479335530595
0.0400040774541445
0.06572170971060845
0.03542328940105721
0.0037794927556789697
0.0016308751532166342
0.021623373181765364
-0.006816100984986483
-0.015951903003702632
-0.022494499009764107
0.06001593257519494
-0.011640810980908276
0.07574702039776621
-0.00827193099046235
-0.010273924631297025
0.09557127313882838
-0.022255497813512902
-0.04055674684460535
-0.043797576749503214
-0.005597813139070512
-0.014269354087380117
-0.01574568853115751
0.01544322520921708
0.016120120883334074
0.06397465399334237
0.06514683388927472
0.04825767755440318
0.04207045811640894
-0.07354152569321083
-0.010564565936128985
-0.07613218322284568
0.010809871511258964
-0.0349439351637406
0.0675450348242955
0.10072083575134824
-0.004949584825167714
0.021248153429256823
0.023838924939456267
-0.039090516389653086
0.040521794883441764
0.002000601126700442
0.009605243701828838
-0.008983008929111427
-0.018148194418710465
0.023825481566947505
-0.056427295337967656
-0.037792009868643714
-0.06516536227256783
-0.07196117371401155
-0.0217438256999146
-0.03094001265643945
-0.08083592464339111
-0.07783975256015264
-0.10342073611378835
