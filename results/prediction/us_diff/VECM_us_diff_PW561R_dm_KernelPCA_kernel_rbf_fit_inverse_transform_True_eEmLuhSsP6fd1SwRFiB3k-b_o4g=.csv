# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; PW561R
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=4, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.02126610752230107
-0.0672600172594991
-0.015546009837701893
0.004906080614480002
-0.014988058713707845
-0.005828336624844338
-0.005563166957260416
-0.006162308391380865
-0.02205824308871259
-0.005441200640859403
-0.04803358751573724
-0.11540298358785192
-0.0037782324931110844
-0.048763296948426654
-0.043696706885495935
-0.011084740899396674
-0.005548510440622675
0.018022636201358747
-0.017075928221647215
0.01781733331913372
-0.0028828525517089892
-0.04440446562788591
0.029904407723784495
0.014357501770178967
-0.027189194417829573
0.029071543635222942
0.02418488938660926
-0.050905661557411705
0.024242160807165555
0.07171849305397458
-0.05403599193712849
0.04563610019200709
-0.001988084569129956
0.010603555539639545
-0.0729849841624586
0.03359506491072349
-0.022216333109526785
0.0022759290144335905
0.0027028738706199786
-0.015826986061799376
-0.03500830100004147
-0.0031347565599506764
-0.020028769571976825
0.023578503174598198
-0.007171584703962024
0.0005790055887437999
0.011824794005316962
0.005762989250486031
-0.012968208903996109
0.01596166382551148
0.0010902404925752038
0.009857617761963975
0.006446932541817
0.034892907864011766
-0.0052951020052368
0.003228314049271822
0.001994792249116091
-0.012338845033926299
-0.03964327484836031
-0.009660557875653612
-0.0318024095485675
-0.024884433928317632
-0.00020474849640365195
0.03279297979888282
0.010579217598345177
0.03666504269828665
0.04999562916295687
0.00858379316758822
0.051231293686923085
-0.0033209328628074197
-0.021400245204215386
0.005830446036750767
-0.009593056148999052
-0.045857648077125175
0.013175149936227846
-0.01007068960648059
-0.012961050741782429
-0.00042806880364941804
0.035371044744263176
-0.024723883368003737
0.04216976887460198
-7.589730569933228e-05
0.03853097243348445
0.003912103022002763
0.02656153029181086
0.02790928313827713
0.020719567449472873
0.03686399209179126
0.05364574050053629
0.008536796599526665
0.059088783046563155
0.03809580519214651
0.017168994702732136
-0.022926693900287322
0.01647888025210969
-0.0278217911557692
0.017812246892550024
0.06733932370929727
0.08501553180443111
0.1680793275568127
