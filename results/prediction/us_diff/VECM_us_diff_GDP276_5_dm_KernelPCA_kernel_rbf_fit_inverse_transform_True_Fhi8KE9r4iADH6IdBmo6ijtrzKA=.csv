# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP276_5
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=12, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.015426322878088268
-0.02467083037405014
-0.012145604991994217
0.00338868835382599
-0.00233850370986554
-0.0037696982919327247
0.035099352366195984
-0.0060659070456961
0.006293501106264152
0.001985580905218589
0.002197397454060548
0.0030708229908193913
-0.008795625364003298
0.006559204821641443
0.013566213704205297
-0.010083681259262697
0.015146020146031516
-0.005366296918102011
0.031527002098200654
-0.009687263270667372
0.02156048926914578
0.015649309263028446
0.002981580238504324
0.018257373065271372
0.002432744811862126
0.017374955374035994
-0.0033459574721474835
0.012799821478157777
-0.004621877715809379
0.004327179006875613
0.008592649901112167
0.012242618269684705
0.002194801930508034
0.007363197584709648
0.008761053868586497
0.003761584361638294
0.0032541980567627167
-0.0006645444295707626
0.01954905519479497
-0.016213833056616757
0.025622124369144912
0.00477387332020361
0.01041579168896246
-4.495846733555513e-05
0.012825572094266605
-0.0066878126420045645
0.004548164192032998
-0.0011535699039098434
0.004861710626620206
0.01588081948561952
0.004078626231335789
-0.0006452491173498127
0.005972777802698712
0.006936524354601491
0.010401077386138016
0.01071520684154615
0.004266769335127157
-0.0005656579190477537
0.007758152725905986
-0.0021186553901756363
0.0008520092217188845
0.0025198895942496547
0.00561978050723653
0.006377585092133253
0.0008063587794275824
0.013210747372777831
0.0055470318297286955
0.0015235080595540134
0.004498733732066169
0.0011965811630303795
0.007035061312868475
-0.006061549280633511
0.0068286725959905755
0.00010271432487777665
0.012758786135278664
0.005896093130074119
-0.00667480773905522
0.008878664139601707
0.006391268565427313
-0.0036726584133530537
0.005685552171994306
0.004452215375113745
0.019334009257109038
0.007054023424383609
0.007559589044720063
0.005822444024233877
0.004836862423531223
0.005505530190948864
0.008404804997078134
0.008292027512063156
0.011404440723979423
0.008424870099990819
0.009988488775511733
0.013697309908862905
0.019097818202496022
0.0009030180993393317
0.005520713150128889
0.006466936080731806
0.0038473615568486103
0.01015349316389947
