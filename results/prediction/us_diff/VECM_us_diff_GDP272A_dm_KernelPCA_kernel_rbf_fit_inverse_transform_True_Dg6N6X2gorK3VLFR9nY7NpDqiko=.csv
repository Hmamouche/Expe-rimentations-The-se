# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP272A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=3, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.005143806878557172
0.005084438884262756
0.00865366795255072
0.007536740826336586
0.0062529623764713774
0.003955057726958154
0.006735179244705174
0.0040998735723285
0.0033484646983603294
0.004539876468949413
0.001912105577830565
0.0033648501442483415
0.004634789345201855
0.004459254579431628
0.005122584528321287
0.0043340016845412315
0.005739042438325324
0.005600483279112264
0.00526562072361595
0.007074506184731547
0.00786969964466438
0.006991761441205786
0.008039161413083654
0.007454898868894203
0.005614778293493104
0.005819531012945952
0.00782139009173262
0.008049774406125101
0.007412767198712386
0.0076086352018922485
0.00798664367295482
0.005598335309873314
0.006450621897774865
0.005651311574222228
0.004229091263470972
0.004998856950476074
0.0034052989912529263
0.004954542967244907
0.004987942247916117
0.004458881700885148
0.004669047759726028
0.004989311398302251
0.0049142561719021025
0.004596708979255152
0.005882837740348791
0.005108672705342669
0.004629367931740183
0.004190629003034537
0.003582347357574399
0.004441960594674114
0.004203914498951862
0.004391839234681215
0.004349293943530034
0.004597373064023995
0.0038785896172519635
0.004198350724109626
0.003141682821864827
0.003686248477156503
0.0018292053181987442
0.0019999157047779206
0.003043954914909868
0.002428033254995232
0.0030720788209049406
0.004336965873132558
0.0033748662739354054
0.004735248013784794
0.006641571634303523
0.004975630979920558
0.005471068897313546
0.005353785105068753
0.0050641180302173775
0.007159574825079884
0.005164483356080282
0.006026773841405035
0.004729305983081379
0.0025327484344864317
0.003973588456039964
0.004829816790872958
0.0069040602934538845
0.003765559504982515
0.006120782784263409
0.006181391549652181
0.006838287907146115
0.009735398723452235
0.00731356737946586
0.00950550973976089
0.009759726765733147
0.005753264420974294
0.01021185190523359
0.010208001927343774
0.008456721395295522
0.01048567804820843
0.007998561181892324
0.0074186529313696745
0.008842118513664185
0.007187135336299946
0.006017545225425089
0.00861761033293131
0.005980220275524202
0.004851967691073021
