# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP275A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=6, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0011625063929390092
0.0013218578177584964
0.005973142304847278
0.005935182588594934
0.005963085176292501
0.0016960951011696693
0.005086960764497717
0.005379749128395466
0.0035003739222477437
0.003013482840070897
0.0004991915999518956
-0.00893060435438568
-0.0009188721415225678
-0.006630981525597277
0.008490671402631898
0.006153820036268741
0.007474462078060941
0.0065680709773727995
0.005363003180835802
0.0071146082425273425
0.00837583431891133
0.00645865745865273
0.007940358467534383
0.01468277488146789
0.008540686782729684
0.0063269476554122525
0.008516321798514435
0.008199682273424953
0.012800936161894146
0.012147927185652043
0.00812470655791345
0.006161799522629007
0.004320496151012501
0.008456314192523047
-0.0017272096964698158
0.004202034167455547
0.004749760116993682
0.0030960295126333547
0.004751040202369971
-0.0014718748209179252
-0.0024995471175884776
-0.0006024557631127118
0.0016966055801313315
0.006568849915972078
0.0026645505867968966
0.004160750358905069
0.0032566727025698447
0.0006856028388442302
0.002816453424927398
0.0024302899856247758
0.003073070575077593
0.0061882637055125185
0.0032156181612058633
0.006676930722883849
0.004765759040762689
0.005148761784696029
0.0009356230678112738
0.001234712983987952
-0.0005647209585303065
-0.0010152909866565471
-0.0006508687347259897
0.00213569088397945
0.0033261507607929342
0.008048343094421012
0.007645247757086708
0.010939475056157026
0.00847624229948234
0.008990649921413985
0.011306332234605934
0.005405777272577922
0.003529697662892936
0.003604560477110384
0.0034614416112389605
-0.0005234173895829982
-0.0026928558695051242
0.0023159360612315942
0.0012878891585968878
0.007387806134218574
0.004696495775958516
-0.001136862018599586
0.01036878998960934
-0.001279067357628862
0.012412514529520014
0.00862441382417688
0.009734744916985033
0.010791192789939058
0.004504046910343639
0.009083178311124467
0.012047272539654064
0.011007426110880639
0.016116167519973777
0.005500302552248574
0.01276286723569373
0.002892218737185805
0.006339050111950189
-0.002768530843886597
0.011595216284799424
0.015739286933480725
0.012206794478271079
0.02042921779568316
