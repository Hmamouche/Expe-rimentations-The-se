# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; LHEM
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=1, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.012570904182092932
0.009723169260071364
0.012707990155673813
0.013645625459768995
0.006283774923510116
0.008020954879042265
0.006265055917943652
0.004797490913196
0.006398911890762985
0.007697431190152813
0.006639027626148185
0.006480470356279214
0.007317152584883985
0.00634292285785172
0.010373476198255129
0.010492615707357012
0.0104314083903034
0.009419113758838653
0.006420340199570239
0.00795992119676531
0.007297801281616832
0.008061822327719077
0.006849268358891542
0.0037006875130666163
0.003691608606903872
0.004424506972673358
0.00926409244046308
0.004407072882327063
0.004563977382682714
-0.0012473063582918744
-0.006052504252655308
-0.0004743549978573965
0.0012788261750396753
-0.0009677598355582286
0.000770449676066943
0.002642858408824008
0.0026071503387587016
0.0034510089079230525
0.005567023672561387
0.003951760236701319
0.0054363824358382405
0.008483280670190682
0.01101842453581446
0.010624457285936285
0.009204731627454098
0.011185093193683522
0.0055253430566695
0.0022211096137416
0.004257804905408827
0.0013743847463841027
0.00265786027021512
0.007279570216973222
0.007903908245322696
0.008358515146073879
0.009117296674839194
0.009874585520919335
0.009126050393977885
0.008691624444576319
0.005599282202438749
0.00493143348728623
0.002877222082224696
0.00527698307103368
0.007233172662524336
0.007766769794747094
0.007993768029177431
0.008163907075773948
0.012552275682614085
0.0034673734412713282
0.00850477934419196
0.007504959632852242
0.001429858637298725
-0.0012391716642139471
0.0018102271254420736
-0.0040277940064337514
0.0019368327859733238
0.000705174313361549
-0.0003818628093680774
-0.0019768791964946755
0.0033881064057463017
0.001537118783454125
0.006780801703703371
0.010741724834474001
0.006288920564797247
0.006375847206446739
0.00354592703078593
0.004042178222573814
0.005162541146776166
0.006184919033692622
0.007173674046982332
0.009475857780407913
0.010055313525459084
0.0063109903805543335
0.005240671067536601
0.00595418342199395
0.005109069590606381
0.0075773574550105
0.00418845195678022
0.0010688750654395277
-0.0020955960337075644
-0.0009839226208277346
