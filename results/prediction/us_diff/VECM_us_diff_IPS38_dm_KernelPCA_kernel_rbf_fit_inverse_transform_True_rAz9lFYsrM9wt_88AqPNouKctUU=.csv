# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; IPS38
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=5, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.009756768941359826
-0.002518045957027388
0.0060717944408643885
0.008305647788595844
-0.007827960457054015
-0.004143803400552622
0.014435592654129232
0.008718294948079134
-0.006518581853997839
0.006072499625352184
0.015494273539401863
0.013841897241585889
-0.00045383303135587065
-0.008106134505164517
0.013081531895697765
0.019782174295729094
0.020454046641090556
0.011945505335900719
0.006183127222788413
0.009212972877241215
0.02053536727778448
0.008196207922314722
0.0056711313008932125
-0.008499296396101289
-0.005418628135499698
0.007211162475269048
0.011594837405420357
-0.0016135314738506962
-0.010782196415293502
-0.010001872521573635
-0.0007900748498484815
0.015161340566525055
0.022567660695867225
-0.008910918285315672
0.0030057310097780995
0.00962312969720437
0.0011148997922120745
-0.0023004059709031445
0.006003054567984233
-0.005500249475303036
0.00526931813324572
0.020465595820946005
0.01181361555284766
0.004249718026287627
-0.001380903792616837
0.009405510765840511
0.007402775554120268
-0.006520302304606282
0.002200894584034072
-0.0046902516736322345
-0.005894821125428454
0.017211944080504582
-0.00216465854433924
0.012351069574100941
0.004374163165290326
0.010702824325310466
0.018069892244826243
0.010268207748385407
0.010620005571073407
-0.007587958646747122
0.0014878425564915799
-0.0012866827123745907
0.020226811873148447
0.0038031369693578543
0.0030281956647638256
0.008444414155760355
0.003563071551129822
-0.0009864504082835093
-0.025153354873848836
-0.009646697841412906
-0.027194142005905933
-0.006758173486076422
-0.0134197721364256
-0.014497398473719655
0.011132587574921339
0.0014983435281219412
0.0024027325723665234
-0.009607927580790918
-0.013288057183026463
0.01014752590385367
0.0024975476003812674
0.019860815965259255
-0.008296765164953632
-0.0012044366114267418
0.0036719799229645595
0.016585080793271333
0.007855360457908581
-0.006765840062027215
-0.015377059666943605
-0.002947020277151595
0.04004271609456193
0.0017442818771871201
-0.009279194914182026
-0.018367315431586352
0.028016288545209267
0.007939214058274581
0.0038167831589057577
0.0013195370035403203
-0.005276301953169585
-0.00824780724024778
