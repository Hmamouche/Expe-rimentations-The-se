# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP255
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=2, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.008690126829315779
0.006740853446671806
0.004385550097985294
0.004070652432765838
0.0045778764572233155
0.007591140027914389
0.009698721936163272
0.008676968687058466
0.009053429868038788
0.007043466766818027
0.004264902677051639
0.004127863350206582
0.003534116805537343
0.004927892364823843
0.0071811110378089404
0.006865152762199158
0.006839189653903816
0.006456475981521943
0.007618322941518179
0.005433126315724536
0.006586023662235183
0.007011772184862181
0.005126331920963743
0.005010673949155376
0.004623482156472535
0.005941251912538052
0.00408314848752916
0.006460125102099842
0.007042092600768969
0.0033923210797312045
0.0017851481733033498
0.004675630073747266
0.0021670550986806142
0.005032048007776778
0.006648886550606683
0.0045687963986609246
0.00809929600783777
0.006261717557572524
0.003860001797439342
0.004280457716503067
0.005795511916448459
0.005604373119342368
0.00752908612438188
0.006272603063250456
0.0049839253531068755
0.0039411036278059345
0.0038941090978378092
0.0067564360066539545
0.005556056015247572
0.005652531848073533
0.008695689532552446
0.005352400624955541
0.0059395046278101805
0.005885951483729887
0.005811386606304003
0.00689982659709313
0.00831192813337649
0.008929135088992866
0.00978030186043147
0.010052743411166468
0.01027987504341026
0.0070759891248024015
0.00868528556586684
0.009346320845244043
0.010040973304630843
0.009297204631604838
0.011754658911401927
0.010763037215908034
0.010151710930090136
0.010564571670544606
0.007863900273829272
0.00709478779155616
0.0043736365943916975
0.005780078858418235
0.0038471107368015763
0.004331792061442769
0.0047617631606493675
0.003978609820422793
0.002777880958313282
0.005121751318864898
0.006416025158479091
0.006857348277004128
0.009049182267450927
0.00921213191298072
0.007186819613023064
0.008725263383723618
0.006579921587234258
0.00556793536265733
0.007986264922873368
0.00676027384719154
0.007065915946492211
0.006880716662701157
0.005840013737286196
0.00796902997308833
0.008891202097469686
0.00751158678898234
0.007498788158603128
0.005923950900647657
0.0054853167628513035
0.0043878671214407
