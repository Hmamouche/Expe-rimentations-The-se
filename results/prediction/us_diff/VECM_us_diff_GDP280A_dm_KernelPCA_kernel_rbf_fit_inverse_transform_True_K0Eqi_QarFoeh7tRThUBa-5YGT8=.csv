# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP280A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=6, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.0007143089585696615
0.002238283089497281
0.0012866014081419018
0.003951012763705366
0.002513192530774302
0.0016505546720818973
0.003298569546410268
0.0006485424380095593
0.0008582711405717284
0.0016348208007596569
0.0020832714115371913
0.002162479208909694
0.002104783566724602
0.002469045801314209
0.00037594718061356144
0.0009670406515948575
0.0025615051331678135
0.005130817452668737
0.006398909134145277
0.006243117203375098
0.00447104795281504
0.004453045873390768
0.004575388701706155
0.00439823775017788
0.0039101878893903165
0.0037333290624118856
0.003715874761980374
0.0033110152888697524
0.0034121628590909826
0.0021028065814518372
0.0027297721064164122
0.0024624316791500545
0.0006347621438876571
-0.004423575220740901
-0.00011206433448602128
0.0027638136770611497
0.002185451198941041
0.00257351276149773
0.003355147165283124
0.003898610967218076
0.0039947671700675935
0.0049281233735653605
0.004925699358156446
0.004379040936477674
0.007350910071488061
0.007735006737342084
0.007031392269438345
0.0028905266369014843
0.0045874740902084625
0.00448312003685018
0.0006101728047333446
0.0026503234497675422
0.006363979010559882
0.005253989850272173
0.007034948320836497
0.005761767167708658
0.006901833829516263
0.007023551626836799
0.008592788207177434
0.006516594651751753
0.005343606783228482
0.004730438616377161
0.003992489568555271
0.004596968814405368
0.005025910956861884
0.006291765759123527
0.0070615055576678225
0.005229061464599785
0.006504507935781375
0.007870219863411099
0.008762123211805953
0.009883412802703698
0.010612634636857321
0.004500580668355568
0.0066353302798348454
0.008300216726979222
0.007922453152338051
0.010205111699876358
0.007919085207879673
0.0009363682697079082
0.0037300749783222694
0.006141685402846649
0.013948502493680709
0.014774420461356708
0.017961366995684267
0.02183319173050423
0.022862310061746913
0.02134094017708892
0.028745432056494536
0.035905309475414475
0.03367887280110598
0.03075320251740745
0.012092674331035395
0.017194154532890575
0.009567462500975787
0.004786477003941616
0.002114468019161971
0.007678205745485925
0.007035832211529382
0.008427202967120961
