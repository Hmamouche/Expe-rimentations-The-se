# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP266
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=14, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.02112684455487886
-0.021139833434201116
0.02812230651528852
-0.04546877263065846
0.006151166693000237
0.019686110112084692
0.05146999688445947
0.013275922156532075
0.020750978569946985
0.0013212786488702895
0.05435378214171799
0.012067750813445454
0.04484549478299589
0.01805875417063175
0.003928187413334717
-0.010289266632429902
0.008789197556048022
0.05119230210561623
0.048107509592161396
-0.018494739544186012
0.02104598568807528
-0.028234154276891955
-0.031338100345298193
0.0072484684796245875
0.02256314927759268
-0.021804616180477805
0.034784071773273015
0.01991339136138757
-0.00870360693937505
-0.0049850341996275
0.019080091408653597
-0.001829898312451948
0.04128676574046945
-0.0019331083078523888
-0.013640889752483024
-0.0017121761770312821
0.0006683111799393269
-0.01670814343376551
0.027381882441015266
-0.014351565926813052
-0.03259771906406329
-0.01771839210416896
-0.040262714188684996
-0.01407761333435601
0.0017988740393770286
-0.007785199608921872
0.007969389314043479
-0.0312067795569666
-0.023928525278462856
-0.02821260527354093
-0.0011162924681467346
-0.009009490477608184
0.002932222734179653
-0.01163475920469832
0.010282519075955957
-0.015589913043579099
-0.008476028268168295
0.006739269143460002
0.015331815624952182
-0.014231351184799821
0.00039717855766874255
-0.01696998092513613
0.0010409227405565324
0.021963272646008378
0.0027800239255242123
-0.01869031319809298
0.029399457348961922
0.025248544660648863
0.006897033913907452
-0.017499624867597128
0.026516499847339545
-0.023643256178568293
0.012110937781798566
0.028320211955974586
0.03679173748471402
0.031307788826286806
0.03612620678333738
-0.023105371126886643
0.05089220521209739
0.004775117677669267
-0.006484000109377875
0.024477747513708733
0.04303193062889267
0.015497694059244217
0.014767636498247453
0.003035563419596734
0.019612999175823653
0.010276431309955524
0.0037003263233273288
-0.008624178639413168
0.01793215656764647
0.009898820373493985
0.007252437762795367
-0.01820370450443479
0.019047375525620143
0.0003637457405630618
0.00404299293907213
0.026108530002377058
0.04882276874392533
0.0253634058543223
