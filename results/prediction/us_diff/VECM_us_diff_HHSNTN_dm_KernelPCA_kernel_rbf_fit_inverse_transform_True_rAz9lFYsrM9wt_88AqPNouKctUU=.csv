# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; HHSNTN
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=5, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.02817317700610516
-0.18126220275031626
0.05838870823519917
-0.017663580936428624
-0.035872198535085345
0.08872822765938021
0.1066024657827486
-0.0029947977475735313
0.02072365094440389
-0.05246058346700805
0.005540325601002503
0.02907843847000894
0.005986197961779429
-0.02600468647907768
-0.06650134127120085
-0.053026389979935584
-0.07821556477411222
0.02613349533891058
-0.029671965700055244
0.020147263735198997
0.026915123260315563
0.01773415036803364
0.005991438302239539
-0.013214620622511625
0.03267600582895176
0.018443781660511242
0.0107271216924232
-0.04337548501237202
-0.07455660437261694
-0.11080644172517523
-0.06424828067518863
-0.04278081048867592
0.06104728461618293
0.009827027920332923
0.0315197694736762
-0.07765131029984156
-0.04116456317503135
0.10551733278985867
-0.03878436428171693
0.0763696056086389
-0.05019925574303169
-0.004370005062612835
-0.014714523112080862
-0.04539051324254944
0.029925144505629588
0.040593853428983154
0.004414592786094289
0.0999600128424233
0.04793282053243481
-0.02344092141037285
0.02114286812140072
-0.030596172550887955
-0.017982303653342562
0.055798756170796784
0.03937879374812882
0.03323924885106619
0.05388029978012933
0.04220512387552572
0.04815967209316395
0.021114253420785146
-0.020581428467553484
-0.005048437617112798
0.0332839297927896
-0.06195609727994367
-0.0008476659682032286
-0.000956275004670569
0.04158507225511213
-0.02337677773528574
0.029339182412333322
0.007263544311933635
-0.021100325280567354
0.0073484625701774695
-0.10289038460334532
-0.018436972282670386
-0.013680963122448368
-0.002056398894453593
-0.030908286735945055
0.020394353009564208
-0.13937607595399648
-0.012809670995805128
-0.012329782523781377
-0.015502719998657467
-0.0066791060339610325
0.0761694491702375
-0.02069957290913128
-0.004114146278165413
-0.021198130080765227
-0.07422433452295968
-0.018764808034732954
-0.08667234457811238
-0.010830578411661806
-0.033136905314458356
-0.04588204400361088
0.055169390093716374
0.07036541871190156
0.014638298862398369
0.023143940220825034
-0.011439716635489573
-0.00842564703876052
-0.04421814766122153
