# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; PMI
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=6, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.07993298626989359
-0.1862874609963339
0.016377216667509867
-0.14771482856880191
-0.1012245832739739
0.09784628079311734
0.07464529020110183
0.0824205458760077
-0.06814745372425098
0.02546746434308901
0.07520248417975298
0.06613657041897733
-0.10865793860452923
-0.06786940580412021
0.07778312631164144
0.011425377082304863
-0.01433292177005515
-0.044523862760639014
0.08273042851318413
-0.01498255385517111
-0.05185139344262087
0.09836655214308865
-0.09581693631776375
-0.05119378022219611
-0.020176969850694917
0.005779034970726932
-0.010308458791711377
0.0007060869072490622
-0.08520586170958575
-0.04931756764909058
0.18944658702615852
0.11804985936941381
0.0341244231644572
-0.020216338890870714
-0.018452212070404952
-0.001085667454627022
-0.02206581786477286
0.07091084045915126
-0.012230000322112654
-0.060142118334355066
0.0232488801422071
0.05707252143724291
0.02809090214250824
-0.10864937966473275
-0.011697909233133264
0.035845273170459505
-0.08360455171873599
0.03606270707772577
0.010430965918610063
0.00039371828990328664
0.014489954494947867
-0.010213318870590526
-0.0168129344975223
0.07251905384281464
-0.05305067945272772
0.011787815746375444
0.03000725008610247
-0.05435605802497802
0.011422132298861465
-0.015532932284310245
-0.0621175393125144
0.006118818725193978
0.10868390172002541
-0.044738870225840846
0.005322150647727273
0.03729285111975559
-0.0008058353704055339
-0.08327604219986766
-0.014878396423402558
-0.03264983619600173
-0.004699207578814538
0.12952177050125552
-0.00485785104755394
0.03619393910733948
0.14250645445447413
-0.06404405858852069
-0.01507680048103761
0.029404072862158154
-0.10801342078842797
0.03640985390572722
0.024383888443359605
0.04725241655521394
-0.029156578427586934
-0.07868089116713574
-0.01796011511794385
-0.0010133899118036013
-0.04513233894634455
0.026736405464672784
0.013582988240399926
-0.03960742446819471
0.07184919192290487
-0.09388709227472984
-0.05583464354839888
0.020710396895876573
0.037441427941560045
-0.03236302426439422
0.025912457319842045
0.006208474511878791
-0.05392081259365271
0.07356852610543718
