# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP286A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=15, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.006639718890294066
0.003882469327415485
0.003478215109572423
0.010078347274404313
0.006684868582579904
0.004288872491934478
0.0072605620501646866
0.003669720765304158
0.0008962189973780007
0.0032958999856434364
0.00031005157023855027
-0.0027496359863909796
0.00615961735749476
0.003546774040091575
0.006391108176854132
0.0044148053187702185
0.004687185201696053
0.005408983264513826
0.008748935503842478
0.004335553502112741
0.00479283972014489
0.004480841779622939
0.0007423843010815965
0.0023804451978216424
0.0033348519300502484
0.005358168300516656
0.00493077840726076
0.002024629345752068
0.008772127833618582
0.007728002511471835
0.0007062849764603533
0.0053414963724199484
0.01001329039712575
0.0004694090923243858
0.0030488096423179345
0.00747687797922064
0.0032691091693813584
0.0026894237743015624
0.005105139960033495
0.0028264445901529786
0.005560737928023688
0.0033138610820227857
0.0033844897150827856
0.00711291195706813
0.006758743964197917
0.0028698102898837724
0.00390258269139759
0.0015329291320111064
0.004530339659163236
0.003448200934488044
0.0057324203027178805
0.00660849143502704
0.0049195250739580785
0.0055887298343967415
0.000852920371419742
0.0037148922680193285
0.004158760171415601
0.0037864233041490967
-0.00040792331156293184
0.002881758143800533
0.0021565408674884315
0.005795656783135679
0.002579714026680855
0.002285162492416689
0.00826037621778402
0.009058375116903532
0.0059090043516653815
0.006238465005545412
0.007595068725998412
0.00853972242472059
0.00474234928344274
0.00861923128473339
0.0055435919720182684
0.0031881995048005348
0.002757921971104994
0.0031863059641746815
0.006776901831302305
0.01106443753790417
0.007215750257767069
0.006549687161236379
0.007585776893197222
0.013542778181222733
0.001524065513343424
0.012895614835368639
0.010454070511955599
0.01188366967223422
0.010217460136227697
0.01157131492981031
0.015291136315505046
0.017286843534464125
0.010615297002026233
0.015581856982208552
0.009302413754958634
0.010586376651358045
0.008989095228578067
0.009869402682283996
0.014221505842029537
0.015376988360107533
0.01225771131498949
0.011409082900632011
