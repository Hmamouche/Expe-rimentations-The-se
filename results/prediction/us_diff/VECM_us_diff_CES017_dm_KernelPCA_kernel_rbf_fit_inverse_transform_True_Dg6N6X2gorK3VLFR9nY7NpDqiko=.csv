# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CES017
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=3, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.045079699107830724
0.03292028025837758
0.04013433971603893
0.005098289509866525
-0.022157958407983517
0.019399156566075063
0.01740896448736471
-0.006103610513180896
-0.01266403288709972
0.0004369692050078394
0.0019167181619103822
-0.014426536001009394
-0.03965093888125244
-0.03660179976997074
0.016966159426452646
0.0069423074999995045
0.0188368809944631
0.010780909373847363
-0.0004757443871128441
0.02651249749149956
0.007938272056471008
0.03104410033091255
-0.00013575631953241431
-0.02968919186479837
-0.027634114379057603
-0.012290960775649267
-0.00010730552414130526
-0.013995452921217092
-0.037966321768918794
-0.05837876043722071
-0.05582475023704104
-0.0007011254657874285
0.022089917294302173
-0.02330989039122234
-0.02017060760990816
-0.02693637824800523
-0.0195862705313267
-0.007114652223456669
0.001200730891087443
-0.012840260053247711
0.004877354201766769
0.02166396952089925
0.031925089558927755
0.029042242012904597
0.0089485075715899
0.0422736516676022
-0.0019310635122197733
-0.012177212536075472
0.0073314448795598185
-0.009242586340687052
0.006692252523132132
0.022736433017250323
0.013782144010575481
0.027976594274644388
0.004899297407616476
0.015442424515504035
0.025306150702499412
0.024725735724006877
0.012832612107654935
-0.002914785525594092
-0.01821543892564703
-0.004045991435295724
0.012400903020720656
-0.00998835422398421
0.010174426468013406
0.009343995728857338
0.0022646889598518876
-0.008821235831316571
-0.010795311741582266
-0.016805866269574154
-0.03621846336291271
-0.04726943204525022
-0.062967044530402
-0.07950299363852512
-0.026984924683771807
-0.03864966258540642
-0.01635823223502899
-0.05309860809239972
-0.04344229377821969
-0.03343091485496179
-0.010124803071722008
0.01478981023483079
0.001575977064823798
-0.008265238760430008
-0.0052681560158636615
0.0036730490469867503
0.006113068808685376
-0.010704823534968096
0.00747162070347785
0.0045800677575399806
0.014124244177709697
-0.009330693998179498
-0.024171752597854375
-0.014515382523092268
-0.0021587748924756798
-0.004918976881286153
-0.0254881964966719
-0.021816595535599614
-0.036018000534143786
-0.016270908417103984
