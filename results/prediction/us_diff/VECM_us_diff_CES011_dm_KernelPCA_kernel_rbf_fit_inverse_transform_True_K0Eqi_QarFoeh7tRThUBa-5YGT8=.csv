# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CES011
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=6, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.0007452725970957539
0.019393515954054637
0.014268716874505453
0.016396309427935275
0.029920957500420207
0.002069796186662198
0.02989732257493251
0.012593256834951674
0.01317020313225516
0.007472519288750305
0.013355231920032934
0.008006435137588582
0.005768871494149655
0.0007204819334205009
0.0024455625330889316
0.010889778707977629
0.007428198535628294
0.00789406257792633
0.014675647992296353
0.003975766110920773
0.025016564624474734
0.005115846275209425
0.006719660538810027
0.006424612881059143
-0.002125318968455642
0.0011013803407742533
0.011149120150834992
-0.013531971702399555
-0.025429102611781003
-0.028030023378037415
-0.028402424699066536
-0.021861521964032557
0.009702243050735552
-0.021214620160647017
-0.02047975620610047
-0.013968343053225089
-0.007153515508317224
0.0030611677890942496
0.009053741168422719
0.005482907328426552
0.002062385096107617
0.018617656273619346
0.016068662385675166
0.02589349991445846
0.020768257090262456
0.010715634883054524
0.012906156813545516
0.010819397141450842
0.01496380311052278
0.013548482841823618
0.007264902724811149
0.008468414314771073
0.01377064710226291
0.017828159220344447
0.020817435205457972
0.017954428200592808
0.020482825867549712
0.01414348302070892
0.017748256358472346
0.0162963274484692
0.018168607267787684
0.017203501892991798
0.021024614232415265
0.015996065631296966
0.01948528004238545
0.01675886761555472
0.022499143302991964
0.008292971888773266
0.010481430685394488
0.004040131745471966
-0.0015944110114551578
0.0012993493771858255
-0.0077399535694662016
-0.006345207633315574
0.00525484640047916
-0.013007808797976892
-0.008354991571041887
-0.004038818993918792
-0.008297815874675993
0.005811503806502133
0.010244843608388138
0.01946652770231279
0.014844965931844844
0.00896582970075907
0.01018074963238286
0.016648904269222782
0.018341484785658335
0.01911496545374278
0.022948648601660914
0.018284671545015847
0.03304307741359516
0.010089091450598213
0.012892019241674203
0.001604528897800845
0.002664930554323551
0.007130162978505335
-0.016072715335171357
-0.01968834912800023
-0.01879663403338405
-0.03833405018394476
