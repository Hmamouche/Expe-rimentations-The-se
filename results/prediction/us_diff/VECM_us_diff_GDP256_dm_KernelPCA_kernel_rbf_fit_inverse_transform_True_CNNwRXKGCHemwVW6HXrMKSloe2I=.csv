# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP256
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=8, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.020489964456453014
0.004965318988226406
0.032991572133634406
0.03239819478883424
0.015499931861442922
0.002112477958108661
0.020301778237338315
-0.01281365566899706
0.00485829573702195
0.00911755871112127
0.01981841508758018
-0.002252048772885036
-0.003923276074757568
-0.017162902512438627
0.008645193591789275
0.015800650083526362
0.002137178310628675
0.0015728504946416922
0.015106603910718799
0.002562326050395549
0.004682655671439507
0.01161459204694101
-0.0028568197418210937
-0.006429228384220175
-0.010518062097021741
0.004785266229959744
0.003179176589978287
-0.005523036089845815
-0.006365602828715541
-0.03382883050834947
-0.017672970999209562
-0.0034985065871422265
0.008562449114550924
-0.005332556044780818
0.0003579854732601133
0.00519296307008541
0.0003252472235485617
0.028387772095771306
0.026290442644878776
0.003019747136283291
0.020480744765541556
0.017572258906712594
0.022108290090849348
0.025796489256754342
0.020597507380151786
0.02088018343043288
0.006369594194209173
-0.005668412798405805
0.0054522538557473755
-0.007016176588607524
-0.0017817420961743474
0.02250763701347741
0.020093184908527705
0.026162198002033343
0.02865650283565175
0.013273495174642694
0.03800808740051384
0.030762275864467066
0.016341088799134776
0.03419223005368061
0.0062756000567336205
0.002726467704261111
0.026167069963239847
0.022723705962142408
0.013122137413488166
0.026381529997640426
0.028145376306558754
-0.013590580607450223
0.014887188322376331
0.013693573579976859
-0.0011120091350086468
-0.0015027697076403397
-0.024449338001643915
-0.04548902894324949
-0.011457651198854384
-0.00605444358063113
-0.019331053555376374
-0.0017400363728801846
0.002797673366799697
0.013805349226330017
0.004239355389519462
0.03835829494309452
0.032366696739588245
0.009838423803260053
-0.0020394953503231157
0.01459264300977143
0.035422847450063646
0.015628636047212426
0.014499138422428589
0.0003908725792968776
0.01509700942204049
0.0027842521930902223
0.006228046600568485
0.0072913618684931885
-0.011861965073415477
-0.0271077925594282
-0.03598476690498938
-0.019981177564008773
-0.019989954983129266
-0.011992972997996374
