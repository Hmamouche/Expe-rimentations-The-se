# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; sFYAAAC
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=4, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.156255079064752
0.03567273933241383
-0.13530467587741385
-0.08912007360447699
-0.040866019374111676
0.019075018316815254
-0.028350363168442035
0.09661280799540187
0.05694920526418305
0.02154041186887252
0.019729754832014376
0.04331749431964529
0.12381736727804143
0.09888758210764131
-0.0027353390717746832
-0.047459037936796254
-0.05145320709476311
0.0018087049125993003
-0.042668293554668495
-0.05661624368103065
0.0020620592007903824
-0.08057780048876712
-0.0592215144005511
0.04246142436738427
0.01245392795775008
0.017940564040299114
0.013182767275001624
0.025785886535818404
0.011574373715207833
0.03966205414547807
-0.02528276366316263
-0.06015744087608606
-0.018987066699764306
0.051789225001876674
-0.03684680263087055
0.010114642158148364
0.13256133005666515
-0.009927633584667018
0.056410270506210745
0.07592388931323076
-0.02129804061036339
-0.024126962795102718
-0.026136717189563674
-0.04361622764529528
-0.05542824318815598
-0.04954172367293018
-0.019757836832746147
-0.008064815419890892
0.007349508343141648
0.037479873662083316
0.045523641576681824
-0.007098371709450797
-0.026381422954244463
-0.04320733782409449
-0.033009455960922696
-0.002597512239967981
-0.036263274888223326
-0.0035492211984552648
0.01013528751373948
0.03943618761840457
0.06496973994028464
0.0964459745399551
-0.0041560642609334494
0.04718044241521331
0.02751108153729262
-0.049187173444235
-0.04037451487090887
0.06447728427056965
0.02486542793671287
0.047579114414863205
0.0818386278779804
0.031181305505081545
0.04913436228778864
0.01806734889475522
-0.11328880619820762
-0.008951764532116935
0.045564453510521775
0.04085676658519932
0.06315763505028776
-0.030167073786389945
-0.059117508283735715
-0.06365143293386827
-0.04316947282175312
-0.048202333676368225
-0.011167007845786331
-0.013907596946255506
-0.04262570881596323
-0.005030997546764162
-0.038909681932137195
-0.001578172198446257
-0.06490599949735215
0.0072659183069788
0.007502291023461773
-0.02675364723379267
-0.04240339459545113
0.014691526797784443
0.03930425254979895
0.05927237010032838
0.1284746210993913
0.04527054249585135
