# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP272A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=12, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.004636025082165029
0.006835489442069192
0.005505425294178025
0.006028667502352074
0.00636277499860797
0.003581346177959056
0.009342412855260442
0.003940344191218401
0.002805813878722498
0.00629438971419701
0.0038436858946105817
0.001595644751876548
0.005779292915232978
0.004533394711054343
0.004550415259996202
0.003898474726255284
0.006903895485660913
0.005523377483695997
0.004500466176058825
0.006407668753340014
0.006631528235184289
0.007431469184855513
0.007352772227269806
0.00721303615778521
0.00572612272321326
0.0061654160115866274
0.007798551294852458
0.00940124146466606
0.0072485478643406105
0.007795084190733296
0.008449703022479969
0.004696661568790851
0.006670326126972768
0.004418206408359096
0.004559638430427138
0.006085498425414083
0.0022228469505486807
0.004318766007293329
0.007861866500972254
0.004441830776877207
0.006528455350330434
0.004360921180795966
0.00416992099317131
0.0041268179714823135
0.006103239273798397
0.004541196479575873
0.005017041956648398
0.0037372761948083312
0.003746535087041104
0.0057959964614823865
0.002820876151232605
0.004194532220777524
0.004461097485644748
0.004382211515852785
0.0036389469679497114
0.003655340858249383
0.0030174425367718023
0.003785176280308806
0.0008296887662354523
0.002138351033110689
0.0029124981583087905
0.0033346188744254194
0.003340213568058667
0.0032290737182979114
0.0037427609447049934
0.005463319179957292
0.005866920763217006
0.004986465873840218
0.004032229404745203
0.006806791782144561
0.005156321468842126
0.007361076432452287
0.004500091891258535
0.00486948194110906
0.006971881031092711
0.0018304021578131363
0.003819397061869917
0.0062519204918800725
0.005823637442960411
0.0038650333074379986
0.005209478858376879
0.008030798276650963
0.00580231691852655
0.009897976892955669
0.0075250981053447095
0.009074350125525937
0.010023932346576746
0.0068781009502649525
0.009741481632252478
0.010346538878090849
0.008250186962325727
0.010957973136883958
0.006973989554576659
0.00819433436782149
0.009456802726659027
0.005575381462996935
0.008596792104838307
0.008072537402091842
0.005866758112386951
0.0028196479508032727
