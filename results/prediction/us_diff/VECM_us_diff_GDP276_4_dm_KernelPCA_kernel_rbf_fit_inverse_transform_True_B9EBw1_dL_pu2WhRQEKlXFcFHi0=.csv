# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP276_4
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=10, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.010781451526124997
0.003893507608244268
0.0172797219351041
0.00992719329366347
0.010197339328199252
0.009903950326071366
0.0035093920482637707
0.007318467242164724
0.011938754955755674
0.012038843893825138
0.01066356600841254
0.007388627086874416
0.0064026830840165
0.0034684970388311753
-0.0008119744949063348
0.0002525307406371494
0.00445612484551027
0.0014810147750510374
0.004644785339439727
-0.0011415109980143262
0.010573420715882834
-0.0007717053876352565
0.00821272605451662
0.0016592406359294464
0.004260434614832611
0.0017693875678060356
0.006649890919039856
0.0036411634827926117
0.005754658704822795
0.006206367428537178
0.002548705012257118
0.0024599949202514107
0.020965562163243533
0.008405652838555688
0.005341776399273918
0.0016638321697366116
0.002477148964177025
0.006500420513962635
0.004328018477034074
0.007203269557541656
0.004888431094812559
0.008106450113991451
0.005408866275372147
0.008709751562812994
0.008831809240875642
0.005257846089465246
0.0039518259774800925
0.007527104088107254
-0.0030220774425424885
0.004187151095711565
0.0011357146634140458
0.008444956102338355
0.00427326783229706
0.007547504153095699
0.005845889753439306
0.00110379280725195
0.003574088607303105
-0.0005652632428328739
3.619516769039991e-05
0.0025724326418462623
0.0028877867554093304
0.0034050325041441593
0.0027732729704349496
-0.001790613492030163
-0.00013216045444460178
0.0035720563927383645
0.001508310662049364
-0.005459545149187155
0.0005313807363412737
-0.0011199150805764769
0.003111773316518673
0.00046897474894928604
0.001886977561378579
0.005109420302550767
0.0038201373487589743
0.004440736531258374
0.008828290722348586
0.009213595549935175
0.004085869935998206
0.006434855520867535
-0.00503299418375721
0.00983330985007503
-0.0031050825027609348
0.004454172286936974
0.0032704366762107227
0.0010115127656759408
0.004389524115414646
0.0047432814877516475
0.00511248869098956
0.008230460047908464
0.0076436580472870105
0.005464633340711589
0.008200303179271992
0.00532492012915034
0.009668216926346743
0.011581545527886178
0.00735894516224187
0.008202785702718533
0.007068130583087948
0.01088370357025337
