# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP276_7
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=9, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0037012603683347807
0.005471470406770838
0.005148333470900047
0.008520080250618652
0.004983060700934873
0.007362497711010654
0.002578112470726082
0.007532460068407385
0.003430266415432
0.004031698879300199
0.0077627850126753255
0.005745487387412183
0.004936300643638567
0.004932482248334652
0.006655624543476289
0.005576896283841691
0.006200284917346159
0.007254121993308955
0.0031180981118985145
0.006886228118890456
0.004583492755399874
0.006656817619516361
0.010560673872268597
0.006229110702387103
0.00539770047263431
0.007626277552367431
0.008007439038997385
0.009346708968087605
0.010342191822522166
0.006384544297622554
0.007841443902916467
0.010365356199684383
0.00975859841951918
0.006496520999673041
0.004825342432221455
0.008140878570023508
0.007731356026400585
0.00349815104066117
0.00395509735147211
0.006048386869899905
0.007064119828568953
0.005752938594451865
0.0046907847822140435
0.0039345406072041345
0.0034947461680279
0.004655773680954688
0.005234769174871001
0.0033966936205994253
0.005140039593203806
0.005486825341822478
0.005580833227194429
0.007207275629022108
0.007233430935888845
0.005839986165522538
0.005799025287335566
0.006935735278675495
0.006859878907603207
0.00555433040540255
0.005920769057314908
0.005799111693842408
0.0055344318308379655
0.0056395204873382655
0.0061833974952223035
0.00772878726382323
0.00567810454166639
0.007803187458518622
0.008458907981174782
0.009346414012804427
0.008479294046962207
0.009104621565975274
0.008054172320307295
0.008573592989410753
0.01011512030178738
0.0043141320223865085
0.006628697124022493
0.008971616734946057
0.007205301536449068
0.007519881987554811
0.007079840748977958
0.007290906893338285
0.0065542749340606055
0.004999093295789671
0.006425088966032905
0.006887686241237529
0.007410726340254608
0.007892258054285197
0.008088998210304007
0.006556350805528081
0.007311283433775891
0.010414514473903548
0.007816554702133136
0.006847777029818546
0.01097341018492676
0.005677199291521957
0.0011504178133612286
0.003826240915054984
0.005249324688009089
0.0072915753537038715
0.006830251036535373
0.010624943546985706
