# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP276_7
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=14, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.004641182422893461
0.0049391565834522
0.002030640330982329
0.010998289104894761
0.004662552026342962
0.005888277923827748
0.005415333132944041
0.008223279218153318
0.0012866224269738559
0.0026524392147596015
0.005046754934703237
0.005621277685313137
0.0038528293685170323
0.005699207583088926
0.00783891022976491
0.0061463790548755585
0.006498582994593115
0.007221400285405694
0.005086231329115538
0.010931395078852288
0.0019680911670131684
0.005365829711134171
0.00952376247402011
0.005477371664534354
0.004153212033357455
0.00849505721288577
0.010474402482462793
0.006730804820085915
0.011758053950175118
0.0072346494114199945
0.0040283595642542185
0.008324702101412496
0.01006189201205268
0.010074906757282533
0.00676374285780702
0.008093322104700519
0.007181092151383865
0.004537198536405614
0.00464372380470581
0.004121216702550098
0.007259626749192265
0.005267293234063206
0.0049136672743123905
0.005733930147349724
0.004263004959601125
0.004258328378124399
0.005696816822172499
0.00268136301228414
0.004695292266918005
0.0046334521292201595
0.005342454319602433
0.007830006107313898
0.006366537827956098
0.005207932374786121
0.007803778968999164
0.006595465708213403
0.006079034568791708
0.005740365882401783
0.006156703531257987
0.006141022386383819
0.005352656856330741
0.0057806982038723295
0.005980420375195544
0.00798594261133095
0.006093201620234043
0.0076642166493501255
0.009041664757649878
0.008177139178630178
0.008554772086162015
0.009451215547274468
0.007962226292003107
0.008935251595690143
0.009022855441172643
0.0032332405320646077
0.006694597147955844
0.008104553992184122
0.008614146776220763
0.010122556535860194
0.0060151299762122214
0.005061397421370217
0.006415315051483518
0.005910119931564969
0.005845778162348325
0.008571982974026938
0.007053962248923208
0.006285428594666149
0.008788550414694285
0.0067439279634686645
0.007083050995180557
0.010720990223578059
0.007844221027975834
0.0060425755839559085
0.011334041848966383
0.004722987409770408
0.0023436738896160632
0.003568134319677798
0.005886146571848274
0.006250469372780119
0.008813197517012705
0.010460141304589507
