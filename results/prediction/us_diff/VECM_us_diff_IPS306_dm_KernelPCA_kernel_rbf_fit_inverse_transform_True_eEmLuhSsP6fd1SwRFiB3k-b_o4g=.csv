# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; IPS306
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=4, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.012994942732515943
0.030249398241721057
0.01147093621088629
0.011266409135705218
-0.01640205567298491
-0.028066206712948395
0.026602631367979884
-0.022420159375413716
-0.006189474452344381
0.0014864839078892172
-0.016768666401256085
-0.010633306569716942
-0.00421021173894123
-0.005203401816957163
0.011008803642765264
0.005815515745778527
0.019890297397790094
0.04440400808171421
0.024317610689997007
0.02995529617810311
-0.0033786907722619186
-0.003547661856828966
-0.0011196716134280436
-0.018270879665181566
-0.013540257196209892
-0.0031609638532998363
0.0048797095382761176
-0.022539117696074806
-0.0021849254359282977
-0.0175790249879687
-0.013938671769264017
0.0030585527929420167
0.04158937222279959
0.001929608201757923
-0.01102665378164501
0.005454959874776538
-0.024343142608637902
-0.00012292399887691438
0.012128335888331464
-0.014229695472700369
-0.013820916353157735
0.010735109225145239
0.012421321891863308
0.01906831601770189
0.014325775311075095
0.01852403147670577
-0.005084022070098477
0.00414087918317808
0.0042461216347540265
0.004076172310857979
-0.010210682916933143
0.022629820070757416
0.01008820571536502
0.006839754258721073
0.023306684846403164
0.0063349097504957815
0.022244610008434144
0.004920133729457856
-0.013920315609799887
-0.021121312991130327
-0.024014362548002533
0.0009704789633391032
0.006200313696936584
0.031025853229280975
0.026777998198289098
0.037604343271830376
0.00973170180526469
-0.011950864954957991
-0.0002250863424318357
0.009737790613483718
-0.012746302863800463
-0.006936292748694864
0.00943750154688899
0.004245049712156473
0.027900042540490777
0.029278634325453905
-0.004154132055590768
-0.015674672182014217
-0.006292955204350616
-0.036684163655645356
0.008803387130376771
0.010200490978214394
0.03078385337232633
0.018462835234888814
0.028009052341784378
0.028259212722135607
0.037057046408522455
0.028038379519890164
0.011870143964524502
-0.007604479454344908
-0.008735965365596442
0.01129988150061306
-0.0039838169936837016
0.01836986628934706
0.003733376587953729
0.0017382902144841852
0.003597891606689207
-0.002224550499404341
0.011161708510753434
0.011801527399947206
