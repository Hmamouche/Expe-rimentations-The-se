# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; FM2
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=2, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.00910662124438405
0.0030872976597752415
0.008664808287768912
0.004437243948152762
0.004000433115168001
0.005681348602575581
0.007388305561102765
0.006451059440779862
0.006802658242436871
0.006032995186909223
0.00690273444070769
0.007209159004251039
0.006755551753344061
0.006591711974570853
0.0054684404052344785
0.006283584246015864
0.004566826440968651
0.004890856449330568
0.005567912495769073
0.004866805954087652
0.00303649779325932
0.004398344630492851
0.003709436778772437
0.004745482597474144
0.006521013227417813
0.005749754175321878
0.004695544434043063
0.0037929871783357926
0.0067111159443307335
0.005065309802393611
0.006402896921481958
0.003953242748800788
0.0030640577035434464
0.0030671325516985187
0.0038051422329783797
0.001581786463327103
0.0016111369749394681
0.0018275589520100348
5.832160331710489e-05
0.0026343428781958026
0.00023574820385810654
0.0028003768778913744
0.0004074075245190268
0.0012617920811170869
0.00022046880925169233
0.0002476939563513234
0.0011911219423537051
0.003728698883467889
0.005164514723607476
0.003690245206731753
0.005058936775885807
0.004011821944208818
0.006471574395813732
0.005150628158733171
0.005159264218125717
0.005554479714156288
0.006920182928986052
0.006807364421099735
0.009075756837539136
0.008833077831726608
0.009188371252344923
0.012916372956004271
0.009333270920795937
0.00965611317465348
0.008239385747146031
0.009097756656476321
0.009455166521464978
0.009918400439794063
0.007631023026402655
0.009408927094628513
0.015434830547905952
0.014173088357464142
0.014571375904734226
0.01487965169183866
0.01237848666563548
0.008765189125259644
0.015833964236914994
0.013026064950956345
0.013094737720950263
0.01366344857856563
0.012904648969142037
0.002765013619267898
0.010854041403037426
0.008833530591394837
0.009682423553106553
0.013256846971612921
0.00170106684509176
0.012756801381690306
0.008165213659005688
0.01003902077705528
0.011038855622618532
0.007234643081720344
0.011860869190111686
0.01274727026694625
0.012621951366106676
0.012182458765435179
0.012501320460483785
0.01444393049451383
0.01737052119789153
0.012557782754697275
