# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP256
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=5, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.007677634647597455
0.000304941682588435
0.03551951270530335
0.034523350098729914
0.016992654628194555
0.011208388881752712
0.019104378542914587
-0.011445429455162562
-0.004972177652360661
0.00902638045970933
0.011421934699234013
0.0014285434390796216
-0.0074365586641541685
-0.01714836950882632
0.006518960454052153
0.004566904586139236
0.0017898045950477544
0.005247620031038498
0.011894219841546051
0.008516215508984359
0.0056925260639299055
0.0040029130481071575
0.004367332664027978
-0.0022161745554443463
-0.005255786897492017
0.0034293296697439912
0.00447141699480384
-0.006277588677587695
-0.012025753235251275
-0.02359058708988787
-0.019522983217380555
-0.010966292755537503
0.004509979169483151
0.002083490932515403
0.00935483703256829
0.003138061481276728
-0.00251695489649843
0.021534516134763926
0.02339234469687129
0.008366897475145105
0.019789633811950643
0.01724213680647418
0.017773266642522816
0.022806679328258528
0.02798560326700217
0.024195664837407704
0.0036844325547625454
-0.007184685113588395
0.008562327674418103
-0.003871782276965361
-0.001471091930345691
0.021246150774345798
0.020333793559512113
0.02977147107736154
0.02595266517946906
0.01653191442171389
0.0312932821475745
0.03008550560547583
0.023085622824714856
0.023663404081665253
0.007167713395845974
0.005675962404841261
0.026484621368554295
0.022505923227161734
0.014343354795919095
0.02525650266376756
0.025941146785084107
-0.0071036590354687686
0.016838216630975164
0.014488373878823091
-0.0013796377966168905
-0.0050621712339621976
-0.018376766672455407
-0.03841630970295644
-0.01826220051372
-0.01997703731181113
-0.0191583080406494
0.003378011269731457
0.00024259048150339444
0.009068076747528887
0.013547924573537663
0.040047665032975716
0.03246157453787792
0.007074934778322406
0.006518088810965313
0.023485067314815228
0.030685089058313526
0.016426621033812584
0.01582543927965511
0.004174033618095783
0.014165288926702383
0.00351423306217284
0.012540748421608894
0.004070819112901096
-0.018216365536013943
-0.017649746575948748
-0.02455419987031799
-0.01927541224852752
-0.017386469045778462
-0.012742483808146333
