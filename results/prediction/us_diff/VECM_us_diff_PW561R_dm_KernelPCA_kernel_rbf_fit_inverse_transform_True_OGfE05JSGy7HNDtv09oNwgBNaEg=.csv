# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; PW561R
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=7, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.005745308772739623
-0.08607684787964481
-0.030342962285982183
0.02195953903820284
-0.027733148049401853
-0.015627645495769532
-0.010438938491127921
-0.0022343012254098923
-0.024685396759005263
-7.200246313020936e-05
-0.04977287394182787
-0.1114162645584094
-0.0028302184719796184
-0.03782083162664701
-0.039314548136369754
-0.028446315454808385
0.0009422061180289886
0.005514040014842257
-0.026411977271319633
0.03321640136242068
0.003934407871443637
-0.03295705983770579
0.03170941775852526
0.01287613788155951
-0.031417814039275155
0.013174760457183982
0.02148743948197301
-0.05837938691677427
0.011772203142104268
0.06319055401027868
-0.03156562738943798
0.06603812948318834
0.003172867132919588
-0.0009629057503105637
-0.08952514524478467
0.06547374556136376
-0.021613285833813587
0.0009021529924943096
-0.015383854208969924
-0.035170391538532166
-0.03822473256761144
0.015370901243650738
-0.006505385762094279
0.021730343238012387
-0.01157046055765242
-0.0025416431954700027
0.009049281087815756
0.015627969903834804
-0.014936496860145743
0.014073843694962944
0.0006651002833716127
0.001750647418117382
0.007134518111997173
0.024346714583914787
-0.010342579736406713
0.012467328954496974
0.004933968343911573
-0.006598397729727756
-0.04504538058706576
-0.002137640817598253
-0.031818533786725806
-0.033873303219338805
-0.0007872365473991366
0.035282150428460855
-0.0013067400563349678
0.051048219644627635
0.05187390111156723
0.010337820972217351
0.03738976475531092
-0.003904093620943785
-0.020945638733011432
0.02396409576326518
0.010062981331549932
-0.06303346359060576
0.00973112861188397
0.0020901285640738693
-0.02663181490898199
0.004232519944119762
0.03020162636624016
-0.01678262419935847
0.04866339418647285
-0.0026225201924077422
0.033212802722530264
0.0016469289076894104
0.03449673904059376
0.014454893436329474
0.02679369651372436
0.036341322777741845
0.04761924549352054
0.00022254288269690087
0.06721336525480687
0.03253981978190782
0.005840057045586088
-0.0022886843276267704
-0.003984365286280284
-0.02547742998592492
0.035573141837004274
0.03875032138374907
0.061595860548569595
0.19441193861543443
