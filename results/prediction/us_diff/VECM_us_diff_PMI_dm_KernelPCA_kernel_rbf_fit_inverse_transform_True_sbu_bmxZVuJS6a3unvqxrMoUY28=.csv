# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; PMI
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=1, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.03825631135182961
-0.062231605662818816
0.0071579355610192005
-0.0406275570630179
-0.04190443087694142
0.08666667816992762
0.07642375371715558
0.035892320254983345
0.032856275188510066
0.011385501967769732
0.007719163294449357
-0.006669101929977451
-0.024316359327547023
-0.0105722853182182
0.025372421507795596
-0.0171410025419206
0.04744514436300634
-0.025825510348962702
-0.019053934475397886
-0.007238299078403093
-0.04843217553874378
0.0637849091774947
-0.011843463125834942
-0.0059230802616161635
-0.002411498661646465
0.013077242700955179
0.05144099461882118
-0.00688669335301173
-0.019283540945476532
-0.08677265197526753
-0.04324160353400393
0.04510316015939283
0.03993647159701551
-0.021827800718365525
-0.041558896919032626
-0.08852255090117592
0.0025033830845389744
0.021972068747804756
-0.023951503815246928
0.002178721507866051
-0.0009540414112991138
0.018301348499837285
0.0516512447234457
0.07279415512185171
-0.035895154946676985
0.044011150978239585
-0.060275506489071005
0.005893110179802576
0.020293101808829723
0.0065879334015974955
0.05938833333810653
0.039180461169830955
-0.017524845587951865
0.041881716330442346
-0.030826672283307537
0.008841345929321657
0.008325840344479888
-0.012601628845906567
-0.01572703170669045
-0.014649080398831445
-0.007505247147358824
0.023600829042269095
0.04771284381346459
0.02229137197870378
0.033410222505570776
-0.012644728010930816
-0.028859680732510225
-0.04503193924779259
-0.008741978509204891
-0.01993025479222784
-0.009316533204085181
0.014147237797098387
-0.006068632347731737
0.017624208792271334
0.06728872576952807
-0.09577591597954668
-0.009480881803146265
-0.06878110077350712
-0.038816097135950516
0.01840996274314504
0.025252702987877778
0.05017119207918956
0.01421231279083572
0.00612817669395509
-0.05846521938328091
-0.024521872293869457
-0.003537350245814497
-0.013061219730429795
0.06494796301676992
0.02352817298890396
0.052242582213023546
-0.028960676058151648
-0.012545626802090048
-0.015471530412503546
0.021179309915916253
0.009109153096058212
-0.04258652104923661
0.008115387958511388
-0.054380886550807604
0.011904583586925997
