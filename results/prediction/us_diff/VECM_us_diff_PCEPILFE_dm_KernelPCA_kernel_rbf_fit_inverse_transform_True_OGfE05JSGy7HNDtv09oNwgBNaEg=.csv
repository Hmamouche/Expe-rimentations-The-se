# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; PCEPILFE
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=7, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.008059426239391624
0.007950341230086512
0.005986644226344748
0.007060799906446088
0.006874954441963912
0.004148977028187131
0.008279983773804275
0.006163561080907298
0.005975075068710102
0.005508121887410705
0.006159750187356081
0.006965408293450823
0.006879096719166311
0.007102596556875788
0.006007617597696821
0.006410027571828619
0.008141888981544818
0.0069132002942092555
0.009189166260286616
0.00751091639977585
0.009701604419242772
0.008897201549049473
0.008979278182725575
0.0077426368540220915
0.0057075708316997684
0.006514462665561497
0.007623964375397109
0.011338476567421766
0.009603114695731333
0.007431559588554052
0.008087464630040732
0.006299439842622943
0.008266634807653394
0.008365739120604052
0.008936858316075887
0.006676146205214785
0.005975590148092343
0.005800764829695939
0.0062765629106653125
0.004360568973075669
0.006471923674088906
0.004111567656141963
0.005254860373717529
0.006420485020773522
0.0075440037588851054
0.004338930747806418
0.006470873424366863
0.004311377627704877
0.00535822893398893
0.005451878109484309
0.003560001615461174
0.0046355228960718526
0.004130696485288175
0.004234222548453035
0.004454232164662653
0.004918955276023231
0.0032200849235735026
0.0029422825879390456
0.003542868982418368
0.0021979192083209868
0.0033506020120954772
0.0034602921419729375
0.003570256064090737
0.004406977472095159
0.0038187978101134373
0.005038684422877707
0.004735168269368286
0.00466998912259403
0.003057424812017453
0.0035449375601708643
0.0056185288498696705
0.0043858607301775565
0.005620115090953644
0.005068082095524032
0.0052239948141713155
0.0048286022773810725
0.0034421014197846857
0.0042566246901523126
0.003067721991308041
0.0026249724426667415
0.005855806029832319
0.004285436621286193
0.006227697095633367
0.006214871262699122
0.0054326761441697395
0.00536493080997999
0.006391695861996212
0.0064460063428897945
0.005253391394921151
0.006524322785850799
0.006059699426539722
0.007453532232877746
0.006740610840307568
0.006466163460534972
0.007102866567278536
0.0056990987421771215
0.0072044729170973746
0.005597927650942655
0.006151405952120115
0.006814269071862857
