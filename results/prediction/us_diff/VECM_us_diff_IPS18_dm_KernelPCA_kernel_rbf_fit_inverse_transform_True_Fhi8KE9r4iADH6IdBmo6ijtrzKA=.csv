# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; IPS18
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=12, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.018918874960516058
0.009829570764470292
-0.014340658142701555
-0.0006241196035415835
-0.003744831488935306
-0.005860133434585571
0.00952008924839811
-0.0002611570139424797
-0.005461430345920552
0.01119134255556472
0.015698119101410543
-0.0030770470497673338
0.0019527286261841487
0.02021962158809182
0.012081962794658178
0.013526072581336215
0.0035122574419147014
0.000992891896822503
0.0054061463373264755
0.011502101709203943
0.010423340827411115
0.008856266164412306
-0.004006642559168576
-0.00676556818689075
-0.004251723253403702
0.0019061855767592989
0.006738085456643204
0.013195502471511973
-0.014790839894443105
0.0045076795752246384
0.01717112528285984
0.016814788991178938
0.011205492880693373
-0.006352358875081468
-0.0012245334983991755
0.008994082975377838
-0.002229732702148336
0.016834932840493012
0.00543035564426229
-0.001860115058588919
0.005708974214165871
0.011989638525670178
0.01197246750901456
-0.0006619321275231475
0.008377737956095513
0.01111309329760963
-2.6806118802377536e-05
0.002023857670477852
0.006129405754984409
0.004677583205255578
0.005176989781740588
0.016943384533941515
0.011855438227071951
0.006526917862349838
0.0044521551390956215
0.003372992337810627
0.005419455022651327
0.004840135179312817
0.01021670176578212
0.010309229292635573
0.008182301487244433
0.005400201164826044
0.010145285006090327
0.003168141883781237
0.013012826610645775
-0.0020650065595986
-0.0019400996813393589
0.0006714178485031511
-0.004618147047672915
0.006386888762397127
-0.0008799086020345832
0.01206258945613428
-0.0028960865101773647
0.007954242676695821
0.007785400810029772
0.004360863591131982
0.007130155988148661
-0.007447857508926566
-0.0011172981774230464
0.018528448461535126
-0.000703957122698731
0.009546453717277994
-0.005193924687074946
-0.0006510392163068686
0.01368720108021324
-0.002266794201384253
-0.004336640667032375
0.01602445479859272
0.01373835154344984
0.007052913646043497
0.012260525573397796
0.002406826464665483
0.002129524609931921
0.016446049676021483
0.00712899567778149
-0.006635882612004941
0.007186181920035934
-0.0026554959573993515
-0.0003585412826257943
-0.004577860574125446
