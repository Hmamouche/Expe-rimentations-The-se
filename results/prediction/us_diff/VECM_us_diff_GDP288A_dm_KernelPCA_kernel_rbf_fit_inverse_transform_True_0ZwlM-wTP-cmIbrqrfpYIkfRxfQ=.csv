# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP288A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=13, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.004226922378955076
0.007104664035641705
0.0061704232294667715
0.003686977834487829
0.00805113826138097
0.0033171453534561602
0.007500436899459167
0.004473528571406195
0.0033761995490442266
0.0023675811989014636
0.0022292218298730526
0.0006938433824258048
0.006615537244086094
0.007661559197776909
0.004560012929530332
0.005892483086482383
0.005140018789849941
0.004025337033900061
0.004376358449989554
0.005911558228786605
0.0009350490302310786
0.004453509649675358
0.005499390068657027
0.004369489284269676
0.00417228251711761
0.007955169834553345
0.006473809281043833
0.005987221513297283
0.00749998579523156
0.007704915801912884
0.001971908285697667
0.007571906583178729
0.004132510489794303
0.00048438253634961815
0.00037426702511543215
0.0053637202659110005
0.0028665349963301234
0.0036047563504858315
0.006621081165772158
0.0018402208776904484
0.0030226976316700817
0.0012980176617681607
0.00677621958417758
0.003245721854013696
0.006781902089118086
0.002683864742269817
0.004310507667416844
0.005585744886766063
0.0050269903697165216
0.0022969236305635157
0.00570934160311808
0.0035097949427785975
0.0049701515292324945
0.005438363838817082
0.0018633855265244416
0.00454977104343122
0.0034960625867421526
0.0024241511643153086
0.0006041614381086433
0.0033930868259299555
0.002429945252461166
0.004814600278092495
0.004769395396880591
0.004856394017172591
0.005952753170009791
0.008902790489141672
0.00873981322817281
0.006830578160555583
0.008498808126409178
0.007643113237083125
0.005698380892893304
0.00780205975139155
0.004704857641690924
0.0019014678236648618
0.00255168316856416
0.0035192608728391085
0.006099540958639812
0.007702652723141498
0.009975562933675602
0.006303074749409528
0.008269231618499406
0.00992123205718753
0.005484719920381015
0.01124132494276961
0.011079377474067202
0.012691275517361263
0.010271309543664339
0.014482968156726601
0.01733040301062754
0.018432312495833724
0.013609642565627973
0.015377220195061544
0.00698978091320052
0.00983261762717424
0.014323201154563724
0.010498660562584288
0.016104399818234926
0.016363428260162172
0.015437116148265139
0.01662193787168949
