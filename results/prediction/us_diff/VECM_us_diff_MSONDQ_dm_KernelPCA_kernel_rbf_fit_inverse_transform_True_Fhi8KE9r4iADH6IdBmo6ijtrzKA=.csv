# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; MSONDQ
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=12, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.013224537898793576
0.08456359772676002
-0.05235670499844721
0.031994567476250575
0.025961213512191363
0.007516257246141911
-0.04828934639917235
0.051485051998914164
0.03523406640150269
0.007056645316588728
0.08262989516184871
-0.0032660367578227385
0.01078321894301604
-0.055563916127950606
-0.046832701259201706
0.03973753303826291
0.007609321861443686
-0.01619508342853723
0.0002564255798258412
0.07651285774730725
-0.04703187409270097
0.050424037549803964
-0.011842046781373135
-0.021969427204941758
0.04448363266257241
-0.01632610185839639
0.031159329083168572
0.03253906966856039
-0.04799855622341444
-0.012587080858078067
-0.0852389953896256
0.0635534130891283
-0.012965059381570816
-0.0572129424680309
-0.005555079853367326
0.010139511854289112
-0.011818017218176644
0.0013839270307242513
0.025045391240247915
0.04393541502982211
0.03466030880458749
0.02213831769992064
0.033061094639518014
-0.00030599648553365777
0.0018557428334858104
0.004402557061913455
-0.0004667614775640122
-0.0003912119743934711
-0.005523101791388617
-0.009476886845865687
0.03271429481095556
0.07420985684406846
0.03391885867389305
0.011220269574918326
-0.0021563021917097892
0.014617837498057052
0.013710688770204357
0.03411265588089584
0.05827977382052854
0.03983887329081726
-0.017452785911999696
0.007260775680614007
-0.010646635820762146
-0.0032295148887650227
0.03757831035428377
0.036366013162146105
-0.029456713247623067
-0.016827040855701397
-0.025899713427625055
0.04911928961117435
-0.0026754131699830274
-0.008683327674685246
-0.06551226200759816
-0.08285355074923845
-0.0800114579389427
-0.05279136737421152
-0.041234170323326276
-0.02784823542995485
0.013867471327246953
0.03682489745089594
0.026608178116990816
0.060496312494433664
0.07658798621489712
0.006077743419849383
-0.0352502440413893
-0.00180588937145916
-0.01183582366988042
-0.017887494821544538
0.054769024887203324
0.0554667148406271
0.08404590994203612
0.06547401803241704
-0.03555233898114821
-0.0018166567235269595
0.047331274667019946
0.014776187741781851
-0.01733461654099401
-0.0004050074303107937
0.010749420662876843
-0.02800582209487982
