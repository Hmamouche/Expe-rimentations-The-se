# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP286A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=4, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.005697008151480111
0.0030187734184162073
0.011069959716997091
0.010231834370931335
0.0060844472740808
0.006332325476386145
0.00510142910572391
0.00251266369594902
0.0028758899640048663
0.0033304347103144632
0.0017475956213335393
0.002042342293061384
0.002575623824421481
0.002492633232822169
0.004800163379625669
0.004787659688608843
0.0047460920467186085
0.005627265129561128
0.00247800794842689
0.0035336466487544725
0.0027408936636661835
0.0037437658824513898
0.004781584789282003
0.0036485808458800225
0.004720022121862056
0.005020399136145132
0.004824766600073766
0.0054624396408664
0.006563444031536358
0.008357202089778673
0.005192293002579571
0.0054406423737820685
0.006637337860492309
0.0034084120995356883
0.0028965524701904813
0.004216303401835091
0.004073044166349018
0.004523077072120492
0.0033246272692867805
0.00334352281032706
0.0038765701929071284
0.0037586638133853133
0.004574634777484897
0.006521260630736512
0.005724609572402193
0.005665310864487886
0.003456849131972366
0.0038279048995533537
0.004429458791873688
0.004661635249213462
0.0049002805479911185
0.00450683860139445
0.005994937708021161
0.004149017361988812
0.0015553180318490856
0.004775696397828406
0.0043026108948049984
0.003945002086251273
0.0010375569063866242
0.003111525621857267
0.0028434792616374408
0.0027436781178974273
0.0030287089977664916
0.004606733454759078
0.006363772232013907
0.008576719211579278
0.008377848735295625
0.006622630226033449
0.008403065492871675
0.007852135389791145
0.00418896098039474
0.006358373473244436
0.004095138545416202
0.0046379912946546455
0.005295669675809852
0.004839057548524995
0.006226198784577629
0.007270482479176015
0.007459032065711042
0.006862936708942249
0.011732881190523738
0.011054596081764363
0.004161534669908304
0.009902993499386661
0.009993488737035885
0.014089314229025984
0.011191225430953081
0.01184592495090508
0.014205134167292662
0.014861663173142171
0.01107249339177532
0.015919251453766856
0.010436373819188358
0.010237620142063454
0.011017806612427038
0.009943612866755472
0.010311614152839817
0.015054385674083572
0.012753635998118476
0.012923775331504699
