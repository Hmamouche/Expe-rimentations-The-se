# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; FM1
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=15, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.009315898441646148
0.005873234890912374
-0.003047942086007057
0.006814288481139487
0.006592724759881732
0.005978449324840526
0.006257845982402536
0.007844160949459498
0.011548222142088164
0.011598965884498486
0.014140175656117148
0.014055883296140263
0.015642479917339393
0.01535748603557545
0.009582207291521764
0.012407066637518043
-0.0025330599388067613
0.013079634559855505
0.010595354392187187
0.010906552326265428
0.005341789627877101
0.006279099644894477
-0.0023549262273690292
-0.0009255273353954031
0.005129243070016281
0.0058156343026046385
0.004932756997062787
0.004148816846459054
0.002409628891362708
0.006569272207551649
0.013793392442890066
0.009961935644854075
0.00559889289383559
0.011177130678155105
0.02118690537296319
0.018582961729204855
0.017327213985264826
0.02368647149265745
0.020974852810837063
0.01885422559284811
0.014634997978813416
0.021296559922051612
0.01465658628247683
0.008463993477969084
0.006125794844145291
0.0016405253529980924
0.003712842777411774
0.00021309520263906433
-0.0005771576626354808
-0.003969518089772105
-0.009341588002446704
-0.0083044772748616
-0.0073693934750821335
-0.013877020377863295
-0.007759339572596885
-0.009203487467644605
0.0012916807550771659
0.0026205536345610923
0.006470931727111962
0.00024351097192329473
0.0011603355366764637
0.0058954258498209134
0.004922655536130015
0.0018132372791572822
-0.003980040580326234
0.0004976049680037731
0.0037932734486303887
0.003867441572378288
-0.0036228826807913703
-0.002357057914724266
0.0046895532380515975
0.000887748036510524
0.03319364417375138
0.014540841915261463
0.006529701016619498
0.006677696857566815
0.00888180001144401
0.009458187591317353
0.014467774204148371
0.011866660222970601
0.011513790037145448
0.01252134896637775
0.017744495049998227
0.012442542032146151
0.013229790249218372
0.010652386231116327
0.001825502619639921
0.0034995539304003365
0.0009714815848739608
0.005556776618922668
0.00237424243942495
-0.0012015613754971862
-0.006070763661142506
0.0011861386450301666
-0.001791478429202544
0.0045112590552028
0.0034178953811896512
-0.002193538718356523
0.011218691372248386
-0.0006358443674745204
