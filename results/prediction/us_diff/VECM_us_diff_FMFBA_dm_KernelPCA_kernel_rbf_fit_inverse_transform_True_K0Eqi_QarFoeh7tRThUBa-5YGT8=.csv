# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; FMFBA
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=6, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.003113778020825881
0.0018634798819560318
0.002629685091487178
0.0019521699149957171
0.0022042228017523165
0.0026938849388924565
0.0022348668619165445
0.0026132501095046975
0.003246599599295888
0.0031179796099694763
0.002798996003586648
0.0033700941370537834
0.003460919042910834
0.003592475448130493
0.0037913513105240415
0.002692930151649173
0.0027405322832185844
0.0041187296576064595
0.0031088551018223633
0.003558871251242002
0.0030734931299705075
0.0032716953049367636
0.0022727035752163577
0.002275201244696981
0.00247309511936191
0.002245883047242082
0.0032756358396597053
0.0036702321806562836
0.005260172242365868
0.005148600759986972
0.006388254609947662
0.0038518539240096953
0.00263666356336289
0.005848374438274859
0.005326686058442348
0.004241178710235106
0.005732160485534817
0.006509347608686518
0.005824946109199924
0.00695422295592007
0.0072576952493085475
0.006432618719967826
0.006796364897496
0.006901009026930246
0.006152921812494499
0.005231822135231179
0.0046021891055964695
0.005392496903072877
0.0021519752214520117
0.0017750883842254156
0.0009630105219044833
0.001614311800491128
0.004130656066010614
0.0035732488544043504
0.0039024096108588725
0.0035333090743468482
0.004812839940845273
0.006258946773385071
0.0054675687349396455
0.004294930708085205
0.006875578383989495
0.00832258775784364
0.007001757659938327
0.009603229250746994
0.009347537554717638
0.016377784913002937
0.019192924104074107
0.010420389764842325
0.019143933151444886
0.002572525856387762
0.004824466884002646
0.003672555661980879
0.012834044641909716
0.008344925134852473
0.010520068670944759
0.009404825082770392
0.010707756286810092
0.006385002928225689
0.007958642014015556
0.008809458935010868
0.005135788189379578
0.007930662611756855
0.005155010822131553
0.007256413569446684
0.0075811903458116595
0.005425976589035397
0.005434667626028762
0.005866426297132625
0.006263136206961767
0.005960306757131711
0.006594993942532906
0.006217256848356089
0.004966731619724542
0.0027813012984557114
0.0029733648311241175
0.004977690389549366
0.004591692162949029
0.002619821394393845
0.0021468849479583277
0.004504494623738853
