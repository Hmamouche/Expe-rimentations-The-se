# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP275_1
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=7, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0010818033464429027
0.009303242466155343
0.005914876845932735
0.004647677030881045
0.007348176759867353
-0.0013894109260073255
0.005364935245887857
0.0010965724721582384
0.003101437549688573
0.002988020340501264
0.0025953074411850913
0.005548498369962136
0.009659263685910833
0.001486429913536936
0.00789739717658013
0.005407543156048683
0.006950764772896865
0.005944717901919774
0.00209285597668123
0.005443818934875129
0.00805165200946722
0.006629172654994327
0.009894180170301138
0.008697210991755338
0.007065385863493184
0.008483341089826249
0.011025351534458702
0.004974146292215037
0.013230397230354476
0.003740457650671529
0.005118226089680103
0.00591754824938327
0.00606620638160437
0.004273889468522162
0.0037697581980438164
0.0026188004482792524
0.0027452262920891063
0.0006084476871412309
0.003383657781559663
0.0015907779337229508
0.0035700149659695537
0.0036053767765848142
0.002269411245058167
0.005005209929817831
0.004860849974162846
0.005332167049629313
0.004638994156481787
0.004441078198805355
0.003914578795209506
0.0034979090246496205
0.0037223092854571822
0.006287437294259504
0.0054000659231721
0.008846982378712627
0.006204875785687313
0.005016562943088108
0.004231016002922992
0.003344721010102783
0.0038513939981244813
0.003924525904884009
0.004178515970150437
0.00504377879856305
0.00309031150862492
0.00510631887225701
0.0042875696817095835
0.006340924073354506
0.003575166687167857
0.005511780088649062
0.0064981520998024875
0.005159825989608347
0.008521744871123298
0.0050302023327594625
0.006981190220514315
0.0054616210655282485
0.007469704215825628
0.004271381501927854
0.003328887898744987
0.002126305300106111
0.004264681145209893
0.0031226211574060664
0.005217605997452378
0.007750457904805718
0.009025348049567297
0.009412860786053969
0.006837707048683199
0.00725563114861131
0.004205569020167693
0.006373912605184837
0.00435543369505271
0.00792214229275599
0.0046828425694888
0.006424274984561811
0.006598587495430786
0.005052536588526348
0.008153628063680638
0.011197040393664114
0.013435487237062536
0.011851833454773279
0.011284583834224461
0.014422625994748401
