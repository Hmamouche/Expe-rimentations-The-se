# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP275A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=15, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0028120709707379933
0.0005924056535791282
0.006491820747315214
0.00883395747689998
0.002190062997602992
0.004857478163104982
0.006219338138503576
0.005119172491348575
0.00486389238771545
0.005253083630701605
-0.00045450623199092335
-0.02082353884929724
0.0015678755959898066
-0.0029405842496801797
0.00488986260538869
0.008763615511259384
0.01091100994563001
-0.00025694078918791574
0.012217184032827134
0.006523339478116308
0.003303556170798508
0.00533694173123859
0.010448874003101287
0.009537416784892552
0.010120285320218156
0.014293451988158595
0.00892295185743764
0.007297530300584494
0.013602734486908078
0.01212277014587006
-0.0006541259171207172
0.011345594556849197
0.002758088548786653
0.01686928158504611
-0.00815065970790974
0.006830503581953597
0.0012236663261460327
0.0007168735959783776
0.005682460921893723
0.00029365634416576186
-0.0007093142215096162
-1.334911441521684e-05
0.0010332847894744613
0.00700900780312249
0.003257095933205051
-0.0006730852213255689
0.005091613952283167
-0.0038300475757764973
-0.0016865854672713646
0.0016604346119511713
0.0029396529607890504
0.010449274777282316
0.006073151107857336
0.008372136737944711
0.0013165404331738787
0.0013998904733797334
0.004904856981852255
0.0015618164875769351
-0.00315687914219425
-0.0011837085441046876
-0.0028305467380915286
0.0012209194764096335
0.008375601792704482
0.005276764042329849
0.0073826002706087815
0.01227581989787396
0.007655166369936432
0.0022377142949557612
0.010409393124943243
0.007179524167428838
0.005291859169450177
0.009295038765379494
0.0026621016977840745
-0.0018525640709714062
-0.0035388692647318055
0.003120032887492355
0.0016907745917180863
0.0009557567560495618
0.004050740308858557
0.001217542354466204
0.008040517132402357
-0.002016389193308512
0.012818538874619409
0.00835197157942337
0.009012379320933671
0.008509276418083068
0.0035650493829129486
0.011673833377821347
0.009675452760069049
0.014243915280508366
0.01822324939885423
0.01031359369757276
0.004720533253026727
0.00848382966505468
0.010105568750715072
-0.008862652224209365
0.02226272573747633
0.01274241785446667
0.021231751445522244
0.013928764413870538
