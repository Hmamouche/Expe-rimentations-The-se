# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP265
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=6, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.006106506290827716
0.006979377940402159
-0.004895572975278327
0.013602143058994104
0.006072526801906487
0.0008891204144857853
0.024184736919215268
0.006270622265668294
0.02361507214151142
0.01807189171533176
0.011811137404858632
0.015010118765807774
0.01936749615995124
0.010173149858492244
0.012515960858291438
0.012808236066374238
0.003157516633873505
0.0010891514820335275
0.009995686641189907
-0.0004475248162381703
0.011128664173161478
8.655179809403815e-05
0.0038346671569546424
0.0026182821317385593
0.011489993940689086
0.006823509506630012
0.010554930811415581
0.005881832821939928
0.007347751148836068
0.012025519343434082
0.005564505067486054
0.007715185687944609
0.009517220458183697
-0.005207308429791202
0.003576815776846755
5.819405923760735e-05
0.002269068326490262
-0.0017515854777311393
0.005200298412200485
-0.0018455279290715996
-0.003584339475477242
-0.001204632335495777
-0.009187788823998972
-0.0010792938987260708
0.0046244985807470575
-0.0030811722094331168
0.007041247331920856
0.003191805724582825
0.0023925843636755824
-0.0020919375188891004
-0.0036906658796332075
0.004489828946361867
0.0014415268794807663
0.0018714900381000365
0.010963300901934214
0.003932418412135411
0.0034069344461416613
0.0049137221513360484
0.0035557053311658722
0.001966885411103952
0.0078900290351871
0.003960052364608836
0.012622304364240106
0.012880578472606177
0.011975901023088712
0.009829275575319336
0.008807438750462962
0.009761607555894005
0.01020097111199049
0.0030650337119693745
0.008372117200906363
0.005292316547960162
0.008390427256614335
0.015332676545294615
0.015457864664491812
0.012777834858993663
0.01929011175298398
0.009907780638049894
0.015655620778424632
0.004495586284841705
0.006356714915334958
0.009667958696525706
0.0019181484441934374
0.008940958026066311
0.004065689230858762
-0.00010604157033789136
0.005506903288887841
0.000591880800345247
0.0009959779507902134
0.0040796136368591186
0.0028617482430324664
0.005274437754730093
0.0077554210544195
-0.003087807604853451
0.010462408249978475
0.007127676700040671
0.008429963218901881
0.012149470111629111
0.012753916484760982
0.01089758179747282
