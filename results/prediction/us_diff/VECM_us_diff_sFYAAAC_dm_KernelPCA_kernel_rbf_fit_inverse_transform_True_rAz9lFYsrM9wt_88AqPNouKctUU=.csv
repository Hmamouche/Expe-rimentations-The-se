# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; sFYAAAC
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=5, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.22742044241075304
-0.03506058477846162
-0.16466953310479499
-0.10268937343869006
-0.010987073066015055
0.03454286261818966
-0.024942383667277128
0.07644137026196139
0.039018766263500676
0.03311795929739557
0.05790631439939199
0.06029448152135488
0.09315425949844952
0.06854592338933337
0.00045036109718239997
-0.0240959752686575
-0.015201283867293261
0.02163748456035145
-0.06801269609698588
-0.10571995841861956
-0.0041334764177879835
-0.05044875284248613
-0.09712324344364776
0.04096104716725523
0.04756666622112256
0.006094610981315609
0.016212557744012604
0.01434735636958801
0.007836129846869563
0.06738471558695548
0.022899516407655692
0.0020167517063874076
-0.06377240565258913
-0.01350047802563887
-0.038663694543610086
0.020157265184345814
0.14672805296501593
0.03334506847896787
0.062091408976847624
0.03347600506027578
-0.045860144188842704
-0.01887803771987393
-0.006168568767824491
-0.04348190221059468
-0.08644116349057683
-0.04673368703641369
-0.01527551926043217
-0.022818041541525856
0.010111560700038885
0.05752519517912295
0.026410923527404744
-0.008676686656317344
-0.00930079407551317
-0.044937839965757474
-0.03797694756225165
-5.352395079955864e-06
-0.044638520090173994
-0.03859410492121441
0.01149213175581526
0.061868073046249146
0.056110227274819714
0.09734940811102243
-0.008461262086707454
0.023441032758146192
0.037057075437228124
-0.03969768533159379
-0.0518225362799211
0.07105663909941488
0.048796842011326176
0.009698623898093322
0.0609677290744428
0.036777715753943285
0.06374055556186588
0.04414497009936133
-0.1385788445846754
-0.03495313988086571
0.10344032094990999
0.0822787330406511
0.057684280406325006
-0.08441429942946616
-0.0507603478961068
-0.03897459200524295
-0.07301185459919034
-0.0470970311358723
0.013124350135630337
-0.027091598793242282
-0.05727931509584638
-0.0004114028080882521
-0.032606251388679085
-0.00541417773801694
-0.06042403227023461
0.010718429627465881
-0.010650500446503968
-0.009453328955449997
-0.028529407578172808
-0.019795593907979345
0.04021694449301434
0.07652285680376388
0.10865246856929614
0.05629344001567642
