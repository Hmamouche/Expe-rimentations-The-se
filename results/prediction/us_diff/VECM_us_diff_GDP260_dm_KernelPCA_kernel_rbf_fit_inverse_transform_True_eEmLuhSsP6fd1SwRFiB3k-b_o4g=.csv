# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP260
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=4, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.013718668418418126
0.007765902186064788
0.01688196389121812
0.009369834044529346
0.0051497352346579
0.007680432135050592
0.01046880139726519
0.005799933934074809
0.0016455894004397983
-0.002944235339299763
0.005828337489202112
-0.00019960410218522028
0.001976515746003541
-0.0037886150705216735
0.0028680044008706157
-0.003581255204841464
0.004283737640424034
0.0032139569115171734
0.000964690112431035
0.009719819194563412
0.0036360770029729367
0.013130257410611988
0.0028671346140257932
0.002873595101230108
0.004225133504554992
0.008220203961408667
0.004237241796795127
-0.0010505484511951191
-0.009874358142380761
-0.004057101313625451
-0.0027345602235865516
-0.00303153259337032
0.002753517384216359
0.0027325199313783777
0.002249606268557374
0.003745338159417644
0.005697760837731487
0.011186689275294313
0.016275504511500092
0.008939552421134343
0.013244346035028548
0.013767807428434628
0.018814951183579093
0.013099906576656942
0.011929110066575948
0.013991338743978487
0.009326971806372809
0.01563134840043375
0.015913300775603243
0.013559985291692198
0.006942904997514966
0.008451195786280974
0.014878507166100858
0.020284447211687102
0.01811174260887684
0.02163685031331143
0.022718867616971415
0.023242391749909077
0.019258982772827296
0.028035686068256918
0.013977955163986174
0.0159883139905946
0.023396178852570747
0.020152662789066526
0.025702949828720713
0.03381422970752025
0.023099831484473962
0.020254970068537347
0.02002482679360344
0.018104248619620626
0.011536988682070454
-0.010792924118118111
-0.027822424098639647
-0.030720228082923996
-0.019325666249884868
-0.007385492118025201
-0.011048706776831512
-0.004168420668811446
-0.0002955462176126532
-0.0001367908333481686
0.017336676174036326
0.022771865327074616
0.013232320998639052
0.012054691969440616
0.012071525352649954
0.024897534754248194
0.017317052976347856
0.020164332890601766
0.02335362748833975
0.01479455523979657
0.026180524695404956
0.016880024118766226
0.015077418486517707
0.008124934500823855
0.002957817382003107
0.007451566926383721
0.003811706368452575
0.00254370432893206
0.0018854344336305725
0.0005595513631077749
