# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP252
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=5, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.002530440633623377
0.00270705944736905
0.009169409772748048
0.0043368250788472125
0.001525447668095012
0.006322775667270607
0.010544490408589869
0.006868746437687591
0.007975172588065843
0.009331878731787906
0.006600880693488653
0.004307567392979388
0.003944790634324774
0.006003523902862575
0.00556396780895942
0.003860209151920119
0.004700346041526031
0.005180588111001721
0.004696473231606008
0.008311116407170733
0.005008801408547256
0.007031991171775039
0.0049740785015981274
0.00266289485729139
0.004794928630245044
0.005817989404679851
0.005013868757795834
0.002896466973239424
0.0028071710137988386
0.002083213785332051
0.0010601119053196733
0.0018026071992840473
0.0027929879625926777
0.002002259693995611
0.004124999332689984
0.0034426186601841046
0.004739257288281911
0.006813393541262948
0.005847158883736034
0.004435255835387359
0.006300173675899817
0.00928389078585362
0.00875432038972682
0.0042474153280465015
0.005785339508514548
0.006764518562892355
0.004095443386407318
0.006652698924969685
0.0064695948427039695
0.0071968375231149465
0.0064938274727424925
0.005580459477641084
0.006815800341499625
0.007753133836334092
0.006207108772665483
0.007726149681247983
0.008842399842768078
0.008821529207180526
0.011637224933829786
0.009348871137043793
0.010160163364078831
0.013297146736446478
0.012239408344590598
0.009873721670774677
0.0101850691366208
0.012793712735892686
0.011889407675671414
0.011915779847410324
0.010377414941291402
0.00892101882280106
0.010084764989360746
0.00820689873400245
0.0037222620522677744
0.00513078533454287
0.00833918542295189
0.01113738802794403
0.003997129398980743
0.0062021728910047575
0.0027308579460080884
0.006092374541777298
0.010043121165400175
0.011779729129107604
0.011314352751987212
0.006938577386554703
0.008134521363721604
0.009368774177973903
0.009111818428572333
0.008350705945677123
0.008194330937094214
0.008467288837947996
0.009792118942202367
0.005689761314292644
0.007302755253529562
0.009327249000715297
0.009757684850249
0.010767730803253826
0.010061728027090187
0.004041038917911521
0.0036705434792776034
0.004232827314423438
