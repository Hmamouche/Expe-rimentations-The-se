# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP288A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=1, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0049493841995723546
0.003940149621663931
0.007350656314590106
0.006246525031701404
0.004718968725730159
0.004438270723631207
0.005756334511495043
0.004688100725345147
0.003494111819878466
0.004655076915991169
0.0031656321055880576
0.0021597440390171314
0.003988841056907623
0.006164693019360161
0.006145012743945631
0.00520912433397771
0.005334114112018101
0.00306747635243135
0.004099917584349412
0.005345555740796356
0.004697429064023024
0.0037551754537775354
0.005107034048456838
0.005199938771894872
0.0034567282715522603
0.005996324042043796
0.007845892984421591
0.005339270978609173
0.006722745477610612
0.00779514710462304
0.005023271365833893
0.003452201341547072
0.00401253072113179
0.0014471502207722613
0.0027195212819153313
0.004401815123539117
0.0030275860542475536
0.0033186663261824145
0.005341008732440354
0.0034997821010724697
0.003268358604510868
0.003460378060572873
0.005500181239712505
0.002741390663106501
0.005628997393823201
0.00428013477149981
0.00550055999260868
0.004766600739445789
0.003932784507031297
0.0033313161303423766
0.004932533345424317
0.001837899921294185
0.004049848664464834
0.004181583839424826
0.003228557238838756
0.004037823097004602
0.0025914346309754643
0.003606321382087817
0.0015945832250600608
0.0031541574134963364
0.00385520121932526
0.0030132692185854946
0.004031126615702685
0.0059686125860423135
0.006372886342125755
0.007792128838292315
0.010857184599044063
0.007881146263193459
0.008603265085138501
0.007518296776506478
0.005979044049547516
0.00593580881672821
0.003922346460697557
0.002195067987275828
0.003339766112355641
0.005680420670570744
0.005710587051939314
0.007154787024286105
0.01257521513057997
0.00762438316464726
0.008504451402626704
0.008216499067980224
0.004893869142372722
0.009324210014176201
0.011033558599771892
0.014353581196891944
0.013574773119992601
0.013583291922576634
0.016692757677808628
0.016332477803240698
0.01337944231603953
0.015262842137898682
0.009165145832481646
0.007823302238062208
0.012628085460156016
0.01207334898987085
0.012785254339672326
0.0163569539057872
0.015655339719253387
0.01846732019865458
