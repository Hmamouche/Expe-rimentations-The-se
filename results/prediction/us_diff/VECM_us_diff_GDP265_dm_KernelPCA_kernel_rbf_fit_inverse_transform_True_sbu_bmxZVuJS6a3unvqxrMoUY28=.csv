# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP265
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=1, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.010542127069035736
0.004182074219677964
0.00033250415583524267
0.011667157537289708
0.0030340492259631454
0.00645616349984658
0.015934199511819937
0.014260257264413666
0.016764555763225743
0.016497114248051517
0.01408550768863593
0.016522826433905104
0.017153872699609135
0.011043441078855113
0.013007964021386256
0.012338381824467908
0.0024652853113085933
0.004650524071633729
0.003072395733286485
0.004793610521088302
0.005245500869633979
0.003324117513279901
0.002247055040703715
0.0031601262154786723
0.009850807581280291
0.009053359335142248
0.010242084221836768
0.009761825998909374
0.0047637377028064525
0.008236564925993043
0.007820999611086593
0.005523226341472649
0.005506156653983182
-0.0007935047956086367
-0.000205751845144171
0.0032675259792168615
-0.0010600923676295912
0.0013823437162359994
0.0030290397918587134
-0.0014697562998600684
-0.002717734917744156
-0.0012365893541549156
-0.004617670206571986
-0.0032382611164114778
0.002606028784726263
-0.0003689075556488992
0.0025125868098840086
0.0037866423837675457
0.0037992532444801825
0.0003341442931643578
-0.001789666104866197
0.0012035356357400157
0.0003470353685486176
0.002541679473654476
0.007840321675729804
0.007199346564620427
0.00457499119670205
0.005263493357211454
0.002630985563015124
0.0037315504730606065
0.0038779447788194286
0.006660200738578373
0.011457961635435861
0.013019865881683686
0.009256790853573437
0.011289934169062318
0.00943776524734397
0.010203782148160926
0.009062632825327764
0.005218445587948541
0.004018523397362184
0.008256659583464592
0.00937148697136935
0.01350199944367654
0.014058121348337425
0.01629350187880644
0.012062295309934738
0.01336264936576774
0.013763529532406874
0.009971324427498774
0.00992821771124494
0.007014069575103535
0.007825659249568667
0.004114426409474542
0.0038629917852352094
0.004461709388457106
0.002668191619355774
0.0017699112745270212
-0.0006127833540267077
0.0029843011308825548
0.0030371196920593283
0.005256195555634542
0.0038939610995849814
0.007456548102150886
0.0068747497359135
0.006468280609655441
0.008612085351861639
0.00662446070736108
0.010654524867056503
0.011203219938269376
