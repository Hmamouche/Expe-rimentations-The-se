# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP254
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=11, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.007385439189852599
0.005375469200727245
0.015589774197857557
0.002850298750774822
-0.002907241737268574
0.005036447326776663
0.00355120944098102
0.00333880284350557
0.007713517959329619
0.007502264988002257
0.011245474721209426
0.0109274467076035
-0.005221299043478476
0.005669317232248859
0.01097417153345072
0.011921089795157049
-0.0023019404628905225
0.0024427656477653253
0.00853579189917896
0.007426553765086496
0.006131666237141578
0.008696839947381355
-0.0018244212738188774
-0.00298776788665449
0.0052151936434340134
0.00712164251319487
0.0024246499338436917
0.0021711885633456758
0.003967696969456908
-0.00453791275188542
0.006643516580554468
-0.000207328580224942
0.003158365644285342
-0.0031006730499713014
0.006903493535930552
0.0012211338931947633
-0.0016376891599655125
0.00965797306535484
0.007924213412641642
0.0041831114034180175
0.008157031712641984
0.007223134678377767
0.006422348906235354
-0.00010136030804338333
0.00905990204233063
0.011782523038067826
0.008000140532109564
0.005633330592216428
0.0071903232038398835
0.0021867988865451604
0.0009666872052542148
0.0031620984994106694
0.010421146238198117
0.005827347026335434
0.007814165797102354
0.007955518687592608
0.005273235363162651
0.005447927499619791
0.012833779546634732
0.0057583086121034315
0.010081542769375685
0.00961031404650296
0.012715582497982632
0.01059259352259668
0.00845713301649817
0.014256249163404199
0.012770951496109564
0.010104298488881404
0.0070612949985050105
0.008709242984217783
0.007592677904284435
0.0077038987608573205
0.0012783159565676998
0.007011919051262045
0.010135610875742553
0.006479984621407853
0.006376848941343058
0.003815552977194307
0.005094274086457486
0.014038991260497898
0.008687884002666447
0.013169051693586105
0.014378783928026169
0.00790196138886162
0.011426283614750168
0.007967666050634778
0.01083004867175261
0.009377454259800954
0.008267501313575497
0.010907981043883054
0.019601884791363645
0.004299345520037788
0.01187409025979111
0.014195502368007273
0.005850118411323621
0.008965323499999636
0.013525106669812204
0.0005231377639360139
-0.00044717768931271844
0.004336385622692207
