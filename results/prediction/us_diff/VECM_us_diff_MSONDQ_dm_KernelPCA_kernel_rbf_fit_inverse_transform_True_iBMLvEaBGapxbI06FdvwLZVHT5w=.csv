# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; MSONDQ
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=15, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.00859234778998215
0.1458012541936034
-0.03216614458241651
0.00886553436734526
0.014053159949917654
0.03736406459509577
-0.011874748470514479
0.02071751833992985
0.08257042321458698
-0.010409056518933493
0.07624488859367079
-0.00042535740880381145
-0.0528969787732776
-0.02683393389320627
-0.0012038321591752756
0.059467141814687124
0.01570109195562834
-0.07800092269807637
0.02207762331821084
0.04646838095759397
-0.086339637558454
0.06254761691105419
-0.006325765677612439
-0.02626314165252356
0.06667488697212143
0.0004861288331559771
0.03532024359929272
0.031408508847539304
-0.054868858731517665
0.0008262985531931871
-0.061143613409802636
0.08098138919239233
-0.03493695521395569
-0.04377562415234645
-0.03166356370552954
0.01979263428288426
-0.008321576548086032
-0.019982094368385425
0.012799654052846589
0.020060343545480898
0.02321390839251633
0.03551970145769113
0.0425735214641674
0.006941569836835665
0.010883884920617315
-0.009195577324106481
0.012486216577335911
-0.014822567689762721
-0.03367693969539949
0.002065975188806697
0.03108717649491033
0.11125671426021466
0.035584878230671066
0.023985206591291285
-0.0006374302898071622
0.002725652136568356
0.00547090819603779
0.029674549801167446
0.06483516833618932
0.04101916177669637
-0.02556461769716005
0.00721338070100392
-0.009256454838748346
-0.009682820736764821
0.05500693756707757
0.0662856657105638
-0.051670248594012085
-0.03496165824750716
-0.023964482554363987
0.045752113092278245
0.0014527027682174135
0.02976944605765912
-0.05875434067509254
-0.08834945975681531
-0.0905299074469212
-0.059759883718440335
-0.033090765103618934
-0.0465186630001444
-0.0016050757214367706
0.03464514805450997
0.024018273115177687
0.04502351794960402
0.08566122012428432
0.014388078171675218
-0.04051818386410686
0.00030741927111671563
-0.016234507785152903
-0.02519023638459689
0.04620257914963142
0.05494256702154953
0.09286112548291206
0.07424844524305553
-0.035746470826406376
0.009726288075300807
0.042662874251075227
0.005365201924714218
-0.01689803352857767
0.004155942321995851
-0.00046519422987120404
-0.013757909895217245
