# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; FSPCOM
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=14, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.008116185926167578
-0.015658159780255292
-0.00013246964808196816
-0.00663203999234448
0.006402239034098365
-0.001117606335718769
0.00355875955859673
-0.0012007620596932497
0.007089302147477544
0.01655840444822023
0.023811456454272927
0.01657484851281865
0.005715355742150062
0.004540735296676771
0.014085546304892798
-0.0020071756853378836
-0.0008982731034923425
0.01228249325311842
-0.010278537980878374
0.05365139472795681
0.0076032947972661
-0.036494762881594985
-0.0028337160907667496
-0.0013988817375276867
0.013858085850734603
0.014520346561508241
0.008672937218254718
0.009262770392546122
0.0038033934942255238
0.0021359754218029034
0.01762403010410592
-0.012880638145318715
0.003621266158252647
0.005088218331492038
0.01746337579364976
0.0003226754237278687
0.013119772893921435
0.010896396236856166
-0.002458954197923094
0.010873840553815954
0.011263033255085259
-0.0022447552918977392
-0.003746399276589994
-0.0055069449579758425
0.009002765271487242
0.00022195612704978968
-0.003347493094794517
0.011475717476205568
0.030049661078090182
0.02271991181917092
0.020725579338164747
0.004790620686175105
0.01771949876115723
0.014416615438391713
0.02886650263586756
0.02086377090512833
0.04265911815395162
0.050584136873122076
0.05554150830087183
0.03242471374255794
0.05909724739400266
0.028299753784389182
-0.003235762196899814
0.026630006512199222
0.03932576777891174
0.050414891832004406
0.04951455737962866
0.037115888585322845
0.02649851489504405
-0.001847504950894618
-0.007835480847145299
-0.044813385333217964
-0.05073704454833726
-0.02260943868689619
-0.03631045407715941
-0.017552556019033713
-0.055945341161083656
-0.011316632496637747
-0.07739460321604456
0.004219169055599152
-0.03318511792069924
0.014537823213397586
0.04169763043081542
0.014135197524006785
0.0037149094373905046
0.032668840911610215
0.04757919761694916
0.01647254067946958
0.0003586051269475095
0.0033616013918737996
0.03903178740789846
-0.007522730262757481
0.011959268303755457
0.05542679677505579
0.001021402876542319
0.0495178174983431
0.012665249507449208
0.03447673983106086
-0.06316163054644176
-0.013518052086450936
