# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; FSPIN
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=6, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0026286037472619712
-0.005716663419527285
-0.0020225237470249853
-0.0068497617231645345
0.0018866520230456725
0.0029622348135073997
0.007772391779985526
0.006823286309183432
0.006177992894299572
0.005123929674074078
0.009676485734274574
0.009901388188059376
0.0033300065414754174
0.00551821553645771
0.015187145044074991
-0.0002375751241380043
0.00798604749633348
0.010293436853997697
0.004818928553638276
0.04332159955918473
-0.0025301861060880206
-0.024781786729736615
0.00408199697139222
0.005807135331375177
0.012158262980228873
0.011522262933303355
0.009188199974481056
0.008666997707602625
0.0016069275870390348
0.001926404511653938
0.012442108058118722
-0.006037267036621446
0.004336595428406425
0.0034966319983429084
0.012745443766160658
0.00023088412444098594
0.002287531422541811
0.01169666706420008
0.004234395839405975
0.012657398418064007
0.007352315988794838
0.005592867421281327
-0.005644924617869413
-0.010657747215872876
0.0034239425607641566
0.0007193469516882055
0.001366291265764042
0.01863709267708871
0.024912218529171245
0.021799524998509467
0.024225776046982117
0.01685405090677514
0.010679511280903407
0.018588623979857416
0.02097072600843642
0.027176256741631728
0.03951066731930515
0.0393660289124971
0.048171381290263104
0.03150950339648456
0.05570522714928419
0.03934289615394249
0.015205369032333986
0.03757450536053873
0.058089551532563684
0.04547562558176287
0.05310187102667345
0.030047991913233804
0.0400032303333645
-0.0383138416304925
-0.04522736593041353
-0.06774979383794656
-0.06781730796200242
-0.02283957835379046
-0.025155204536568304
-0.02182601615107547
-0.0767812923533041
-0.023159350589188884
-0.05746980440646133
0.020160305214846748
-0.01753279854448048
0.03348746732012561
0.031927733564843276
0.013564860489849704
0.009570093729701032
0.022487106791761042
0.027927694509578854
0.017806884815296024
0.012382537868253685
0.004941037109964495
0.029128894306983278
-0.002602992892437574
0.0045379588536214365
0.03812751818021426
0.021051343311398
0.05402262448867737
0.01716330735881301
0.04173301867922359
-0.030965410299632425
0.01236660055814655
