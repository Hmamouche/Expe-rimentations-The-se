# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; PMDEL
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=2, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.038387368524432516
-0.008857597001478765
-0.06536596337744344
-0.06599474021346763
-0.0798506890235142
-0.051896764919289254
0.01792201474425036
-0.0029050949481832424
0.02653851009975386
-0.0008073306939563995
0.017911945248158916
0.011053885674283052
-0.008558606250728023
0.014403866383155233
-0.0037216356948429176
0.03483708774862687
0.040726660324060526
0.01830340236911986
-0.04251739929519215
0.002531006817335037
-0.039776240033559035
-0.0034048796575240747
-0.03153273955605599
-0.05224279354215219
-0.02907887018937873
-0.01638842436812513
0.058728097262230855
0.02733227681241005
0.005741415333635587
-0.00842921389697671
0.001617829038155113
0.0794577791118316
0.047626140980228535
0.02740452928353522
-0.010425741772151553
-0.02375111296591683
0.007614394410537055
-0.005070045527674226
0.008112495474304057
-0.025949558572877517
0.017356995128575706
-0.013359917954032002
0.05255087233716478
0.015713784607613895
-0.0088875526934656
0.010014572761988524
-0.07075651004630622
-0.04684202221676443
-0.03235784500597879
-0.004209568538733173
0.04293633935608795
0.02230549405634514
0.0027072187165584974
-0.010140643518790685
-0.01639910001515268
0.016667291046525774
-0.004058977591209576
-0.006183377808964179
-0.030268763412188808
-0.009115187469771593
-0.013252801173174782
0.004207969137416565
0.02979093500558048
0.003814870891764681
0.027224687687914122
0.0018407152458035651
-0.028752991214072716
-0.008661738139342233
-0.047900802054540455
0.009414860957858357
-0.005935202771802157
0.039814558309124025
0.03158957295006318
0.04353767593974561
0.05257323636612937
0.010442107743741783
-0.009372616129905894
-0.0343625582172252
-0.016789105231820523
-0.015229975364989313
0.06563683129068079
0.030307710180071855
0.054104647792964235
-0.0007931016293056623
-0.06281479976838628
-0.058203610508843644
-0.031150703597703982
-0.013638015255194477
0.010299546549946012
0.013375828015483315
-0.024663551970551076
0.012146345595852134
-0.04940177468194687
0.00956229478936782
-0.004471905397953566
0.020287027847280426
0.01827635154367072
-0.0015355741280477023
0.008154198805075263
0.02589128487321031
