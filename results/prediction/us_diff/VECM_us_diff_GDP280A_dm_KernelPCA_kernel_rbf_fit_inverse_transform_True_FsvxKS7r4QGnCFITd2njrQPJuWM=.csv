# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP280A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=2, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.00016978657533251666
0.0018897482777904167
0.0009649455798314453
0.004599611127000986
0.0031226901964682527
0.0020686698982113846
0.0027383429882968944
0.0009207673368868904
0.0012712672264841858
0.0023259095585200793
0.0020505863946515784
0.001988430880291658
0.0019240612596784657
0.0022387118245831778
0.0005627289196762411
0.0018904064291179034
0.0025238219769007212
0.004910898102807003
0.006648688854722564
0.005543302364448558
0.0048434074587218635
0.004338748739641519
0.004469901796770261
0.004712326408022707
0.003312766744687465
0.0035247617767538864
0.003917701477656022
0.003321291233770836
0.0030725152602136376
0.002116746817016644
0.003480345970316232
0.0015167273664143802
0.00040891561968896506
-0.005000954329128263
-0.0015996902880432162
0.0025654157204166037
0.002364110228960327
0.0029926714604198825
0.004086906042039212
0.0041967139332954794
0.004046345620340905
0.0053657668023462095
0.004831112284025513
0.004189232015832465
0.00693245283970031
0.008130535712785453
0.00722917815085126
0.003188237641470253
0.005147804173766236
0.004569956762109748
0.0008539128147981162
0.0021127198170095354
0.00668352719671556
0.005095274992744181
0.006726028360215
0.005605320585897267
0.006663009761363215
0.007152824097221307
0.008530262704427253
0.0070389327061228255
0.005409593398805298
0.004641779718033695
0.004248595448298826
0.004208162910189243
0.004407630265731177
0.00596446323477865
0.007670745438386827
0.006006650602329799
0.006786414454964266
0.00733983382491077
0.008396151637100722
0.010244193498470123
0.01077423652941044
0.004447156668227012
0.006182201302361443
0.008832705640970719
0.007219233988122292
0.009868462651007097
0.008263312846700647
0.0015124085392483019
0.0042273775171768075
0.007087534894345724
0.012907565639980799
0.014530846455957924
0.018362228453072407
0.02296214793240867
0.02393596219156777
0.02111915257341071
0.029995420950934645
0.03567080567146368
0.033137486628265544
0.030840755535332984
0.011650350273159209
0.017207737425928838
0.010732348347674097
0.002805238620930059
2.377034370701104e-06
0.010271674180410386
0.006312509204774148
0.007314138240152839
