# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP274_3
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=7, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.014960828551758332
-0.002178882049271159
-0.001446034494364456
0.011474802410534146
0.005282848619800014
0.007423644165287894
0.0008845882474088395
0.011210595728763546
0.00043427457797574984
0.0027666899598024074
0.0005708148528033544
0.006032616340378714
0.011377838387657286
0.007612961294717621
0.015820123424559095
0.01039359092185077
0.011130214153074516
0.009564795031266404
0.018850820153862823
0.009942261245938083
0.009823489285166343
0.015914490745098972
0.013892239986820938
0.007603726969394675
0.012447032895370006
0.010313934268995378
0.022417219176610773
0.022501422130408816
0.0029738752614196706
0.005656034794116657
0.023037027588939395
0.008802096485769104
0.013440310415024498
0.014604094152058968
0.0020159095490651707
0.0042448131252466334
0.0047777655649848035
0.004381901047029489
0.0034161770077181493
0.00549336357470332
0.001901074377138815
0.000823842071457417
0.004349889454794234
0.0037742389704510694
0.010854533533758277
-0.002409102601278342
0.005890208647333965
-0.001642458103312646
0.0038875842207587463
0.0062494103657969
0.004620875053966903
-0.007657269241023262
-0.006240573781819903
-0.002064280935857344
-0.0008829006593647293
-0.007515987787363319
-0.0019221313261279138
-0.004911165459578669
0.000799485024852879
-0.003041622269969219
-0.002886918727173854
-0.007089829008425221
-0.0050174935240188435
-0.0009218602658867165
-0.0082233404289602
-0.008784619363233841
-0.003368343320663521
-0.0015109009033042536
-0.002163287143064417
0.0015923784560352076
0.003651821981656029
-0.00018391753184014736
-1.4222820867077152e-05
0.000996995535977026
-0.0023209955270537498
-0.005698591187457745
-0.008232285200350978
-0.000853933133032207
-0.005491314315228377
-0.0061261484596304
-0.004192414061169535
-0.0009502227793542441
-0.0033407916993155803
0.0033583722834111067
-0.001226644959788364
-0.0017446639207448654
-0.004478589228177515
0.0016392490921444507
0.004000921499925123
0.0003922614654079731
-0.0006842388140918173
0.004422831198727486
0.009435471528742632
0.0036529775610180367
0.009587591403956427
-0.001128148416102891
-0.001461430802360375
0.0005813455730545691
0.009909751475053234
0.010774203459187637
