# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CPILFESL
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=12, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.00891203213011112
0.005424865842487863
0.012016648522733028
0.006308791265848607
0.0059249602138956425
0.005523218266725562
0.007912552016725041
0.0068370393526739175
0.004539696949168866
0.007014271293259719
0.008292491022820694
0.003250678855919357
0.005957557688930007
0.006734707232645083
0.006181825400122896
0.006308888897613697
0.007243312448461774
0.006804523497940118
0.00607551508942799
0.00810604591360104
0.003947112617302309
0.011210609356256793
0.006368321205439333
0.007922669007210194
0.0051830863020460504
0.0071492559704955
0.009207888011641572
0.010363222594109139
0.010266523168374644
0.009510737316669807
0.011550125236777788
0.005361928240769217
0.009055297219173562
0.005991936970322412
0.0072095547188821
0.005780950042785881
0.005862877699932146
0.009859898867214553
0.008171488195421088
0.007513124324273496
0.005807783979692245
0.004879433714090568
0.005462497038121799
0.007577137032806885
0.005800401009901919
0.006826024407322997
0.006902034672912367
0.007396148118210127
0.005457070051359296
0.004718969137714114
0.004991671723928548
0.006680032508889844
0.004598857921726922
0.006916049679916581
0.005482079165546819
0.0052866410250859905
0.004181819812811908
0.004809542175374105
0.00512623509719105
0.005406594130363158
0.0048494475581219295
0.0050452451849042
0.006937597160424531
0.004183428324739849
0.0043486126142669385
0.006227961533822093
0.005287381490973031
0.006072260937060497
0.00625430997845986
0.005942234761720705
0.00538449878373547
0.005591018079215419
0.0064895869118300935
0.004512712526046666
0.008754632785359137
0.005195955046862436
0.006136093027509777
0.005683656990650689
0.004348002438336549
0.0027738229471081285
0.0026732386531741364
0.002198434932678884
0.003742676823385056
0.006159556235267269
0.004837314878661017
0.005690448755460108
0.006733603309335921
0.005861582223548038
0.004254142149759384
0.005322323936254468
0.006706621388649695
0.009108417588631009
0.008007907685653539
0.0062156835944891615
0.006163605405760447
0.0052378747937086865
0.005011663720652587
0.006006646255309667
0.00655910974165563
0.007696176890253412
