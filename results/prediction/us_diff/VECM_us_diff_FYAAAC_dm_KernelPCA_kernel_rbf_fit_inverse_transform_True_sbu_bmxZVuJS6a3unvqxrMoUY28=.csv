# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; FYAAAC
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=1, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.004414735902600827
0.009764046275052271
-0.010447172314273511
0.04701076822299937
-0.011669284556015281
-0.002476304798306626
-0.003385798932086021
-0.044955030183374496
-0.036848952032602536
-0.043269102241336475
-0.06962860604962087
-0.060472712567837775
-0.06321228998992555
-0.0475402722167059
-0.026613987622853195
0.01943217821706355
0.029636924542390863
0.046267738307914676
0.010318792895108016
0.02253527043609565
-0.009243576933822089
-0.01200758351472539
0.004424367899985533
-0.021663716940468036
-0.0325957912153533
-0.017687594436283094
-0.0043709554284101495
0.0061433281900414635
0.010898266417888457
-0.004330543605749073
-0.020674203428918826
-0.0011494932783082184
-0.009084464058520035
-0.01478584015438458
-0.009845329800919397
-0.02586620551555012
-0.01759073359703947
-0.0031767045479622847
-0.023356008572360306
-0.018089464237599325
-0.027343338168038186
-0.02505429351459359
-0.0028465439531621855
0.035063402503027224
0.0251700388132822
0.05471051344652813
0.0002511831995167925
-0.023069637754122397
-0.02429515310052574
-0.04878825701413505
-0.002650581033803329
0.018959825554984877
0.002739308619199453
0.010062842201499616
-0.00034896263469890495
-0.00361054526787586
-0.015562584214059424
-0.011563604977057712
-0.024740892675696617
-0.01985075125904605
-0.017686308875444198
-0.009232269924846628
0.004686764802975387
0.019073002011398596
0.028914433907203895
0.02216306637586244
0.022255732455613665
0.007590939938269035
-0.0063359668739481016
-0.01213713416856761
-0.017293665433953862
0.0048614062260326565
-0.009430497605703131
0.001664375575825071
0.0005020640368556006
-0.014524895646082094
-0.00965094177203488
-0.01866777788322652
-0.0307186397383173
-0.033175497654407804
0.008664889531749067
-0.013816837828301363
-0.007385571479321925
0.019439475228700785
-0.027712881609857
-0.004675594168780548
-0.0117587913758956
-0.01828465934312867
-0.002674389345960341
0.0017543177957515764
0.006802028745215042
0.023039421640509403
-0.003995425955327644
-0.005271533507540972
-0.0014090953426854512
0.003308727654678915
0.005850536413185164
0.004079152703186894
-0.008427998697729163
0.006235629851453733
