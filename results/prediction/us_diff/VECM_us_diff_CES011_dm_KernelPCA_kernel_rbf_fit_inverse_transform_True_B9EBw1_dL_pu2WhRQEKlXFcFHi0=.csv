# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CES011
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=10, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.006029467908349571
0.038101871452264194
-0.001428926865331692
-0.004831617779770732
0.0188658158239175
0.005941558528950364
0.03938195941576659
0.009730897472749776
0.01420917774419467
0.012048679852090509
0.00989889197066616
-0.0006604506740603543
0.007943970457492391
0.015750639040442597
-0.010784911481820758
0.017514893728060768
0.01777213578488454
4.3845904366232764e-05
0.008512733463239814
-0.003833244102579371
0.02188675709106538
0.00675894943540755
-0.003327276431769469
0.004493795763197826
-0.012140153656821721
0.009265249841739858
0.021484075603311767
-0.012169957162177522
-0.017211906514507654
-0.03666449572494819
-0.034614490975201105
-0.018571344667856086
0.0002686465501591062
-0.017024816823225656
-0.02655791428511348
0.002365583389776241
-0.0026538757900754855
0.004049164044358269
0.015480293602143697
0.0026005124939577733
0.012980900928724897
0.01677261447060918
0.018300219903616508
0.01649967371387847
0.01938507575184595
0.010449214407241947
0.02042972175633873
-0.0023752704710031554
0.010295555800254444
0.01371786600051002
0.011294592863312577
0.012798015208118536
0.011263725563565127
0.01722897016494712
0.022494181824780062
0.011854254584420042
0.01958446043810034
0.014791385038176487
0.010684769715125405
0.02334166962249947
0.021336937776376616
0.02260588785319225
0.021732074734589952
0.018940963142450862
0.01796593083157116
0.0129221359516365
0.01681327969517441
0.003122838548566858
0.0013352473628501162
0.012031836548028781
0.0018684342507894562
0.0033198974352312825
-0.013874519415351774
-0.014178195887324361
0.021341238506420904
-0.0072871290838978555
-0.006090044911574401
-0.001515544605673609
-0.0033062763553029567
-0.005984665231014758
0.005439015413876808
0.01812620514120112
0.022034040516522784
0.011746897796847877
-0.0010436639064124373
0.01162986610436556
0.01727706468067426
0.02469827059624863
0.026272367801326132
0.020795658985696047
0.030627799740222606
0.00673322498850711
0.0051416461952889635
0.004122700498517252
0.006608827016320436
0.0001675223333905268
-0.01650183042879635
-0.02330437442514154
-0.016600700038842342
-0.038614562434879804
