# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP254
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=8, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.0008015843101973445
0.006191157875724852
0.012720164084238404
0.00605592497514621
0.0031473565406196402
0.005504922058129197
0.004845587564642922
0.0043088988824362875
0.005272848444510173
0.006635501519682988
0.009438904651331369
0.006080814232129996
-0.005724795424801291
0.006573989772359558
0.007586619392415261
0.007446136386941696
0.003379715594637985
0.002468812081991979
0.0066159237958510605
0.009772641836262348
0.006125332849711582
0.005992428114475611
-0.00201296780282396
-0.0013695915278725023
0.005217222163906889
0.006189170378541585
0.004701139266000834
0.0015740031392224023
0.0009598370124960767
0.0007704130193679269
0.009140708044394945
-0.001654460247469845
0.0011485580498943404
-0.0015181089078217945
0.004828911422348441
0.0017994140168720182
0.0012656137698075693
0.00904180455586264
0.008790877249087446
0.00795090278976428
0.008485860800233848
0.0079719004969696
0.004585439091101111
-0.0007460327419694878
0.007695657871019514
0.010645524400708716
0.010246383352826271
0.005665083368508912
0.005231023387039759
0.0030410132439521844
-0.0006766692065032815
0.0035918979697458875
0.007769447328849381
0.006252062673988826
0.0047393401105708275
0.008943804340546856
0.004963244600261361
0.005650732098843293
0.011451174337366666
0.00492030475365249
0.008873931954200127
0.00885579467684174
0.012070316087720825
0.008837856966803873
0.008136618155956307
0.014580708182175498
0.01147835808447922
0.012406751227135767
0.007565734433605082
0.008172604946684968
0.009608228102722476
0.007010847527642835
0.001131668987091793
0.0054322777337082895
0.00922144199646487
0.006864711618420958
0.009279318528710754
0.005681380677185537
0.0007762345636138882
0.01582202106791516
0.009395485935148627
0.013964343799075888
0.011043954966282604
0.009528874771630063
0.012613854152536616
0.007165100743583179
0.011076544312621665
0.01078089514230461
0.007277925244060568
0.010804613885333743
0.018023125259824548
0.005191468826135216
0.011835753390486323
0.014203183584424796
0.00485006823392863
0.009180530880730894
0.013534676276158859
0.00036903792506104443
0.0025631122571152945
0.004841700802482132
