# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP274_2
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=9, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.0063692660130917605
0.002490359096907561
-0.0035320255954175246
0.002666811676286542
-0.003119734478782576
-0.013756432058500754
-0.001230058053473265
0.0046464260439021444
-0.022033221825452268
-0.010103203003445674
0.003195498972476161
-0.007013711638109262
0.0004561638406775856
-0.003850562577733715
0.005856050860268444
0.006901585378254923
-0.009386540045862072
0.0011856137314480125
0.003558890197499818
0.0024404409221295553
0.0004284414211646137
0.00025440734304198274
0.0019491210056336605
-0.00792296099964948
0.0001655764500114443
0.0049841747099125585
-0.004749658119246899
-0.0050610228697271385
-0.003659737295370316
-0.0035246561283871517
0.0019512077810417896
-0.012817339652135992
-0.003684973397304176
-0.008727925113057729
-0.002898291387346685
-0.003862318845980843
-0.013811236777772101
-0.0074467530487945886
-0.01443952772024164
-0.010960644790272894
-0.007479849550965721
-0.011001669944953349
-0.005373885006234093
0.0034251058101438404
0.004769978024802267
-0.01235785828897217
-0.016154215424376683
-0.0061739265106907585
-0.014279934934730693
-0.019755279856099994
-0.015304948607448457
-0.022375921873618254
-0.01481661310989771
-0.021392424569256874
-0.025579014699267422
-0.022771882107567896
-0.02208164691339327
-0.01927764276731425
-0.019851093211810868
-0.01978408158039117
-0.024333630562249207
-0.028680451181806472
-0.020524393461757953
-0.017822143792032064
-0.020412756020076576
-0.020840381584011483
-0.01670864471526866
-0.006521689151221099
-0.014948060149734365
-0.018554861815552687
-0.0174511550456894
-0.021390985151049202
-0.017028214067366487
-0.016203506206904212
-0.01852529243557898
-0.01716899263442466
-0.009697927682380793
-0.021268041129323494
-0.021063818655407428
-0.013602288090775282
-0.022425406421368088
-0.012472679984356406
-0.0033432462141212765
-0.014332333311764832
-0.011750329786177821
-0.007698634498220519
-0.006847187757286566
-0.005433874105698705
-0.015735424260439515
-0.0112533878678082
-0.007768044984519291
-0.008950302533531296
-0.008550169831761155
-0.010445189464222921
-0.014992622554582901
-0.007031109453013263
-0.006782623965151259
-0.01594148394917186
-0.008337568282915363
-0.0067077604760183915
