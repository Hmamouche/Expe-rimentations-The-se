# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; MOCMQ
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=10, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.029338737173126808
0.01211450382932704
0.04699637613374116
-0.019142251620897305
-0.0024635480672765345
-0.009076854760614254
0.015435779749764286
0.02955164916768916
-0.009345129127753742
-0.009461527115958792
0.046129404950194804
0.005268275594615019
-0.009999386151353474
-0.017037474584401132
-0.0023548329151866446
0.01901832859891685
0.03569358502551972
-0.0008285646542596581
0.023632271431024296
0.01435248711606155
0.015990925942531743
0.051998222941078066
-0.041262175574906336
0.017027228038208945
-0.007390189831223387
0.02858716111646197
0.015248287194879613
-0.017556869316287974
-0.006021078277293225
-0.027292216630310454
-0.014961186819206619
0.02345356758421455
0.02994631335726896
0.021508757761267705
0.018981465109096426
-0.01635011240469679
-0.02103552973879824
0.02960596189713259
0.017317902762966932
-0.013102332167880395
0.03195142343579383
0.028953332886494966
0.014944784346700154
-0.010456196996271008
0.012590211098029457
0.0029610552470215774
-0.014608594751327399
0.001735061102886449
-0.010305883282437023
-0.008214470331535148
0.014589883584137113
0.011411874837610938
0.006626692059420817
0.033182161851286855
0.020882632842224948
0.010161306152098858
0.018657470431728926
-0.00496916427927992
0.01428550540351863
0.025667558393613614
-0.0031273221087271
-0.0034016727526058124
0.01458769772428613
0.008167828892779044
0.02803861240674508
0.020421282602750383
-0.01445977048432772
-0.02929046116284429
-0.009552302872594877
-0.0034593613413145367
-0.012259824743954399
0.0027671142947449066
-0.021086985111257332
-0.02199984685932395
0.04103578407524851
0.005184411146991558
-0.014705636326339894
-0.004293290695229938
-0.029906914934337392
0.009646379382490702
0.017407561489909604
0.030185192050067765
0.0316310271106498
0.0063652248464023346
-0.020006873586756825
-0.02580363590947193
-0.029957776243685976
0.007103390998462297
0.02628075995781739
0.0030534655798197885
0.035003274898366264
-0.011207573702266401
-0.017655674428111525
0.011620751332477652
0.008493010096938
-0.016273043578836594
-0.012572403113289924
-0.03735693049635151
-0.02320288611449704
0.009343684254046023
