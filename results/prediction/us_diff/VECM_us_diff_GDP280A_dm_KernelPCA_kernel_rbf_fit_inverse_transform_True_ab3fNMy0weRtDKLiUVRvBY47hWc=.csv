# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP280A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=9, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.0006632913501819775
0.0029620179878353664
0.00035260429883696224
0.003335150331603883
0.002322933872146471
0.002551469061950722
0.0016203597291832373
0.0002841580770545889
0.0012078006875730044
0.001771216938267775
0.0021224380142140253
0.0019375276003768644
0.0018920475023242573
0.002822878705062497
-7.555325092726227e-05
0.0014933743972434083
0.002941968134161828
0.005519705621723402
0.0064673491884901695
0.0067977494926713695
0.005249858955004644
0.007313743308361326
0.003375703777178608
0.00481434600896368
0.0033049908193786724
0.004171004727868105
0.002600430160607128
0.003691690936835538
0.0026792875175716876
0.0022504366833105242
0.002718717226669393
0.002657583614698672
0.0006913854142876002
-0.004463614077657557
-0.0005940892911125072
0.002533080434142583
0.002379392646736281
0.0018358565092746566
0.004259420974911975
0.0027804433354182063
0.005208805410003164
0.004893689497230361
0.0040233024550154865
0.004517002121045872
0.008396182148963842
0.007471786813166723
0.007962643665884795
0.0031220841525779705
0.006009193709103391
0.004521283101629521
-0.0014221852017322842
0.0015910201096127966
0.007751253974950562
0.004589296932256655
0.007647794881731306
0.006203623921612049
0.006705058082656223
0.0071821009833065485
0.008571658629564731
0.0068449807399885605
0.005185891311266851
0.004485925460890939
0.0031883322859769855
0.004180482676760519
0.005609906846400897
0.007435163190947779
0.006649419196630657
0.006157704621171083
0.006017448530174221
0.00837075703901994
0.008552397146183041
0.009828148010830696
0.0102633204770906
0.0032155526255494816
0.007204401620596949
0.008293777863095821
0.009822698761979125
0.010570845992893381
0.007408960925410273
0.0005521991453089601
0.005096939760891216
0.006163526434112013
0.011989496172911639
0.014878543918215168
0.01992116851105294
0.022047556121114347
0.022684902773773736
0.020936892726224208
0.027519567962117648
0.03615609160844826
0.033954291436924564
0.03083289126668276
0.01245759595709844
0.01760310082250697
0.009479677119473427
0.005448102281635836
0.0021132557143018495
0.006334331531747856
0.007057266702704199
0.008723780057738885
