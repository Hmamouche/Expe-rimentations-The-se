# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; IPS25
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=15, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.010682553220021838
0.012315936999906262
0.019749115149245083
-0.015365831030857677
0.0040673485282281974
0.006420902822774481
0.012968385953315776
-0.00512931735064894
0.003611156765632151
0.009896474756170233
0.01206691805114981
-0.004207285161299935
-0.0015032321761510236
-0.004109779694714748
0.006596714509935154
0.014077565247601058
0.013232723274494266
0.009915969392313095
0.015108246961414037
0.009816452894489007
-0.0031241201355544394
0.01263587919166969
0.002317407727177894
-0.0005938656571008288
-0.0010557042928654177
0.002991429613335608
0.012028328962240884
0.007666907981745805
0.007648645490255342
-0.009823938218364362
-0.008422121280105492
0.0076277848816046195
0.006888025260603566
-0.005200271406316348
0.001093236481123667
0.01620688658255952
-0.0023160193128609965
0.01758085853868816
-0.001627071480563531
-0.004689586953603098
0.013183554587598966
0.012518914482313778
0.007339938294365468
0.0010795841124536599
0.01103874365172461
0.01506251692709166
0.01074205378300205
0.0053237210439055545
0.016219214034520597
0.002360930964020144
0.012634847725625408
0.018834132961589048
0.018998941305772597
0.021756291365601785
0.025977937848880098
0.024930589875626526
0.029586359393347035
0.029999012948622884
0.025211545725107722
0.011837985419848724
0.011588818476736918
0.012547073412296614
0.018518959897224754
0.014495166364397911
0.016911964176360796
0.012527098177178196
0.017334130428980302
0.02181310100914235
0.011574581336830588
0.002356998630791211
-0.01079565003204369
-0.03250278107762566
-0.048066704213555835
-0.0322041167980788
0.015980947671967217
-0.003762079689565972
-0.008697138138270843
-0.013624920321442541
-0.017260920806417702
0.01114611942120185
0.009064235885855294
0.014658355201300929
0.017423572107292184
0.004272055497732199
0.014327473544252739
0.006839839308366376
0.016415942815606308
0.011426691514785429
0.0011504482455413681
0.03693806728526462
0.03214312707570243
0.026806788208214576
0.025142807166054448
0.007401189516617454
0.0016889243043617845
0.003954283310679624
0.014570306305713297
0.005678324247949579
0.0034526113773424034
-0.006126454216782033
