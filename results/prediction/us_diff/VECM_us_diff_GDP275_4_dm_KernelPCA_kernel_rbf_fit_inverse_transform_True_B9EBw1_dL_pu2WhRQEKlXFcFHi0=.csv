# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP275_4
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=10, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.013718533388246497
0.005433051538680284
0.00988416232289957
0.005884013454989904
0.006518453414592125
0.0021899508155309552
0.009632465258247066
0.007920584299948127
0.004461123892243658
0.008712327583784377
0.007444718889711143
0.006376348448502426
0.006374335616299485
0.0050219149634743495
0.00801531158499344
0.011321889691869898
0.005566647509853046
0.005329585331660657
0.010132553341495525
0.008798593990935917
0.006935486158449882
0.009701644505144328
0.014082435114601456
0.01038594860711518
0.008232580724336244
0.009069176513295004
0.010131080901818225
0.015578045368579749
0.006318360512291257
0.00897819117438564
0.013158248968992765
0.011712092522263542
0.004756788825366379
0.011774551163727602
0.009391930800334656
0.009282829277181652
0.006940937379936977
0.0021539909161334683
0.00821702599958324
0.008095973440176112
-0.003842180752009975
-0.0008365785910835108
0.0014665062061588506
0.000762312169456854
0.004944557845636613
0.0020851787160150064
0.001447400399707011
0.003836084193621155
0.006117726399307382
0.004553994829816946
0.002585992821315798
0.0035852441733542845
0.0013995272545873777
0.0018344749728273573
0.0010492607364721651
0.0064363131384464105
-0.0013043846560422143
0.001581618151032093
0.0070045445072478086
0.004266986561660115
0.004555726865155995
0.009364621724700175
0.018252618456729583
0.005980314943311058
0.009921288406549059
0.014553386821229416
0.004669618391636981
0.01167279879707504
0.0069802841411934005
0.006200244090344489
0.009552763995301488
0.010952360524784065
0.007661704856145897
0.007259503148706597
0.0034227818312936326
0.009963572191267795
0.0069064967808468705
0.0003025742306843717
0.005044995127093407
-0.0011517509213914917
0.0023978944970420536
-0.0041443299130063446
0.0036611459834952234
0.0007503835270004147
0.0005429914564896395
0.006541335516682996
0.005269532371455213
0.0033335859493431605
0.004489598515028524
0.005720729343929531
0.00455442661311066
0.006089382561656215
0.005565438480072099
0.002559454607411665
0.003463102228459767
0.004342394029342603
0.0031385324267138755
0.0057019786368473005
0.006454180796907045
0.005212204115945966
