# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP263
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=4, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.0019577581925938397
0.0033982089451100473
0.0034052937861036633
-0.0001592253126789777
0.00644499864633933
0.0005919899984430017
0.003889438969818299
0.002693536883297441
0.0018552675777565486
0.001984745240860227
0.0012165083171314164
0.00041282743226589056
0.003628479031789248
0.005684854916304993
0.008692671291719155
0.006135673169752267
0.006298216438921385
0.005973786177559208
0.008267241530110154
0.012467859681247263
0.011699138785231478
0.009911568455153067
0.008864095360968882
0.006449377501880381
0.00875352072473078
0.00840985423749095
0.008064233333686584
0.010163661076905564
0.010182156315643317
0.007572295921148257
0.003796386505541788
0.001118944590935254
0.007411684976919609
0.006442652041477126
0.008004345615092995
0.014081512467925326
0.006044316173831584
0.004530233282716135
0.007587362721890732
0.002767093913515051
0.002736511127149192
0.00427484187811818
0.006897597340175783
0.004427279960453885
0.009614318752745502
0.015446361217131024
0.013387816048103372
0.009658463389363936
0.007613865549698633
0.012409037115232295
0.009798029213582308
0.013604782401221559
0.013263757534845558
0.007659831469319932
0.015626039225825308
0.01359987340007236
0.02205334799098986
0.023273051346612596
0.008226372527213026
0.00540704691523785
-0.0007124954627945232
-0.00016006961173723253
0.008647696591346055
0.0039930063972473655
0.006303551086652976
0.014618141632963148
0.011538889222233485
0.013141026175392869
0.016700542668149302
0.01337486291313322
0.0015365785631005382
-0.008006074295714167
-0.01812680477211316
-0.02628598358065239
-0.0121294531361885
0.00782560723334124
0.002796906174437278
-0.008215321291378776
-0.005376838951727776
-0.001655526891383968
0.008557105693655432
0.023397088235383653
0.018216896584834538
0.010057927718381533
0.009680516129141416
0.01731236068683539
0.014356281068530746
0.013072292150476275
0.00639578290993306
0.01827978281317411
0.026415706335206905
0.018045341606963607
0.011212944429179608
0.02283702982007417
0.0179229809759543
0.012890965744124482
0.02657178976085635
0.023149487482374196
0.01724320421047382
0.018030223355668482
