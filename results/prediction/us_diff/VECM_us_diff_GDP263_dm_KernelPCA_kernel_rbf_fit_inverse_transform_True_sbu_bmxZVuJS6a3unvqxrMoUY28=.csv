# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP263
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=1, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.0017644807096227298
0.0050368529691632346
0.0036849812889200905
0.0037995178492731614
0.0036733577657070207
0.0018935109941700407
0.0043757362624222956
0.002624895723440057
0.0013813953782171652
-0.0007598167349346579
0.00023799578452838698
0.0022887598295305007
0.0042590041796027964
0.004831067746018486
0.006950616356567641
0.006054558499030423
0.006609497196720134
0.008594294540565773
0.00863981229678629
0.012303853107480224
0.013327562949156439
0.009291897994948109
0.009466451418781153
0.006334389194667655
0.008663498043778896
0.008613856281440537
0.008067656585237016
0.009700128176207723
0.007806242312303077
0.0062140744194045
0.0028844948337003987
0.0014858505686644445
0.008145884301758647
0.008298697131826197
0.01000551986164155
0.012825083265406587
0.005767002650987105
0.005782908824086596
0.006086753134924901
0.003070617963838389
0.0031781390290039077
0.0029672393756954196
0.006726644670972934
0.006877360283563214
0.011103606143352701
0.014045430064205382
0.014015833914756807
0.010049507034855656
0.009126056174766337
0.013161802790497036
0.01094116567802546
0.013460536123318712
0.013228918939452241
0.005610603010791457
0.01599746422151105
0.016010947096757218
0.02071536309828373
0.024804366258298162
0.010061621421429176
0.006274257001557485
-0.0004143580401546414
2.1512503587341485e-05
0.007230272329445503
0.0034966133447481454
0.00415257693858984
0.015241653785915042
0.012392882020204925
0.013767782418495782
0.01618552171217612
0.01511359638068296
0.0036658840571188733
-0.009298228282806102
-0.02281994748456189
-0.027851961905028273
-0.012088509568399903
0.009093249499618697
-0.0008599075342655875
-0.0034987179568452143
-0.003568078540736896
-0.0014962517419739845
0.008926289198972894
0.022093991201878965
0.016304320797471315
0.009604580153293681
0.01121742970305313
0.019072124095528213
0.016240569629886674
0.014863973491409072
0.0056576107703810545
0.01732047113844789
0.024522163962695694
0.01744938203416939
0.007140783214864647
0.023085748006579726
0.015280197277036365
0.015470692757670419
0.027313154079953886
0.022941026624111703
0.01777904274256037
0.01955217585011008
