# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; HSMW
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=5, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.15367666887275108
-0.07420458162816904
-0.03721820458830174
-0.011416822333210647
-0.06929609614314415
0.07148905489800451
0.13147118852306217
0.013510649441530563
-0.047742962661086616
-0.014904696065382944
0.023424090426980432
0.05377527951823196
-0.04438153884720748
-0.019476371239332338
-0.012975391614800866
0.04991516762898709
0.03939618446757914
-0.020551484031726963
0.05848935483872675
-0.1529256440500062
0.07762607510148492
-0.007424591518517931
0.01277872963600122
0.025763742902254756
-6.104867407288536e-05
0.014222317786264324
-0.009437835370820082
-0.034369122401608554
-0.1178930677049971
0.001496516443143775
0.008641577639444266
0.064285224347586
0.09313252665354912
0.012019625458696732
-0.009782630986204015
0.007054532821890211
-0.00862990337883001
0.05771718341789816
-0.017721340400017344
-0.03148626836675855
0.009920713153114186
0.015823722263297896
0.061336700253881785
-0.06934933296358708
0.07153022512726086
-0.08458304145287507
0.035220494605027027
0.030026313849684766
0.027014891549693793
0.050613918994992
-0.03517172728728698
-0.004782135335681038
0.004900251611093455
-0.009284657629899423
0.028254544879428963
0.015712488736415828
0.013976736954381218
-0.014644625691043741
0.02553040581363003
0.0031744924924542416
0.04471876350067121
-0.011510020948290284
0.06707445105887047
-0.12348101472860366
-0.011202955362448891
0.006258608507479033
0.010138274598605918
0.03381404982185161
-0.0077574909389031554
0.03160498252561257
-0.05727783806452419
0.04083683942172106
0.03434321729536818
-0.016172412434919306
0.04690993447301866
0.030267902869540682
-0.11639401399490953
0.028857931320482196
-0.04261682225151048
0.035595886887862596
-0.011820108573949419
0.10333871701867188
0.06547651335390742
-0.058899820755421106
-0.006831678990019963
-0.08674843302357105
-0.01341802523261064
0.03267983727928173
-0.04382438085113103
0.007132953012161021
0.02224268786130523
-0.11498024132164518
-0.0714892609610509
-0.0012462137644655442
-0.05029326487150925
-0.05181769634795637
-0.05022989823714367
-0.11950634433583784
0.029356521352480295
-0.03269427401191756
