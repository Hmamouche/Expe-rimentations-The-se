# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; HHSNTN
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=10, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.015134575624858265
-0.2990043565362678
0.13375110841902876
-0.06423435747672016
-0.022761606108902682
0.12545915892350284
0.015393303509271206
-0.016490867047195823
0.1131667246598071
-0.009898187760807677
0.001455142574385556
0.014638505694296935
0.03598383740167771
-0.04917000668735445
-0.04188130910377811
-0.06499373253521858
-0.11601870871081363
-0.0161013763939626
-0.09136560046803542
0.06035285779473762
0.04125369246096727
0.06197951406544839
0.004456072980922536
0.035372016071408593
0.02929420473487828
0.025592033030833586
0.0031669380794076933
-0.04726022597891725
-0.06862005117193921
-0.040010691100312114
-0.11210150707713079
-0.17862319925609285
0.06520388135667163
0.04144244028738571
0.10003901635256057
-0.11353209275254517
-0.01046081782139962
0.06500105964843061
-0.08979051316233246
-0.012916558822026372
-0.0022040126893976865
-0.021494851228462685
-0.005091572855139025
0.00021987616400571952
0.02931021534910619
0.07210317470455219
-0.018502023574128543
0.0809357935257436
0.09002077134051278
-0.044485166239908405
-0.0513310401222047
-0.05512532173774082
0.05664979952582131
0.0682588299059876
0.07213745439290394
-0.005890875986136385
0.03711155448081292
0.07732891996136242
0.07447649416242216
-0.017825130865584998
-0.04187917251809169
0.00822683793210771
0.011706065612914525
-0.07988248950808231
0.05561338438584262
0.09971136612347888
-0.01683405736113731
-0.023577182215876416
-0.011459937025461737
0.002246721702010235
-0.019364862633232727
-0.006492024957850222
-0.11647913123713216
-0.0228961246987762
0.05046153695056808
0.056846724239020985
0.07356944764351145
0.03147559683184689
-0.27792016534636427
-0.09444150598622708
0.09612586654318986
0.004561208563157851
-0.03850186854486311
-0.00880272550694913
-0.028012431948031206
-0.0012215614815507397
-0.007312474826564113
-0.05249881771491331
-0.026114644815745963
-0.05395398841531915
-0.019408835692122622
-0.016623494014046336
0.05664673103296937
0.028685126715216287
-0.02433287439245331
0.09759686018073366
0.08715817704757862
-0.054001141223134645
0.004160790124097881
-0.1251309591363173
