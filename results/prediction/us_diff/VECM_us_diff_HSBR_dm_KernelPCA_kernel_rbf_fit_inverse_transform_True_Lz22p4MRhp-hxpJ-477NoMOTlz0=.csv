# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; HSBR
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=11, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.13160419257726647
-0.03480266857996485
-0.04637764356619884
-0.04219877765089331
0.05023942936491707
0.053774555862685744
0.02280062755859673
0.07405787449874264
-0.009009157020615395
-0.01678836476054951
0.07521479881261581
0.06721653799578664
-0.028715364461289635
-0.04272650361004161
-0.09345006335588256
-0.09024045763029495
-0.034953547020749536
-0.06684357820796734
-0.06287152145644245
-0.0752567665711044
0.028681997752321525
0.01692605507768546
-0.01964369658960749
-0.0013293105206679326
0.04619658516176376
0.049874805084762025
0.017267430696993602
-0.03770484156895762
-0.10398410470056557
-0.1170860382526014
-0.007075068647096741
0.05036720247271481
0.09577025152450389
-0.05531627537281494
-0.03079616568396721
0.018501733305604222
0.023754923105520222
0.00856679750503006
0.010671165661659793
-0.09674771821438752
-0.03893081667995863
0.06727202965043466
0.055939776837487715
-0.06863394926648755
0.033249691851905384
-0.07535218319745947
-0.02091250107885395
0.00691648205798993
0.03626925986995041
0.046094129312146806
0.04779116335907643
0.021891383289593048
0.0625551169069358
-0.0005051677078539152
0.03118325224127391
-0.06690270767827519
0.035244606881425763
-0.007576507958079862
0.03866383636262248
0.015505741584019381
0.034720642042406574
0.03840332231753305
0.0642133662583894
-0.0266259998770633
0.008831868959070514
-0.05734088731648699
-0.029086649157165686
0.0007361771511847082
0.0006199537074172926
0.040644192723812776
0.015454904157649975
0.027900122091040976
0.0005825026688456936
0.059245396387750365
0.06595136997170233
0.005296919534848461
-0.030452606658112988
-0.0006329802774098295
-0.04885608023698527
0.007706300480357694
0.0719488610485568
0.033773886255839915
0.00446174829354827
-0.01839431259827525
0.03378993027930535
-0.008355305521424997
-0.012058715870069955
0.023994645504894115
-0.015834274509197263
0.017408710132870046
0.015062760160404106
-0.022241541113201115
-0.035513138551122585
-0.052427977664002236
-0.06336863791497324
-0.027353735303262086
-0.07089186336915232
-0.1388494414113744
0.010815633476683843
-0.12799492291456194
