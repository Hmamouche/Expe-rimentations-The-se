# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP272A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=7, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.006097087456282134
0.006456155398854616
0.008027618775339893
0.006673783744660565
0.0050054679684139606
0.0035231100558332966
0.007558641827013499
0.0037329983483616576
0.0031964200146522475
0.004610122638098501
0.0029192641237527814
0.003301610033736978
0.005518354625426434
0.004654300714493223
0.005136549015376518
0.004712847916286089
0.006846512442206926
0.005933653324866339
0.0053457266947954584
0.006446889148474161
0.007726874094842737
0.007580882951769067
0.00749117849357261
0.007945057876890491
0.0051185794569782814
0.005822348212867806
0.007301371276667783
0.008685803221962926
0.0075536680377713775
0.006895214272332325
0.008952940450318315
0.004726987405083457
0.007206332563863203
0.0057162951872016645
0.005165366062530153
0.005051131956871721
0.003241885032297676
0.0046620822999132285
0.005739051085625779
0.00315272412647732
0.005018360345562332
0.0045258842275089535
0.00493827859509813
0.005667004598252678
0.0057329438476927
0.004849899664012945
0.005048268674858462
0.004008775587406679
0.0035333779869722286
0.004507608287651595
0.0034760082753015906
0.0044378683445444244
0.004506390982847681
0.00447694247212147
0.0044672855076808415
0.003930512918199091
0.003471697385758726
0.0037051646620098566
0.0019295986727021835
0.0017543291825686948
0.002788454431751553
0.0028579443918012068
0.0022524352618822465
0.00473423842351895
0.003950569201427273
0.00513353694846516
0.006452301083012763
0.004856625713565621
0.005081844544454535
0.005822683026509
0.005227152771395136
0.006584504937212966
0.0050608746636140135
0.005313290725977001
0.0060568556655516345
0.00272588518427118
0.003924184092910354
0.004781184068272262
0.00652828813336112
0.0032033154813533183
0.006698187565281326
0.006227983608042482
0.006956426104269586
0.010175306451025528
0.007343380857658719
0.009108169158923112
0.00933589989928009
0.006167590040108981
0.009922198241586574
0.009942759336490735
0.00917629088630384
0.010571837530988832
0.007545981618273693
0.007993621772630525
0.008715439984267465
0.006749766324937517
0.007573325133451571
0.008246055846752316
0.00496486174164848
0.004176969226005982
