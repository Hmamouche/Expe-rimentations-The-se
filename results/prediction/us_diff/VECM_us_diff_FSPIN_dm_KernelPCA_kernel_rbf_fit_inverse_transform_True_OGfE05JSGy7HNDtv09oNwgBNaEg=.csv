# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; FSPIN
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=7, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.002854426984611272
-0.004915887827839699
-0.0017364745437882891
-0.006263549845440062
0.0032339091928125993
0.0028963710073910726
0.00791178521294679
0.0065243942175633495
0.005738570105303604
0.004410424032926004
0.010153473724696759
0.010257760568426786
0.004460806528017612
0.005134369625280109
0.016068793461770817
-0.00039408383413554627
0.007785033220473907
0.009985548190193563
0.002023080767754327
0.044783205274654805
-0.0015659334932221457
-0.028343055348648734
0.0031965354482968848
0.007611422112814866
0.012774525947922577
0.01128817562397734
0.008030645460036526
0.009650161928014989
0.0022110221702363016
0.0030793381898706383
0.01447376707364446
-0.007121642014563275
0.006459490762765574
0.003224981730752089
0.013568759165021062
-0.0002801905519110807
0.002314717665791026
0.01256828755171065
0.005858226296548356
0.01336649719525649
0.0069958982506731285
0.0038801343602897546
-0.006979630549947436
-0.009825270265537426
0.0019411953649988184
0.001528718061074091
0.0014529698516596071
0.01650723571127785
0.025528067789191894
0.021434832077516664
0.023182567007870136
0.018137590042103354
0.01090130952777681
0.018577415732366074
0.021011752149176798
0.02677298504101914
0.03982551000323358
0.03912449702360708
0.04784851680925431
0.030535636213971516
0.054946917691712116
0.0395139696344277
0.015071534576595056
0.03951989414048898
0.0573263112640946
0.04236994005618338
0.053579886367147785
0.030954837233678402
0.04014667290293873
-0.04029606259639607
-0.04715814116030792
-0.06428383596122511
-0.06528641608522011
-0.025082442258367678
-0.027255442042696237
-0.022294477279959896
-0.07308018490453778
-0.024231614959793576
-0.05807065148369188
0.020391162884674005
-0.01749890663414472
0.03342800886931353
0.030889112941124706
0.014533060705013685
0.010303231685125843
0.020568667304348587
0.028672401962630233
0.020835513847512643
0.010628532270484166
0.005057202652531635
0.032542177700723
-0.0021300117479460786
0.004502001823376751
0.0413837233377929
0.016919700350861575
0.05411623790874283
0.019210475754499762
0.04590814134816991
-0.031026223083108713
0.010839885452311251
