# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; MSONDQ
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=14, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.01240645359621581
0.12299398383251543
-0.025602117015140664
0.011887109559237226
0.027302643318554073
0.019071670301539168
-0.015366470213660447
0.007091582948470378
0.08903087572291891
-0.001066175835167521
0.07563298862230336
-0.01352727919203537
-0.02647702241502068
-0.02047102262446123
-0.017638301293646328
0.05975453711696302
0.019087335412184474
-0.0640491090255204
0.010444340608951233
0.03135658742666996
-0.06404360710505953
0.06832538014421943
0.0008371566923686402
-0.033489061108141774
0.06928591292461565
-0.021816930736033326
0.03326370051186503
0.033883809110052086
-0.04576383366319568
-0.01228389168316961
-0.0666679816617245
0.06677683517453156
-0.03586009092735577
-0.03292879154875772
-0.020330829166080172
0.009455772852734263
-0.01141257592555037
-0.013711724491478249
0.005029028219537525
0.02576055136795776
0.012996715195039678
0.027333055499997486
0.04792846679762614
0.011813460967623833
0.009398416257360157
-0.013919608903457146
0.017346789773272087
-0.01175028819769087
-0.03524081781062176
0.010018618362948562
0.03306319262675116
0.09700333011649444
0.0387677083269736
0.02776792182776421
-0.008238807750208256
0.0036295138447430125
0.014424137768681067
0.028523580391388643
0.06095777358454531
0.04200398133777962
-0.025776844913039193
0.00962269601169214
-0.003129523240566274
-0.009346782013327434
0.051770327527078955
0.05435730989813815
-0.0339523983757344
-0.038416854926834214
-0.025763869253839115
0.048908740491187874
0.007046747417019838
0.009975199576234845
-0.06037540273716084
-0.07037714218078647
-0.08880418627713102
-0.05923586164278374
-0.036042843539092956
-0.04450206948029779
0.0029585156104921535
0.03690700456942246
0.025235939218423178
0.04519744610360127
0.07536999357785766
0.017184183820334053
-0.03957237791572772
-0.0018596681002010437
-0.013037268689910245
-0.02544311973339338
0.044872372474512465
0.058403001083523365
0.09046476671813349
0.0672802464864543
-0.03628076562258594
0.012079534308147124
0.04796063089660343
0.003531595032572275
-0.02004068601640096
0.014381671886590099
0.0015481829332887782
-0.024324875670337462
