# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; FYGM6
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=12, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.10201761035377879
0.07371733565897197
0.034904966896965
-0.04772642865716285
-0.04743630989617298
-0.1496903884566361
-0.026607982341808833
-0.04512389126027144
0.05866564727109781
0.11599639044887917
-0.05188380114444655
-0.12124375726021962
-0.08377404725353191
-0.0060093721792198705
0.020931493996572972
0.08897374206394078
0.031165901065104838
-0.1328581829134126
0.030198763764387584
0.027100682075106353
-0.00588351531447056
0.10200309991224926
0.017568743504069215
-0.04578449530179448
-0.04005861974388279
0.04209128434407709
0.02662458765241376
0.00319103713670414
-0.01398075279759246
0.04789129361642111
-0.16816661071446512
-0.09947839401509433
0.0430952247672023
-0.0009201901649755345
0.014979861808288334
-0.02461582898661841
-0.12669455936675794
-0.04047678306092127
0.04545817615356997
-0.045509652487260965
0.1253130550392737
0.01669896725483237
-0.00787570751405937
0.0067109883904549784
0.012375916211056298
0.06467767433567254
0.017087529392961917
0.03448662937656698
0.031030943833760344
0.00414376009397922
-0.050435059566474386
0.006770694429926508
0.004125395790886612
-0.01090753378384711
0.00906443779692527
-0.003059897286675434
0.0008053303765255954
-0.003529860487367432
-0.017311033926684052
-0.00541765588689205
-0.02034213160828271
-0.05443316175773155
0.05359722376411141
-0.03378123179946478
0.019400525761776016
0.06445295042425264
-0.01348477725789439
-0.05026345904434076
-0.02905794119413814
0.016327608608588028
-0.03277743842623434
0.013684021157271605
-0.07816691610376074
-0.11083970246244088
0.10539429458313077
-0.0407831848161609
-0.03380480570794313
-0.039674596539173816
-0.05545039739901843
0.055795921261121234
0.050654770043088646
0.05634664841893202
-0.022506111936421526
-0.04104238858059708
-0.0005060924452703411
-0.0004437532772779071
0.020555986588241038
-0.007234763325599827
0.03287801906038789
0.016041194476393968
0.04088578592774452
0.041854138625165516
0.016703065557861104
-0.031485861183108206
0.043650223186551075
0.02856513081020349
-0.014572417579704202
-0.053665649513386135
-0.09332572337628894
-0.00012328035398696986
