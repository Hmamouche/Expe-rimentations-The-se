# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; IPS25
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=6, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.013978690847846746
0.006199409120428517
0.017971304710226246
0.0081202666200707
0.010442051519202735
0.004578019016926348
0.011561029020663426
0.003683996707880855
-0.0006641990654468902
-0.00015050058082318395
0.0013544077691457503
-0.00341435509970766
-0.0047389780657816375
-0.002849555883840125
0.007354493606497503
0.008269888383716496
0.010842500532189082
0.015587468943816784
0.013939750306862573
0.011198800082289349
0.01056790380767713
0.007556340226423895
0.00374942115181041
-0.0009118650147677265
0.00016292027975947046
0.0009306192247824361
0.010423747228292958
0.007813166896712688
0.0018616385113357026
-0.008608004766242948
-0.002992037803666251
0.0011485223945084532
0.007430761938126408
0.0004641955045883873
0.0029605087437180595
0.011275255909180182
0.002655960551009843
0.008679837568479754
0.007591028629816148
0.0020868850339738005
0.0016401924714516771
0.014501987316142472
0.007610676060713324
0.005111380545890012
0.012703722025080293
0.013623878633448017
0.008678643208635336
0.0061949681617278415
0.014390008062597421
0.010800260835813863
0.01091938751665047
0.018672176412217495
0.019713334643028088
0.01994863575107307
0.02432729341106863
0.02920803428135464
0.031166830743479555
0.0298986240920371
0.027226176073527272
0.017770695952050823
0.014663978154525619
0.012859118167327755
0.01716871099461752
0.010206022077457166
0.014981330425778188
0.014792098087184201
0.019412856372734284
0.0176196919613812
0.015125288270184329
0.0071046277801107985
-0.007342473556903229
-0.028549614975606343
-0.038343892216524275
-0.04077089632049105
0.0014086871055308328
-0.009234169362268315
-0.009663188811619063
-0.006893369216505701
-0.009233537325871774
-0.000571625601399243
0.010260480035203742
0.018009227139928596
0.015454907191059334
0.007687844095997098
0.013158229560385242
0.008978434165498714
0.015595325134733043
0.013683847928168886
0.003923722431431011
0.028538812126175806
0.031016948815099896
0.020751861349235845
0.02272497542307891
0.011261732919432154
0.0022815122941139774
0.0026036130044114355
0.015582827283456061
0.010697499155202777
0.008313506274782122
-0.014435963675244842
