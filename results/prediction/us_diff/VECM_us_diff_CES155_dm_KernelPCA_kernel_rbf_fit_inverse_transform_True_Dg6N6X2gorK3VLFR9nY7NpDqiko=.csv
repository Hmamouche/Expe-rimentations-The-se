# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CES155
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=3, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.011663032737275116
0.03059081651539178
0.03911710456026453
-0.0006777140584320468
-0.10235939095955364
0.00925176752144358
0.046600353409585904
0.013282921507119416
-0.001350167469174581
0.032037194179311695
0.03733498012446375
0.03622414038862079
-0.027761933873249406
-0.035510578561698244
0.03691556372228377
0.04794898200686383
-0.012001519218226595
0.01662056544547624
-0.018619885054484545
0.049203593220200126
0.02111418045290195
0.002446251063238916
-0.003011872545785055
-0.032238057475865056
-0.013143337634507334
0.013562377151541554
0.014888997270607662
0.02872099048967211
-0.006922080055978516
-0.021427782002853498
-0.02231039225380648
0.05400759986189591
0.06604367113479641
0.027617182581509463
0.029945485249654395
0.0023828874669941085
0.007424451442720964
0.00301169161982258
-0.0009179403955037781
-0.00725225871816591
0.057286150567351965
0.0720144865949934
0.0656777920387247
0.030087121151286852
-0.0008561313815508256
0.02496787557685467
-0.02869960152705648
-0.03184900494028069
-0.006858117271809717
-0.018117397504593503
-0.0001157099945557653
0.028481507252961245
0.01096673318943257
0.029324583321546516
0.028430069720718893
0.03543794070624649
0.02604476212530888
0.008176677397524828
0.007855671331829591
-0.014408913582870072
-0.044990463383971856
-0.04072339868289342
0.01196795156892214
-0.00011147694285903098
0.0036211442751357655
0.0069786074672675245
-0.0089807245950116
-0.03858803940675224
-0.053615193756028016
-0.04596534837119473
-0.0409987783120055
-0.01629053649612797
-0.016677521000529504
-0.030679428823461648
0.023495371994073
-0.006048890212507749
-0.0008121414623827312
-0.005275955007307118
-0.007364928391684499
0.01715018014359927
0.03914109589073848
0.03620530581387296
0.01902220869700703
0.007185672115588069
-0.024965795281766234
-0.007976896786054583
0.005541552829285627
-0.02083060272533925
0.006875716348752202
0.007391609647447939
0.021893924508096095
-0.010849279576687994
-0.03907170166502848
-0.033599745026146925
-0.010769642261462492
-0.004264095364081908
-0.024557476478106473
-0.02750078760698462
-0.03446048723406331
0.012581048296444082
