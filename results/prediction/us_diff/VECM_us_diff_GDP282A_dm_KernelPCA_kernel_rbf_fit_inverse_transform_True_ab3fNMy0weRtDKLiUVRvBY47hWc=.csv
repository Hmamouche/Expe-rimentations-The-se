# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP282A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=9, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0044119942217422875
0.005335850431787953
0.0034543295926676067
0.002344128440045548
0.00553912122164672
0.005977871969098129
0.0033059226067241243
0.004638426436886864
0.0026699088712432853
0.002669030432746402
0.004357272453295592
0.0034254410194014726
0.006081604771464971
0.007209663209917187
0.005244852786177525
0.00550484587974113
0.004778479022817252
0.00620081671290551
0.005148374976600127
0.005192036896062053
0.004720851743654856
0.007221975805855293
0.004822813684267282
0.005497224503094749
0.004871829857814858
0.004247954252466492
0.004291756950229194
0.004064106077209538
0.002712036926053814
0.0025893454309980995
0.00016757285242067203
0.0026998337383122013
0.002711588135382945
0.0014833474659548779
0.0006157177884351767
0.001675776603930533
0.0017348781574038456
0.002217740711824936
0.0068869382359255885
0.0061791233614762065
0.006552789539938524
0.007091363459581645
0.005489647107317497
0.004294119554624056
0.006101528747405404
0.006018555811822517
0.009667980097027056
0.008576486932575848
0.004850358281355389
0.005112704560728421
0.003245249865795859
0.0014772463010256105
0.0054327490727214215
0.004979500451984101
0.0033428599900913723
0.004794206740000734
0.0054079577134245795
0.004981689297609418
0.0042506824741434515
0.004831841344911248
0.005916868360561381
0.006032967261553941
0.006518976156123559
0.0067432973551760835
0.007673263756669419
0.007110916475132436
0.009789156460715834
0.0098623020521217
0.00725984012418917
0.007658306112605806
0.008468143327164866
0.01209654445496408
0.01145775391547015
0.00736337461476136
0.004385532291557571
0.005162233031109065
0.005540783669387551
0.010270786857257543
0.012502901754030172
0.004152048780963157
0.00551552504442653
0.013466815163570775
0.01033239402750846
0.01284023885759573
0.02037668605510428
0.017979415836075423
0.014465783128669753
0.018916124973795287
0.022166557371349295
0.017332100305930555
0.017261811608607607
0.01578928179471364
0.01450100257501907
0.01504440861110845
0.008254529660437538
0.002651414937741842
0.007063852207542388
-0.00012229374943475632
-0.004596249575512452
-0.006983687089500977
