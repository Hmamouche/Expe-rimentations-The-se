# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP266
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=8, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.00483861431063462
0.0016314954813893604
0.012852454424117414
-0.002092833696353308
-0.006495608517803045
0.02296497763169536
0.051419653410853694
0.0025028984408797315
0.03627947582405406
0.01164339717907062
0.010436074990397774
0.028822716270711243
0.025815860700496625
0.005824362927267656
0.0034805079535660545
0.01256603228465825
0.010547711493973854
0.008045300109247842
0.040926575310638556
-0.015739557106251488
-0.010982225172527667
-0.02531167976034506
0.0030570524161241267
0.005035709292704478
0.01603411467811658
-0.0035650196843736263
0.022432741827687647
-0.0015818370314710098
0.0021157648549213004
0.0022645804990807012
0.003472511584477978
0.008360836890069804
0.009370094722708248
0.005126833513972361
-0.004876848307031997
-0.0020136585636695097
-0.009845202439007134
-0.02476737054450131
0.005905701039711709
-0.004180897608840337
-0.029016916552395886
0.006585285201772288
-0.027527279236254937
-0.019962099343588766
-0.0038008859865788025
-0.027243985372635362
0.022664629361569495
-0.020931543376835598
-0.01646120796142212
-0.008542930448161068
-0.008065225844495006
-0.0005073272776485917
-0.008533009240795825
0.0027295046691255967
0.001037841662512022
-0.01548023658270315
-0.008693251050216115
0.004534765398772324
0.0030527020465103694
-0.009542625077119369
-0.004883103683556916
-0.008316217230436684
0.015462544682692592
0.007666408496051337
0.0015946738955337444
-0.01052506558629421
0.020504359569418176
0.019215378145318023
0.008934757607606699
-0.013866350037929244
0.01818250163744172
-0.0018308666324996937
0.012945423340266856
0.02706382914864399
0.021135166887820186
0.0219167159996929
0.02573479540640563
0.007663407226023773
0.04378338577523574
0.011083662635065621
-0.0005946841558520533
0.035824547195437775
0.04102422303197862
0.023698523904493923
0.0005364050686384302
0.006247008755986473
0.024307789510003147
0.006734263192379705
0.001567062375444051
0.00697436245564886
0.014519111327352018
0.011807846004076321
0.00939014569228239
-0.009680129654429083
0.01571292808851456
0.0002905491569607892
0.00893244382881563
0.03019324647319583
0.04010109371740791
0.014205484262781353
