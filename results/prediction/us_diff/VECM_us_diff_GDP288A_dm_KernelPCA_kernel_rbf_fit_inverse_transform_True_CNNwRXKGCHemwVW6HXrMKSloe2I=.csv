# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP288A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=8, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.004553782553159629
0.004210319002460365
0.00708563974780051
0.006115052578997461
0.005085606081487006
0.0034764234365443287
0.006655202869197829
0.004533459761637045
0.004441602202853436
0.0048787408005082755
0.0038728108569617624
0.0017567795287566248
0.003603856995066314
0.005993170333237756
0.006360335744233364
0.004855678411942904
0.00551082430847293
0.004641096790899072
0.00335996699527389
0.005738461827398328
0.004037691600572964
0.004158224190972627
0.004881072973055874
0.005802387422682296
0.0034225235177015824
0.005706470070002782
0.0075277859672641095
0.004608699230181433
0.007504211555959345
0.007114851318382326
0.003808000592568873
0.004228945852298215
0.005767174253424794
0.002792264571178968
0.0019927118683996567
0.003600597191206263
0.003122752926884963
0.0031863280946411963
0.0050296585637383245
0.0024607789888320165
0.0022345333099743204
0.002665070596315127
0.00609113587267109
0.004689106803399909
0.006461218962536973
0.0038342120292153446
0.003880678133232315
0.005971496158364099
0.0037649920621182133
0.0024963672668326807
0.0057636677950719615
0.002519456086920885
0.005130737005121201
0.005189083663882537
0.003484331889322548
0.0034819581198539873
0.0032213467607363723
0.0035613367091810086
0.001525915388768042
0.0035330368234219433
0.003226643602587928
0.004038448894247675
0.0038132294326065214
0.006564436694446802
0.00659062661166709
0.008198667701083653
0.009580111282051539
0.006593030034172278
0.008631298578052506
0.007487308873439189
0.005160757896875288
0.005929836526558034
0.004896672688394548
0.0031902577656526144
0.003983119068680699
0.004930448202967053
0.005894566694893276
0.007237617322822263
0.00982629189281815
0.006103387963237611
0.009730898294051195
0.00906138751320544
0.004016421721414685
0.010006278516733445
0.010916816820015971
0.01374580439382696
0.011051494054788166
0.01321753734720439
0.016891685100557594
0.016306633602395305
0.01453954885858734
0.015168457908720864
0.008913399412776624
0.00886575320676843
0.012732257944465043
0.010700672422471491
0.014267497559542174
0.016421516116647942
0.014564162680708185
0.017853153075923316
