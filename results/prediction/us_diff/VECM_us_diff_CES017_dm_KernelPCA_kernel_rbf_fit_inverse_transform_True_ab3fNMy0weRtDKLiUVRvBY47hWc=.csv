# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CES017
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=9, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.05045984384163712
0.05878822997101024
0.03878791032732487
-0.0074935213114828494
-0.03632492632097904
-0.010026828502468423
0.025639221419714784
0.004559150242388307
-8.726557763013773e-05
-0.014535878516087147
0.01967733102836484
-0.04308342567512382
-0.03861055819419853
-0.018931201790717844
0.015568311647831656
0.024475289840714176
0.010733392556745667
-0.00489329789912695
0.018418904190107277
0.019433596492974065
0.01812391320107808
0.05685058415565685
-0.03172775286467623
-0.01750104349335257
-0.04299695391481302
-0.0017234408557143255
-0.014565420449184092
-0.02257830199032007
-0.022014062194502814
-0.08812613358745966
-0.08005587800058314
-0.00668722294471491
0.03964890851748249
-0.01613315380990277
-0.0021270540240862987
-0.01992295223264626
-0.030045750623023032
0.013722835931948427
0.006896183453349306
-0.03151072710472059
0.019211466163211545
0.011203734351639709
0.028072172710973918
0.02984932170306735
0.019261362426828816
0.030635357944621397
-0.0035309750061737824
-0.011441856520604385
-0.010323354206205042
-0.03937335723008546
0.006369685383442474
0.03474175398312998
0.029687521642779095
0.04260863408061361
0.016306725836111903
0.0042956672092710965
0.031395824177373556
0.014364421560272445
0.010222756977247074
0.009934550059472205
-0.037160221995977724
-0.0020430373090812286
0.01759897602344611
-0.01600882307525874
0.03696896430614008
0.010097015803790143
-0.007713484596905042
-0.022819741085480127
-0.012310317621915347
-0.012909719376083394
-0.04316771932861908
-0.04914943596946308
-0.08761605838160748
-0.08830950100167721
0.011375667767208487
-0.024151371717773873
-0.00620318569951904
-0.058491016662254536
-0.0552000773489791
-0.020777941664108842
-0.008646928223952053
-0.0008926770924045542
0.002236078219639356
-0.0011959913700730126
-0.0068888612271795595
-0.002093250516343412
-0.013612367368294081
-0.012594564446481785
0.01271036561829043
-0.004181773140205151
0.02665587045740302
-0.007699565375369357
-0.028905547829845363
-0.009157984578053814
0.012750059544667127
-0.017732480948591145
-0.025142719286373648
-0.03571055666328694
-0.03762852174268611
-0.012757373416416574
