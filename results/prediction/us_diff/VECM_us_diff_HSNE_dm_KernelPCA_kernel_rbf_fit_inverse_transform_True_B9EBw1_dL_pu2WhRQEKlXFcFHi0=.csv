# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; HSNE
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=10, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.11732594615844102
-0.00036058624761572955
-0.16545282850335832
-0.19732538556963455
0.18510033774702217
-0.03902631884285322
0.12928013359872548
0.012787402015703317
0.0232069637393011
-0.14201775288040144
0.12377904174218737
0.19925877137294512
-0.023432268808469638
-0.004942765436965049
0.0007104340748917623
0.022170154418556284
0.11269150057114383
-0.07164419484669501
-0.03122416725092058
0.08081246904402228
0.12024601422002612
-0.004582881624906332
-0.09112568697690229
-0.11161142504741534
-0.022183606815551378
-0.06263328762025311
-0.039164109935163144
-0.0051681369660537095
-0.1264178473723221
-0.1557263197694302
0.04830979561806961
0.019122711036551075
0.1973194629360724
-0.14959436999532932
-0.031351878906988116
0.027194769752153413
-0.0018734802199869595
0.06866883367952553
-0.046473726146182046
-0.023196431553875227
-0.010504129799521665
0.04131624346130222
0.0031080533068892947
0.04668410637349972
-0.0019192934474431093
-0.057526603932091455
-0.016345784000168645
-0.01928748538370155
-0.046807294559205015
-0.014658555888041496
-0.04395317850930404
0.09369206699460546
0.08849826204552813
0.0007941698590457312
-0.013500648733524348
0.018076850280816348
0.014395594742009464
-0.014944902653669892
-0.02700412611862964
-0.013790903933729552
0.049679326070296154
0.02913360303702413
0.0018569740663537566
0.007783377850031203
0.03479311617085616
0.019576134758471676
-0.061648717312627783
-0.017749666518834615
-0.005157396766710211
-0.045502093928503524
0.07218575154238305
-0.027745522587017665
0.016638013152676753
0.0031085778102287083
0.08321882821925283
0.11847258746159808
-0.09081044851465471
-0.017893327506596626
-0.14350624069265264
0.06669592456814964
0.029821212162225066
0.03783042137720195
0.022757833160733442
-0.042930180135947425
-0.06075114448184511
-0.0014877216246735117
0.05529721064380521
0.0026847971106235893
0.048773830439950226
0.03425221637757554
0.00806344343167914
-0.045682210249060676
-0.005762019337700561
-0.02855087842000903
-0.04170989725417614
-0.008144209405019861
0.005656942254842985
-0.10297728313952972
-0.032339336925807594
-0.07523390882662034
