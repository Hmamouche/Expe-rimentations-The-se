# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CPIAUCSL
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=14, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.005476549602407385
0.007156142800178743
0.010178413363259054
0.007402861980422953
0.004484116503121017
0.004014580091668152
0.006550132641231841
0.005559813008220277
0.003932097426356381
0.005206146783815261
0.0021203950364881785
-0.005107160500602072
0.0035360800734022904
0.0013757378862779108
0.008677881512739622
0.006777147687510156
0.009977755172652243
0.0056844382979067
0.0068366959635550026
0.007037612279544837
0.003899421320682238
0.008650789144233258
0.0072113470774826
0.006892012075854286
0.006012886405153446
0.009557061258041882
0.007780087551335745
0.006414231423869817
0.011856119289186822
0.008887184826446785
0.005405109472746187
0.007354563055844423
0.006351086984609046
0.009563938092073124
0.00342364008262611
0.005232901939455898
0.0036551654919676794
0.00738947718595968
0.006698754864922661
0.0057243958638978475
0.003310322972720375
0.004641128577897433
0.004961102996956803
0.009329747535850141
0.005464478727864761
0.00384895117387905
0.007670464577017998
0.0023184857185698554
0.004456804481803379
0.0041661738423211464
0.00539225964371301
0.008723250929524917
0.006877137903774352
0.008166869978558122
0.004478082304957776
0.004200944264271048
0.004975871597548426
0.002439731752544182
0.002826910942374345
0.0028614788341342467
0.0023190461603625635
0.0034820662013866906
0.00596502259622992
0.006329882626040909
0.005695961227783158
0.008767543325981295
0.005405612824681242
0.004900272279321867
0.008243186332130994
0.007119171526304126
0.008725568595971109
0.0071238274823490705
0.006389371448174311
0.00032873095434098195
0.0034800953956738703
0.0020740579950232034
0.005366364435890692
0.004769772187077801
0.006891497901139739
0.003409425741791508
0.00730417867903341
0.000493025668151213
0.008823012155901857
0.008072332365269755
0.006504335780041063
0.007506719203462839
0.006847408351243495
0.008877214077673065
0.008197915439713837
0.011682108728491191
0.012195968961783927
0.01057512906355737
0.007195115746945944
0.003540808065325263
0.00787037991124835
0.0009981713557889941
0.01163273520224004
0.011916194310972858
0.011529337135002628
0.011892888470002205
