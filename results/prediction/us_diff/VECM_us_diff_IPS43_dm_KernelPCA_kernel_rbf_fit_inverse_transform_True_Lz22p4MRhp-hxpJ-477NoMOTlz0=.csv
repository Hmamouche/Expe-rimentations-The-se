# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; IPS43
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=11, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0083393859480222
0.010393885840331962
0.008924417177717359
-0.010216487092027566
-0.0021467534760322505
0.001812877379049168
0.015437687595766391
0.012586182301840734
0.005379833784190335
0.003894593457957057
0.013777592756877366
-0.003921291053855689
-0.0005754660055718942
0.000377846915655407
0.0085082458922516
0.014189776546713722
0.011483232441065971
0.0015583445010842285
0.013644222350026394
0.011628210886869484
0.008753695407568022
0.01528950757918642
-0.009909704697329614
0.00040428426832699255
-0.004646799889023256
-0.0015470372255071071
0.0030188702880191935
0.0047491861445288705
-0.00032483582162177223
-0.006991410074182441
-0.0023290659590348194
0.0062729281938296135
0.008311624291693426
-0.00628034564983634
-0.0016423638395080438
0.004544389913869701
-0.000750693686278225
0.0171203962358614
0.015216657010958829
-0.0022966336725622023
0.012774760727887722
0.009467900262661866
0.012895540452243073
0.007871647166070047
0.008468594723432511
0.0128629993158452
0.011011745265244384
0.006495538975252298
0.0023157963622999233
0.0023937061651055592
0.0019259068864677885
0.019709858174910007
0.016138760829895783
0.019937218947043797
0.01845705222016904
0.012653504083626387
0.023041330396009075
0.01648856678965779
0.018155836757571247
0.01742683963367051
0.0065922026596049454
0.011109360499643778
0.0201171584003965
0.014094500557669512
0.0229572684347302
0.022845385353937816
0.006986791584918082
0.0074662829928227635
0.006397207168943056
0.002345446381433079
-0.008278777735343152
-0.006667978730211937
-0.020853782142350168
-0.01960018786656849
0.02111426730889307
0.007939296107653485
0.0014362109577014726
-0.0036620588853386675
-0.007026132328438408
0.011571720671530892
0.006166782424316552
0.016143997600772515
0.0027100000555165087
0.006165138834005865
0.0021273517003706425
0.0018813766292022412
0.004731255180418975
0.007359586847768414
0.01527286735470694
0.012279329419037447
0.01403288806106443
0.0021351010236558003
0.0009667229796655726
0.0002274107931823843
0.01627130472366378
-0.0023126178815608116
0.001978152114567189
-0.005106009224208182
-0.008809092609733244
-0.0020556028429722034
