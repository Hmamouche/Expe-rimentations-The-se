# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; EXRUK
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=10, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.03357477453948375
0.012113770764528811
-0.04435206742943862
-0.05996342925187856
-0.09957784644857383
0.0852331801816342
0.01925789643867752
-0.028082654449773155
0.023443023454471267
0.06494358831470082
0.1017755364334357
0.03466874437052908
0.004842819141647272
0.015107160465741662
0.05200198518375518
0.050282288710932405
-0.005769630915551701
0.10487446131069875
-0.008976188369501661
-0.09359804433024704
-0.09605615495655297
-0.057579198837260995
-0.032823062937552924
-0.08436735031272723
-0.010144266104286724
-0.0015364747551932165
0.024052409020739705
-0.01492960614820795
0.08523630086102674
0.08291954897769786
0.05103918950690058
0.01763597156262544
0.012739254094753925
-0.04942777589059418
-0.08128387228948265
0.004436614350220684
0.12060003753412273
-0.050062547475427106
0.0077621301523147085
-0.060925240637985364
-0.06446240187185114
0.013723730472413813
-0.022483675859705888
0.003151063261030748
0.01670320388574354
-0.02629842810721201
-0.035668246670454644
0.0012313917181383353
-0.04205526474240327
0.009934545813699737
0.0019502402715337094
0.05075068858125729
0.03684752156533845
0.013367293189012357
0.0038934312005407647
-0.021037811328574286
-0.00034771665531909204
-0.006656744874297993
-0.01919765360236074
0.008805421742825389
0.017888387158922877
0.039480622341977877
0.010246801261065211
0.013138631899245414
0.005721317196684297
-0.010762025056192136
-0.050305371383717934
-0.05157823690764713
-0.025446345573727783
-0.0018715231885679572
-0.007316159847671465
-0.015941733632040662
0.02374203185271774
-0.003245938380162674
-0.019468146421347976
0.004723805410197824
0.016350531167038745
0.017052517871272942
0.03283600207629411
-0.02767476555032019
0.012546197180967722
0.04066588111470064
0.019476804236335372
0.04595049926164944
0.00358799352567782
0.01229506828926984
-0.027287976542196474
0.0021812802646508003
0.028017125139352027
-0.0026321221575368245
-0.022419838438915207
-0.005395543344105434
0.01596606771077038
-0.021637826974867408
0.08708709630310014
0.021021178986950023
0.008017898550005446
0.005060956904084701
-0.007958383237879688
0.014340506181651952
