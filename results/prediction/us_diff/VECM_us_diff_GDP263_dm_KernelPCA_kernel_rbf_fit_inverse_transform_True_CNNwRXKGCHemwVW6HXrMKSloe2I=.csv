# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP263
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=8, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.006164438296319543
0.011399120570920362
-0.0010497401736971799
-0.0005751580544175786
0.0042898144872524305
-0.0006048675355168113
0.0020613391716100492
0.0008372388170080876
0.004909468736646347
0.0023422447148951746
0.005209762340771369
-0.0005143509202882113
0.005674161661259701
0.004548868599824032
0.00716870982594708
0.006873199190791285
0.0046718607969959275
0.008685001600542664
0.006704084107415379
0.011408721054128603
0.015034708796991385
0.0104666115656411
0.0098357231849636
0.005898393970334228
0.006172969623014408
0.009077643587967397
0.006342233662846664
0.010992511794701355
0.012271487032897297
0.006477246500515501
-0.0033585661523453793
0.004751332715088841
0.012051501615595425
0.002740697630316264
0.005444755324575687
0.01249784852478544
0.009340835065710033
0.005024477353143381
0.008176852957866815
0.002335375241539915
0.0033319936173312236
0.003958288024047111
0.0084306416957725
0.007031545246783752
0.008028774254803955
0.01579547343538147
0.01865071093721798
0.010253352818060314
0.009808158448936911
0.013107324978010888
0.007146786304768489
0.009388790917603172
0.009648485297340203
0.008343956856935815
0.01909723511933635
0.015076594634728177
0.020740007874802027
0.023171758068785603
0.006635977935989818
0.0049019435661668284
4.2980010139763566e-05
-0.0017979270523393407
0.0072401385720684205
0.003950208126094541
0.007458176637312657
0.01910352632636178
0.009665949129401274
0.014718096656016576
0.015008185033580328
0.012050771176477576
-0.0007203491107412954
-0.010138086048332221
-0.016935143826089145
-0.029478500829854058
-0.008378540235006459
0.013811868040008666
0.0018332449758113722
-0.009030060538797045
-0.008033183844533543
0.0028322192233414777
0.007937492058585223
0.021442066830039856
0.01550035943784991
0.011658603472840845
0.00835419667563237
0.0219442784045674
0.009301842577734651
0.014180868363919664
0.00608119581510411
0.015287195132986361
0.027313935417593173
0.018668858976259885
0.01126193910627457
0.020423927504074263
0.026677269125986523
0.014311633645407395
0.018315016895515714
0.013075521226140491
0.01755873311548382
0.01836876990324089
