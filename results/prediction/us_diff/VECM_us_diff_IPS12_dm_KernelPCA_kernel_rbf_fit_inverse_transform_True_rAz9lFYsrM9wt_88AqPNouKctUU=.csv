# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; IPS12
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=5, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.011568069685954804
-0.005185291930368398
0.015708274068067386
0.0002058671134675383
-0.003636117313054644
0.001553662107553914
0.004604554324430732
0.0048139843540126155
0.010438479059540033
0.0038145243795990338
0.007641535337371294
0.003578114934245067
0.005256075808841007
0.006022841228729558
0.01683439522888895
0.014874159201743698
0.007928457895314149
0.007093800487072541
0.002448492902664521
0.014090569424167266
0.015658976852189394
0.010408342429788598
-0.000522934806388025
-0.0036205013174144393
-0.0011007046487825673
6.993677205709549e-05
-0.0022587850503014715
0.004622666387983705
0.0037277458517936952
-0.006511984284047192
0.00022901163074382576
0.0065370708761526685
0.009859978235634293
0.0008624256735985604
0.005081911341229906
0.006995488068049481
-0.006826525807777789
0.009857462684445043
0.013907437055038937
0.009944986572825483
0.0054563738905664474
0.010426739357657132
0.014667040667940083
0.009805343658894822
0.008247936581103874
0.012109594718168828
0.002686077808098295
0.001385531792880393
0.010864055064348128
0.007876079472588003
0.010671306887402863
0.013457829668565322
0.0070293129742392746
0.01143223991911888
0.0041699833451706615
0.007857178506795131
0.012682879240112254
0.005137140728603611
0.009557478310915574
0.019387771630855106
0.008960359275773006
0.006211942980585632
0.01080023524345705
0.0078236376649198
0.01339174521244247
0.006306782642886457
0.0005741267965997333
0.0049884552289259435
0.0018595027841566971
0.001460293591337761
-0.0020758528098914143
0.0037999899505576583
-0.0006049264469822505
-0.0006172485166225014
0.0049221346099747945
0.0018684819843307948
0.006148892231242308
-0.0021703564227670475
0.00021378508693403915
0.014099279986215773
0.015430954485803382
0.015329695865156876
0.0006632602054625007
2.19474633274101e-05
-0.0007990881845885831
-0.001457386766104972
-0.004532467916914763
0.006400306507287369
0.015872573579303915
0.008978700440715342
0.013161442610252158
-0.004672014539722756
-0.005290710882303272
-1.725395956167779e-05
0.0074838716889047766
0.005462389282184564
0.00452267972740674
-0.007250692328204621
-0.0032163643296840997
-0.00488969751816278
