# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; IPS25
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=4, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.014837368482981856
0.007821936220914486
0.015703964682911298
0.010055418490909048
0.007906733782703132
0.0050525350524848744
0.010731227144352084
0.0042500580094222435
-0.0020163215437028733
0.0003544091632128577
0.00034729361439409255
-0.0030606664138719277
-0.004451803418133144
-0.0035786877083124786
0.00821923475511696
0.006438696904258649
0.011732177647132974
0.015222039881877108
0.013691571880413677
0.013056557725334709
0.008577902107284723
0.008344547951322159
0.0031316336070996965
-0.00027630644036857676
-0.000556914089454085
0.0018442802906273033
0.008831281602213746
0.007180725618763657
0.003006871997948957
-0.007787334451958415
-0.0059168017533944425
0.0022148001693556183
0.006928633571986044
0.00023357680860179
0.0031557142340146887
0.01082217953402588
0.002545076510468235
0.006193078679833609
0.011491958104266254
0.0010813381401323138
0.0029284698524872726
0.012893200566496048
0.006005690546323462
0.006936965525591048
0.012199890643742396
0.014092393956552571
0.00859604511621636
0.007891106885142229
0.013767468385062251
0.011083874582830002
0.010816288609266174
0.017832913571024952
0.018506231573761044
0.020619513301859602
0.02436321054547172
0.02866158741643059
0.0315928452877932
0.02984033253773338
0.0268605303559165
0.01835321019679794
0.015203623434254972
0.01398092957920888
0.014332856897929392
0.011809317478183545
0.013933273308461313
0.01503224684402665
0.018450876275423123
0.018852327297192824
0.01532738313827305
0.007708401386577786
-0.0053960862324869815
-0.03240033733657274
-0.03734421305582082
-0.04022118479532643
-0.0011602373537393591
-0.007192253921413518
-0.009418759402204345
-0.009504156732903786
-0.007048607427419599
-0.003347458454493823
0.011740916412059196
0.018340849282396175
0.01583338293825849
0.006008709540259437
0.014031234924826426
0.00848646100006851
0.01546775717041011
0.014979704176474486
0.0038052332904999387
0.02932279869279544
0.029981555075995755
0.021398812580075185
0.021089827851435275
0.013502592211554046
-0.00272906894891042
0.005730272865747845
0.01777632298792438
0.009783305224475588
0.007551979021735211
-0.011900012103970826
