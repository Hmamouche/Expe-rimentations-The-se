# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP261
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=2, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.040976083588417984
0.027088274946067997
0.007685700213557389
0.007589271518910981
-0.013807554129631796
0.011979506158872914
0.019057620261562103
0.016200639660373876
0.010201412412345833
0.00804695448493286
0.020211251181737423
0.03748225106544342
0.020604368252927698
0.0029761176537220586
0.0032851424736512723
0.009361524284215782
0.001167785512874083
-0.005791095692704088
-0.0189917906896336
-0.007440672599319071
-0.0041063645321563255
0.005108528631560634
-0.006369877734163803
-0.01416902903763264
-0.0028207241725574784
0.0022402022150742364
0.009199763047657836
-0.009594614205175767
-0.03221375518665384
-0.03860290866534709
-0.021805910701243585
0.012973971343612223
0.015345601034116498
0.005239214253687532
0.02087292550116132
0.01319924868535994
0.004188270724929387
0.013889698473804207
0.0015786053175638683
0.00010598500255884686
0.015536260635259865
0.03681521737933828
0.028536642328626415
0.021733241406319014
-0.0027821935488340247
-0.013489174106704159
-0.029007694027300645
-0.01998880073637364
0.014652014120099099
0.021458482838302324
0.032002831151280456
0.034294319766525874
0.011351537452307265
-0.004211318425301979
-0.006007559212120284
0.008653037114756923
0.001522379145763214
-0.00119262546732583
0.010773754540328001
0.021586145794631872
0.024566046706548675
0.027771906697260727
0.02082740390972925
0.012427863841227568
0.010019382800322078
0.0055681342001042975
0.002063000203167807
-0.005810992356181184
-0.017535450957131677
-0.003907790728181306
0.021049345513366815
0.034836568247825155
0.015006357407266595
0.007068738055873712
0.01794372465464534
0.008221420563434844
-0.003551935168865231
0.0048264287146008635
0.004087940235255983
0.028017006214001272
0.05211342640986444
0.03680651996808753
0.005800338983809505
0.028644351857873968
0.016733287973064535
0.007964401236594604
0.018170647178627913
0.03089421596708859
0.024984848130960073
0.005598172567819
0.00040887479299258137
-0.036968104042189885
-0.062291592904810796
-0.05849463141099313
-0.04503186457601052
-0.03437754713896305
-0.05141750079540418
-0.06682041110899362
-0.06677164151441924
-0.033008517169177964
