# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP287A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=5, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.009515764925002187
0.003093283920082243
0.008498060738563002
0.010068988348902045
0.00426978668099749
0.015349937025782566
0.007640132107616642
0.0008550846880245383
0.0035039350809155075
0.005825664927752295
0.0004630151911527702
-0.00030675922638661516
0.0020707741623599424
0.0008190095978402485
0.002465773019066628
0.004415636943623619
0.003224764564501652
0.0051089426127840076
0.000909773414929989
-0.0004361565352783191
0.003055526417102829
0.003789420347073678
0.00472930997952405
0.0010011282133200725
0.003001056499779024
0.006938304931471832
0.0019709485077754898
0.0046633880780452145
0.0033015444394123798
0.00718372998741472
0.004619663017774363
0.006764157934724066
0.010354661877285573
0.00668543343510019
0.0028101781678761856
0.00477356552536345
0.005910291750896576
0.009105288906712406
0.0034222773217712065
0.0042588418281694134
0.0036428376735126835
0.004525903629159549
0.004684117577077707
0.008327670549077265
0.007138122644946676
0.005927439230115605
0.003868859342181356
0.000934536067380553
0.003910155704875163
0.004108761665232995
0.004278656553362474
0.008595822757602612
0.010894134384072636
0.006723296570913532
-0.0016175130783369343
0.0028701790029139196
0.005283134812260915
0.005612144395812638
0.0018245341178175795
0.0023706556987045874
0.002883622542190889
0.002621769961154833
0.00017144772088452663
0.0011274327358552529
0.005014094336054547
0.010078358882835491
0.005418794821479432
0.005977352970495333
0.005478935598863988
0.009696592815761422
0.0021580962773067743
0.006011645092492589
0.003669369703476639
0.0037330800432231743
0.004432626621246008
0.006242793617821431
0.008849993712578347
0.010487988662808156
0.0029421688168359767
0.004489700600600394
0.014408513622969856
0.015883601450329604
0.0053162879590455195
0.006099104514061264
0.007764084647305605
0.01936071304454905
0.013207806486011674
0.008210201140760522
0.009283234401374976
0.020773623863679678
0.0060120725608671525
0.010295006691981357
0.006062071137668563
0.02030957262060338
0.01190007061570936
0.0036293100887994393
0.005305679380853913
0.016777343261716628
0.010294606973370268
0.0043021339547228196
