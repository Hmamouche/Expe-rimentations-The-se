# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP254
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=15, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.011781495447941319
-0.001894054943679912
0.005066438041114449
0.0036398243706396577
-0.002474548844549552
-0.000385873988651508
0.0024088697089355753
0.003877674543704396
0.010124329345944327
0.0069656985456202775
0.02781245971913123
0.015388795234739247
-0.002227739870065448
0.007208897166324765
0.01169492682522787
0.009984307539306826
-0.002873593076045862
0.0018526512800967451
0.0031613646090092942
0.004259240818408422
0.009255900039130568
0.011499203783498408
-0.002443882207898401
0.0016402605908546013
0.0032385980669785235
0.0033001435919890157
0.0027754567058235523
0.006987493526560395
0.005645284525584651
-0.0030228756361044265
0.009977256769567835
0.004803407824245121
0.003792955477595047
-0.009286263592286055
0.01031262104081703
0.002654610970392194
-0.002326327757332742
0.008597222830475147
0.008614877957259948
0.007176875355904409
0.006176486005130035
0.003906540870447992
0.007008800584060158
0.0006172211801861102
0.007240975808972823
0.011073001378579053
0.005709431033689073
0.0032428077619826605
0.007992346697768937
0.006092827265924871
0.0037884005779830698
0.001581837735327498
0.012206819422301946
0.0017253130430157295
0.004494912915001208
0.009426762197598419
0.007544822684254919
0.005262360948671371
0.01360032064146988
0.00615425051661963
0.01357045474242086
0.00853745560219408
0.011345763406476814
0.00952884712954404
0.0015619004595565276
0.012691383204609117
0.013614984158997222
0.01398314344712022
0.0056042115802387195
0.008946547304928004
0.008486259773650619
0.005847188032434849
0.0035799912114363804
0.0038809646598296377
0.013435535547116854
0.010976346999406073
0.005774269930947975
-0.0002869887775739158
0.006615454164653225
0.012411004973348305
0.0071885596388287605
0.013422977857880698
0.014753339129585506
0.005468383963020255
0.01182986622672034
0.008565905812237375
0.010156520029837217
0.011513623289045623
0.00905365986538292
0.009814384378457698
0.017000482577812785
0.0024709820272359176
0.013709889012759501
0.01278804485808083
0.004452194983427492
0.00903469599065556
0.014597702674491154
1.7432616056689554e-05
0.00020750735026178703
0.0029415789008794503
