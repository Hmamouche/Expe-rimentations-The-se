# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CES033
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=1, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.03183252517643375
0.023277681717548765
0.0096066667087781
0.012758845480760702
-0.015365023826926618
-0.006041756636935472
-0.006461678557463697
-0.01219980066055255
-0.0010305471809551017
0.00048515497169441743
-0.001937981002424107
-0.007923126135010351
-0.006053484060616879
0.004397590048201579
0.011539384815478374
0.011772987912112206
0.020776575128355474
0.012903094317210193
0.0016398969339232817
0.01118163905119856
-0.002555431922041938
0.017534759485509668
0.00648531555973816
-0.008334047341053705
-0.013457714810003466
-0.0002965444384443938
0.011798271006506215
-0.006410186328606772
-0.013552968107226919
-0.020432302544157822
-0.021670365788087013
-0.0058414516858824005
0.011925101893902765
-0.0016403862270242607
-0.0008885316512214402
0.0018525074316627175
-0.005263938618656789
0.0080088797401861
0.005144083601888884
-0.0032529486417966374
0.0038362604206875145
0.006641704798921056
0.008918266735091648
0.016727551193723777
0.006562655245858648
0.00856801911264195
-0.007818684119568913
-0.0211915250190189
-0.007304679208302708
-0.01816904973561818
-0.006756549533944877
0.0005883220349013891
-0.004510237135519171
-0.0011140775836893588
-0.0020719390118649258
-0.005779335855003736
-0.0021025752735426557
0.0031203087704225743
-0.008621781377530542
-0.012588650946445472
-0.016866386894372202
-0.013768973457469571
-0.005747489625618943
-0.014594326482384503
-0.006561848942903376
-0.0031338158330895963
-0.012204242684620923
-0.020946535566177798
-0.02030285481402777
-0.024596429225070732
-0.030486023050596826
-0.03361890925452343
-0.041275515155631444
-0.04235743573586427
-0.010842032332034204
-0.026048509141702626
-0.031976596922793414
-0.028655043155748763
-0.029793912295229562
-0.031147850767883713
-0.014321377536500892
-0.007251306621936846
-0.014229094594708851
-0.007412341781555546
-0.02231381616097062
-0.020857641654237175
-0.016788492564023275
-0.0125907736383715
-0.007243256942171868
-0.007729520350259268
-0.006341340050420611
-0.015974633478706132
-0.015300163700727839
-0.022552874609632817
-0.005974967909327329
-0.010177937932819146
-0.015090273937203184
-0.01159223501261777
-0.016681931806097894
-0.01745104884701096
