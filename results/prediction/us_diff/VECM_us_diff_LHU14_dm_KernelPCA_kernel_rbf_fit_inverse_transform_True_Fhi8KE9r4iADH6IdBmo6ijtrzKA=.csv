# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; LHU14
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=12, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0829551688557283
-0.09479916092409083
-0.024892169664582325
0.07363979300935251
0.06122888298167778
-0.01773080874574903
0.003150818875186673
-0.07468928429449391
0.010214071575185307
-0.04424684672155213
-0.031586527774961654
0.0854966117465955
0.03094726315816773
-0.00898788678699957
-0.006680221845823125
-0.011624686488939523
-0.07462374648933205
0.04372436173256963
-0.023010505943619534
-0.1362975494728223
-0.03907965146930722
-0.07807173029675413
0.04242292472000478
0.04758131195254567
0.03534758535116646
-0.026312648767941028
0.01558967179568134
0.02611407229695233
0.04887853959171589
0.07577562046983108
0.07306570941758105
0.00897688405749082
-0.055410148812597475
-0.0015238301756379281
0.008427178227857622
0.018437535167945406
0.06393138557464041
-0.013176399635281603
-0.01487904777839706
0.051308676222710625
-0.05369890834282248
-0.0298558805437467
-0.06780435659934646
0.00495442011875461
-0.020073557772434643
-0.011015186665023963
0.025062354511058312
0.014590760614063022
0.007019757908642381
0.041090748770635996
0.04552376451083417
-0.06533933001873585
-0.03665001305722777
-0.03194821314444823
-0.03185195620227077
0.03639359150550481
-0.039796223871366145
0.002339947417939494
-0.02042728483906879
-0.006231964275450384
0.019076246735686458
0.0047176768507763735
-0.04774701066018388
0.01155827891643679
-0.02748833393304698
-0.06514446214401028
0.03305442028713511
0.017600510805228578
0.030793465081192052
-0.026172919570524995
0.061591955357951665
0.018255393506439756
0.05554696056292157
0.06912922009516326
-0.10258627650439472
0.01717640419703178
0.05447175213038158
0.01876566794252913
0.06711550156954646
0.005916737193988525
-0.015159980967482785
-0.021209259888629373
-0.01295287169517901
0.03039635870530435
-0.02160452657393985
0.024544231571597838
0.004009865472178142
-0.006688781677477319
-0.02999880602623045
-0.03488306147422378
-0.03361255012195051
6.45240289890471e-05
0.0385692123876456
-0.023285103345770733
-0.03399546884097522
0.01728402289402636
0.029573403034513154
0.07638290152912589
0.05419058113714839
0.05428320279622561
