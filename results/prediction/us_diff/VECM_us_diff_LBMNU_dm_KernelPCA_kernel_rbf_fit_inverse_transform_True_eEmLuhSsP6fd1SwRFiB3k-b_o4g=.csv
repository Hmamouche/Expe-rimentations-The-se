# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; LBMNU
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=4, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.01594786428604805
0.008354964928525731
0.020301174697100847
0.016665881048026427
0.006419469251369636
0.005838507490494157
0.020910241013570516
0.008717837963389775
0.008113641525597858
0.015086005610302149
0.010882513120646288
0.002853256045156962
-0.00016173957175832595
-0.0020884269818238106
0.013870472210198959
0.010293737723264387
0.015568838167251048
0.017437064661188512
0.007435785079934023
0.014100267589061508
0.011365057468466012
0.014696017925453312
0.014514760882763742
0.005174483160062374
0.0031272803240188383
0.00827613500590592
0.007219430059626468
-0.0025574958670450446
-0.011120143627053354
-0.015423801660933458
-0.014500579296621637
-0.008032675737132816
0.007938116640722175
-0.0027589579881610892
-0.008612433338092178
-0.0014861035070187724
-0.0031260899449408576
0.003245878120056155
0.012429425193810439
0.007044126182535628
0.011964959882785793
0.016459174962118267
0.015883517956037253
0.022677462485948343
0.020506288726423412
0.016693740807815723
0.010843892044200842
0.00817411745991311
0.011416503867203867
0.008772654052584804
-0.0017554982646506528
0.010730131882717866
0.012485689199354992
0.01863192492721459
0.019574513579300797
0.016808544094092936
0.021672188090155423
0.014283054465892241
0.01015785634930574
0.00481238021476728
0.0012157722356692892
0.01201833129870871
0.014943241588167146
0.0093614859139181
0.01735646223569885
0.015863219555464332
0.0075036543902903576
0.002979203202557311
0.0004923489849331295
-0.007055832202256515
-0.010390320477277743
-0.01158063245168381
-0.013742407709087624
-0.020698347340919618
-0.008013511377368564
-0.008318687836168013
-0.008822389555077626
-0.013061712111949958
-0.009490135715188332
-0.0076638700950338035
0.0062368049191504175
0.01380148172450261
0.010132999080676438
0.00041488042896742306
0.0031600264391766614
0.006787416225057357
0.004678775144689159
0.0034614474902765627
0.009622785876073413
0.008846157800632871
0.017600186783145923
0.005949590638357306
0.005511821600838938
0.007942633507276007
0.009709354005670578
0.006383844847574973
-0.001326356373043272
-0.0035758610298821563
-0.010317424000482479
-0.009178589126646349
