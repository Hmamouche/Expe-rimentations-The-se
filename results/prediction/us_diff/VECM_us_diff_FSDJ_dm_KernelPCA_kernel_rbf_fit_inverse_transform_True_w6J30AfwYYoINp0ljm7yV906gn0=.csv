# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; FSDJ
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=14, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0005291392402329116
-0.013201332743287782
0.0028384567799089
-0.007396443715151413
0.0074310405596026575
-0.0029665750184084245
0.0049300225826106655
-0.001661474064096398
0.0035086919015926542
0.01388031293367267
0.016172485691920833
0.01594906893209009
0.004177641272792265
0.007910597514643979
0.012071709519942658
-0.0016213921213583278
0.0037241835234155547
0.008713995638118982
-0.008000989118007833
0.053395120029696326
0.008463420014643895
-0.030102119032969773
-0.0016959107182447715
-0.0017712498797556953
0.012585636461867934
0.013917788500816753
0.010739059521480963
0.003981518799831196
0.00456149358048372
0.0030916164547173386
0.017217087122133774
-0.008969078827872443
0.003194823825516754
0.004706731226555905
0.013835429507246434
0.002654700820457678
0.005607014464314277
0.01014087084600349
-0.0009575607758760443
0.008702443385704407
0.010622066696957285
-0.002611563549356316
0.002261551665077188
-0.00428067671703589
0.012420226291493369
0.003412748395737919
-0.0052841038314486635
0.00951897435242808
0.03139436619178024
0.02457765520899074
0.02168515692702861
0.010842691935646858
0.016981764852330158
0.01449292039724289
0.02682222021737543
0.02308632073563526
0.0448661483848607
0.04259579120748846
0.04584321174863733
0.023759763603696284
0.055187183826535466
0.025724078544911357
-0.017078004105583834
0.015000448006451094
-0.0015029041562857857
0.053949616776286555
0.03535207292312414
0.04466324787522541
0.019355595878727
-0.004098900149414813
0.004535442418712706
-0.0027203859971346367
-0.017958267791476048
-0.012293352340115287
-0.0025563813084302067
-0.007371174315761711
-0.037317829362196665
0.008616688340278449
-0.056305990640073814
-0.015141082152808127
-0.04121577922819239
-0.0006895830895957316
0.025752998872907978
0.019002583521802466
0.016266889559761463
0.028011144556145125
0.048275715370114984
0.006755114154106337
-0.006314185846754514
0.001027303339723673
0.019763750725596788
0.001368522823729939
0.016457559597979676
0.043858259272224434
0.008342091557168757
0.03933103273129217
0.04022314129265155
0.020957820370330792
-0.01955604310097283
0.003212516790763967
