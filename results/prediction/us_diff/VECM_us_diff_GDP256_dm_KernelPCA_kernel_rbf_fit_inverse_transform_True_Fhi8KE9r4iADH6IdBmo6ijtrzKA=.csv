# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP256
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=12, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.021926636732398166
0.00010860260077013607
0.039584786831741665
0.023477048527173316
0.005606729135761778
0.0030608486181119606
0.025998824192584914
-0.008877603756268651
0.01156330430610366
0.0024141531702521254
0.027355900380889364
-0.010708296132016433
-0.013695233427185146
-0.02287602170625071
0.014411478642677694
0.019423627024051197
0.01590341659663771
0.004812104145157632
0.0062064396453556814
0.012904447008154765
0.002344464918405049
0.006366427095267184
-0.0029210347239174528
-0.0005526074007141137
-0.01668212020514453
6.132138829677888e-05
0.016249603696718965
-0.005736557298271921
0.0028521055877053954
-0.02661246231845613
-0.023724033428369627
-0.019038197793248057
0.005173758526396062
-0.003052595183729804
0.00808420967706256
-0.004268193091748276
-0.00020592831692215537
0.024123662652923733
0.021753020569704865
0.010848537439454492
0.033125343396717494
0.016788840348363858
0.017685303392996243
0.016779690910895245
0.028539297689083438
0.01967099846774827
0.013373724631999673
-0.007152346885995406
0.002131219873276696
-0.0020062470635858164
0.0020209830000889077
0.020995248193370012
0.014200240957794937
0.026969585962277724
0.023885139503876943
0.004868434344318597
0.0362916274605946
0.024908859940369506
0.011645425999745981
0.034527467270685334
0.007225870222238636
0.003883393546789024
0.02230095905310456
0.03315365170455617
-0.0013690217312875824
0.025437223846160918
0.03487177171450474
-0.013754360765002686
0.019392486722629096
0.011515451745726843
0.007047852265942605
-0.0003744726077503681
-0.02391820616900959
-0.04557623646967968
-0.010794692794147279
0.006869190446667383
-0.028775967904029972
-0.012446514701870004
0.009525063135811777
0.02294921019877973
0.004533537690939511
0.03413435245404976
0.033061190894322655
0.003032546848871963
0.003563860571221295
0.01563335763121388
0.03834859649891143
0.01768324869080931
0.013734732387482164
0.004425996301175853
0.012574411128830456
0.0075628413880097145
0.004366739181751014
-0.008707108787834265
-0.010074726041240774
-0.02248415426329898
-0.0444567590406403
-0.027442676402957937
-0.013628375252062721
-0.004822224510966987
