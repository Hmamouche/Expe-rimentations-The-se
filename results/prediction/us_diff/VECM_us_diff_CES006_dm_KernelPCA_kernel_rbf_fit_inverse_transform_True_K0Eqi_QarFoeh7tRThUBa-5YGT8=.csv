# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CES006
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=6, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.009623076508838955
0.010153559710995227
-0.022180721321166344
0.0034980846593261616
0.01639998540836217
-0.0014498874473231824
0.0006682490122050799
-0.044532682991581515
-0.01049074010648329
-0.039906169989705906
-0.05663582495841164
-0.048672866116950306
-0.04830133900935753
-0.025840463309089182
-0.06159434254231789
-0.04942671570438534
-0.004535676921306336
0.02192827542662598
-0.0248817897379114
0.030935424204689473
-0.02906607170634893
0.03070262875515088
-0.010231542923442733
0.002959450845650526
-0.005320908525364855
-0.021020842012940084
-0.005326219333947805
0.0032670005473974754
-0.016581409571370935
-0.020282401055621735
0.013858072363942644
-0.04111865144510331
0.02489744863444745
-0.008736676830385766
-0.03560390493816772
-0.026364126287112735
-0.04933292906120301
0.0583707894247731
0.010737032600688728
-0.010335717326685409
0.007850410170530583
-0.045687560137616504
-0.01368002310896174
0.046018234399841484
-0.009602304353518158
0.005601378528386767
-0.01713349132372284
-0.02051373534649488
0.016002960928181903
-0.01671909859519448
-0.022321699823498586
0.023033654106130765
-0.01519007848250676
-0.013503267945608913
0.031024252991606088
0.021758111912882544
-0.00022951836802567434
0.0030185752919746284
-0.0005417511886096817
0.014117917959048243
-0.023762613444496126
-0.02087510615390052
-0.013955908034174276
-0.01315718708882866
-0.01837128683097111
0.016968678257719014
-0.027621605572635325
0.0029147776070054003
0.009817440735926788
0.00534716859909801
-0.03354508059979138
0.00025985346035930666
-0.02069301550493875
-0.024524647315117228
0.04059181976289347
-0.012194898410698497
-0.04462272247176207
0.012995597620903961
-0.004150552321454657
-0.01558915402649981
0.005919526260260611
0.012837185212210113
0.02893578293581835
0.019703941672904766
0.02350429762807559
-0.019479603662402645
0.02706573465855528
0.01282230868341865
0.013701426745046794
0.027687652780592882
0.016347597100294375
0.034183689492354535
0.04221904252929122
0.04522024837473945
-0.02108642952618649
0.03929497360099006
-0.0017928842190354033
-0.001995823387659034
0.004572817421675417
-0.00346076694340431
