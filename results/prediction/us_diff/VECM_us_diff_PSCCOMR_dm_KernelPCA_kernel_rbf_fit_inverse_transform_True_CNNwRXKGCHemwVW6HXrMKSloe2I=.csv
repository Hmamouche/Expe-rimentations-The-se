# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; PSCCOMR
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=8, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.020894562953933493
0.07150420913445008
0.0475741075604733
-0.05822816119911163
-0.02605683334849834
-0.003690888907074759
-0.040067327289376314
-0.021553149135286397
-0.03227880426033527
-0.03056257952316787
0.01931593247832739
-0.04665178491202691
-0.04857196705412963
-0.008689387317591467
-0.0045644094282302605
0.06462303428632216
0.039704011809935484
-0.029279367324389162
0.044299468098743314
-0.018941246523847426
-0.005229926269047714
0.002105519892129166
-0.04056465350644797
-0.012628141769232774
-0.02261301832896502
0.01457271689613447
0.014913148999282368
-0.018057714629479145
0.02596038483865047
0.013462909167766785
-0.04885332595912736
-0.08261215789995839
-0.03334292124133734
0.03648961970111364
0.02231659931289477
0.026726703867118833
-0.056918009654493215
-0.031197716021608996
0.008411143539976629
-0.03232640450328692
0.021252536376220887
0.0402375178791169
0.022416418848450748
-0.032185027049788956
0.028087315806971613
0.04703356746897727
-0.032273467161121006
-0.01573397438652788
0.006186531915273194
-0.01994075572748423
-0.017633929008958594
0.04733034943809326
0.009807927783084845
0.0035933518272595498
0.03323730817354763
-0.03522178114759002
0.00027770906327450294
0.0023238460467388767
-0.04396264281957404
-0.015579459327030705
-0.03673713960850377
-0.02759441761762791
0.017664942489194608
-0.03279348059222902
0.005605015370020094
0.0034639851162939824
0.0005204193208343923
-0.055886225131617846
-0.02172284214225615
0.007041789402869382
0.0010563855016956294
0.004397736318768666
-0.050707462124443124
-0.03282275518253653
0.05746933790819517
0.012389684929962463
-0.008956001572979124
0.027281799043226064
0.02776913362908367
-0.005777264067854308
-0.012935697504795004
0.06681917622479251
0.049446682641838054
0.013742920076348867
-0.002873098600722603
-0.020119582559849986
-0.03225826306969173
-0.020526675980060385
0.016495712985224613
0.025174476617549645
-0.002137866709700325
-0.002742486807582784
0.013064302091993555
-0.006028649229873628
0.037102225176578754
0.05915539515182603
0.0315864733138955
0.0006897103183125704
0.026005044200295653
0.03032595312731279
