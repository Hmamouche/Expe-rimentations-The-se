# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CES155
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=7, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.03597227706623227
0.051605419630090785
0.05492758572510569
0.023305409377627276
-0.09155853070564475
0.02385343362917717
0.11327773524217506
0.0029432127283253442
0.01194905328034334
0.010171187729083096
0.05195669122970298
0.030282370719916116
-0.04106419726795706
-0.018051130314086068
0.04217162824407078
0.037693800884971415
-0.007052518362478605
0.031954300694189024
-0.030417606381113724
0.06207484532547629
0.02447487999833397
0.051848175913062094
-0.006631655946389433
-0.029400879435983296
-0.027321517110578702
0.005202199985840532
0.006016854866858171
0.030575006416709963
-0.02345952304539249
-0.049909520302861596
0.002675423876130325
0.02240251303547903
0.11096769767794464
0.03675830660140603
0.016189279552209612
0.007716693893483928
0.005644518096295216
0.022695920875037207
0.0053604392700693435
-0.01809026631571605
0.07997848068718905
0.060418615497650756
0.05275685112332331
0.042531830014604616
-0.004356374429381853
0.012260610874213863
-0.017524900138663285
-0.030769532045029954
0.006946874365958894
-0.009589857579434643
-0.011729478821232594
0.012109825951232703
0.012215840723623101
0.009232180754487838
0.04202427530113297
0.04661723698651934
0.024039244654044195
0.007949402199224282
0.00816998669574093
-0.0037441223434959915
-0.06340523346530849
-0.04858350023334222
-0.0024120236529800183
-0.007870736371543206
0.0036502363405045883
0.026194807892889072
-0.012955707572588513
-0.031591927361107726
-0.061510329691249005
-0.04155908852413907
-0.041666346191055165
-0.0257718956307383
-0.021069972740364738
-0.03959404018368972
0.04394747266561023
-0.006095991129770955
-0.011808829468406426
0.001168959615659851
-0.01551845706920012
0.023823928884853754
0.043988029930288
0.03896031332648762
0.018680561161537428
0.011715013100103156
-0.01258779698202229
-0.019585197566271112
0.016284607398844644
-0.02418922240041767
-0.002041041081367656
-0.01234960735417218
0.03127863076450969
-0.01010087044962206
-0.04843747154128475
-0.014427881834829178
-0.011827371712777129
-0.011125940048560566
-0.028869662969470106
-0.04282860484174048
-0.05093989171149816
0.005895787170488376
