# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; LBMNU
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=14, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0015112874090083116
0.03426904241205454
0.03552800934874385
-0.01916137348961703
0.004324571702259047
0.003915600671044777
0.025814034047933046
0.0008012247840063769
0.03351604817187141
0.018925108768443125
0.029856609720444773
-0.007189519304518017
-0.004720617904313442
0.011324743652011585
0.0031468873198318035
0.020468277111083764
0.013859468787551687
0.009179862805494113
0.00903349276085464
-0.0009570810832143818
0.004774873514874796
0.0224314721399899
0.011791741522951548
0.005007272719406282
0.007755847989419999
0.004998993373437697
0.010583445326310073
-0.00392861056472866
-0.006601891701448109
-0.024939853733383407
-0.013274188752951784
-0.0023657963581708804
0.0054840558835413805
-0.004650943325256367
-0.019473295120442907
0.006727990403078465
0.0027016085393694036
0.007763107976731702
0.016569485680482592
0.00781987676762855
0.015496930535430583
0.010021422589801309
0.02108951640742165
0.011406388558938616
0.02150692119374472
0.013469407949303505
0.025217046502159817
-0.0009152627306590182
0.009792914217954293
0.0010957453386606928
0.0009353856235600179
0.005640184727734256
0.01908917917381526
0.01708646584248429
0.022365927251225423
0.0057252189297770165
0.02731687504731746
0.011010226645620652
0.006808121939366124
0.01226217092794275
-0.0063758275384546495
0.00736798879770174
0.020798029457503454
0.008357053960420645
0.021679988517434433
0.015376974203852327
0.004017750695731409
0.007297482926161166
-0.0018588193676144624
0.0014292788821177213
-0.01039802918888863
-0.011805316887494253
-0.021036826915609125
-0.02111326630721116
-0.0017146169687623936
0.005690706538852827
-0.010707569581381474
-0.01817397823327606
-0.007081100649049184
-0.00045748797378294525
-0.00020705855973826267
0.0027558700432323727
0.01149767348133087
0.001314422223575773
0.003777960134229972
0.003298666297827635
0.0019497900143143282
0.005418476506351494
0.009433323256769596
0.011691987751145617
0.011421098661317073
0.006136321714091838
0.0035481301688597743
0.01365146792496279
0.01043124949768185
0.0044088177084608965
-0.004742178624549862
-0.00923158699206314
-0.009503644951092708
-0.008919406562447668
