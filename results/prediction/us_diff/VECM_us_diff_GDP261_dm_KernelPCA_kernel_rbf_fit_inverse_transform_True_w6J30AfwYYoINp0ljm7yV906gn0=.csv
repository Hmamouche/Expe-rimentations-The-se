# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP261
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=14, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.048591064554983965
0.0027203706188605944
-0.025686616899874785
-0.039347036164203604
-0.01621952648692513
-0.01227806174892105
0.04137681117388025
0.05256371818876792
0.012351614830949362
0.021760500752304478
0.0641967285188626
-0.0023337820526526964
0.002069415002148976
0.0012535566965388156
-0.008164200185943783
-0.019386562392811165
0.019599763719062427
-0.018385269034365506
0.021656056751357056
0.0107827809193287
0.02061192934432857
0.03871233777881687
-0.026890236889555386
-0.03013725603771989
-0.010659931027328122
-0.027343571218826995
0.03436986657801177
-0.022432280807761412
-0.04803797109793233
-0.03357428747089477
0.00912784729388192
-0.002611845757260779
-0.02811708799537313
-0.004752534232101346
0.018460743610065083
0.026382595732538636
0.02024400253114366
0.022497360403974768
0.0023720393344890704
-0.0023330910921440873
0.02713041607546576
0.024935065019452543
0.03984211069613579
-0.01595616062056241
0.03042966670796693
0.007183890757581578
-0.0007019007280924033
-0.006580086151715462
0.0012675630967834742
0.007427045708333531
0.007955134724332291
-0.0026357112365413167
0.006420674798133658
-0.0037650825086546933
0.024317070776744026
0.005693146202749424
0.02095322486638
0.00734993718196743
0.013099801122532896
0.008032518023441357
0.019828115700691817
0.013566483033164989
0.026669106825069247
-0.012404654336464082
0.0033631331726896524
0.009168989512693744
0.013567838804202497
0.0034591021941940067
-0.012049041986104153
0.014201148989389449
-0.0023338406089297463
0.014863980425886297
-0.03238356436901525
-0.0034293807264988976
0.05174115056084131
0.03990342385823621
-0.007132079541699229
0.010084607312603572
0.011357840571119208
0.014744600329968825
0.0337979251852416
0.05814474735763737
0.030226889957793844
-0.008686964342590173
0.024150138411862303
0.015907221426120596
0.031312953191397236
0.02202280418652234
0.013528364275093631
-0.0020460760290277233
0.008114375211205583
-0.039508814287463556
-0.05460535778903789
-0.03281603866089239
-0.06239459974409109
-0.035508768925972274
-0.06366801916304683
-0.09491405896093616
-0.05426059911337982
-0.0471490639577128
