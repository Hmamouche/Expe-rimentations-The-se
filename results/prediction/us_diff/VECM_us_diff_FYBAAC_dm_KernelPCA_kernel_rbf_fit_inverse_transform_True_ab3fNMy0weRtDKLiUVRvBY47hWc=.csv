# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; FYBAAC
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=9, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.0639499266621078
0.003781862733126813
0.05969453369070482
0.04308656667285904
0.002878855247970909
-0.08162878113612078
-0.055510735799940425
-0.06826982242330971
-0.03410972912142446
-0.03918153481089534
-0.07005846783300045
-0.037484476514945464
-0.043336173497301476
-0.003663658662249559
-0.0433559866502929
0.01893184826777039
0.03088714671377496
0.04702461836706392
0.014611516226139959
-0.02060289783323392
0.009251167610399636
0.027550195992820783
0.01345550609766908
-0.039847703360864906
-0.04465076143883099
-0.009277662947134564
-0.002540635626588475
0.022872889117204413
-0.026993436200815478
0.004580369330228248
-0.026681071314583398
-0.008211427215079066
-0.018575209805338874
0.005216140571258972
-0.01295111900622846
-0.01184952587113662
-0.03960294155488521
0.012710866753693909
-0.022823072361313753
-0.04272036093310988
-0.01504711280694105
-0.013328853035417943
0.038042178357784
0.03166670637083876
0.02770281231819316
0.06420706060358165
-0.026395098797304024
-0.03096535597774943
-0.04098599621462927
-0.019311513293015933
0.009967220013441455
0.01658573970903728
0.025063041951455377
0.0030178874227741667
0.004096070535470774
0.004697880602710004
0.017534309949496524
-0.01106516957431824
-0.018762126059506595
-0.01699021217419831
-0.008667190748381884
-0.04239791547455983
0.04261483952400537
0.01429526950828676
0.005791486724471541
0.0507880392531732
0.01689610765827639
-0.003724280232191835
-0.02626214955406903
0.005794954988434953
-0.04013271894167522
0.017927330166240957
0.005409991238647995
-0.040975771320227186
0.016975300590638696
-0.012270298448259855
-0.054585203705153705
0.008295233285745742
-0.028552731450873337
-0.01506659215161936
-0.0030293621132983107
-0.0022202707135038657
0.03670785000483034
-0.0008686852061889578
-0.043152869871770555
-0.0016565795862167106
-0.034724013757957674
-0.026894004702029885
0.0037339900375115455
0.013959210774106695
0.017109374057606864
0.01902583211470503
-0.008917432508111745
-0.00855491099267874
0.02453853874121667
-0.012371664756295381
0.027000629795898748
-0.01742491840969667
-0.040712481757200394
-0.001261684178552284
