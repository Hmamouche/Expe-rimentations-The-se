# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP276_2
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=11, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.014093803875914383
0.00334881811774807
0.010657854207923416
0.0023366341238930913
0.015627196746282334
0.0061127231770121675
0.005282860401701747
0.0032552488683887967
0.005887080120440081
0.0037927039406715425
0.006080375173408433
0.0037566333857854675
0.0019428201346380358
-0.00587098616622459
-0.002225375370342458
0.002700862191332287
0.002262239604866401
0.00115900160126502
-0.0030369450913983725
0.0030975365403947634
0.007232408444443292
0.00317663212368742
0.007819879356169573
0.004073382014144989
0.0026382675648318208
0.00171095360422358
0.00536685060574711
-3.08656478288029e-05
0.0024822350166729948
0.005218399097122801
0.006696852930520891
0.0032048954141263644
0.006183188051756161
0.008001668151957408
0.005067366092252637
0.00342823974548871
0.00531389978680088
0.002767036424301595
0.005177311229975336
0.008868478539434736
0.009028847008552072
0.0037445759524819297
0.005178178300771568
0.0010469883489660917
0.0059450605624589755
0.002566390500583702
0.005769287428044181
0.002367562910775641
0.00030833961725332303
0.0018120664863664673
0.0025276420970231006
0.0015809755738985139
0.006793398618239133
0.00380942621842817
0.009418329237831504
0.000309475001317176
0.00330446112643479
0.0016800117958050901
-0.004785218135273317
-0.002064417981139198
-0.00133648839241779
-7.972185779092091e-05
-0.0006180021292314301
-0.0014110015445662298
0.0003957650536483196
0.002469913262693383
0.0035511784969049645
0.002390384667760526
0.006053590182118583
0.009703366193079606
0.0246243228610944
0.012105901144097535
0.0008729584551557055
0.0016706310865462434
0.005492690365635827
2.628149092925706e-05
0.005908490512721118
-0.004074902165793817
0.013752217037747774
0.009336001548234678
0.006890785513483809
0.0034528444163051605
0.0038514984079700172
0.00834568623472836
0.008816889106988647
0.007685596321323457
0.008136505055193765
0.010822870283667517
0.01642270221898633
0.030816815672993873
0.020839018795179125
0.002316322045559434
0.009732194956475102
0.007728947179686127
0.017295993843929824
0.008088779513985603
-0.0053973148976421735
0.010305522088287555
0.012913338480419482
0.023470230633229155
