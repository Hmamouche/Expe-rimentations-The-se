# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; IPS11
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=1, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.014338622733907274
0.01160714768876126
0.013779966692097741
0.009023024562532764
0.006522770105270662
0.0036339386585401033
0.0026221527070179173
0.007096442771259285
0.0050532065698246625
0.006226881979972487
0.0037204506640844247
0.00336345735011336
0.003309647468985742
0.000907520166869063
0.007698604375803002
0.010189859995151783
0.011519787053653358
0.008284278708985455
0.00554461630596312
0.014818276177872005
0.011715011207318837
0.008262504288101397
0.001071231305301757
-0.0006195794099551423
-0.001936564429709883
-0.0010745445640697024
0.0015146543957101771
0.003022447165209871
0.0009447231497927359
-0.0029713937604382945
-0.0029051174620577038
0.0005980801245973518
0.00016955836195253955
-2.6803815216058877e-06
0.005686445928648369
0.00771023062611977
-0.002300860760117469
0.006139354939781577
0.010293251776260035
0.007460630240871795
0.007743639235395657
0.008775365852109123
0.009596889016169173
0.0128469764132429
0.009327481442115211
0.0136909787820304
0.003340831648727807
0.0005917641038092614
0.005642739352734636
0.002220446031118625
0.007554855648602396
0.012130477578972851
0.007873810496936614
0.01358707237207563
0.010989389017655964
0.013187199100679177
0.01624593043255281
0.014982946125297358
0.013728266372538545
0.01888084857738983
0.011470938215078663
0.010402818858188173
0.012262340993697163
0.012156401296251
0.01136256725448165
0.010764025627069698
0.0051667682050511865
0.008973244545787306
0.0037270369120634985
0.006485128041860818
-0.002321977431768583
-0.002588654405641777
-0.007954883470564425
-0.013997431540116529
-0.0013753354401628646
-0.0031035656748136563
-0.00040345227413973446
-0.0009831669818825143
0.004452969023241817
0.0015171221395199994
0.010962027694760408
0.010093682570785894
0.009626456973425249
0.006476660988035409
0.0036164842055044326
0.004830954893956127
0.007219806294114106
0.006574271886328662
0.014086354739662757
0.014642612845832135
0.008788503483937386
0.0076063122201302695
0.0026715458823733176
0.001419041878523087
0.0038673117342626663
0.005859470776168488
0.0008831520678659772
-0.001024993348453891
-0.0016885243862044422
-0.0034172066743380944
