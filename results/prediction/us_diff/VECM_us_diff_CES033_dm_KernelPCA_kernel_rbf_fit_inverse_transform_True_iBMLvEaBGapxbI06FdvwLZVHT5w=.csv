# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CES033
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=15, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.041283256609596315
0.07370497330624039
0.06184877264238908
-0.05924482499306633
-0.004580749967526866
-0.024672648051500674
-0.0117872273002116
-0.015519987799028582
0.027908291244097355
-0.003942170545245118
0.022642728279757694
-0.04270818752997414
-0.02141700811418617
0.008731178740556646
0.03164415790066781
0.045935888810062865
0.008659046445237756
-0.014104574329563132
-0.03195810291932476
-0.005176813888638892
0.011403369889086416
0.019779279597996642
0.006116387167557712
-0.00914150979368656
0.009253706238311649
-0.006687180552281084
-0.005175879764975812
0.007910049999297723
-0.008240455227815895
-0.03425642578078179
-0.0012449574882422206
0.017308881701822355
-0.0036931365797185697
0.0002985548766694596
-0.0189361008451396
0.009034068085601058
-0.010905688855503264
0.016776905330285086
0.004005109773202218
0.0048487015119747035
0.01857685960063199
-0.0034116126216659852
0.017553190028701194
-0.008726120008402144
-0.002769678025875239
0.004463965900834947
-0.002366129361776462
-0.01198418882621649
0.003260188569316928
-0.030936654229832654
-0.006379533312336335
-0.006372270921144086
0.0017969834761129531
0.007950758982964247
0.0013991233608777387
-0.014173901156162221
0.0001490596892321141
-0.007835386718718647
-0.0008155350010120221
-0.0125627903205099
-0.025163429611660612
-0.03137343618203292
0.001686156929033386
-0.02502532295059443
0.011851429376973201
-0.018845749371000396
-0.016107688797743606
-0.024863746346061165
-0.02457523741682922
-0.0286654435326293
-0.02820799450115204
-0.042925950193956744
-0.038690293338074576
-0.033249828275646896
-0.006180546344846019
-0.0012192627137756103
-0.03473660851484142
-0.05278396296333897
-0.029770082874980175
-0.030325244169959215
-0.004455750885644434
-0.010566584701503057
-0.011884168883300066
-0.02221060379803907
-0.01502395898334296
-0.01999105623280047
-0.04529967015950633
0.0006810684714929445
-0.009350360563333883
-0.007459097444189522
-0.015975832413828765
-0.010817952068269744
-0.017982998012379525
-0.011660249898395932
0.00601843411013238
-0.03616383639658933
-0.019872494876703766
-0.026141602315217633
-0.0225749373571931
-0.012110545450295006
