# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; MZMSL
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=2, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.014448148524989672
0.004703542230582551
0.015875530719016682
0.00140906387923608
-0.00035268869631060497
0.00255277065772195
0.006930517748474278
0.00530388684914848
0.004732373846031923
0.0049070485115057325
0.006103442736293828
0.008491019693021646
0.007576973135608026
0.006898008701428407
0.004742067374008776
0.005993629918298568
0.00265379686519127
0.0017091008540546957
0.00248443150239489
0.0011080841060168987
-0.00012276203118850144
0.00023743885058368733
-0.0007677314045319931
-0.00015910459214203292
0.0041768055365931315
0.003635978217354191
0.0029045764354450263
0.0031790827870395158
0.00584129390585542
0.005100147486462593
0.007438911055132561
0.00602432218598878
0.005186903718285515
0.008486744747141254
0.009497015825643242
0.007459457421226211
0.007688320061394041
0.005925608905634976
0.0042435009751439785
0.006800837807358469
0.0038473530899231557
0.004390778649161918
0.001790087045755921
0.001065809865618062
-0.0015954922559143806
-0.0019365877529801978
-0.002028160133890009
0.0014182799132360137
0.004022206042412659
0.003513114650894445
0.005022728996952928
0.003506873483156572
0.007100461537768412
0.004702722612223669
0.005440167119494386
0.0054106779311523905
0.007568315257855357
0.0074590148089524674
0.010146654851833152
0.012175113378793047
0.012151007111398493
0.018166158467899155
0.012444231660699905
0.012227287335203691
0.010091037132071764
0.010400852133562073
0.010546128132875636
0.010092801827381346
0.009618368130783662
0.010833776072982533
0.025718271137774647
0.025739465632716604
0.02039556395460446
0.0319731256760455
0.01710286768390164
0.016510212538758253
0.013510118862199888
0.01982862142625979
0.014265281173154922
0.010855812838540538
0.015175397623965955
-0.0010622329078561026
0.005444126902235005
0.007810092627050529
0.009541994571333763
0.006628656461852503
-0.002923003243414718
0.006692739536080189
0.005012190033704887
0.007415127619012823
0.008670895472032201
0.004928824488783224
0.009293527135275918
0.013736370427053252
0.01490624148373991
0.01734332699626723
0.026089045664711312
0.03433029416975376
0.03491423406716735
0.03200486208328338
