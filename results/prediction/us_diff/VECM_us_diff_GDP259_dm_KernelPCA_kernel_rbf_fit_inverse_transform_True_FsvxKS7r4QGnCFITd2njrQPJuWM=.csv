# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP259
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=2, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.013654885331671005
0.016942655146452698
0.013169373850548716
0.028933909918396748
0.03178055372654082
0.022403086604132615
0.03954260738412769
0.024825509867179858
-0.017998260668546914
0.014994775124075904
0.014968473940797429
-0.061741585221449416
-0.06091162881555537
-0.04040580592154018
-0.039618613133582704
0.0025477982919919198
0.023258241765291243
0.02262681236741541
-0.013263713036728509
0.013498693478542984
-0.0030118078390577304
-0.004955834899359398
0.0038081241596543535
-0.011499743505986152
0.00801223997123235
-0.0001742861673676081
0.017203461798929138
0.004274326149295175
-0.007551663554743528
-0.03153636492520741
-0.03088946073591404
-0.024165568405139084
-0.04153164510828007
-0.042131033231768894
-0.030438901873624975
-0.00848387339347653
-0.008844527374198316
0.002108206504424916
0.0021127841677947056
-0.003359422287554237
-0.0019283821010819787
0.019605547807214425
-0.001259758341749664
0.01864856876956901
0.011016255663034068
0.014146530749820375
0.02023927629016926
0.002107038649485727
0.008622540945420738
0.0066379674454544535
-0.0007761995864421899
0.015432934627036845
0.025197305134711415
0.030120402895829953
0.027877210241030598
0.02542337175763228
0.028653459088818323
0.013437329425415815
0.011851916040875788
0.021733511406801374
0.0022487583165344376
0.008278874070740353
0.0015937158016761299
0.005403545567232203
0.0012678011102592332
0.004799299867090602
0.016078042512695737
0.02017279742674464
0.017898785115819552
0.015306475101953688
-0.0022198593028847705
-0.015935154305307342
-0.010963829787787501
-0.057951736103030796
-0.052447384703764414
-0.0458759575382861
-0.06624634368346143
-0.05349128404018954
-0.0224012226938768
-0.0022426265490945226
0.007150802916054279
0.01988072092821694
0.00956917212755172
0.008263200747174699
0.011152695384683792
0.006167285357772067
0.010251071326778487
0.004856064753638671
-0.006107069230738627
0.003307193945585219
0.01374107855694276
0.016363866957538272
0.02702565794549143
0.023047153366522303
0.024222305220561204
0.030959161120855852
0.03785923876895478
0.022158145300137353
0.02142803146672976
0.04351400132776438
