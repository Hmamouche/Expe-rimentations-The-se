# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; LBMNU
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=8, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.005853218230195896
0.019877907857662643
0.023123844918659632
0.003936040871167666
0.006010744261111532
-0.005046550909945029
0.02803704781628777
0.006415136951192979
0.013847261249531923
0.008172224172954965
0.013182549332104774
-0.001991138835259323
-0.003327726129677247
0.006961353050443495
0.012505509770309444
0.016233060815976925
0.01580265924057304
0.01096690725911233
0.010663215555969495
0.012966373335163494
0.011915857478043978
0.016967365763872318
0.005559040461128602
0.002123842223198896
0.0009816052838089561
0.009314914939080005
0.010279541082334562
-0.005164437513534473
-0.006325342472215425
-0.02244438516331015
-0.016098620793237806
-0.00959485009867871
0.013120831037348015
0.0007341750796630514
-0.011702752039912171
-0.0007245643303553798
-0.005886750253067671
0.011509974285593218
0.0104388669386342
0.010450635591371112
0.015300100567143158
0.016470979083167303
0.015908865723841932
0.016431719185185347
0.021750403010523205
0.012602628103006032
0.013154916539612205
0.006458337749356929
0.0028888832923288843
0.00021877205548635238
-0.0008894663612251902
0.019562967199713108
0.0198983159572136
0.02038062606801548
0.02538484827726909
0.006600772096099838
0.01793243199273462
0.01228707106693041
0.005118158300645728
0.010555158788884427
-0.00237854360735256
0.007138742214569459
0.02178010214652879
0.010314964884895195
0.025355615693550725
0.013743596726202487
0.002268104499337938
-0.005183966623015119
-0.001275762458095456
-0.0045953149229385004
-0.013690990002751783
-0.011993266939459244
-0.020106241570537062
-0.021050896849727038
0.012673541297456618
0.0009040931806715766
-0.009552914035294032
-0.012219861202773697
-0.013440794668008847
-0.0007194901003571871
0.0015329832650367416
0.009342478890640202
0.009299888448547995
0.003170664170828241
-0.0003746406338552442
-0.00025297003251004146
-0.0003545325293286359
0.003725910059483184
0.013954990110220592
0.006638503619297182
0.02016513442805168
0.0020231877437252442
0.0018608227072540679
0.011369573401818147
0.01856505922723601
0.0004395274309097379
-0.007448474281845793
-0.010455937759651673
-0.013076387924442833
-0.006557211052251069
