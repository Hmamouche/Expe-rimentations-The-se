# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; MZMSL
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=10, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.02104690741716726
0.0030373262022263636
0.007727698186625534
0.001022041741667357
0.0038674340445849203
0.002145830609700502
0.005048724407660192
0.008804068366603244
0.002990493527702402
0.006719714406465322
0.004273808037182859
0.009069948486415718
0.007522840837499165
0.005333127216532512
0.0032338247243815905
0.0024519058286742255
0.005653422609650762
-0.0003233773338591904
0.003948743150209025
0.001555240205618757
-0.0010195712635179778
0.0017437481708380625
-0.0013225573203985313
0.002193785019051637
0.004299390621177052
0.003148601821990703
0.0016668239590123864
0.0026842165688826455
0.00709167421567836
0.0038079652859266586
0.006064133989748232
0.0027796028337134958
0.004874407629045355
0.009878783522053035
0.010483326786149699
0.007457126291144992
0.007630775366263792
0.0038358677061854475
0.004236661989065961
0.0054120941724238765
0.004497528073213284
0.004865869985543452
0.001312863873728521
0.0012358890940272291
0.0012701783803922067
-0.003485110315002291
-0.0011204787142897045
0.0019423392835106173
0.0025443940572944593
0.004202640788694742
0.005078848379693599
0.0033525327185936708
0.006619041671784731
0.00685593426888346
0.004091579991673644
0.005486329823436465
0.009113778216856222
0.006712351846107187
0.010932278064481231
0.011183067988768114
0.012816859760692773
0.018440986423457012
0.012511512117085864
0.011981921584468425
0.00909746273918372
0.010149608674005127
0.008653013788835316
0.010508258687755116
0.010846997367886862
0.00966776727328913
0.025974061341614472
0.02341576010925309
0.018348955024553717
0.030354645528787944
0.017032025091132358
0.014234442015846869
0.012651137076941796
0.021699957958723322
0.013340726476130386
0.010221280053529345
0.014376628734808453
0.0041385519665801
0.005845611701785329
0.00953145263382367
0.007589741482176366
0.0062224679998538245
0.00033481395523232986
0.007192636000940817
0.003992571605088754
0.008746366206755863
0.010305664176810928
0.0014828513223908825
0.008935034294204811
0.012278593009314338
0.011018957100085866
0.020124524490781993
0.02751508464691895
0.03296139316568694
0.03916638273744116
0.030181060038816425
