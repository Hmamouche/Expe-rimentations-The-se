# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP276_2
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=3, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.012261864814630853
0.005904834405420161
0.008882264890377066
0.005143365453137273
0.010642330844699984
0.008046639859263089
0.003696091668036111
0.006125072168065833
0.005277006561926695
0.003914070309552509
0.005209387046993831
0.00255603213543518
0.00226824318745339
-0.0027131886583699025
-0.001684393268291523
0.0014633555140515474
0.0012158521373691804
0.0001507163388389544
-0.0019214506132841907
0.00337064045009518
0.0033015449862997663
0.004459298476372354
0.00449681166128988
0.004311497067197866
0.004892978193364676
0.0028284254490983938
0.005211146804715354
0.004252735803637471
0.0014237153902702238
0.005172265691843234
0.011545103160297896
0.003266914553478375
0.0060955817585329995
0.00736309405489661
0.0025261489356176005
0.005410045671902395
0.004035761461626045
0.005343685275503483
0.004710826611776659
0.006606390168046763
0.006652196158651777
0.004642632376483406
0.004847909486164002
0.001915972122915255
0.0026460776198665467
0.0020306384046737827
0.003947594101369272
0.0005884698321725838
0.001383018172384341
0.002697400766353266
0.0020222171670651167
0.005377704902282773
0.005973577528270624
0.004041249940476818
0.006286087418128483
0.0027399167835413917
0.0012353968613803262
0.0012737859113807416
-0.0038677964306262553
-0.0008975774288879433
-0.002104296722864442
-0.0008046100927655286
-0.0011276403997462579
-0.00040616518229574246
0.0005702575746456415
0.0016033688624808523
0.001967865368236686
0.00247255578810432
0.004848620683886476
0.008392106986940864
0.021294100550971397
0.013890837919160504
0.008376329729160834
-0.0005742886202319006
0.003316659517421285
0.0009365185750957984
0.003391696764837642
0.0013815136345415582
0.013114264386046067
0.011504966763698509
0.003244664009590635
0.0003715245028409612
0.007856492520928439
0.005764317758538222
0.005969844591111974
0.006593670883892211
0.008249453087121812
0.012146254001488822
0.013765115751809042
0.030855864226813384
0.02228105206793737
0.0020068720993471198
0.014862624146356173
0.015400461414074487
0.009430830092544187
0.005092231648906138
0.00422347842526655
0.0065287765048012225
0.011612486062426371
0.026349029734260527
