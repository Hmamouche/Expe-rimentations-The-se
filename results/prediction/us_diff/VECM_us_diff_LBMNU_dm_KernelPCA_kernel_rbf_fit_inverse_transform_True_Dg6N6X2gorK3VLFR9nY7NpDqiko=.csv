# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; LBMNU
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=3, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.011604376081848437
0.0119263082358206
0.0180205811011429
0.014403595638151244
0.006717042798482256
0.010297562081335754
0.017062925307463644
0.008763667988988744
0.005528242253177877
0.013812003208212135
0.011120220938589012
0.004774335621964673
0.000628951228273594
-0.002922318337341307
0.008878993072582324
0.010524941345573744
0.016818513317379723
0.01709055653166372
0.007387755052926979
0.012694752604443311
0.012310427816582602
0.012715518303278418
0.014161784498533336
0.003541978823660597
0.0017281153828459228
0.006787102493324759
0.007594517063008006
-0.0003866461558908185
-0.00892694790985346
-0.012371790336910726
-0.015118558606405917
-0.005347388130922535
0.005631317664348085
-0.004841953065002243
-0.006230011021863085
-0.0018510431057710613
-0.001693177811940881
0.0012327058147355537
0.009284639155544498
0.00851460213913409
0.012042412537220945
0.017472747479976087
0.016703705426753212
0.020791513718791968
0.01787421787313649
0.015367382153424319
0.012724650699244371
0.005386714915485019
0.01162047741821735
0.007072159970764064
-0.0011082962291028425
0.01135432359190312
0.014942406539927
0.014222532079759308
0.015518086007132
0.015193179206253663
0.017951264581368347
0.015983814678780104
0.011314828516491331
0.004595558752602896
0.0033232815617395793
0.010892812679635551
0.014185148137610442
0.007298058759595115
0.016612057513819358
0.01614832174474027
0.008434688182858169
0.004344807672263432
0.00010828365278048725
-0.006802914839617483
-0.008141355603194763
-0.009977730515339891
-0.013046059908090784
-0.021052811657874794
-0.007184290921371448
-0.008185444935139199
-0.006447510148761843
-0.011684292616311983
-0.009099049162086481
-0.004948272078112673
0.003605313152687869
0.014382487571016705
0.006007740306338254
0.0013313176375715071
0.005170495842104459
0.007333511349674921
0.006530282687772259
0.004209781896278466
0.010123306564264278
0.01014259930161455
0.015997699647093976
0.004566611515688772
0.0035775848654412325
0.005493629227885088
0.007917791977874115
0.0050871501117113254
-0.0005565665881336287
-0.0026962837165293366
-0.009117608172572506
-0.008102195726998076
