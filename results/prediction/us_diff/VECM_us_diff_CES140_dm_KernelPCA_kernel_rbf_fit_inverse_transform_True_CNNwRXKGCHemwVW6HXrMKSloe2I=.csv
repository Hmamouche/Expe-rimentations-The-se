# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CES140
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=8, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.013066098600912157
-0.003567126262988034
-0.001680371838729257
0.004491365961245606
0.011152019244682397
0.0032967092289592393
0.005412511981336814
0.0031674774627580104
0.012754453729472816
0.006160921102364302
0.0033812758964992338
0.0037562855982081825
0.0048013664677562
0.009472830083073168
0.006748846420908631
0.004099731707249591
0.002926788564641408
0.009005277767896024
0.006414988003165245
0.007328093684833701
0.00351757977512682
0.004874257885721038
0.010215080942886349
0.009113340325863134
0.005659386749935208
0.0038485079987575204
0.007640799156057658
0.01820546170701726
0.008951078790854263
0.001924167793111916
0.004089207319848645
0.007798359196925526
0.004281190527745281
-0.0012385810244255702
0.0028711490035972374
0.0021306347834343887
0.008371988877680307
0.0031603219784373353
0.003285756004914845
0.005949996911500218
0.003645301310807855
0.0022110539672370306
0.0037854216667239085
0.005661186214935062
0.005353870930092249
0.00340002799406574
0.00385544369989983
0.0038542454671804116
0.0015331241032401815
0.003284200596158471
0.004764371034558165
0.0014772064281622875
-0.0009102624181142206
0.0008606314067623005
0.00040230006389314183
0.002258483543249943
0.0018388270241129203
0.003889999107974774
0.003227443283129723
0.004583446567852835
0.0065180963248415305
0.0050912477061070965
0.005483335607309186
0.00745391028524297
0.006675170670219702
0.0050349576174509355
0.009795112078203076
0.01596260012213888
0.006181691422362724
0.0031984500367943794
0.0023538178839999685
0.01035101156443494
0.0040880379359057644
0.006512057698861423
0.007998955305177712
0.008199175358147931
0.0033799918701705282
0.002666596724044832
0.008632540423925836
0.0028830354753947253
-0.0011480987749930595
-0.0004020230641056412
-0.0012653171948992451
0.0018654835489089053
-0.001876043798854537
0.0033281174097208673
0.00414034183583694
0.0020625990069591486
0.006208882355209958
0.0008966676249298719
0.001795464403968356
0.0014529030246996327
0.0075710527129896725
0.0002955335314949963
0.004505913122262558
0.0064384628738437324
4.286727975332644e-05
0.006854591815831274
0.006911730633037825
0.0054322792968569
