# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP263
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=12, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.003923260832866602
0.009664039419157484
0.008708945323081637
-0.014148121795700987
0.009810277142763281
0.0009264825943686539
-0.003923435962123502
-0.0011605324813398704
0.010214730966372407
0.0016484074687582182
0.01116052547740087
0.004976285145825421
0.003358164950632744
-0.003922382494368808
0.009390052360409592
0.009439539935647787
0.007824454482093677
0.008144064413736073
0.0008384697957810492
0.008896824264228413
0.011994847053559353
0.011112102366561464
0.011685596561687838
0.0009930049087684934
0.009302331170544426
0.006359213638131149
0.00402121251672068
0.015152269159856038
0.01694645229909962
0.005029679124941456
-0.001079309993479111
0.0033908637492101094
0.0071515437030941036
-0.002676937184499103
0.002591974137704592
0.01329457069552787
0.013136279129290204
0.0043007229869909454
0.009900713018776156
0.0022052762633890917
-0.0022965011842210987
0.005497065987899872
0.010089519155346735
0.006002612323566001
0.010605931964558822
0.016164532750579743
0.019259586274860567
0.014119197214818899
0.006007199396828701
0.0107859080229343
0.006002419271265698
0.009971110199409036
0.010705716188427234
0.010099326708375616
0.019111761941448913
0.01246923695507351
0.022807346868679627
0.022433367140465375
0.010664450510933942
0.004399384702505901
-0.0021109048545230862
-0.00366506366616629
0.008457308981689492
0.006665487771505571
0.00856408813896228
0.01945487872356115
0.007589259742005258
0.011581893629413136
0.01566618099183979
0.009378479735575826
0.0008230761244484349
-0.010120301844755259
-0.0192732686907953
-0.025893768888614905
-0.004717777945102827
0.017600633024973684
0.0026958872645615355
-0.012614470340187589
-0.015009220062022606
0.010444116692362598
0.014044862547987026
0.01567206624022099
0.01356333022237045
0.0046086327498483706
0.010554821996933125
0.025093805168706032
0.012805707833118853
0.011414767900874655
0.0054505496456619335
0.01092491297875116
0.0230223796500078
0.02628569159312865
0.023455981310563367
0.019464031629864403
0.02172233190509614
0.016991735313563697
0.013635761274858318
0.007262181262083703
0.01772815076285378
0.01582849750846455
