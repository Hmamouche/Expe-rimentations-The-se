# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; LHEM
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=10, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
9.728111028020408e-05
0.012949072515422346
0.011038446331646294
0.007433529687624993
0.004347381007344197
-0.003170703612936472
0.02001611092869663
0.0040730924914610805
0.005816781010070608
0.008181235231101203
0.012011567241389555
0.005935692702344017
0.0021129070903584037
0.009064843519179931
0.011249928950055124
0.012444384433075328
0.00618614758268707
0.004765396294755461
0.008985652709178194
0.011323328064914881
0.011203625872972156
0.011002586498890549
0.0034079850139072604
0.0034934141359954174
0.0038570078120897765
0.007272058954409549
0.007351467758955764
0.0038984133171083334
0.003326763868952794
-0.006336929221246376
-0.0013508019257519317
0.0010154590319670057
0.004912514746062876
0.0014431869362888042
-0.005373762552230854
0.001790702177564074
0.00198940452895652
0.005860939228664817
0.009065103282013105
0.0015968300700283976
0.012393773994166309
0.008238598965058236
0.007264709467401958
0.0049007824009992575
0.009044627805906796
0.010308724283263404
0.008659150647657436
0.0034735411483786272
0.007092884097458395
0.00028190757803489433
-0.003206747701439079
0.006585620766090266
0.011424898374308708
0.010652890961598606
0.011663246909689225
0.007815939372837236
0.008032137248244382
0.007449514304973683
0.006098281548845153
0.006307248412365797
0.0001843010880221577
0.005302917251778582
0.010599727058104616
0.0036060155118939046
0.009026433767107399
0.010483472952861207
0.00868092853815738
0.0012110835609458704
0.005247919328492887
0.008476005050876197
0.0038285935446481082
-0.003218627352507994
-0.005200211926622488
-0.004155544961898509
0.009976408246081571
0.0027119097856568935
0.0004797561962963815
0.00636357307773701
-0.00261714659459175
0.0025580412504413287
0.006855481203563433
0.013013767454155105
0.004062623655143763
-0.0030350848454630355
0.0046066400283435414
0.004022104748784299
-7.083026343292567e-05
0.008739203613817147
0.009957199418673382
0.0072604083510835245
0.01103415982655224
0.004657137516051152
0.004295910737276022
0.010854651549383847
0.010364242847399128
0.004947663660273558
0.0050883372832153115
-0.006040807308323581
-0.005461054327726124
-0.001685047945104507
