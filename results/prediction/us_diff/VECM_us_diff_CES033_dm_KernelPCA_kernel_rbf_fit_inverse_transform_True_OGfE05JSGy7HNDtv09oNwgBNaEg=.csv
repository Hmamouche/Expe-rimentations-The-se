# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CES033
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=7, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.025401841456262314
0.012350019963143138
0.012891132889150806
0.006459331948028818
-0.03514384229982332
0.0013061687830993249
1.1294022952860333e-05
-0.011678336222882849
-0.007982485490051757
0.0010714906792994444
0.00675999799435229
-0.00840693107425162
-0.02530492952686031
-0.003564904344692184
0.022994950809070533
0.021857308213786765
0.014412938980269012
0.009987151663352511
-0.006323080942400135
0.020813355414326325
0.007664037592135925
0.02039351448965453
-0.0002959121876900993
-0.010735542748684674
-0.015735144128509036
0.01363774464642863
0.00555250328914776
-0.004127841423680147
-0.02349567822977405
-0.03011132533868671
-0.010703907127138111
0.008190011752324916
0.00465719634089542
0.011838159528618454
-0.010111194983280355
-2.3423355393773285e-05
-0.01218747025574577
0.004880828245820857
0.01782092602186481
-0.004543845869230735
0.01913168498292455
0.005969331240118734
0.008923425512415862
-0.001108706062872211
-0.0001646119266526455
0.0012206100158877612
0.004338734510198668
-0.03135672834294549
-0.00029037640423590274
-0.018134669963197937
-0.015467886339134162
-0.0023165356488554336
-0.004186523437990788
-0.0012839967497689543
0.001937208629493912
-0.006883547759889349
-0.006881676420966069
-0.0014469667466228426
-0.006905227431285148
-0.016714374197598594
-0.02070697316538748
-0.019315202665209082
-0.004794087001504715
-0.01801233083356805
-0.0028412768200433685
-0.004407934201391837
-0.013892233081565746
-0.02352704620168513
-0.022416846047515253
-0.021358247304610042
-0.025040487936626506
-0.04815975672588463
-0.04470366146637179
-0.0476181883702038
0.002157921989698712
-0.02747447106224792
-0.03335522881896288
-0.028493940230880328
-0.028676002320379368
-0.027392043395096155
-0.016862414430140582
-0.010378771927299364
-0.01419841588525039
-0.014136318946058492
-0.0227710780028453
-0.014191971966479746
-0.02705661882494225
-0.006655240667555575
-0.013523908796399229
-0.009389678690583617
-0.003172760958844531
-0.018632781033771133
-0.022927564467536524
-0.014363803455466544
0.006717155816974022
-0.026063294572673413
-0.0068272385286530235
-0.02626494866886727
-0.01682117303340358
-0.01038340877620821
