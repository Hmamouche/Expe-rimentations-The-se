# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP276_5
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=2, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.0006331544587592245
0.012837024789931583
-0.010788868803603776
-0.012842147916664447
0.024759336682635864
0.005042159711578435
0.017692666845560673
0.002367275395631145
0.006055016983912606
0.004355641178316053
-0.0034788918454110363
-0.00367845173884198
0.0026567144122637497
0.003819678289944876
0.00969881994607653
0.004689118564205691
0.00441037758586777
0.00402471447817182
0.009048756450514589
0.006056954321472035
0.010073518388901262
0.007939340449154252
0.006826759358266678
0.011314028110817484
0.010415344030347457
0.008568854002217994
0.006250710029217097
0.004042495754558761
0.004004012302817391
0.007942630835628421
0.009390050028196503
0.00905053850734145
0.0045652684095259235
0.0013162254752516244
0.003517956041419263
0.010630293204128031
0.008558321537030457
0.003948182719378234
0.006510410802486703
0.010237733543211312
0.010446415629697817
0.009445411201106067
0.009469311230679324
0.002965311660887115
0.004725376746265305
0.00448342749276069
0.00215772541197646
0.0022029378892055307
0.007483645805103884
0.011265598070640082
0.006652387527346083
0.004540807004930026
0.0006513423817634991
0.0012124090288897387
0.0055641135681929865
0.006195929033609788
0.004440305096832385
0.001962446145396049
0.004096492389448414
0.00569449090688995
0.0053701425760237925
0.006447023235188976
0.004166644683465975
0.00321494423160939
0.0038821437015824894
0.003430466393262103
0.0053558609274257235
0.005212629742692723
0.0050863910405175156
0.008704252296937477
0.007188426043685604
0.0057186283962616935
0.006485021910945016
0.001518288484501662
0.0035030958659469733
-0.00022274929942551602
0.0017899450395489906
-0.0031039466699072905
0.010102670275601446
0.0022796809913878907
0.008693448552155038
0.006109331405504297
0.007768817348725069
0.0046247001036756755
0.00592991023815595
0.004318713460584436
0.008740665237187261
0.006186480234593906
0.009416588061869532
0.01250825886422106
0.00991073723587925
0.009848848101539066
0.00784561432658291
0.010600895374850577
0.005306008680253331
0.005290244020696963
0.005512347629924923
0.005405639549438128
0.011106481967964845
0.01319391146932462
