# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; HSBR
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=7, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.06672325796725694
-0.0634048694921964
-0.05242064432282506
-0.02373895145349475
-0.02207849204871548
0.044826478586984755
0.0786898949941083
0.05372647707881341
0.0061892250815413635
-0.0033709232655824393
0.049241097291710736
0.06511582342642248
-0.00881712273311497
-0.048112509833025445
-0.049635863504572664
-0.06373515276011615
-0.05864829054296843
-0.060897957292273916
-0.0458783747852769
-0.060450254055022225
0.06334072013353496
0.005876444514318036
-0.028050464844832743
0.011531351162848251
0.019285510056523514
0.06871406534562678
-0.009983745509318397
-0.051795427074369925
-0.12526279997820264
-0.10805067327227497
0.02812915166795969
0.062340687481491214
0.11394581254346065
0.005569081762034647
-0.07095592140427082
-0.025783853014560213
0.012813194311906577
0.007426366310549985
0.022519833630894746
-0.018291210124018825
0.004659802952925042
0.03542243444135407
-0.0003302100657772353
-0.047992862838122305
0.00271851564945938
-0.08424044685496458
0.03091657758541572
0.03595429622608888
0.0742029920201644
0.06998967452901993
0.018470125634863013
-0.004342205932306276
-0.00544290563435927
-0.004003661274221999
-0.0021484100737151467
-0.009165223533146529
0.004398339387369752
-0.021209352872792846
0.051916281694234026
-0.008135815690159977
0.05486815623683773
0.04622747748143706
0.020462488384860283
-0.015943623209492486
-0.010786522781318315
-0.0540504830947804
-0.02879393904174731
0.005903725447331862
0.02170631696934219
0.014625960519330319
0.05979737912556334
0.029988680378919032
0.048381556455034176
0.05875189501918017
0.010344887904948384
-0.008171020398214074
-0.0664061305376589
0.02876476836740457
-0.03132133472492195
0.06538952613092877
0.019514109021893693
0.0288235877292709
-0.0015751735848094188
-0.0513217895191391
0.01691811719752475
0.016974608941471413
-0.0014971718390731689
0.05254013180224274
-0.0033277400617578454
0.009673683802707939
0.023410070360237473
-0.058640412063271086
-0.04652858721027275
-0.04386046318129821
-0.03759470700652015
-0.0534455882927521
-0.05660545834621409
-0.1338439069472156
-0.0011721901268322218
-0.07924933251632107
