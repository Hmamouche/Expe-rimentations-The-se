# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP275_1
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=11, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.0031104134167812235
0.009767623291215617
0.004986330224009015
0.00496561405600525
0.008491104954275368
0.0034011043905911287
0.002764503281181556
0.0010185354657537404
0.004269404609469994
0.006313005423415542
0.0038575305911921686
0.0030561604717526305
0.011977951770403006
0.0050251320496734996
0.004122633046244024
0.006055249248838629
0.007335105575938777
0.0032707591721109325
0.00031875314541317474
0.008349992112791634
0.007621192311988428
0.006851811278097093
0.010028741035378123
0.009771448240819113
0.0061424321393874085
0.009712525496979325
0.011944804360546254
0.00317031670119204
0.01340370035727289
0.0059334659781589095
0.0065532950385398464
0.004091723237851063
0.005624863652835178
0.0023154380815592103
0.001909465972222373
0.005064182601405466
0.005187369457287402
-0.0024568058866993245
0.004446226050900546
0.0006734008972501596
0.0047166053178990305
0.004329444738753073
-0.00020342807990543661
0.004589788773177365
0.004424176353661579
0.006016988850474317
0.004755954717772632
0.001831499515013137
0.005249700918138303
0.004883163063041056
0.003333538639540464
0.006458161937698276
0.008358426802111006
0.008625333349423163
0.0038830377399943694
0.0037023857832812557
0.00376477682836876
0.004970233123855442
0.00278772390848896
0.005275560317478528
0.003949542490949838
0.00666793540569777
0.004762033837553667
0.003198426188015317
0.003484457514707471
0.006939346392508538
0.0009917775634190327
0.006719649170452869
0.0041650783758117255
0.007145155760097291
0.00838746113581779
0.005075933948893831
0.007179393360823394
0.004811990676967669
0.009010305728127813
0.0026951188970819047
0.005625294031630062
0.001005898930780463
0.004307355475062004
0.002645779014988429
0.00495241150123053
0.008222398447607056
0.00731282002080727
0.00936001314220846
0.005425789760420971
0.006998722860136982
0.005424415915383719
0.008050076305452996
0.0028730664230937385
0.008463753765308486
0.00477988228891161
0.005143770243661111
0.006774242335320768
0.005992769551520584
0.007199684739488579
0.010881173397710841
0.014040740098438132
0.012797478487882439
0.01185825134179906
0.012601580020157606
