# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CES053
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=15, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.00013201382373597033
0.03584705391927877
0.026295309970064525
-0.006998615918837114
0.009181933315541277
0.013219504115822171
0.012822935522651952
0.013993426260105708
0.01991391311998306
0.012165636818550424
0.007318954779459224
0.008366796819160367
0.007990643275777575
0.005653964405505149
0.01369950211649431
0.01114235065919228
0.004565357559314342
0.00513448511468844
0.005318605775178285
0.011274327458667476
0.018223608350487357
0.010752108501554686
0.005851944313442102
0.007434800453464914
0.004217053698926955
0.002162089707747272
0.014916034023194287
-5.607905833476118e-05
-0.005057612694703981
-0.007474131262847026
-0.0029206035085748237
1.0457626464233094e-06
0.007142534824666562
-0.008663538178655823
-0.00911473932275805
0.0012430394837468347
-0.0077793150119923405
0.009579700229607947
0.007891909845681104
0.00025269596512337905
0.016106920725974524
0.003394415697528657
0.009500205343395695
0.01295129850534709
0.01021352784551692
0.01745976793024097
0.013334132487255056
0.006546818348467727
0.006073336407755543
0.0031071338190938533
0.0014184096524237745
0.010711314979157888
0.006910924333841971
0.012198566935731818
0.007198480851282405
0.005473744165742355
0.004908266596673887
0.006360527553863567
0.006145492308682578
0.003055942221218074
0.006208659819364198
0.004256793860368746
0.013876274691086241
0.006470484299552409
0.006710880834384149
0.011437544786607955
0.006605617977653654
0.011304714580925346
0.005954244614641059
0.005876129979687395
0.003307528218703725
-0.004602694712639615
-0.004501307302291766
-0.010193317631905592
0.0021904602101155144
-0.0020459384782116155
-0.005543423690359312
-0.0062567681795762916
-0.0027334489102859775
-0.00189130264498512
0.0004329697455249307
-0.00103830643381971
0.00554950567033025
0.0012459039559806827
0.0023629741589123988
0.008006447208006017
0.005772590406612019
0.0051897468186525055
0.006951141907635071
0.007505135399835934
0.0024620308819456914
-0.0013300605013398217
-0.009029794311305666
0.00038061930245076214
0.005253535149548524
0.005274554055091539
0.006933250461005932
-0.006304382082935516
-0.00625179037477574
-0.005467793044756385
