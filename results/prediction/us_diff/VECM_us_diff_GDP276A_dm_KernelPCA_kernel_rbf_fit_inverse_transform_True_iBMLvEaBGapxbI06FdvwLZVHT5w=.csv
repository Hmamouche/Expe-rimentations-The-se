# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP276A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=15, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.007290777177683655
0.00528854938463269
0.004337271757450986
0.008668096501438592
0.005902172871898643
0.006121492519783954
0.009604372127500002
0.002974737607082803
0.005286394107790131
0.005986034608177056
0.006468909836947036
0.005581372080092227
0.004934387333232856
0.007124211758833382
0.006222420817254156
0.003744059040120406
0.007779108382823447
0.006084655441021206
0.007801465101630367
0.006275959290992925
0.00855123161786296
0.007309921553209474
0.006931913940224514
0.006262398858544373
0.004966399992690909
0.007876688891290829
0.007295199652435934
0.010001813934545713
0.008720446308169908
0.009613383229628042
0.0055941465708842925
0.00502598619375444
0.009281414139274056
0.0077665467508039555
0.008822993126718852
0.005701270294720922
0.006801225780475563
0.005394123571682093
0.008827732036093211
0.0037599712118719705
0.006291130511186125
0.005366070612096668
0.0064300762148853845
0.005391583919510796
0.006925836458146092
0.004020590698687046
0.005858913997937559
0.003913162128508077
0.005264566436902616
0.0071288942531523
0.0026641614188264895
0.0064672121073743255
0.0061933070156325945
0.005152870306549072
0.0069127718103693895
0.006346187162954974
0.00459466245253424
0.004962874448108532
0.004025871119598877
0.0034863380088311405
0.004898727625004917
0.005247473347586191
0.004351193304442708
0.003853715623598732
0.004382892091691006
0.007747237624876412
0.0056195260638753465
0.005939538033749488
0.004166508668505383
0.0054668951513977835
0.007910154203260354
0.0038964279626666756
0.00764270402873558
0.007277554711030894
0.009014695546879973
0.006201318515125707
0.005427062077556717
0.0074912309881787105
0.006925483267988113
0.00515759349857595
0.006334058459755662
0.007869611052290988
0.008433390932896401
0.009062759882997496
0.007672510337297693
0.007300277911910346
0.00815531870974354
0.007189893360134291
0.007794242930933067
0.01235310619820317
0.00893808528581765
0.007787943882415417
0.009607710959060916
0.007042149393039332
0.00977605857801615
0.009092535257091881
0.008103814896941874
0.008979848664451059
0.008632721688769607
0.009810667527885232
