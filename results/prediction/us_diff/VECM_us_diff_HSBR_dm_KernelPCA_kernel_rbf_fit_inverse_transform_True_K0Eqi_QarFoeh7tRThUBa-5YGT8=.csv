# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; HSBR
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=6, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.06550069047852274
-0.07177842424334496
-0.05052222311767206
-0.006847725221645097
-0.024355954638364433
0.04659694937388753
0.0775012882412335
0.06674334935616412
-0.002388736033559293
-0.017666065351143775
0.027562388362158706
0.07455360526200505
-0.008543789114225873
-0.049345910877331006
-0.07560295453180545
-0.07422529868090119
-0.04774422379235849
-0.048370571800644996
-0.029923652221544333
-0.06305827389522024
0.06074889963421102
0.0025945055285077163
-0.010036587394431114
0.0038852581836355607
0.015268975524080797
0.05851401775661455
-0.01315199900241908
-0.05290902007736838
-0.12422600042226717
-0.11647938644693481
0.024117307869158472
0.06558852259088271
0.09784798575344517
0.001853981363305529
-0.06564702387281139
-0.010348057219039775
0.016007535409160854
-0.003054699639732081
-0.005007623168888999
-0.036356851035985474
-0.01647821850895502
0.05471376255736741
0.034468387995680805
-0.052895470173305946
0.025732756852771314
-0.08905653948000061
0.02468716291217357
0.06341283030541092
0.06050465337888379
0.07246896170790391
0.020630581888526588
-0.022535555280744107
-0.0050897686212678615
0.003256159692804084
-0.015201276712239817
0.0024545487389888085
0.007111918519149028
-0.013968795370552057
0.05270004450835815
-0.00982376694912616
0.061716794461148236
0.032469223936432895
0.03111357727237995
-0.024530018524210887
-0.018785439000851348
-0.04408310215476942
-0.025469863582883025
0.007746919896324686
0.02391763082968665
0.0038785157930822916
0.06654075768593185
0.03586265488403525
0.05735215619024719
0.06840669314619034
-0.023206742088951272
0.0016369540147132032
-0.06645312848427468
0.03315599062464698
-0.041343490890570406
0.05511995537162756
0.025382152747072947
0.037546747952172915
0.0029408217575692328
-0.04721123191206261
0.022335996089101536
0.0037161444256492322
-0.007765238815518353
0.051775006256439916
0.002253934902003046
0.008666687828934424
0.010545160794094104
-0.04095410443746987
-0.0523310573615756
-0.0562551623483454
-0.026555027338408376
-0.053526450923255225
-0.06377871067368551
-0.1222775116525144
-0.005111736503052067
-0.08821827418608734
