# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; FYBAAC
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=15, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.012703623155941902
0.15793786750631483
-0.0010232063265345065
-0.045446363263801096
0.008568142841405592
-0.04127836681821925
0.02242130183734385
-0.03136641015062801
-0.06354428455823087
-0.02556097979126091
-0.12467090634621524
-0.07804554543967109
-0.03854341727752796
-0.05329121000463556
0.03408629923307933
0.049164754577503716
0.01893694775877166
0.06554491704195146
-0.02387309638586356
0.023945052693480372
-0.03487864672676706
0.02364220468010075
0.018636592174944063
-0.04822954505844347
-0.03749758019399467
0.01831520707706043
-0.029492015353603986
0.014516390963993871
-0.014149287571441595
0.01995710894954445
-0.009274368129770887
-0.03456751979656818
0.03984172501523728
-0.03903917727270102
-0.045543905463308845
-0.0006815304047408568
-0.0807285228801931
-0.0030987862220909317
-0.015378621472481431
-0.046440105144720856
-0.01336719662247432
0.026982992735176875
0.01223109655702036
0.03558466296065532
-0.0006644361152687382
0.07854125722447619
-0.013097349255228867
-0.04492766835777035
-0.0345997806103599
-0.03977817749987028
-0.03542359610079103
0.06393295837447262
0.02518766914000286
0.04029297524603447
-0.013426095365643556
-0.02546015220344034
-0.02117171889631156
-0.03265161573910772
-0.018117290751977072
-0.028559243818999727
-0.05071604269987315
-0.0006623187759032777
0.04351135518608178
0.064030752598861
0.04345188474249971
0.04734075761726431
-0.06230041665452614
0.006591407696306599
-0.028499496458238426
-0.03014820971481369
-0.04476788079716481
0.05479478053821996
0.0207843093021907
-0.020595302224221863
0.007167800000101584
0.00019955318825634616
-0.08652070194403301
0.032644128088875096
-0.0741655196270512
0.029417175264946933
0.025143026559141496
-0.0013723549419567948
0.023469638153828867
-0.022384727709148185
-0.05535514180480695
0.01786571842515664
-0.04065345218613471
-0.017299780623438753
0.014460378926566268
0.02540291058090388
0.006907683450697352
0.03648913384223116
0.0001344038129221627
-0.01766418761752157
-0.002197602747786167
0.008256820960963784
0.01634526626997354
0.024889301527338804
-0.031182115098562054
0.010817999479258118
