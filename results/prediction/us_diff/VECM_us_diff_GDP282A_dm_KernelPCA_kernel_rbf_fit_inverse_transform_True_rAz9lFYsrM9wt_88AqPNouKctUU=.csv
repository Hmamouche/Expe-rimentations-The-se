# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP282A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=5, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0039746266291331355
0.002343967604168595
0.004227271507290657
0.003763145044669643
0.005600284961029703
0.004203958938439456
0.0024679956465254206
0.003505288411867636
0.0026152328848658346
0.002778243893988678
0.004483780163094309
0.004096340674486773
0.005938636548341413
0.007507586790806371
0.006385458522066254
0.00468463949246152
0.005130884287781764
0.005439818259821057
0.005264726911199408
0.005928175690611287
0.004520787127730763
0.004888925788010414
0.004530848487499055
0.005409514464206549
0.005359550379487322
0.003082557502316283
0.004371450717713725
0.0042330428759496195
0.0025309578306989995
0.0031566074257370225
0.0020758825638860735
0.0013525107448831577
0.00227583670612551
0.001072408055029906
0.0008170686114261761
0.002476585422004804
0.0023876092330587023
0.003650994394785304
0.005644190674424462
0.007413403975258423
0.006518722182368251
0.006149047378585647
0.005465911779190501
0.004597388757635844
0.006458005196812561
0.006973313977859857
0.00845434477043144
0.006781817723566112
0.004331527848649101
0.004438986802027689
0.004152125614053432
0.002991187685612451
0.004893497413339651
0.005108653416128075
0.00341770135641958
0.004867271508080909
0.0052381609271718345
0.005035807176509113
0.004199253960837968
0.0044601208129881505
0.005875568720258621
0.005636966169732962
0.006887389865597409
0.007351581604520621
0.008004115651611469
0.0065764916700207015
0.009521520773338345
0.009560504769338847
0.007504331624285763
0.007549922671863349
0.008118434457648992
0.010437358555309535
0.010385679449621288
0.008544143507086497
0.0061326021014061725
0.005573310192058834
0.0038777744758991283
0.008729129264048745
0.013600952747447454
0.007043568742681293
0.0027672790839456526
0.013829160534562904
0.01607373383504896
0.01190609770132433
0.0174779648860853
0.017600127174919017
0.017190039947092964
0.0180782700477894
0.0227266930356538
0.0170376701924116
0.016928208547257767
0.015512453223554473
0.01497137223571788
0.015179162277469843
0.008180521286740523
0.00249894720028411
0.0034352629284900085
0.0010997884952569997
-0.002925717791800516
-0.007544413557458119
