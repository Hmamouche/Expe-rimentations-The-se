# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP251
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=12, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.007023435973296703
0.006673790880295748
0.02279998633124972
-0.003085798485561295
0.002146178289517393
-0.0005172376875635055
0.012815855273435107
0.0018890175442798972
0.013458938428938456
0.010398993695663121
0.014019274895971531
0.006394721694396522
-0.0006750945374297814
-0.0006828793159299726
0.006643822396682628
0.009288084722353719
0.005874878955321704
0.008273475615432206
0.00893924054401534
0.007393484186554498
0.00811664001396874
0.01295086904048844
0.007969341320681259
0.0011790321405323306
0.003348096146249083
0.00502677392756458
0.004284864427241598
0.006348179140758716
0.0021830835874644514
-0.00512531619638998
0.0008089443514952094
0.002616382887039572
0.004740306131173233
0.0012421430189045414
0.0023795800369859265
0.0037225822993772863
0.0033674040447270273
0.012843228367840184
0.00797014712018913
-0.0009157867355290314
0.00941294699622288
0.006743658279808914
0.01019578155258194
0.004875830649734433
0.010060906381030202
0.009964840702837317
0.009134107797546162
0.0023795163021905668
0.005394815393621271
0.0036599062755028507
0.004631293746443872
0.007164502692979726
0.00794634717170819
0.007474763311424963
0.013404723315201903
0.007495941233289446
0.014911928594636577
0.010486198855709075
0.009834359622830703
0.0076889564773954385
0.007194600145339346
0.00942565427506151
0.01361846917914029
0.009508101579085663
0.008157746935305965
0.013617462354615629
0.01348806334038539
0.007847699780365596
0.009330716299051927
0.005190501385646204
0.004901276645947141
0.004573605104669224
-0.0006447161700524737
-0.005296402183723391
0.01111995357009553
0.00805239270401965
0.006205299643726176
-0.0004716604005269794
0.003938876153296335
0.009649705701997803
0.007066616961415658
0.01345203035861817
0.015583322043064401
0.005894294850743467
0.003913378950371464
0.011055795671366414
0.009361517767968602
0.006161348037389122
0.009909725762170394
0.006962079717308874
0.008770140840015418
0.006110325926143143
0.003964592582559272
0.006449008769888747
0.007283977372111977
0.005114871776097658
0.005515473451688935
-0.0010692182030898017
0.005670584189344754
0.008134418313880044
