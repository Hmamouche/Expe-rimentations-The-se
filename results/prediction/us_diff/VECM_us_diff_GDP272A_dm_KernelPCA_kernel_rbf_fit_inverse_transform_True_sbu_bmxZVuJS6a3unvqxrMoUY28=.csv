# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP272A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=1, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.006055479266507685
0.005157023782753416
0.007798199050749159
0.007203303706844989
0.005471329730894277
0.004756116431998498
0.006807144299560363
0.004240111376530238
0.0028908185633814286
0.005120806687490424
0.0025841841800443993
0.0033434370942791725
0.004481908162132714
0.00461527299336166
0.005275999148686406
0.0044458076695753
0.0051570525209707506
0.00525673674367629
0.005375004005899747
0.007308161071842463
0.00807989356912121
0.006667797111124184
0.007841878533246154
0.007698624774760941
0.005660963630713118
0.00587566201910402
0.00782145835882888
0.008030023606054246
0.007399795167684088
0.007872371604383286
0.008737432603891874
0.00579694509712295
0.005765206714899116
0.005284134930860909
0.00438086534710801
0.00521383620018519
0.0034036638082690384
0.00486288083473098
0.005721966535809681
0.0046261370999455724
0.004738446323315664
0.005222914583267665
0.004430375023213031
0.004075984557750032
0.005303203640732985
0.005156835503602626
0.004851000196977345
0.0044368279434416355
0.003845407246316758
0.004470367134567534
0.0039329902327857914
0.0041364410622865685
0.004212658167554309
0.004340886603731574
0.004088842423155697
0.004276928518539549
0.0028128974388934645
0.0035547673053741716
0.001989626525523768
0.0018694644576257085
0.00307919803983971
0.0023907385632941777
0.003202691110779556
0.004212002474050533
0.003208247658399493
0.004557276695491591
0.006785658614473555
0.005002066889825581
0.0054968787393963325
0.0056358316293730944
0.005374585490588257
0.0071119432907182705
0.004796993863167323
0.005567399177949248
0.004816948771612821
0.0028092222726694522
0.00365583007822196
0.005424099771502749
0.006857180204853138
0.004153799353334027
0.005826066630963486
0.006381713078708075
0.0064389382862914905
0.009715925022243617
0.0072882990103329505
0.009388345238728545
0.009955406876957396
0.005939373488547021
0.010239050953633167
0.010239412013264459
0.008714914272842707
0.010011010919636246
0.0084116720814348
0.007037483569925312
0.009123472787743826
0.0074939334687556735
0.005734780155510936
0.00836552022286772
0.00610546906259805
0.004883019152083965
