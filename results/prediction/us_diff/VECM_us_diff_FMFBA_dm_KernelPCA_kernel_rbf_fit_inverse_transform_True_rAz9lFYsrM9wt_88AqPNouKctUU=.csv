# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; FMFBA
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=5, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0031480865736095514
0.002020175842006146
0.0025646151447605184
0.0019723944953464823
0.002165669809601012
0.002674623701357366
0.002215749215204245
0.0026460210618429333
0.003211990550944455
0.0031044373721063174
0.0027703845097652603
0.0034236288986378618
0.003467254949631165
0.0035900677237426354
0.0037903949916050597
0.0026990543093001014
0.00277480414740135
0.004096741776260864
0.0030692130834261045
0.0035427614658563285
0.003140044361822373
0.00327276621849677
0.0022939689639186393
0.0022338615043898816
0.0024263808583043314
0.002283240183891068
0.0032694604753502037
0.003622460705582762
0.0051519389175301205
0.005057483666723468
0.006589998438268187
0.004722425092821755
0.002648180984499933
0.005331094226188177
0.005051407114808401
0.004328041314862803
0.005871471391170564
0.0069376782518019075
0.006051429356724298
0.0068157297357021125
0.007001170597491292
0.006390954936536257
0.006724944542482292
0.00682357767242968
0.005960047768193764
0.005277816150083268
0.0048856908367082355
0.00544284000704032
0.0024573718093266832
0.001656841642373944
0.0009403494864100001
0.0015064734668724677
0.004355808888699155
0.003680138004064782
0.0037176060453087125
0.00359661892920489
0.004818400726219172
0.0063609859882607705
0.005416465824854418
0.004352998171983602
0.006634739094188411
0.008371203417287662
0.0069577761732602566
0.009222474959929079
0.009272650609292074
0.017116667345608592
0.018897601307264412
0.009352786632866086
0.01899462370292518
0.0030680368437687564
0.004358486641914589
0.0037313730685242822
0.013202855181351515
0.008433467951616778
0.010563535856469892
0.008967209913113944
0.010527630940199845
0.006604488490425663
0.00797451856768667
0.009125062740514844
0.005222190736466267
0.007866246620571811
0.004970758735289814
0.00737977043609887
0.007950577145546136
0.005491313538511244
0.005489858061523755
0.005589104056886831
0.006217197644017195
0.005457807762583408
0.007105670358541553
0.006241061790515607
0.004729011546206229
0.0035982035615173442
0.0032630898567287785
0.004052590631348489
0.0036822381415976347
0.002936204643726517
0.0018890841887489024
0.0035026865299045257
