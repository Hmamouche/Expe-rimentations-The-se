# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; PMCP
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=8, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.06484152995564299
0.15475360719510625
0.023110346948057747
-0.131521083060293
-0.14982207714606552
-0.037066444533418515
-0.012617824434940833
-0.01517928750626818
0.025905737323726523
-0.020675761181558033
-0.0074793811293596656
0.016857212370654864
-0.04216943075614672
-0.021138965365338495
0.01148734023973624
0.11050704083798912
0.10227746790879938
0.053627855775074784
0.050990894480611115
0.03883966187673833
0.0856896413107954
0.03945968467144202
-0.09084632454268331
-0.13242101367947925
-0.09729655344438995
-0.10785084462869675
0.0038488456930053337
-0.10028193790066936
0.059017734312483576
0.07035167311807707
-0.05048876794077541
0.1470608923716286
0.016536081297399658
0.018455250818690636
-0.03860233057003423
0.07897613145399618
-0.058453453547748176
-0.029316387628877477
0.03718657080453647
-0.0666440611807132
0.020278577417589917
0.08558385352285508
0.09724283718537266
0.05278954783985907
0.06722983993159286
0.016608144605989347
0.035509771623344635
-0.019557555705084162
-0.0676095200351018
-0.14240752780065802
-0.17361908645234586
0.11294960816077917
-0.020263098910589902
-0.012240955878805882
0.0907395752362729
-0.06649397801929476
0.04584298255585876
-0.011215062169396106
-0.08304301956853483
-0.03708830312515387
-0.0855790019513571
-0.06845877245038913
0.10335495564509589
0.035634214923920764
0.2003792802969453
0.11967795758061814
0.016121345216412508
-0.05527042093234204
-0.024722187179596983
-0.04719579222146789
-0.06407471549488923
0.011384021736173866
-0.06563572383638813
-0.07261288263365392
0.22046613552637617
0.06518246522752352
-0.023809442701026695
0.0619745183274904
-0.05187740179593328
0.02262596353765889
0.04254359320241726
0.13203275495709438
-0.009817598684515781
0.019500766838312797
-0.04191930598553396
-0.09111510316236177
-0.10341191311128178
-0.09181246015663341
0.014166069566329938
0.030718111762547944
-0.03199983919707488
-0.057089266430381064
-0.05488071176054386
-0.052350162739849875
0.02512471562613796
-0.026625848000884002
0.02465848011153173
-0.03807005822661545
-0.040844057373173384
0.054154127162418256
