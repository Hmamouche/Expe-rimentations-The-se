# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP263
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=2, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0006332883458335294
0.0017172106827650318
0.0024411048622434792
0.001943149919807163
0.005237916802992935
0.0015506774537864974
0.0031861363294753853
0.003747688882244961
0.0009421656290373387
0.0004761629633401566
0.0008087473518143804
0.0014027624814829604
0.004450930496363125
0.005504381796965967
0.007116379705226717
0.005407497211318649
0.006356741806183352
0.007098683095725652
0.00873554714278086
0.012893462713418069
0.012585762137238856
0.010216731142875177
0.009584434364852096
0.0067300635395658795
0.008805115154824687
0.008269052057702913
0.007646887757325397
0.009590311238560141
0.008461512007000838
0.007410809513985192
0.0029931723048398215
0.0006525522135502178
0.007883806918487784
0.007250403206668662
0.008955629150642156
0.013089266677096416
0.005968868705533464
0.005263874558755808
0.007184176930228991
0.0039274241308777155
0.0031088193691822365
0.00259307000803233
0.006000000545419788
0.0060361723724417955
0.010766395031726921
0.013789124778453125
0.014264490244985913
0.010077921076203285
0.008604352737962204
0.013550296502644322
0.010111595577935204
0.012688430842296546
0.01338670907358646
0.0057982983943653055
0.015462589653847232
0.01468675081258773
0.02114231893460765
0.02387482112483426
0.009494100190451785
0.006505810590472254
-0.0008329520641468216
0.00047871307731914953
0.007310023392017319
0.0027029140675224475
0.004908559369125341
0.014993018104367433
0.012192582292170394
0.014143003968822235
0.016806716370280316
0.014431782204448507
0.0033853274011117
-0.009547889190432701
-0.02294473093694851
-0.027560798580737345
-0.011881275799106502
0.0096987640433308
0.001414305389089366
-0.005002331662822761
-0.004175676915981637
-0.001444923605382095
0.007947534368170042
0.023421474286836524
0.01721414374351798
0.009033642397896379
0.011335830432137935
0.019022836805744327
0.015514660577563868
0.015167476574680401
0.005126734114330518
0.017150956870109445
0.025040562896571715
0.017733076305539212
0.006794007403209469
0.02291500944522408
0.015202857851732556
0.014905901722081836
0.02765170551872693
0.022945534751245507
0.01670545523550036
0.018971742772898627
