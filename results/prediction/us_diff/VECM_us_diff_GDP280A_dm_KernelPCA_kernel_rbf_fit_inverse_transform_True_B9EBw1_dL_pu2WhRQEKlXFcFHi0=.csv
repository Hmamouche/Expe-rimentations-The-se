# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP280A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=10, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0009972794092570048
0.0016410595387132765
0.0018221648402588042
0.003032950859987029
0.0028020696654887252
0.0023870261253615154
0.0020290310947684085
7.13104444441273e-05
0.0017851899637131184
0.001174926966859201
0.00226625957730758
0.0015893135404499391
0.001381001001473868
0.0023670631889593655
0.0008478546861095699
0.0018387873327598049
0.0019478444715052162
0.006294797023042242
0.006940581519859341
0.0066361865494401874
0.00555779426705189
0.008203007705507795
0.0034891657702320195
0.004329526525269606
0.003366444406082668
0.004144427372348412
0.0019871113487244735
0.004203440153683422
0.002700938461203716
0.0017512411954863885
0.004207761153588581
0.0030522673187341654
0.0005994764606876185
-0.004242524115893021
-0.001463429981000906
0.0023612977759373153
0.002093153658895519
0.0020825123877291607
0.005316613896910739
0.003121415274704911
0.00528018167209577
0.004685665159216627
0.0037931682363421455
0.0040860528378853945
0.007841719927029292
0.007759310147280519
0.007895119662620352
0.002998773956689346
0.0063249215779608925
0.004091130690290383
-0.0013303040564554888
0.001473755551348128
0.0074486241400566686
0.0036436232341143437
0.007993607348175719
0.006125919606894282
0.00669324311803966
0.006299440871515289
0.008633041826399224
0.006877697164748057
0.0052584642641025905
0.0046625258922117245
0.002843261047532871
0.004517261319344293
0.005641766910890025
0.007482599297471441
0.007082303180243909
0.0060680058777099095
0.006672968567462881
0.008189790464812436
0.008892747386418275
0.01000099874243418
0.009884788959262043
0.003292135791833913
0.007014119230367315
0.008909899525215769
0.009481737188920588
0.011152628110088115
0.00821356279913099
0.0014012166298419727
0.003683670362658557
0.005980862137452631
0.012232015914132005
0.014015492610901754
0.02058748865646617
0.02258158806810592
0.022027913231431308
0.02048956195042344
0.028369236068524765
0.036717600929279545
0.03330049461353023
0.03040520711270907
0.011645922921080201
0.01722677832044364
0.010677132830714453
0.005168166775251939
0.0014398942758273123
0.006417227274631336
0.007224198124601169
0.010073087940698116
