# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; IPS38
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=8, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.011230545662131448
0.007656789371822487
0.011321110190851712
-0.009969558901618656
-0.003566273843579444
-0.01529241109393224
0.01754843006000982
0.01420605627410871
-0.002722323923096688
-0.0014299235763142112
0.015364589143712023
0.008040050919001429
-0.0020907268039071355
-0.0059789761578480215
0.02078049023240502
0.023491171645206026
0.02148647770400345
0.004293002135642621
0.009993920221846343
0.009302900402124548
0.024890829938458196
0.004634533729207217
-0.009843368029536868
-0.01000171114524389
-0.0036431717458157804
0.010232146941798921
0.007163496535216863
0.005288502581512536
-0.00035063471117145837
-0.025707380632849625
0.0075639384681577
0.020781407939703487
0.0057977936094301
-0.002086496013238165
0.00041832849880893766
0.01675257844951563
-0.0005734035290687334
0.002355923513104619
0.014254559106636673
-0.012397228694649515
0.012711143354213002
0.02013500058850498
0.016972536226832362
0.004479700650676841
0.00021846841603967437
0.0009592780992802655
0.011778622945009247
-0.012163202270711927
-0.005967949574657934
-0.013863439245536884
-0.007134020337135734
0.03254980942232011
0.010595364375712138
0.019042367442028862
0.00831032046134748
0.002497413928468332
0.015220988431899231
0.0015636537634246424
0.009643451859948207
-0.003317374016141834
-0.0036629481671690456
-0.0006409166793687926
0.024235623187560583
0.012228380924605434
0.018961707352466557
0.0028173691448371988
0.0005345857770454173
-0.015110547815891733
-0.021833851422242784
-0.007375938023468842
-0.028236668177623978
-0.005305320728449393
-0.021392487405438837
-0.017447751245536405
0.03434729301048784
0.004057210332975913
0.01119242166058592
-0.01007788077409023
-0.018712879598046434
0.00964869111478434
0.006391026881018819
0.016952735326230692
-0.003036361984233735
0.003142334941375917
0.0005837742022733496
0.00257159021188518
-0.009090041613986
-0.0035395875030529295
-0.009073877922406959
-0.005594704952672525
0.04682365680174209
0.006293734416736462
-0.019853343968042725
-0.014306888089364766
0.033216421864252235
-0.004918227666078284
0.011972774845361512
-0.00838543698222688
-0.011453932502890406
-0.003595214167389034
