# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP272A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=4, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.005431703948004048
0.004744932398135989
0.008514337080729465
0.00701777592742773
0.005882628929689311
0.004102458738263086
0.007610732290228765
0.004120326340236502
0.003200173610983341
0.0040366737927621885
0.0022411466490224454
0.003584010846602708
0.004834657506174415
0.004787308943208633
0.0047761258906021346
0.003883147774042932
0.006048138449956709
0.005845313063488942
0.005565558722755976
0.006500198681250476
0.007928347936277174
0.006894108605507331
0.008129888358261476
0.007601557301579822
0.005848353684482385
0.005902572083650339
0.007470320109201579
0.008129584065929533
0.007362113428810746
0.0075604188229559935
0.007945927060196699
0.005413437654643392
0.007325405167769832
0.005932670626146187
0.004106885669955614
0.004670827686827877
0.0035923304573027403
0.005337630852766154
0.004979528356564062
0.0042795570293062205
0.004284798051226701
0.004152566675464652
0.004960548454043271
0.005230606885409433
0.006150228715914723
0.004744577568118739
0.004630835398868986
0.004686344018348353
0.0036858752861027326
0.0044350518701675775
0.003968557719818356
0.004159223642413505
0.004222859189695151
0.0048504912630563755
0.0041415180097952795
0.004373829585848385
0.00323880969781878
0.0036485527207417478
0.00198201585874435
0.0018101850291251634
0.002791662536757669
0.002478348540301308
0.0029044204724882556
0.0043168568000159805
0.00377464983492614
0.004992823454117971
0.006169074146777221
0.004930363301775219
0.005659028272571736
0.005557755048791901
0.004998177494094753
0.00664300304023124
0.004665288056267848
0.006299044099042284
0.005477944635475946
0.0025899032514834393
0.0037818567146057575
0.005026612866685395
0.006408689873518263
0.003750131163018524
0.005966823199089956
0.006251207170882075
0.007115701147586398
0.009736837005573661
0.007665269277033914
0.009030271713022692
0.009261998041647897
0.006197176305700387
0.00986667639820251
0.009918058215855601
0.008908764915101983
0.01064089951314679
0.008164867446262918
0.007679883959558591
0.009280820997824837
0.007398240714970576
0.005769124668940194
0.00813788448773292
0.006191085415836944
0.004695274434778166
