# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CES278.R
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=8, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.009729842275574347
0.034807968050529284
0.01544646022416631
-0.019108249100805316
-0.011754480915078767
0.006835797936730448
-0.014334077103056217
0.005457035066642522
0.007611923979703408
-0.004270193022213691
0.004069366417732484
0.006357343636831578
-0.013768539595782111
-0.01640368305186928
-0.009881027722296142
-0.007761917620972651
-0.0102217622692443
-0.004319014458141344
-0.018749859926276605
-0.0027153992967248143
-0.0113777301775389
0.011311145588021515
-0.016445317490476875
-0.015789868206241602
-0.0014111739456389855
-0.015822953935824606
-0.012835423802777223
-0.000897552099234959
-0.0011986756927593136
-0.023343070545234275
-0.0026588512053904645
0.013244906229620039
0.008577668819025469
0.0027552314669066088
0.003543214357556698
-0.011574984013731453
-0.003978528151721056
-0.0023928791321384153
-0.004338397313139398
0.0003238656506785709
0.002830037216956559
0.0100552128918374
0.005162520430972236
0.00666877540648447
0.0029308584991337054
0.002554257177908162
-0.005689167928052784
0.003405855205567853
0.014335407829679698
0.0014068335896481685
0.0031181435416426074
0.001591318869416639
0.016093272127921214
0.00977028561393011
0.0037002592282660016
0.007331585735491045
0.010609759198630098
0.012676140258718145
0.016386903965428128
0.018735282572207662
0.00122526980970963
0.011054065242033288
-0.003798044470569755
-0.0005342330200488622
0.014315833810595526
0.012353409298400814
0.010625816174048903
0.006799963452642912
0.003084326678473498
0.0013675151751894083
0.002192834760733566
0.014738259583533253
0.020156152161705448
0.015630645963274722
0.005664344871717567
0.00236350565845249
0.023559114320289922
0.013052888177871723
0.0010128280549310197
0.012335720115195514
0.021570489585637207
0.008391045961330428
-0.013277702825395515
-0.0015480401288063368
0.006825843353558077
-0.0023714255641780766
0.0010235180797470481
-0.0059053054918137525
-0.0037961082635671376
-0.015266969005869583
-0.0034313094277620814
-0.01618907558548167
-0.022280255827346343
0.004399037946476392
-0.009730956991941066
0.0014335396028084407
0.010608111281277942
0.0022100382462666374
-0.009473103551254256
-0.010970752146382594
