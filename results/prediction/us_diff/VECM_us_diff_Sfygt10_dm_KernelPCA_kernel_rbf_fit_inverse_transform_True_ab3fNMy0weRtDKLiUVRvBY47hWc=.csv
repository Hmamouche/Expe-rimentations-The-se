# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; Sfygt10
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=9, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.06287709080075816
0.034527327950822806
0.0419605282382607
0.15147539363758078
0.1427851348790372
0.19479668661429003
-0.08764942642857171
0.049730032189770124
-0.1567939666838937
-0.01654469748723207
-0.07378417871885401
-0.03616806151130137
0.055052187593201685
0.04149611817697672
-0.20679199809317222
0.01076660900856783
0.14819516848672468
0.13330128540347885
-0.053612309632507425
0.1599690085347151
-0.04009083329338346
-0.18817379728723604
-0.013637586056868163
-0.03308420613054758
-0.07614001840654651
-0.19582451976704335
-0.08283973033809891
0.049594669173594536
0.11067048762446983
-0.02809679653518274
0.24379911024676695
0.13142968772074878
0.11745271871274994
-0.01591459498395696
-0.18855998622709896
0.09994854858040025
0.0664786187761085
0.12676072648267028
0.1263544483077716
0.003054351481672251
-0.16147665986873386
-0.06950977951737213
0.043682496714719715
0.07044796013722929
-0.019953013262205034
-0.0028039216172007775
0.011163995515901016
-0.07642649421338353
-0.17623429919452485
-0.07920842540382474
-0.0007388755582243625
0.056137036909435736
0.10978859807456576
-0.04817913006319478
0.014926294584561033
-0.017338557246141712
-0.03838853797184104
-0.042777578081160055
-0.027488358652627626
-0.025782037085238768
0.003771920673542324
-0.08558508698640138
0.04132712643851886
0.1465461945094497
-0.08441124467774345
-0.019921786309617988
-0.005190065336187743
-0.026699248000485176
0.01978936423545413
-0.043356281862705556
-0.07613128062742848
0.026966927350618466
0.125758346098565
0.2602885932169316
0.031679815537337064
0.15775511444234402
-0.2413592210005939
0.11264794960076338
-0.027403248821265897
0.03148924538244242
0.009852822006968322
-0.03398627150328107
0.014877889599274441
-0.056339008017102434
-0.0666783881437414
-0.030554370461562664
0.00020383351548851
0.04653304657879756
-0.09610958686847809
-0.03920698178201903
-0.040302055651690975
-0.05288065250529981
-0.04100890939186046
0.05140122940917517
-0.11831377686611438
-0.025854088994984384
0.02646755980162252
0.052983971024746106
0.04584859050757517
-0.00968771822962695
