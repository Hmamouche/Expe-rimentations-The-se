# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP275_2
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=2, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.010597689260400528
0.006753854239372114
0.0061018066004049415
0.0016996396592128607
0.003750578343625086
0.0021590974992967563
0.007085224927508675
0.0035202111918533935
0.008027386438707481
0.005008392891708258
-0.002361590829249233
-0.011618820313157273
0.004561972314444913
0.0037979659188403774
0.00286014246400855
0.008325431945203635
0.013101425859814792
0.013802654987979618
0.015486943451261195
0.017128225463934426
0.015018970744754374
0.012510331686039915
0.012489489895504259
0.0067538533425694856
-0.0003359444975653367
-0.003145515188239755
0.020778262302374936
0.01751809487780321
0.004992348445792817
0.004858382411126163
0.010274999775689485
0.014337759187087556
0.010161536393008527
0.009208861748388518
0.0037215186174800567
-0.00198928351634552
0.008172877763404566
0.008406388636922354
-0.003584364848377585
-0.009929840160747563
-0.002541406121996561
0.0035711271343439347
-0.010874696674178343
-0.007900708379646283
0.005018830483684202
-0.013325589555492371
-0.01603012237407985
-0.007900612354734503
-0.007517455214680705
-0.009905153178358723
-0.007875924445348608
-0.005562966151074333
-0.012778870354402151
-0.005941620684079269
0.004081139558112401
0.0014713906696402915
-0.002705312942472037
-0.008352374212777569
0.0011808236369669667
-0.006184373768827327
-0.0027921417542026046
-0.005140128704004555
-0.022780976129993344
-0.0038788055411413023
0.002968903923211413
-0.010887012558848183
-0.006144264312949938
-0.005950461457622958
-0.00398879539886012
-0.0017658126647921279
-0.007374478973940772
-0.011384601461478504
-0.01164180459395882
-0.00876470867699892
-0.0079198369907461
-0.01491242057601436
-0.010429053277862152
-0.014552515872666281
-0.007739842305114446
-0.014025464389569541
-0.006633430716888363
-0.002201305752846216
-0.00809797919111402
-0.003264694490283216
0.004359738527310626
-0.004468702820050006
-0.0015632989895157851
-0.0021418137591142283
-0.006931799418220553
-0.0044579471415884565
-0.004352657334952902
-0.0005000793914370378
0.0001108856203501261
-0.004726730939994127
-0.0005058534335679637
-0.0014793200925102999
-0.0070429690635509835
0.0012738284014297322
-0.0031182307197164505
-0.01202055099530083
