# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; EXRJAN
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=2, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.011732854988297986
-0.011550367934352452
0.0029392292599325232
0.021106256492967795
0.036169146126438685
0.012089389445637493
0.017875466047886136
-0.01350627845775992
-0.0020998286976949623
-0.08525514782124036
-0.06765823895577748
-0.058293548637269224
-0.052251667483784035
-0.002868760653218079
-0.03228703873831973
-0.05030640637642213
0.0046198847969933544
-0.01437263187053775
-0.01589478085245991
-0.007817037178091433
0.010234398260376545
-0.02722568559555568
0.005048956361700911
0.018212432327566058
0.010865650776840655
0.00012770750981785928
0.013291860623289516
0.015000509594003052
-0.02027018086615029
-0.036594427649287095
-0.007686598980801127
-0.005223903536221735
-0.022238114158423583
-0.014077914424663754
0.006346411507434976
-0.010283233818978945
-0.005445018027341042
0.0007258187296299082
-0.018984227993505968
-0.026819412868385552
-0.01410192577461731
-0.005557694191863891
-0.00900806086462485
0.002060633379043438
0.00411578277841515
0.005817280865410532
-0.010629726868758183
-0.022296862069955656
0.018822617009100682
-0.008451817538448236
0.01731428075647422
0.006352175516211776
-0.0033064343386134142
0.024974708343449593
0.025192119316490333
0.0014289502581073333
0.006811679386127045
0.027350883175569232
0.010625960375441012
0.019392196352051153
0.017257316073235496
-0.037496835051379455
-0.005366427790920987
-0.005767671046252903
-0.021611631552167707
-0.019567629172767324
0.004232550747998641
-0.006628542248742373
0.005100932722633582
0.0012528493841552617
0.008251165276772653
0.004339398563005325
-0.00631341400492114
0.01130137460710922
0.024341806743466664
-0.028344373638251978
-0.010540707455488891
0.012426424070197627
-0.023178025575104108
-0.001054721466316673
-0.006096288478586738
-0.025718820364520015
0.0025986986658706737
0.01118949364798965
-0.0010282533765971283
0.0016039353361625153
0.0015931385942815398
-0.004869043377195998
0.010075939631407979
0.005933283607751437
0.0027760583284650205
0.0022392133876425312
0.011596353506240206
0.002606324416540528
-0.0009735302909491842
0.0010746018912715328
-0.014179808604793936
-0.00246742779426391
-0.01657007859627334
-0.012218896369623766
