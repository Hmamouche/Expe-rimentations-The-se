# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP258
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=9, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.01752236939248069
0.019398804274485825
0.01363870320394981
0.00681069620194771
0.01110258143352582
0.002625245825447183
0.010315622247907908
0.007438668376709894
0.0003769329809640374
-0.002175754297625349
0.008901350632817011
-0.012983088161412065
-0.012274597618307613
-0.001953488998470656
-0.0077927165529938225
0.00829778072789376
0.005698403572005167
0.005326619452696836
0.003602598570874966
0.006320213732041794
0.007475165106530678
0.019520192828748006
-0.0029067066708906384
-0.00030034897636745626
0.004316204876320215
0.009074479764979774
0.00866895705198858
-0.009191597856796598
-0.008445891820718272
-0.006325202992689823
-0.010987859304037098
-0.003995402346612791
0.0030290190441154244
-0.0017927273597280052
-0.005730377828631361
0.005617102197517028
0.005418060367812682
0.01749066528424903
0.015583461176785973
0.003975326865987531
0.01419347957218217
0.014168052258243993
0.015434265931910511
0.009900976034451482
0.012813716409784438
0.011906621291443632
0.01420036938549184
0.011870058075154151
0.010405734297355902
0.00544581739242201
0.009497752228538804
0.018917482913433075
0.01956407577644359
0.018837374561550133
0.022800474379839245
0.016651429100293554
0.025451783848817695
0.02331046003715752
0.014457051588682466
0.028601659896673216
0.012772586506223874
0.017229788985790175
0.02104748930883666
0.017150218003108758
0.02403965977346749
0.025210738933225417
0.011464878325729913
0.01588742730568591
0.015647785559852592
0.019567706119866777
0.005605422592573179
-0.012729994300957424
-0.03141501730760401
-0.03434554219450705
-0.0068095980647168075
-0.014777903580310513
-0.021507983530541848
-0.010154771383088798
-0.008053879378302176
-8.997277936970919e-06
0.017258132524999553
0.019055762434600585
0.010004954884287275
0.005330332264459555
0.011158896075270274
0.022206443713868148
0.014394278942178308
0.012845173540952375
0.015343761277085689
0.012642485621255303
0.02257428803601007
0.01667141707720885
0.015599674333236826
0.01031643356963344
0.00790861391707316
0.016132381323716655
0.01398507606947237
0.0031202155599885095
0.009160983079723893
0.01773766574111643
