# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP288A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=9, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.004902792462820146
0.004130532169423362
0.006120535846674504
0.005041451531509729
0.005110032955936929
0.005170871341505982
0.006717037246669069
0.004301813707064521
0.003916336867504221
0.004530097365431579
0.002497572651329611
0.0009410783580256992
0.003742344559246843
0.007353369411752909
0.006694108031447993
0.004699020199055913
0.005193382462207247
0.0048443237880965205
0.002758350156302458
0.005244125313345076
0.003017405068817386
0.004964874079472513
0.004385248300660994
0.006893076793186984
0.0031500140814493386
0.006405006768538486
0.007490634316439656
0.005348691972374031
0.007952155248606756
0.0065983772723540515
0.0037306896604765516
0.0048924306469716764
0.005033227436424252
0.0022455006753055937
0.0011301720135525185
0.0037709391237297904
0.0033058436206306854
0.0036031041050725516
0.005812654820571866
0.0018061676059086033
0.002369008847482883
0.002357172708814594
0.005691713073855067
0.004117393383058962
0.006931547352874292
0.003736212597462251
0.004575943055660097
0.006143968135876782
0.004245877030308296
0.002264636694138488
0.005094721805745328
0.002063451562025269
0.004825634449082148
0.005797619016460572
0.0029446352660096706
0.004056821899174995
0.002746185839200641
0.0035666847231167888
0.0014003862036161825
0.0037449293846598696
0.003179153438615734
0.004357439084073948
0.003963741068040091
0.006305181989907174
0.0062446587794580555
0.008198457558547145
0.009807419623504982
0.006964051110481997
0.008482563883590524
0.007392639548844469
0.0053582291233450164
0.006831496008834195
0.005102220635330408
0.0023875388689647585
0.0030182365261599625
0.00484539069186944
0.00675268438421435
0.007525040527098978
0.010666368631727567
0.0053931893352530645
0.009329161258084957
0.009727187627296564
0.0033628214574198297
0.00995122878849056
0.011522625763562219
0.013696402667712913
0.0110005014095256
0.013405422447816567
0.016911006833901024
0.01648656285879817
0.014604514117117074
0.0150763282791283
0.009098085558226391
0.009304870356919376
0.012700479718116277
0.010175641798886283
0.014758535244107772
0.016456039327713324
0.01431285681203397
0.018153180246255625
