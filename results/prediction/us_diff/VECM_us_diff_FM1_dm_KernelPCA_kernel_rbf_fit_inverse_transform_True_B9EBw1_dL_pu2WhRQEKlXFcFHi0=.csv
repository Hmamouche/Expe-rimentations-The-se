# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; FM1
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=10, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.010330576524339908
0.007016933439278391
0.005428073135574231
0.005327847464797632
0.007068200310168214
0.006413352930249395
0.007778396470718511
0.009419872338154387
0.010242565124592987
0.010779566814734796
0.013209467732126494
0.012904277945906652
0.017705091170926966
0.018907130888403956
0.01584114272089911
0.014527758659037805
0.001451636670698064
0.011833109891217077
0.007930454257815505
0.011195526673122926
0.0058888386073887265
0.00528799811311116
-0.002831582687693417
0.0010066027922731049
0.004675676031926895
0.009269114284204238
0.006365683370362429
0.002023225470525452
0.0041087751361557874
0.006455865017158523
0.012659998856321943
0.008586674079208679
0.0063845713582374
0.014104876787755743
0.021783334378787315
0.019611097319874544
0.01659335336182687
0.022117959715715292
0.021967958060895732
0.018080638980725518
0.014621603642731865
0.023705783173914856
0.011471007268345539
0.007910484314146272
0.006502764405103858
-0.0005416987728677032
0.004560878365127537
-0.0003639286370540123
0.0004004761376214835
-0.0028225669886491234
-0.0074223616689903845
-0.006547759448688497
-0.008583904366270193
-0.010155446335335045
-0.008317569574078008
-0.011188061015539411
0.0013786094541925766
-0.0016758759022400345
0.006438311774245719
0.0018144590839939676
0.0007131976313899521
0.008933671418939098
0.005525735256678807
0.00386703871985899
-0.004190092417243918
0.0029131263419075746
0.0008963815124490984
0.0012940771072618537
-0.0024987846090209526
-0.0036316581371985167
0.0060792410026368066
0.006543823518651245
0.026888712303199808
0.016129875739844115
0.007533737259794705
0.0037869863940242442
0.009503937226019776
0.011272011900249207
0.013955267813924272
0.012799256524188495
0.011916062912730611
0.011260309495601386
0.013978967413157569
0.015230878856045191
0.011532629683749957
0.010005594552813567
0.002415980831642439
0.0026346881696035288
0.003422889176825556
0.0056388879203456985
0.0036899767215743395
-0.001955697866645032
-0.004319925306342222
-0.0028726928606046974
-0.00016419828411125097
0.004924863018003978
-0.000299278819901198
0.0006604143280306441
0.007923442037236
0.0013318231572951146
