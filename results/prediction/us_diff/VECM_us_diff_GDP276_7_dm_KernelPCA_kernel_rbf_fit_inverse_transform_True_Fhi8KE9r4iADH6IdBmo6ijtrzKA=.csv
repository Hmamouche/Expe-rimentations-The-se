# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP276_7
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=12, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.004185398080036817
0.00420570192021128
0.00392369530785052
0.010273606927396036
0.006448279304763332
0.00587394424921164
0.005172993896428061
0.007351791381465221
0.0025417438553024018
0.003134021929254558
0.00959625583893516
0.005367643731788326
0.003938067067124699
0.005357159719722639
0.007450518914748331
0.0055073609563270004
0.005979436934776003
0.006967004464677641
0.001498022942974092
0.007340640358666678
0.005076694996455615
0.00566526080773762
0.009982144448692123
0.007120297956322508
0.0053424309357708024
0.007066862140435339
0.009267639616208755
0.008016171181905734
0.011450474225492517
0.006902367140623152
0.0071259041022164685
0.010491939733216233
0.010229631251842447
0.0065313927862418525
0.004490684113745461
0.00799986025155236
0.008372221875898023
0.0037663252422927996
0.004659531073895601
0.005806096389675795
0.0075265877246695504
0.005141772696171463
0.0044517758195750465
0.0041830560342925515
0.0033333035110015403
0.004741231361858573
0.006007609244501036
0.003084662941391443
0.005596746350700588
0.005240713444726872
0.0061073560724581675
0.007058009923559667
0.006668344817067881
0.004847337256276414
0.007538109594970937
0.006497154058079125
0.006067696308943845
0.005494727542244332
0.006605078449754847
0.006290130821575075
0.005818998065917134
0.005550103793755505
0.005399439608029063
0.008070938085144875
0.005934212425437282
0.007094994950534729
0.008821960606259375
0.009184475593225366
0.008564575293049529
0.009210346933360685
0.008131423271231699
0.008690103270427378
0.009749419616942173
0.0036900177431769708
0.006655940187369638
0.00886480292397785
0.00819556878912124
0.008705639624189354
0.006394575754945987
0.005155442328488663
0.007517762829451477
0.0061023015908884875
0.005691832970239221
0.007497726039524554
0.007183662604371878
0.00679187261278752
0.008548097123552345
0.007447434017653094
0.0073209243602260585
0.009941967640000535
0.00781824671817598
0.005659917637866921
0.011559839886861604
0.005873149545613412
0.0010178174674960582
0.004028241196809912
0.0049384589502880745
0.007341446254590742
0.008338457063711157
0.011243064531248272
