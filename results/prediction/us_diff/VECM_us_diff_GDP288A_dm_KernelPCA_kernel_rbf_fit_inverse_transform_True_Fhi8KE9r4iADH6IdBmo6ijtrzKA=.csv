# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP288A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=12, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.004067062106006064
0.006304831427741402
0.005535497039483424
0.002696882580494498
0.006563094575906429
0.003671561317914314
0.007792701862766008
0.004128288895496028
0.0044373735269438545
0.0033630888384051116
0.0022775423412141095
0.0009747695697581468
0.005938894230034664
0.0070656023077607655
0.004940056957515762
0.005569706022093836
0.004365079588927562
0.004038836587684119
0.004439441479514147
0.005295519614772845
0.0008085277254088892
0.004424269829780913
0.005686116333566658
0.004146398221391611
0.0038029122359991936
0.008067193476236106
0.006464819095140483
0.005104571988139001
0.006840556732271689
0.00792254441877566
0.0025780452388355427
0.007094130219262659
0.003824102237598685
0.0004802900058276236
0.00023223622745311052
0.005572031591459314
0.0034984566219871866
0.003350327554138367
0.007666792827324661
0.002462764972382057
0.003754042381221884
0.0010403894097602174
0.007225407597266098
0.0015439006767985492
0.006801433592065405
0.003116069691172137
0.005526569875027051
0.005311466015793717
0.004762222912777308
0.0022257865981891996
0.005406772498255602
0.0012939264057031477
0.004427529317330934
0.004773889403948197
0.0018576312926481798
0.0040046386191238065
0.0030824007718305768
0.003169493901026061
0.0004994231586276537
0.003607905758504751
0.003195761106336358
0.005283373422100828
0.004098647302851386
0.004040014286436926
0.006182033557371533
0.009170576510476652
0.009882437339633511
0.0076308971598658655
0.008537622463432159
0.008465157032498581
0.005463138699171418
0.00696965559449457
0.004940948655358868
0.001493642242659382
0.00360078718107393
0.005049454473676826
0.006037133194417578
0.007575356455214148
0.01140389871874249
0.006092107707689145
0.008010126849255861
0.00927371123307438
0.004856850406606952
0.010055756833602133
0.011972118194778662
0.01335749530314445
0.010266980324738674
0.01463569825983079
0.017357313411574024
0.017245519795123624
0.013039038933505236
0.01558142297327015
0.007653868731462364
0.009838699646264267
0.013261163899924792
0.009921445810454581
0.015271595906590092
0.016646302477358706
0.015972292417718564
0.017789567854034433
