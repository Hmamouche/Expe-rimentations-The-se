# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP273A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=1, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.00668536077819299
0.005755648352731601
0.006818809246877399
0.007104499333239329
0.005377288305410956
0.00467958910422388
0.00560168599028126
0.004989392262568105
0.004495772760485403
0.005318902760935755
0.00400467479271862
0.0018162308423945658
0.00332197367728556
0.0035283603439084307
0.006104714937526267
0.008177623355327799
0.00690187615177894
0.007109423779005412
0.0057606418529043595
0.0076824199138717224
0.00829052502282524
0.007801572434510574
0.00852804048787109
0.008994983500353682
0.006651779353845276
0.006860836241525254
0.00842101492913771
0.007150934340367271
0.010169901097984718
0.01057276834229852
0.007765266601362581
0.00655037330003493
0.004975167616565527
0.004106050388999857
0.006108076309735762
0.006938169863770105
0.0058429392564329444
0.005211110306718959
0.00524053862034455
0.005073678282896171
0.0034966385216885637
0.004832678587985889
0.003704922498654912
0.004128511512203778
0.0066164955182343175
0.005444130700604335
0.005404656550286853
0.0040430817158018
0.003964213481308613
0.004312105246912166
0.004264991875068471
0.005462355360272278
0.004912237541566701
0.005416920531377655
0.004566756036639572
0.0036107856425835133
0.002793688425090402
0.0021264335022862756
0.001265269160525915
0.001733538919138409
0.001997174086620408
0.002777636261772425
0.0032636041242641617
0.005148039217053126
0.004715243485544846
0.006261131592914269
0.007828366010208657
0.005525435085451414
0.005734689836525788
0.0042823877272247695
0.005512164123777707
0.006196165117436042
0.004440749756085009
0.0022196521803583675
0.001384537939072565
0.004875159775745938
0.003469951439872601
0.004932032854881284
0.007202361632624878
0.003225691641771575
0.005960017189900497
0.004232255617751211
0.00649075087701926
0.008358278740323315
0.007378679072334936
0.008218716092603754
0.006713753769135376
0.006942715424522052
0.009605762009226497
0.00961693234470474
0.007897677655662419
0.00793922397865518
0.007660720278044757
0.0038685903673929814
0.00710681619468439
0.0049237621570616865
0.008544134509570209
0.01007756911442483
0.009178140388248683
0.012468886313584466
