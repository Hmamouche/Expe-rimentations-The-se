# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; FSPCOM
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=1, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.004449799509600709
-0.004107489114902925
-0.002468956180944481
-0.004085245444000249
0.0017678493874619299
0.0027255800644284175
0.004292179728308241
0.0060132727047693575
0.002227058394242996
0.004835860971963651
0.01243436300127541
0.011579951618931687
0.0011606358147825367
0.00545558757578875
0.021694243808572926
0.004743185391250682
0.00927300044171814
0.012310383952216127
-0.007509624028472597
0.03469619366035634
-0.010065102812416779
-0.023639906502966764
0.005475506564070191
0.009153874836258392
0.013518483009152892
0.011329494751598812
0.00697508663575639
0.01361583318408562
0.0060778047957444365
-0.005744702898641001
0.007758896351714173
0.008018809181619587
0.001488155445321787
0.007336966460068297
0.011203333268673872
0.0028766955673000623
0.0032734419540091098
0.006112678474628881
0.004907383551415476
0.004798416924368489
0.004321669653576415
0.006136468023829294
0.002680703152778306
-0.0032848788319670584
0.0004040306480518356
-0.001971714517497002
-0.0001802302177874436
0.016099899405630357
0.020447675611106202
0.02425173066273469
0.028160885219993523
0.021423998005060525
0.012264832860324903
0.025856707070519843
0.028300611475704406
0.02456020487375797
0.05141241186110386
0.04066779486902589
0.0434109491819242
0.042505170158214034
0.051476905611466145
0.02973701099525757
0.02173640098167145
0.036245663073802496
0.04744326224054168
0.046592174038325905
0.03979266689970967
0.024709486082228393
0.02517688816846301
-0.005656928407149408
-0.0015374106607275667
-0.03720248752355835
-0.05207278810327549
-0.02852389207685859
-0.032778451977092775
-0.030514387513942875
-0.06806556625100195
-0.01340237351222542
-0.06858052391360413
0.007856234479422073
-0.01813922658800106
0.033155169842415885
0.04029735945175252
0.01718758093770882
0.013037988358819742
0.027140887832558806
0.018381434190250186
0.009372718589661275
0.019582547603940396
0.004591536022720342
0.03277881145632748
0.00059335163814319
0.019013804046118722
0.0372264706065361
0.024573722539657807
0.047537674883194374
0.010071809499451887
0.02993076310198298
-0.04615910057554951
-0.0022981650630642244
