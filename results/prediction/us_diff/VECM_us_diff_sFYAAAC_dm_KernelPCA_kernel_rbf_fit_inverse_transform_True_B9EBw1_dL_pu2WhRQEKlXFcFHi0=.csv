# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; sFYAAAC
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=10, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.2606485219848252
-0.09263696067094337
-0.21422337347322495
-0.015232438331870962
-0.06034196208808007
-0.03175680744419483
-0.007901344954756306
0.07418901644177486
0.024565891519160235
0.021773050180386305
0.05031958353011735
0.10637668864040391
0.06828318760381998
-0.015953516429213197
0.09145231256630865
-0.020750351594499707
-0.02288194584765197
0.030758545710980342
-0.06182716872252218
-0.10064702964177893
0.012288842622177942
-0.11026014229182385
-0.11782707220015362
0.09138535258321596
0.06626861294008832
-0.02383993191504847
-0.00039605362554576834
0.040911404254838135
0.0753786943104849
0.027378452370314367
0.1595599261420047
0.05140909677890328
-0.24152697595999656
-0.027729143863234593
0.056965652996173344
0.021755088429269872
0.127927012585467
0.017731848945387096
-0.009011852619178112
0.0309483253096774
-0.06958401428636235
-0.03796527955258556
0.03172792078068795
-0.006295230452770965
-0.07403241833195484
-0.07311768490024212
-0.0088715566651979
-0.07594597728446129
0.0030548405979986606
0.05931664484902205
0.07437682377883092
-0.007018448458880715
-0.048318784266232644
0.005476259317102077
-0.07540487168912283
0.0035340824620453334
0.01742450287306138
-0.03680264125747122
0.025163408243796828
0.07317837203347852
0.03210250755600109
0.12232559126885689
-0.020915062845451107
0.04702062254181737
0.034635215135179497
-0.031385210466535675
-0.025047468164541155
0.05746291659116731
0.07171767539106008
0.005715606043665262
0.05092420252702152
0.023031338642551066
0.03850393327888675
0.06428644255784474
-0.132283535030968
-0.058612332506994456
0.07253811434266326
0.013955938279020683
0.08554041987261238
-0.10389942396156603
-0.028896139885874146
-0.07822104155854073
-0.044437729054685154
0.009609565142582953
-0.014368962996101159
0.0038237508317806868
-0.031008633672238273
-0.045324430876962946
-0.0619309688656712
-0.01971969729966061
-0.0535463441447199
0.030004365980070426
-0.0382193280217593
-0.0027007964254128873
-0.028752798592154388
-0.0405385615578375
0.034938082330925685
0.10286614253851677
0.15756623991367275
0.057039668433520194
