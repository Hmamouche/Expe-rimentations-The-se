# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; PSCCOMR
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=13, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.11947104055275747
0.036630639993664164
0.07580783272879417
-0.07831600014150443
-0.016935718796585928
0.0942883529846921
0.0102896629004357
-0.04247912626035098
-0.01064335147123176
0.06322059058300375
0.053855582749131714
-0.0004399577784448619
-0.02454435983492844
-0.050952654776566665
-0.09729278660657364
0.08158953429317453
0.030714208549504452
-0.029464324476382607
0.11146280781334045
0.01334706491276346
-0.05902330288937706
0.013722994144632605
0.017849501765911338
-0.019246990229463627
0.0026649172423734817
0.02377175498538861
0.015914871335777743
0.017264426791818763
0.019532183864325373
0.022228200710186476
-0.06166737090918549
-0.13294615571121118
0.006716094836962134
0.05347379181869911
-0.0026223619246259974
-0.014142768967929018
-0.0444497954415248
-0.022258232900699386
-0.02815015999139981
0.0010914252295257595
0.023427456526118894
0.00782941011020966
0.014758266933038881
-0.014027772086848897
0.0372268599647119
0.03982391416620397
-0.02994539828142674
0.03040541271193534
-0.0014869231616769576
-0.03556050651114574
-0.029356398974678868
0.04086369897744545
0.019112302548719227
0.020306710450298675
0.038634102087304154
-0.017186509937511526
-0.013276970193532824
0.017258151567227185
-0.030091989305079465
-0.02310032169293346
-0.030363870119037045
-0.040555620859053614
0.023997729625084206
-0.02430134108857518
-0.011884186682151975
-0.006656772368732574
-0.0246472769134812
-0.06130720883762395
-0.03695605968974015
0.007043446148711773
0.0046395121745309055
-0.008874125846383002
-0.050100896936488726
-0.026648758395251496
0.03307759838953461
0.031233756092861897
0.008010266849912366
0.028815980434196253
0.023007866487791705
0.024092582902687967
-0.007929645395427263
0.05961397927249044
0.062297334772449
0.0037581591045170405
-0.015794969440653783
-0.002742180354182041
-0.024698496786713476
-0.0180444509650429
-0.008769647444598594
0.023031182376614875
-0.003910012188903923
-0.014214005623169258
0.011302105993295126
0.04755276027341279
0.05021182676087426
0.040644765366210436
0.0385905584556191
-0.016955946487956106
0.014703482271431104
-0.0034922119349123423
