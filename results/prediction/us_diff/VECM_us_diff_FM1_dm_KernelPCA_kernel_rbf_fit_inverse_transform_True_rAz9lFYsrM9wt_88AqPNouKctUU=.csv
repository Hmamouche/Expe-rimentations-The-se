# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; FM1
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=5, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.008214953786401262
0.006931542310742853
0.006452209619704904
0.0072196064327723535
0.007586414031473514
0.0065022293207262875
0.007530487951955557
0.008974874225683264
0.010202727156624646
0.009740074548521407
0.013320011604466084
0.013741185939170444
0.015234051008775677
0.0175988093776387
0.01586733911077714
0.012643077682583326
0.003613639977108148
0.010386094307850202
0.006532188795668518
0.010646075900651695
0.007141475539363931
0.004819463408514651
-0.0011416908323530852
-0.00022054840113417459
0.0037156742615474182
0.007449136983393723
0.00670590926227305
0.0011227770891744848
0.005406072958582002
0.005739603666127472
0.007581620474885957
0.01019026336919725
0.011245134782054621
0.014103334255433274
0.022913119339522423
0.018177084659340408
0.01804766767282052
0.020312564444671263
0.01841636707898038
0.02121473084546966
0.014917392040015619
0.024286370848688614
0.013378173743672086
0.008514233665022339
0.006575858926100835
0.0005644015838137554
0.0013639667667589433
0.003036741941838999
-0.001200564835983839
-0.0048633487109718465
-0.007538440046892332
-0.007805373311221319
-0.010167389381475093
-0.010924267732449193
-0.0077863111236141265
-0.009494951773881585
0.003109550336468261
-0.00045096934800154323
0.00603279284334814
0.0015577413398165994
0.0005853043861931159
0.008403541402284411
0.003394749566376034
0.004391336423487134
-0.001609939418921152
0.0032403026334308417
0.0036454388495712
-8.350165819635727e-05
-0.001970271886012779
-0.005104627490759908
0.006432369793242877
0.00852341762765508
0.02605401075136137
0.018226411054828147
0.005634930326591365
0.0039672318885675285
0.007149139343219075
0.009674964807225048
0.015040699106822587
0.017332117117815887
0.013023503068874568
0.009972259851932355
0.01050529158573605
0.01632566500406658
0.012096301760535957
0.01198267427913009
0.0036195795062545126
-0.0005998054315676021
0.004267601760658432
0.004822058547684244
0.0034654378152938724
0.0001705911611876352
-0.0030163019883744932
-0.006642302639463559
0.0032624778590057543
0.006020081776627679
-0.004005641237105729
0.0008195923421933422
0.006624566639156995
0.002747964739765163
