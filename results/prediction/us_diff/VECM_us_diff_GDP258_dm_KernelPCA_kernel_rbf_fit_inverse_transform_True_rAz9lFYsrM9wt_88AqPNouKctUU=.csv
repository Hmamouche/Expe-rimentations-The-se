# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP258
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=5, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.01923182635811763
0.005727616531783889
0.015445435278814146
0.01465926017689578
0.008153772191047754
0.009592568614293978
0.014211934312342783
0.007878042213530256
-0.0027460039306775328
0.002380905111212757
0.004798928595479813
-0.0073270446330415545
-0.01082483557214021
-0.006793544848072666
-0.0034233390942823446
0.002441453716620539
0.0032012981614807437
0.007450299561658465
0.003826343041994976
0.006773987127180154
0.0032641377110948673
0.010124427031010533
0.004191039459907245
0.001325634377448657
0.007161408851671601
0.0060105493116918785
0.006548068653722155
-0.0030393461056451936
-0.009802142264684172
-0.0044927933782199295
-0.00809975308015287
-0.005826660896387665
-0.0009512992783468744
-0.0033732179370159743
-0.0036341300744734554
0.003316262869681428
0.005581052817976071
0.015018809462058563
0.014999325041824729
0.0078063463433124935
0.010437643432527498
0.01484752714361394
0.01581705245022285
0.010042914584953131
0.013461382414686423
0.014450444507263089
0.01314545054364429
0.012961316002891389
0.011825417212220475
0.011285589039680105
0.008689930166433107
0.01350580451001148
0.01602017773826066
0.020463861762983877
0.020426611435531726
0.021936509433829538
0.02473383403797679
0.02430950911404469
0.016252818069935792
0.025045197392325143
0.01386048966399445
0.012701310729912327
0.023108650139526853
0.016252497603641936
0.0215175599309421
0.027387184030525376
0.01689450863571656
0.017077578076363245
0.01704911375548468
0.015682144611203472
0.007550743054518251
-0.007620440784953285
-0.02501636456296223
-0.03234833994108205
-0.019630694418087357
-0.020577448835058798
-0.022253904764624553
-0.007388001414015329
-0.007668159947483485
0.0012381836684444503
0.0189782891100365
0.02001753444883684
0.0073614248166773205
0.009061973285542774
0.014327436561425053
0.021163811359711685
0.015123972293870719
0.012641756803002125
0.016072281185114574
0.011109738083619345
0.02094666073801907
0.016987418079867547
0.01527088302997069
0.011593712717796623
0.008731902174563756
0.017050427603862276
0.015797774027940317
0.005886561844245979
0.006371088384594034
0.014225377439715662
