# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP267
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=3, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.005349704143969746
0.001729493053228773
-4.682607302516819e-05
0.0037361253487070787
0.011384245410013183
0.005450591182102666
0.00880602240307814
0.010333086139843376
0.012274681220022217
0.010773752809598823
0.013190750166901884
0.011241388118390738
0.011565534696351115
0.012277337354077161
0.008562955035848849
0.002230342001834926
0.002874120044058439
0.0022872790785187953
0.00631591366519666
0.006552263661956095
0.008367259860620611
0.007298353696093598
0.007116193722809661
0.006812350097142728
0.007554549404527591
0.00908640346516015
0.010603198368214526
0.006322400501022748
0.006824769379802443
0.010705051170921593
0.005925573084250093
0.004431505177767137
0.006079277782251699
0.0019095923810729394
0.006274769341054656
0.006767563186873675
0.0032510028836697374
0.003163418987427457
0.0047744247945964305
0.0027181479065029454
0.002762752989121699
0.004728622256496277
0.003988789614356356
0.006438396101209079
0.00964045601144308
0.00434421876796679
0.008342431034174744
0.0075267568290263345
0.004790386154726553
0.006630003538297955
0.001163667917373473
0.007478740783244332
0.008011839617573848
0.006473751973947074
0.010019177430642213
0.009608878167850686
0.008637263958565029
0.006763663572618382
0.005362925910487695
0.009039136642689606
0.01429844167194643
0.009823149949087564
0.012986432384905856
0.015029565347993427
0.012398133637910603
0.01234002939330892
0.011385718926923801
0.00566031568723349
0.0061424293009421736
0.008040254812240827
0.0075052525320370034
0.012000611872405418
0.005993419907382139
0.009275109977102873
0.014843134189663888
0.012747041576453497
0.004196605780018549
0.00817488704753926
0.005569875175026899
-0.0002650260724983963
0.002716408750381193
0.00038881140667807693
-0.0025680607852497637
-0.0014903093980747888
0.0013075961458621245
-0.0020193493891912787
-0.0017855564409406492
0.0002827230859210974
-0.0013223045412516154
0.002408181187798784
0.0013157703838052154
0.003253454152534879
0.005451406872728794
0.005945578483719747
0.0064754320728336034
0.007320053203787375
0.00837742606323227
0.006065782624632192
0.005832708133233278
0.005698402826761708
