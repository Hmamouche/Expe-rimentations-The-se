# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CES140
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=15, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.006459909510839204
0.0006321484705841211
-0.03138690062913511
0.00909616908336235
0.012951550676792281
0.012108878815495756
-0.0019295669633432773
0.010832178409576062
0.013092488671302069
0.0046249396318010175
0.0070570496802680885
0.005080398411718638
0.002168842437971584
0.006292825857279689
0.005319014424430364
0.0024733347024336366
0.002841200616525988
0.010054140598627805
0.006752926301313144
0.01107222387706025
-0.0013047523139889119
0.005510513676668881
0.006591729795165815
0.016377732690851146
0.00515451112339374
0.001968049160472495
0.007175295988277181
0.014092749859695625
0.01112403263106097
-0.002557197576006849
-6.945635369397653e-05
0.007007539417066519
0.014250884654840576
-0.0051080118317827225
0.004003496605392785
0.00036470440148577256
0.007651653731460353
0.0026439507179119104
0.010572368102575846
0.0012685916474989836
0.0018880630296615947
0.007444457910505629
0.003637600899353813
0.003944833424744634
0.003017475338621581
0.0010696523510257212
0.0020816129744767532
0.001988152162204909
0.002112301239355843
0.005382017544459422
0.0061155465137181855
0.00586277959414922
-0.003404125624246946
0.0004595340354877326
-0.00018184062927372987
0.002252997095417532
0.0029903959699711484
0.0038885926337911235
0.0010012491768643557
0.0066095069763275295
0.007702480449843612
0.008146309277610278
0.005753612962599488
0.0025091146715184582
0.003874109324430977
0.003160637432914889
0.012822884665936058
0.012716695872730829
0.007196270442384198
0.005280236655183565
0.004710356050264707
0.007411043539761564
0.002270834048248584
0.008221529900045262
0.016424586750197128
0.002909438181050033
0.0002958897595824804
0.005291119004007756
0.011319366671659371
0.0013605295193658113
-2.451921559015887e-06
-0.0004171985426897739
-0.002185792530591671
0.0018346776994058783
0.0006625912126838706
0.00024338406484551256
0.0033418115030718204
0.0034613861311073297
0.003663512935521303
0.00327024326019364
0.004021733848284775
0.0032509144360428907
0.001612087243184671
0.00035707445042439286
0.010765502323509285
0.0037799573995383187
-0.0002476762398228938
0.005763223344870638
0.012889348572369822
0.00097834914823782
