# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; FSDXP
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=12, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.022300271411629505
0.06302583459138937
0.08199276434417457
0.15710449968739199
-0.06449796793864283
0.007764283297183747
-0.050188065101438833
0.12754756441639076
-0.14053920200263748
-0.07387091875576395
-0.1469574335618192
-0.102079197862435
-0.043457444879944615
-0.0007154875807600432
0.01756991156119461
-0.03830528908621532
0.06226228881908498
0.08000249873498885
0.02385475359104358
0.024126181326621372
-0.033358314251814375
0.05852042924468519
-0.027264407031013432
0.01399501180984114
-0.021622867787295497
-0.025070773962001965
0.005923402709953849
0.0312720597058469
-0.009945635073603734
-0.0298025735376558
-0.06853189626281743
0.015215185195306406
0.04267539600401589
-0.03378995804151251
-0.02933368329015179
0.0016815335809648975
-0.07045454611744438
0.023539166474785052
0.038832758396774095
-0.005187574502053004
0.0026907848235561077
-0.012864026390589504
0.031136518654210812
0.05904736593951328
-0.028189080433481804
0.013447907062773127
0.002145030524320477
-0.03205165665934631
-0.10941208472589381
-0.0469024286664456
-0.03654242348951598
0.06648999140070734
0.005736267022273648
0.020858003786817694
-0.06602503276573607
0.0473910366419931
-0.03398444839629711
-0.045170375874360486
-0.02641015929461228
-0.04401576753607549
-0.000372107605218424
-0.06951851588471995
0.00865476777407651
0.05499560018887711
-0.05139962638549868
0.005579192433908175
-0.014260988341309747
-0.013628931929862457
-0.00902110715083039
-0.05042200481682123
-0.012842799637390202
-0.034102873711494903
0.06353223281746768
-0.08115002451760853
-0.0162818835481761
0.015893228129721042
-0.0470883806969305
0.038437702213074014
0.08876359493832739
0.09330129028696127
-0.03937266313415042
0.01680655071190949
0.03522895636649564
0.03209114628450894
0.05974327366714222
-0.03307984412311358
-0.017277495220945082
-0.006347531477735938
0.006257413128568178
0.016092240761265808
0.008664457329209858
0.015639911040288914
-0.0376030501269598
-0.004573199555735998
0.012710376861970256
-0.021070542168370097
-0.009165980797530764
0.010117983611401085
-0.026661873421659633
0.025619399860902253
