# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; LHU14
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=2, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.06757039822172957
-0.05190911926785039
-0.021026633094466562
-0.022959418402479583
0.05922803406305277
-0.00910184376427689
-0.028522775232505584
-0.005117967310109342
0.0005383614041011295
-0.033259819043895064
-0.004709017453841386
0.012679780760531747
0.0037795442570614864
0.014642425969195964
-0.022296105094295825
-0.02732431414528872
-0.07276101075813673
-0.009408902908431008
0.008307021615583363
-0.052800846106893375
0.0012278698661164892
-0.019546294018724375
-0.006794332078169449
0.01982164865983724
0.01806570279258722
-0.0015817799163853727
-0.010730978402004664
0.009485048493850153
0.020520090424439152
0.061802655531644095
0.08764002842701546
0.010077497884430233
-0.018303432118626298
0.03560964974845772
0.014320331196339417
0.020993381286289733
0.03431505056362376
-0.016913247000544245
-0.00785404135021049
0.010935700990932879
-0.027726092940737922
-0.0482270826761406
-0.029734414904998334
-0.03141685118475575
-0.010360924169980346
-0.03549279536272606
0.032038174406623696
0.04293706033902496
0.0012058864834509982
-0.00282288245771474
-0.01791650594257263
-0.04422002967030103
0.00021105408417395125
-0.020832414456409314
-0.013750861281085781
-0.0058977742955112385
-0.022076135982495727
-0.0031227338639574775
-0.0064873115741355646
-0.011831366292596526
0.010116402902146677
-0.021546075860781246
-0.02671941692666524
-0.023560137937337876
-0.027310559156358674
-0.035291029924300533
0.019657715028374392
0.00950543811198107
0.02529239197659728
0.020075823254123774
0.04408450580099428
0.0008354107322612637
0.019655688106524342
0.07167712104404225
-0.017840281163141843
0.03555302145065198
0.04840998885300529
0.04471276579420611
0.031740959502929704
0.043589682001425656
-0.060307990691122124
-0.04845169957418158
-0.02004923608315194
-0.0005706571675689661
0.013643953059033834
0.00047691265081575363
-0.015377811022654115
0.007524537443682694
-0.01611260661382051
-0.0318770983842063
-0.01894166490545681
-0.0112408847428083
0.026544730487618285
0.0010037934081828708
-0.01572635798351003
-0.0071432484388567604
0.016886350940189136
0.008037787667779111
0.055061134766388256
0.03970497677383729
