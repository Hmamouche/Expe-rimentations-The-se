# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; Sfygt10
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=8, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.07537079896752874
0.09378435460641665
0.03817723358341385
0.11286697300515004
0.06728988361944038
0.20744201082838387
-0.12698954122524614
0.024869476522862276
-0.14446531128900397
0.03947484470424238
-0.11190464140558558
-0.03556958174290857
0.02187719648865681
0.03646903842408393
-0.16798228287366523
0.020346015993660854
0.13493130177892743
0.16308562662913384
-0.03726220661528888
0.11004826477292233
-0.05856627179711265
-0.17221954427118694
-0.026925623579573017
-0.00765024508645243
-0.07512417343428887
-0.1793766233851121
-0.0903478590130111
0.07594684846265401
0.12496255112906644
-0.03759449702796785
0.26796860175595577
0.15191160133381415
0.09143200626607949
-0.009824246247861573
-0.1859408655582439
0.11115513330184422
0.09447472046196212
0.12074638663590659
0.09839513661245862
-0.03283681141849384
-0.1730231610404769
-0.05151138221997757
0.04434887945798069
0.05255351150199957
-9.95825003291366e-05
-0.01272062540526367
0.016349331492702363
-0.07994044939366456
-0.16002357436970488
-0.07426442653116001
-0.0025344881683643274
0.048201819561256874
0.1278438621970014
-0.0325026047986443
-0.008675627106105395
-0.019762968586031444
-0.039643396853121717
-0.026770146470376704
-0.026658296087958413
-0.02391866895592378
0.0013247926449637785
-0.06835958552897806
0.024194304243225273
0.130170469469148
-0.0804103614106715
0.000598868710622695
-0.006400465653958662
-0.007200567988291537
0.0026687067801999115
-0.03856146474849835
-0.06636007311499435
0.0484610159884102
0.10414926310011055
0.2196673226881275
0.028674322922650958
0.1685863063975293
-0.18092184932107766
0.08628716958925867
-0.03040413579277157
-0.012354916893491297
0.049645901066155705
-0.02506277105427747
0.009737308179015428
-0.07168121305293182
-0.0474172130731812
-0.023547751060863435
-0.014095594452266276
0.04933444038435233
-0.1213348030522497
-0.05097386476401543
-0.056862298946476555
-0.05003445157864189
-0.023961463653898583
0.05377264612903082
-0.14579449247031592
-0.019881888386072438
0.033461651244354705
0.034175081657095374
0.05750796537084413
-0.02089854953151708
