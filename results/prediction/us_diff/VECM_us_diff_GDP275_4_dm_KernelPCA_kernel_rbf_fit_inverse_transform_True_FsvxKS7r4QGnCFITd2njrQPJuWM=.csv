# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP275_4
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=2, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.007975240709075142
0.006499535751905542
0.007409988269233967
0.005416119265754768
0.007392563886590916
0.00444369586763628
0.007926318759987044
0.006574756007316069
0.00577645438996897
0.007224531219020758
0.009141929093589324
0.003647163280310128
0.007102255451110373
0.005431804862173884
0.007375927744433828
0.010526229173841049
0.0051667770428992
0.005447346093413382
0.009596409219685857
0.009711710245273127
0.007776559601261798
0.009776605160678442
0.011743990690391014
0.010481996080951081
0.009022360888940407
0.009261785154482727
0.01058040510531423
0.012949736920962952
0.007995231689087003
0.009038917377602141
0.0129986295595665
0.01326903634323046
0.0057268214224349
0.010226620853494276
0.009602970732520439
0.009126899879236846
0.007176008978161106
0.003034835127648493
0.008130490194176835
0.005789441311834686
-0.005774329962560188
0.0016171219349618137
0.0016525532686216945
0.0004998070263973416
0.004221953900399731
0.003234652114110786
0.0028327607972599973
0.0032268060633132128
0.005205917509141858
0.00380425083092216
0.003867221699527958
0.004588809050499798
0.001944521576030126
0.0021885886719629952
0.002100889474843501
0.004481104755836371
-0.0007536484152202924
0.001967634182332154
0.007606267167418093
0.004236029509431733
0.006054180258378097
0.010603951108417648
0.01899847633839255
0.006945518469910264
0.010647166286401982
0.012000831569514554
0.003130645789353399
0.011010970471938079
0.006657749667776555
0.004753887475155555
0.00911058064453232
0.008197292844997294
0.008819799747105754
0.007127494009976711
0.004974960028043144
0.008751115976907541
0.00531867807821493
0.0004931233093148603
0.0016256269229900015
0.0009524148092651728
0.001675436708339202
-0.002789831870529654
0.0034924030981241796
0.003961959702755501
-8.258957680625184e-05
0.0053930955883220244
0.004048332616243076
0.002839939431597841
0.005214763919302728
0.005850714838428878
0.006024582419755276
0.005794799297818082
0.004938255732096114
0.00302461892293337
0.005568798328012735
0.001846869680076299
0.0025308176466249262
0.005658947638462336
0.0064107482860926305
0.004619555965535758
