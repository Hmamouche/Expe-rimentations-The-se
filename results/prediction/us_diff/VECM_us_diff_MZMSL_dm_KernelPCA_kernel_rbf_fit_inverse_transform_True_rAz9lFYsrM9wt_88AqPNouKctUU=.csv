# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; MZMSL
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=5, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.015457618698439724
0.0009148726572118532
0.009125424948883505
0.0007303738027837476
0.0035910943368974908
0.004013952617399048
0.0061133912552828375
0.008399690638878791
0.0030150914735637283
0.005489429165951913
0.005707863177544172
0.009685524180924898
0.007631926330058254
0.004623278518121826
0.0033824204771749898
0.00269567225062391
0.005338056536326692
0.0006129177438103937
0.004129780153610759
0.002037126227023045
0.0005618038074834125
0.0013022243255811968
-0.0012037252398705571
0.0012444217503276732
0.003983123187344375
0.0034266974154020706
0.0016466867687233598
0.002316171736588529
0.005530452768425823
0.004138506968794712
0.006351236505354286
0.00549891830461182
0.00609698018389175
0.009150757018932426
0.009438400784121715
0.006815583890381683
0.008316734193858408
0.0036850556238435727
0.005198812785494479
0.006101099561613168
0.003980903364524892
0.004886476413869209
0.00158945271225158
0.0006280837408620217
0.00028608491279061586
-0.0029876971048156237
-0.00028146192848175935
0.003664579809929035
0.004228980153563361
0.004022002873374733
0.0047912393410197715
0.0018768192513590118
0.005986800367326924
0.005759200412326803
0.005504872770495873
0.006257375417509715
0.009487548215202138
0.007447150094046876
0.010861657462581864
0.011952468694895302
0.013260130378387993
0.018313139876471908
0.011740530300641514
0.01143276911972582
0.009865388996469644
0.009461263602394406
0.010146137103022259
0.011278981797046766
0.010927955509959519
0.010735409078536675
0.025743615169130218
0.02472945460842992
0.019188595330485808
0.03040372629844328
0.017208655240374973
0.016049987594804856
0.012710698922285837
0.019179634211010578
0.013790397646017928
0.010274295991009784
0.014723387152441685
0.002985216789396627
0.0051203655727672295
0.006958582751823693
0.008496419190470974
0.00759426389797991
-0.0011966303303121463
0.005919756355049306
0.005252022586673039
0.007573579084536606
0.009035485320837748
0.0038113480487671487
0.010447084609055295
0.010948138686944985
0.01325501589203359
0.019758122329686715
0.026236971550775246
0.034174225454143614
0.038108042193988084
0.029311248559406484
