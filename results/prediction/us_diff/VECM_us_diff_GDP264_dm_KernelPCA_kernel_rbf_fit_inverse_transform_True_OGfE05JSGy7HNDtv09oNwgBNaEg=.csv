# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP264
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=7, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.0052264375602269625
0.012235650913809546
0.010885965779153888
0.008622337508483763
0.0057473028076637876
0.004678171241122656
0.010897188322301497
0.0010475481268427816
0.0089939681959866
0.0018477636858310687
0.008147936526383442
0.001184005581763568
0.0032089315199661417
0.003424122079160965
0.007005414294035089
0.012881983037006665
0.007554738141209693
0.003526532756697427
0.002614016340529311
0.006307644954562914
0.004885502026276936
0.006184782151096744
0.0006594408221342427
-0.004852525241629405
0.0013037210321535622
0.00326880902461034
0.0005694998705723317
0.0015543693199635109
0.002852985386368316
-0.0039773121155850435
0.004843032705708213
0.006454061323655185
0.003992646589588994
-0.008483663659667257
0.0022197308738300054
0.009702730257872974
0.003744652202677321
0.007418026107178574
0.009933913974192677
0.0016223493723543005
0.009297521488895386
0.011483923658596606
0.010156977652386497
0.013181317952512896
0.004707127145468551
0.012437425665457105
0.014506513609793378
0.005137358064760283
0.014170226619611698
0.007980397466857124
0.001458495309808354
0.00961079100334881
0.008663125208713245
0.009775846338797755
0.0174302301461191
0.01359694060801309
0.017545862672531786
0.019514109743415248
0.018789397451084888
0.016963394819162182
0.0136894187272194
0.011547226733390427
0.015483937571268182
0.01395688819370872
0.017286431890166543
0.023328101679729728
0.021945980305609063
0.020096136903119635
0.016911072832563205
0.022926077095352757
0.016792958313133936
0.002959844610705812
-0.012342806557844123
-0.017643684039004955
0.01226252855914633
0.009537024654252572
0.0018209115260834391
0.011267696570514968
0.004054023527341056
0.0036580743341915528
0.01760951763633547
0.023998529186815505
0.020211324084507338
0.023033732117640097
0.01727384401477894
0.02033900847101927
0.02416631630740655
0.0028997308886466603
0.0038776590274433816
0.02292375494902172
0.030144418917232914
0.001331766060456765
0.009451476226772289
0.017696855540839884
0.0140228207750581
0.0006952259530222303
0.003688869273545034
0.002415944477018623
-0.010939831404670378
-0.009635701404201936
