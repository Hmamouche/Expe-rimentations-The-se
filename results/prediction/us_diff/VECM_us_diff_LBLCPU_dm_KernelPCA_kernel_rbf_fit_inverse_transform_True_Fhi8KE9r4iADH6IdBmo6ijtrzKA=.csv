# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; LBLCPU
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=12, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.001129041243961423
0.008667473039913137
-0.0010028891428006867
0.013230178604485342
0.0115062793500424
0.002107513944393892
0.0030107943256117865
0.007603724194238817
-0.001317103864326188
0.004272608518300032
-0.0002683648758676671
0.0013831727496901973
0.005657232746997785
0.012762337573961582
0.0048830637342334345
0.006364562131378214
0.0067365523821664285
0.004767693831860837
0.01243717109748196
0.006989145815187413
0.0034443427686855392
0.004459196389000067
0.00457317396845115
0.004750485774403816
0.005384858192845097
0.005009220058306564
0.007415267134748271
0.006800401205073443
0.012747089235421966
0.011548841233598211
0.0017633461044678242
0.013325577933681991
0.013512246103177422
-0.0015290052915593645
0.0008084867256036854
0.006442821737983002
0.0037573210783274818
-0.00387005917238609
0.0050264628134064045
0.01356697952824366
0.001172743004020824
0.00047701826382302
0.0018634117675935483
0.0067804752268624275
0.0011001235151026217
-0.00026157746245171
-0.00026871394972209986
0.0019056540030772209
0.0033455417114107476
0.007671836043872053
0.0018207106176678653
0.0027946373460533335
0.0039779289418399155
0.005369804385066725
-0.0018334310021727988
0.005498681245449341
0.0012706190225634751
0.003529510686859431
0.0024544672723589003
0.013695152707201626
0.0038801757108537817
0.010086067879525644
0.008038813144990916
0.005078872492637417
0.004156034074094658
0.006038645413722666
0.013966493296229624
0.013950935536909357
0.004736045720948411
0.023071349940695117
-6.274286723693002e-05
0.012209930846806152
0.0014810111226926308
0.007184462433474337
-0.004725309112484324
-0.006861349686138595
-0.0007838564378749267
0.005805318106112715
-0.0005949940561244121
-0.007389451306700317
0.005524967198740827
0.0031828608211378106
-0.0003685127897698425
0.0018774066095506897
0.009224836001519868
0.0017779288653729487
0.0037824756072119747
0.005634640067053633
0.007183341495127142
0.0068503482815886595
0.00610519663660361
0.01649678260738788
0.004274709951478964
0.011792223408227002
0.009149820221011079
0.010903184140932725
0.015258690919808698
0.01610822259302888
-0.00300094485681514
-0.0061134876976118345
