# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; HSBR
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=15, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.03886482507118208
-0.15479621466123022
-0.17364670763005452
-0.08492779743752363
0.0088866291524098
-0.004670484087568809
-0.054513410339698615
0.045866889408442316
0.050681263031671066
0.04393470054139431
0.14447626508863093
0.07277247529755801
-0.0493429669988819
0.02578384842581373
-0.18951109787351847
0.009734515262861336
0.11498829077163517
-0.059264101168192196
-0.08540892508499676
-0.2001617369983072
0.03225016316909479
0.0192598788062397
-0.0038381438109142806
-0.044625887043820436
-0.0022693564016466163
0.059121645993100415
0.023905304184469067
-0.017540722259598913
-0.09621186355948998
-0.09140396578322965
-0.05761175718149859
0.11106598374526946
-0.042989349256515846
0.030480540583733482
-0.005164556375480689
0.04225639156645302
-0.011998417763965527
0.021896938187737146
-0.03697427543813815
-0.08215708272461811
-0.023487314200031258
0.04506141452192996
0.07449636530274287
-0.07834799231981107
0.0918260280566762
-0.07816241391141236
0.024934818523581846
0.04840757209646994
0.049160802859772146
0.06787694691452853
0.013012017746400123
-0.07203425598883871
0.02387401810496949
0.012816726227689416
0.014202458108197553
-0.022124188601051458
0.06508440352875174
-0.0016985981431295767
0.037455510549228035
-0.02608973062593424
0.06660746393697994
-0.009628836874215379
0.0459246467658425
-0.036558508637087435
-0.02220996154295083
-0.05346980153784445
0.008666236809636414
0.040908871424779045
-0.029341580927194445
0.04177420603446179
0.016719576069032224
0.023235257747525332
-0.014024476074300234
0.05349171841695354
0.01609928445170833
0.03236018725714605
0.024787993529228735
-0.0159895015559659
-0.078419313034581
0.02597315199577744
0.056713018812502895
0.009391896818126702
0.017713730839495363
-0.01826943036741534
0.016700028624266075
0.005311950839405735
-0.01796289408660425
0.04589797409324431
-0.04852592258706283
0.01730071769915462
0.00020122633857860752
-0.023056878988858186
-0.044356226162962656
-0.04922642640354982
-0.046851169291562966
-0.08440667172457636
-0.024878259619457804
-0.1544045819042521
0.030403482975652627
-0.1541161044678937
