# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP282A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=4, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.004581313120475077
0.0028810200958716017
0.004256491338166055
0.0039400652061927595
0.005563317219259607
0.004296298532340356
0.00220403094209234
0.003442902501876498
0.0024476938544853014
0.0027990975321529068
0.004335065380164506
0.004154805711835774
0.00582345414158356
0.007284005379140672
0.006513950072587517
0.004755782627220217
0.005554702434216921
0.005589705965913869
0.0051579647526639434
0.006033681679880167
0.004408637016004588
0.005319553134520054
0.004588927479010807
0.0054047114473524905
0.005160417769361441
0.0030312088104791465
0.004257341283750918
0.0042470282785438815
0.002620678246475394
0.002929205574159094
0.0017222641736212658
0.0014675161052665098
0.002500372203152131
0.0015018164756467499
0.00030302081696678305
0.0023139468460613736
0.002476779425699208
0.003355480462495885
0.006445813460658721
0.007127462077273144
0.006735318326088173
0.00562946921099437
0.00551844815479857
0.005079637428563405
0.0064935221995272695
0.007112723186847681
0.008345381538371256
0.006902810667132797
0.004389425964707739
0.004660503069510897
0.004136563246056515
0.0028168908140464967
0.004496220153843746
0.005279355008354165
0.0034617373084366784
0.0046977982091229754
0.00553314757450971
0.005061260605670581
0.004194913874216914
0.004519431693843788
0.006050624066374969
0.005902953190559661
0.006080541024005182
0.0074654983136371224
0.007566718490832019
0.0070816333684734995
0.009208545551880639
0.009779199897737453
0.0077916751297326635
0.007574093931031629
0.00840753406915188
0.009630538861802323
0.010431563797052854
0.008591150666371944
0.005958659755826653
0.006005494060080955
0.004201366864242937
0.008144612120413968
0.014198942737090296
0.006148026863135444
0.0034267890701640295
0.013298812038238694
0.015909233152897793
0.012249907939614321
0.018235918885036964
0.017648902170662287
0.016707582872909285
0.018058702398232228
0.022639681630985564
0.017215803611387373
0.016713218917630362
0.016491324892136977
0.014358521861217388
0.013864066771190068
0.009154053201917648
0.0026191228442379814
0.002550666635054764
0.002506897191092563
-0.0023067047261205688
-0.008014760733446133
