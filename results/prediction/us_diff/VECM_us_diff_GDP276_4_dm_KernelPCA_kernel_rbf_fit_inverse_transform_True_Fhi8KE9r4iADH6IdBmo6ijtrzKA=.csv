# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP276_4
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=12, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.007326975485410712
0.0018654423168642182
0.017959178029268733
0.012046366863197574
0.01001668836383711
0.00546734806982009
0.006675003794433852
0.002628517180216187
0.014158196788359605
0.014618634339700861
0.009140886318922075
0.006926543638556513
0.004506125965743168
0.003477818089522599
-0.0038689435575051546
0.0011751341002126455
0.004164295518066629
0.0029397966545725495
0.001879077012929066
-0.0009364887567371704
0.01272508652665595
0.0001779560075153956
0.008051155244572701
0.001565201497028571
0.004608748693010993
0.0014732677031877952
0.006108398591990655
0.002152434268903247
0.00434954229393064
0.009295060462115748
0.0006813002981498513
0.005853461995375961
0.017306469405585737
0.008154275600030635
0.00846516526408201
0.002555302466859544
0.0017365916948986183
0.005937053494885931
0.005777172451358627
0.0070808077610314876
0.008782587427039506
0.008356181896519745
0.006964453147871165
0.004514571771107528
0.01000982987286885
0.004857466835095371
0.0044994652302933775
0.0075519436127111615
-0.0017916493202670188
0.005785050920601129
0.0005680630269735104
0.005895771633195009
0.0038711444990558105
0.006277248356935515
0.0056919854520689536
0.001159499027325691
0.005245553550239009
-0.0014054174253493408
-0.0001821477263087471
0.001547583259904995
0.003503478885963465
0.004252126496023382
0.001998372536417892
-0.003577227946946225
-0.0002236900739889368
0.0038976170819124034
4.7303855658458425e-06
-0.0030725079363569767
-0.0003605910193258909
0.0009417846715502632
0.002535281964956643
0.002339713359846904
0.0015515162733787656
0.0066257290405799234
0.002005417884588089
0.0022434068780217307
0.011466054960218507
0.00897304764390999
0.005003772935716589
0.006904290745251211
-0.00634157427684915
0.008167265649733092
-0.004109644085876149
0.004359411811328597
0.0030313741818178653
-0.0002871063234227882
0.003994786435283007
0.005154522386683726
0.005370585220755246
0.009353609220989567
0.0057705746176164915
0.006362009518175115
0.007030998280693411
0.0056599310747297085
0.00945424852998435
0.010047163965567263
0.007662436903690856
0.0070024582755984265
0.009300191356522944
0.010143686965042814
