# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; PMI
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=11, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.4165107560052286
0.13575193225553517
-0.14485124707362318
-0.3114209666667937
-0.21587681695318967
-0.07718625263866294
0.05645644556417856
0.17195770981257746
0.02945650612145527
0.05730727708505362
0.13002974235984027
0.004802829847176775
-0.001553677885943485
-0.01341868714981994
0.10347362996018925
-0.023137169325736825
-0.05530720120317783
-0.15953536857054088
0.12033763330508371
0.015526609615801084
0.0009729242046774417
0.16481965750616084
-0.20771773146038985
-0.06501015434070265
0.019550952504639417
-0.017527517824685278
-0.0026159821120949472
-0.002693000403087231
-0.017943156974975265
0.028152320934071728
0.06567417454920949
0.10332284262352594
0.04249501186799131
-0.062229832800141174
0.10601377034581985
0.025847202426566795
-0.009885802378105057
0.07799200544489551
-0.0993676132061843
-0.16873207081422797
0.07442718597588435
0.03966659043355034
0.05756440180015257
-0.06060363465729043
0.06724083159985492
-0.03142906841610597
-0.11939595189224368
0.09961541582917
-0.01948834566907244
-0.06027719597233716
-0.06381806075566394
-0.011046586959254902
0.015614878038091275
0.11956465112961985
0.09634743057158107
0.005455841870284611
0.03117141699574827
-0.051302675318954216
0.033426728052468144
-0.0662139700328046
-0.11461190654877561
-0.07850544480900994
0.07829787251969852
0.04275533592005983
0.10533470415341438
0.07853511861882048
-0.0004679380662938465
-0.10323650735706504
-0.06389783477102459
-0.04774383597943421
-0.032358122662414404
0.006335924463487602
-0.024449816635325097
0.10333503428986991
0.2315185453137413
0.0015533630605997842
-0.0400224964646917
0.013351948009871873
-0.10317667386994381
0.06901655576966022
-0.005340223729481883
-0.04152692718326921
0.07424169777634651
0.06718985572800604
0.019808432813670927
-0.12445755251410615
-0.10179747253965479
-0.06407176244751214
-0.009508680691953302
-0.04916793444157802
0.12228072144135241
-0.03452300957932658
-0.061549605267266556
0.10756290756368231
0.02260640533766355
-0.057084219386025196
0.029379350116513
-3.554213220856306e-05
-0.058482841083057555
0.042068283228116274
