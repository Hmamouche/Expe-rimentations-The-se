# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP276_1
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=11, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.005802179239452442
0.003906614666828035
0.005942105399986303
0.008983392174889814
0.0059165233084255255
0.007961850754301626
0.006605747926513771
0.00794490975946627
0.008459452810496319
0.007518868138582642
0.008640992142368171
0.00841506954990273
0.004887271387573388
0.008038374534397147
0.007546071123699094
0.004808526110661078
0.00531420848747943
0.00822906830580347
0.007887879592687524
0.006582209108004506
0.007658875868017582
0.008274744917340947
0.004946554214473847
0.006509107310709936
0.007448136136590433
0.007249036407051684
0.006431960289349328
0.006574554979501418
0.011033589346038153
0.006492376927594787
0.009232816225447879
0.004244427279267344
0.003055518222977869
0.006445059820675317
0.004904144065463837
0.0036335361492556076
0.004294723737142651
0.005508674738839579
0.004770105599837678
0.006875201415754647
0.0048990860195675025
0.004334790898545684
0.004686439241893857
0.0060969392123023155
0.004555683145143497
0.005591275781004202
0.00548297380335657
0.006301930395265496
0.007373551658121283
0.007578071078436288
0.005676013833048766
0.0055634296971351724
0.0052895072015426495
0.003901105262762823
0.006045913820034862
0.007126707867547651
0.005271371919980587
0.006682616195645343
0.00678930447695924
0.006590112932953171
0.007322416863034684
0.007479489558130932
0.004439510441692546
0.0057448427317622446
0.005672951733165643
0.0059516960997818315
0.007211783476698796
0.0076156959588027685
0.00722880313349022
0.008210364951380637
0.009181868085233476
0.008062667439192144
0.008933892426784532
0.008934358985074924
0.009991254279309851
0.008552863540272716
0.0068696176914372995
0.009797619316618671
0.0060534682533141685
0.00624591410430866
0.0049573956575087235
0.006679201264672394
0.004867011663401545
0.006908100631647796
0.007707583515527922
0.006220994309229811
0.006984562568198964
0.006975170866045788
0.005465151985291995
0.006734718295731072
0.007700264017698737
0.010776482176868347
0.011083595752363952
0.012880765393790747
0.011046392474238425
0.009506974810998955
0.00885762177536009
0.007791367394250867
0.008413925739420477
0.006896418565266037
