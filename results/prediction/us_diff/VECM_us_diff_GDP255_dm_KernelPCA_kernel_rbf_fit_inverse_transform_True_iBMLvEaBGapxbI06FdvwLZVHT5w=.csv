# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP255
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=15, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.003909469429500106
0.006940062234371217
0.001032170109449131
0.002212993370456256
-0.00018201019738111322
0.0024045492851899304
0.006524031582637784
0.00892194746848993
0.010582192418110547
0.009615050302470791
0.009638915335862426
0.007661728570993275
0.0039007501227956995
0.002117553477444398
0.004823986249542702
0.007208082524185214
0.007594153624040787
0.007059967230581299
0.009882204370029082
0.005493054110406325
0.007258575269758463
0.00935480887861473
0.0034034544298177545
0.004610992882210196
0.0040208146658348674
0.00647065288166065
0.002686892589859602
0.008501961242936536
0.005605066968594358
0.0070279268837469665
0.0038725542598253885
0.00023543088836835285
0.004945631235402974
0.0036115925582543736
0.007032871750485657
0.008892310097206833
0.007612235114911971
0.007965324482714005
0.003584300493632867
0.0017284948422768894
0.0024462368655557565
0.004548379059986787
0.00820817708271212
0.0067081712482784895
0.002318529364135828
0.0041919748428078385
0.001941729894310925
0.005030878319062412
0.008307826348654257
0.008712799797377005
0.008468042937673283
0.005506768981823034
0.005078711773279435
0.002937833429481107
0.004594101380784643
0.010159758446211259
0.007641827213831588
0.009474306767465182
0.01002876139661703
0.010678214036960012
0.009794396774025538
0.00553782313823647
0.01023297146183786
0.005570355697453018
0.009873101582088198
0.00831774283918595
0.0119336568906756
0.009988348242431111
0.010590049597898265
0.009998209852856616
0.009897626633100579
0.006148746120436979
0.0006580486466590098
0.010056354465071318
0.0077822120017409565
0.005122815222952206
0.0022854413958895625
0.00441179393788777
0.0006183269214881857
0.007946754579289776
0.0021978799237340604
0.008068434578951574
0.008923814985185137
0.0074461629595236715
0.007178128599445748
0.008816306029836574
0.006200089667887758
0.006997793554306316
0.006564517795061553
0.005747003466864184
0.008707958987568931
0.006304106228754989
0.008758203186813921
0.011711093567549841
0.007309093518351364
0.0067915531709044855
0.009730085546978483
0.006339093744359281
0.003781539112587423
0.006829732755943911
