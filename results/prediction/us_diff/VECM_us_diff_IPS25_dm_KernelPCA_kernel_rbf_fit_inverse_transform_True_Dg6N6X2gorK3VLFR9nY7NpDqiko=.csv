# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; IPS25
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=3, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.009765470445795978
0.008952707051285497
0.014273064360996198
0.00920358118191624
0.00856958591552344
0.007932582853000398
0.008662686029508239
0.003312825817637805
-0.0020943839770513335
0.0012133522132877382
0.00013748045144974834
-0.0026231421766877133
-0.0036404245238829424
-0.0038741420338132583
0.005925614087635071
0.007779317147236996
0.013642508848803546
0.014054089532983354
0.01256620124334054
0.011994109765231223
0.00863129966439142
0.007654596437931761
0.0038873476999105655
-0.0010581776826008654
-0.00025159228490028037
0.0013390451535144298
0.008583327348440408
0.008017962863333974
0.0035959173439600286
-0.008076760689485634
-0.0090821238923337
0.0043824313541887365
0.0074810985356020855
-0.0012888112676369683
0.0020972240054048055
0.008534503771298068
0.004383816620904575
0.005210960734061372
0.009368846404452557
0.0020929082242551345
0.002079354731827772
0.012051870263330502
0.008332070513884897
0.009865843074657547
0.010272438591080938
0.013375880515226384
0.010741386864485
0.005566815343082154
0.013369743768141311
0.00937362124736713
0.010040998470012268
0.018705749649292194
0.019216775372009463
0.018960131734867627
0.024310611546321727
0.027333182498198105
0.02883162580481025
0.030537299954047577
0.025877274293215503
0.017387034881762818
0.016416341190586953
0.01415073252085688
0.013530517775979762
0.012493729424668728
0.01528982334233342
0.012624251563979855
0.01835810712012287
0.02002328972906903
0.015293517353205234
0.007225109727796136
-0.005532835286979789
-0.0323153371000934
-0.03527759077675388
-0.038891917229142134
-0.003780716780780089
-0.008536733181403444
-0.005644680454878976
-0.01090453794504944
-0.006852162054648544
-0.0022928771548556496
0.00977286098653339
0.018728702842560056
0.012909154679357989
0.007947000939847427
0.013868452262856032
0.0075062824512080305
0.018700640639566068
0.015458105400905718
0.004367984580242056
0.027704755597983542
0.030799185158036237
0.02104066492806772
0.01824897195852771
0.013221155546332315
-0.004741507043781612
0.004635334814278644
0.016756377455331428
0.011608453567006731
0.007822945987771298
-0.011666573898216698
