# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; IPS306
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=11, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.011850679372978547
0.0016116267119324137
0.02811498599202036
-0.014672999401720871
0.017318891534385497
-0.029685142493944737
0.06151075364025027
-0.04079400699672667
-0.0009568245498869175
-0.03488689612340742
0.029842657358019782
-0.0686913096544413
0.031002946061060875
0.0035756338186533386
0.00043526739762962154
0.013330272735273957
0.0010076266722253528
0.05815797555762977
0.023406865473437427
0.003049897190486232
0.026924942765358888
0.012440651304467872
-0.026034383910979945
-0.0023764823318991844
0.01563789633069642
-0.01430804713145566
0.009328476152525368
-0.013945452640223049
-0.009613253987520259
-0.010640842153964044
0.07518551446973569
-0.017797067494868625
-0.005290689707791674
-0.019188588383493542
0.006858074506013397
0.018452318816229413
-0.005938682868831722
0.02625391995852816
0.020976055866050995
-0.04325498694266011
0.009833150160759257
0.008296556089420917
0.008049946503785597
0.012692848001003638
0.022289024350871843
0.028677245797669896
0.03850119781516909
-0.003585803566189257
0.01780187032579475
-0.024866378949834577
-0.039815723444308206
-0.0006137883655586984
0.03425711892916402
-0.036461755924163286
0.04646800256348306
0.017124382231518766
0.010462370611869972
-0.008479353820466886
0.0054711111788504265
-0.02634395587093089
-0.028602396906385216
0.0063720624236745125
-0.014978251956109231
0.016414865525033386
0.03272306641479244
0.034005963181331325
0.01702343404269349
0.0012037465932743605
-0.020813840109334847
0.019359158478148016
-0.014097803427827828
0.01861724308520533
0.0035408040997975945
-0.03700941551794742
0.01893170031154764
0.018091419460820567
0.026499587033325295
-0.006853185614124478
0.022658862939745013
-0.03532626604114001
-0.008280886856642284
0.020431223462606226
0.03831259853375965
0.03721546661619143
0.042289600125830815
-0.005346601405283582
0.02145363705066787
0.014109415385418093
-0.008421314946853446
-0.018106144265319292
0.026891595305479906
-0.01128400524723143
0.007736531507909544
0.03709217709708025
-0.03767014064727061
0.0050281220062440195
0.02454281658763255
-0.031154461453079693
0.015170385121797046
0.029327826272631113
