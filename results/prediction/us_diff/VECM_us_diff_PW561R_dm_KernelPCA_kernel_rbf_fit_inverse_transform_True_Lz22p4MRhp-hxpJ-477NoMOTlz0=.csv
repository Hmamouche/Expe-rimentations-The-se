# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; PW561R
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=11, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.028111345225165542
-0.11691478429473118
-0.014432543189101747
-0.014888501257627373
-0.03873431087328437
-0.03442388079328055
0.01226058446093923
-0.0010873497031202752
-0.013461336385737686
0.01294052352551502
-0.03804682673022461
-0.12941556208208657
-0.0022799693504420918
-0.04991557696724106
-0.01438127125883034
-0.021604049357340904
-0.027580729234320207
0.014052733377647779
-0.02895088062889601
0.021784531291053927
0.02186761754964628
-0.03768447942885318
0.04724529919559063
0.0008190887962329311
-0.015000969951104962
0.018103171684461548
0.009838024448111793
-0.05022652685533892
0.002770508059351787
0.03353200534617704
-0.014682313430181849
0.0776726909260207
0.030283644673655085
0.0013033147640469853
-0.1128296406402367
0.059435792438020045
-0.03894798097130257
0.010359155904882792
0.0031485873304011557
-0.027391838877166595
-0.05400302909752654
0.0284289058413412
0.008693930359996153
0.034043973968812986
-0.040884638256740255
-0.03335448932089641
0.015835486245396428
0.023330144894781125
-0.008590204989238546
-0.0008963056890104199
3.708956381591466e-05
0.022161421016988245
0.04128810415057762
-0.005154329946145224
-0.03937841317810807
-0.0010734738642103085
0.0030614220154794964
-0.04009777158002066
-0.030135445479991592
0.009719956204552556
-0.014367994871822469
0.0033391718508295086
0.0006502240988783964
0.024538453021664595
-0.0026635552976245046
-0.01314354611799979
0.0334166399041716
-0.03206145632474876
0.04005769814382001
-0.013047680173411777
-0.03476287688945405
0.035914122454583565
0.029004307017414584
-0.05436382982301611
0.012778254815113152
0.01684364904804661
-0.02140618915792457
-0.031161390564042973
0.04012467553800078
0.0028677436674204235
0.03863719947854122
-0.023873718984549035
0.027243797308329647
-0.013246154036367641
0.008122576052168113
0.00151733064124299
0.009625276886028659
0.03981317731616525
0.0690422067446699
-0.0002980365980788306
0.07985939892858289
0.0257126451260592
-0.009584711817240563
0.007785443617283665
0.013115209519386335
-0.04848292612884709
0.032049019053102694
0.040477019002029574
0.05255807543152413
0.2017782568056345
