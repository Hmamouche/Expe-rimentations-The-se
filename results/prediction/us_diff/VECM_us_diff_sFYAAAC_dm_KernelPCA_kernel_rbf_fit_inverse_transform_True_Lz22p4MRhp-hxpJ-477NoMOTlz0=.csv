# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; sFYAAAC
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=11, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.26477953652272795
-0.05866082381084957
-0.2794213501662082
-0.013537418792366779
-0.06377846264404208
-0.02872103249515226
-0.0017539924052284717
0.06691166979186408
0.016854922013498794
0.03239130921934754
0.05492506445143244
0.09931404846350307
0.09570082875209363
-0.016297877059780735
0.09098796393328246
-0.03356000233653193
-0.025233524100884322
0.01905159728319484
-0.08167487316327351
-0.09129627721239059
0.01912390695476869
-0.10481290620215061
-0.1084936337760315
0.07777222775578249
0.06060481552277628
-0.019177394264581045
-0.008558933346510589
0.05456670213987158
0.06262407588941409
0.02368067644960578
0.17195948177859957
0.06724343831210616
-0.25856142803572785
-0.03461897711631803
0.04409368741205964
0.02118056874230693
0.1310406867975019
0.01479367456709274
-0.008295921113009867
0.02756017781131684
-0.07788178675825044
-0.02686186399845525
0.0327302124850473
-0.008971267639318267
-0.06698944515646453
-0.06091461257993697
0.013091233154143067
-0.05413354664142764
0.009894961092666871
0.05663006934209512
0.058700782312542485
-0.016394531092177568
-0.052981904943937716
0.02030890800464859
-0.08817976336290057
0.013725838348914122
0.01531841988395266
-0.036125658935600206
0.027796644768651083
0.07610008656234965
0.01789206630192905
0.11334633177416946
-0.015217361684165228
0.0598825344689356
0.037598784408315176
-0.030010263020113694
-0.027782826646925687
0.042538600359085084
0.08052660061116648
-0.0020523547460255444
0.05236596996042467
0.011019300979266428
0.04403118173321488
0.07304760963435517
-0.11446720293867506
-0.04674085226085227
0.06190550254769393
0.02528093085443571
0.05561133536634855
-0.11363882160967635
-0.013700168055740987
-0.06864938811743668
-0.057885888238084174
-0.018929598359488813
-0.026930264456387687
0.004194164854327748
-0.03457439181919156
-0.02801544773993449
-0.07427325926617283
-0.02978429988984981
-0.0485014615378416
0.018609743383813798
-0.023692321604028316
0.009179947334392518
-0.01999791823527619
-0.05092385300241023
0.038135051132288614
0.10553581566297514
0.15584029097030785
0.0655398955319241
