# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP259
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=4, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.03374257944039815
-0.006301076695160536
0.01042177429984197
0.0426803842986995
0.020519291084450563
0.004558311564531498
0.04601205667725691
0.029010900118635594
-0.002436299046349329
0.012578139298755023
0.01284062652072605
-0.05481668379998918
-0.05824605897443429
-0.036824627116889684
-0.023861160571971025
0.00862486349058977
-0.008787248996925737
0.03505829682028341
-0.015381508521455953
0.0060361462114036715
-0.006843457602667329
-0.016051942736769555
0.006435440233066425
-0.009986238090188511
0.003399996202347647
0.00497395807996969
0.025848658716724947
0.011299541684161672
-0.0020191122420150243
-0.016411685733172386
-0.021554202009347937
-0.045230502134095116
-0.04695391964960409
-0.036266633269353185
-0.02942114590940805
-0.008656266221061394
-0.017240628640684836
0.009386958154765182
0.014021573944185638
-0.0024072122487977924
0.005041284767138393
0.010301216544077405
-0.018023808193291854
0.02357128977755084
0.01491689610808935
0.013160024771617332
0.0111277780663234
-0.004212992893203256
0.007359068492612314
0.014564458240128213
0.0020192012883398034
0.015412618256154843
0.02190117922366494
0.027598375620617156
0.02597561880222578
0.03206425171444447
0.027550003157830988
0.006220251349680458
0.015666506416903425
0.02529818029365418
0.0007055597066869294
0.006492854369075697
0.005467387643678684
0.0019353897652818483
-0.0002172894904044283
0.01071970730317516
0.012897542640226821
0.0138927959399324
0.017396986083015317
0.018012638253722114
0.006418540061240282
-0.009855699753035916
-0.019639033698135154
-0.06191309709209389
-0.03486137988681069
-0.04713591246129546
-0.07469164728628586
-0.04281793016300465
-0.02218981414061548
-0.009198905369660709
-0.0013261401912235855
0.019193444468140183
0.006550137255589049
0.010272925208665181
0.015396073018445384
0.005722245565991752
0.004213971924444406
0.00785746274155738
-0.006968709672072786
-0.003603374525706692
0.005422968194013454
0.020404140205276398
0.032078027362510725
0.01799097238949844
0.03342395355812797
0.03748452134542909
0.042405551274851655
0.028173725139332036
0.026212708924597525
0.04902612733696002
