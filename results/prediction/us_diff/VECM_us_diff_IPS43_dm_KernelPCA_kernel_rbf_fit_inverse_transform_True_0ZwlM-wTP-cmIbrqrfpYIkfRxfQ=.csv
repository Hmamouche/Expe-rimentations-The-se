# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; IPS43
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=13, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.00568489571981878
-0.007226720758695716
0.02227154329947762
-0.018198086104189406
-0.0028487690316170208
0.004574843764248034
0.011951782661126023
0.01800295310966692
0.009666820522079646
0.018043508862594253
0.021436616486147083
-0.00908718229698427
-0.01012168750620511
-0.0026870086779104906
0.003332058308685439
0.013419402234013436
0.012659622975937597
0.005013250840221197
0.011689124709598622
0.013815884046248767
0.015034137049261468
0.016619267677895715
-0.00710851106779692
-0.00020816928972396467
-0.00902862026646577
-0.002231662029766906
0.004305695761877329
0.004396820842076654
-0.003325498551104059
-0.004201455236035233
-0.005071584872062315
0.005193262223747204
0.008531925716504933
-0.002954210999907644
-0.0011044423376306027
0.005625867792665896
0.002317652363109748
0.016801371047305287
0.008275348215777408
0.002411590338623608
0.014184692257961084
0.008593266958309611
0.01707839903915857
0.0057825847644926145
0.01108880012435233
0.013268401959887108
0.007984989515274666
0.009320818248802409
0.0018734881995663023
0.002703371295526228
0.004465731401495225
0.01737063216600489
0.015361172291650215
0.01767072799731326
0.01839137941658494
0.017471988335223794
0.02315720894350342
0.018452135474235003
0.018981759348950127
0.01344369558254416
0.01106670701427729
0.006989271739052288
0.016774298827179533
0.01548930111525675
0.0196265886592754
0.022241925368968747
0.007118354782018366
0.01244694409497075
0.003657705062935654
0.004591624389522986
-0.007620319476071575
-0.007704864180497219
-0.018659869911073896
-0.022190528629522505
0.011423478766700936
0.010714811755507694
0.002253773833466848
-0.006039381049602197
-0.006977096470107065
0.01966358010690211
0.004137127180704804
0.016700804645616723
0.009477957110310272
0.005550544516024344
0.005729701055577936
0.005364682293480218
0.00506811231132288
0.005895184995665153
0.008783277203783453
0.014601129548758524
0.01287680331801187
0.004104745694668393
0.003966873350836927
0.004768159538872068
0.01647200970615552
0.0016365538022255436
0.006213182713711682
-0.009085552514963758
-0.008598299059327732
-0.0041429913323149025
