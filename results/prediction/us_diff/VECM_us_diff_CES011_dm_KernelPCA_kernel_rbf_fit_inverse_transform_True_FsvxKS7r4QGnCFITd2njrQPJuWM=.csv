# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CES011
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=2, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.01688649054226906
0.020544289340725094
0.016616836307135126
0.015583064562503782
0.014049878126911022
0.011424603688229028
0.019283670694119036
0.013491230813543491
0.012166926453537256
0.014438182862362606
0.0141354985622931
0.00853474424466928
0.003977953040378782
0.004553763538388787
0.013257528667392271
0.011752451750971733
0.010154319882320314
0.010931906005013887
0.0034624127291268385
0.00965676623661314
0.011346976929353648
0.004927903664115935
0.002324742944356482
0.0015470909002778246
-0.0021076336862865816
0.00019888398336667266
0.011285662278698561
-0.00255376743085292
-0.01489821464107776
-0.01862549792434041
-0.02656021088452882
-0.017773920613769457
-0.010673670934236365
-0.024338238235589477
-0.014618634661580086
-0.008463558912707989
-0.011255717813092099
4.1473366245792145e-05
0.007432757262982309
0.002999099273232156
0.009775639333629824
0.019538483413527315
0.0199478578286024
0.02345616813526645
0.018970072877821056
0.016526568952316016
0.006674199459438934
0.0005074006605930922
0.008901327276659009
0.01026738695411495
0.006351231332084419
0.019868308262580632
0.017880644150993122
0.014986883220802983
0.013956729166643226
0.017444330124450295
0.01648607266455335
0.012886197594501868
0.013736926173344927
0.01591243200097203
0.01753721246141078
0.01938234553110443
0.019949693593547268
0.024884396848432584
0.021032140743400134
0.019591748153638976
0.019704865042473995
0.007496009643560383
0.0021913609803205464
0.0032496686552285427
0.0027368866474596796
0.0009264471500811217
-0.0007294098155729905
-0.008450157583005548
0.0024038793195953994
-0.0063111669799395635
-0.005951638711306681
-0.00790610266587407
-0.0031242233624295406
-0.0011208803885655173
0.01370162797366956
0.012253062225478839
0.011637699860816813
0.01341057284928366
0.013212747240042804
0.013380175530142315
0.01408282959870709
0.02020609746717582
0.020275394718996212
0.024047639719561816
0.02771031944591691
0.015148786537578143
0.003339255916042036
0.004735811127841864
0.0036086554123381416
0.0005589901469668673
-0.009986777020551405
-0.01549976808419998
-0.018498909163364503
-0.024589544264554963
