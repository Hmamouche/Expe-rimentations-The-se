# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP276_1
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=3, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.006457535600135782
0.0040155114289964974
0.006307440898723901
0.007304581830421736
0.0068823883370804535
0.007721523773131752
0.007775120822168374
0.008152699858804737
0.007646713055549024
0.008081321355490455
0.00883059637125145
0.00859349904757686
0.005370345736182839
0.0075614500967554725
0.0068483830433367955
0.00564442391080365
0.005410589420402355
0.007986099663740635
0.007925725261204858
0.00573766450083713
0.0073993513704348575
0.007140058501062142
0.004841108357489115
0.006734321643477646
0.007425177319055996
0.007549641659868022
0.00646005473229541
0.008228025658312623
0.00974990160696284
0.004774534856617926
0.0077381873287596685
0.006023828729561479
0.0021144020353813463
0.005442895513660821
0.0046436941555059955
0.00515604078539805
0.004562320618684355
0.004875967342871557
0.004473936715590187
0.00576924441112947
0.004262105024065527
0.005448350287265823
0.00557321184232603
0.005152286038278352
0.004986003974604209
0.005812720352791688
0.005326537681460653
0.006498623837057799
0.006295577740776163
0.006844372439030621
0.005974403417738027
0.00598225976984597
0.005870757100626449
0.005379184702329008
0.005650409139394878
0.006282233704017968
0.0059000042875061
0.006551436771615811
0.006417918249077271
0.007093826105669755
0.006609616625224008
0.007614846583302134
0.005359194582202974
0.00639359928987219
0.005522790079443333
0.005374334337236255
0.00744484630365606
0.0066681291672586645
0.0074911897282636565
0.008055484015851617
0.007923769182242657
0.009194497773162972
0.009219763663420963
0.009504636963756682
0.009696843249451394
0.008773349025935006
0.007871941895017111
0.007738117671417526
0.0067343455757234135
0.004937034115287536
0.005978918993975804
0.005918689181808
0.005282988022121385
0.007615778708556078
0.006616684541961694
0.00652794925104605
0.007291102369384618
0.006179551766186882
0.006011708256073072
0.007167276984046925
0.007746723003589567
0.01090094854649093
0.01104249150235194
0.01224816329752457
0.010393441305871486
0.009512716351506056
0.008745857334885046
0.00855457087551532
0.008300763258515224
0.006735892655770917
