# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CES033
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=13, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.026231048338814903
0.025269211496906863
0.03487663200725533
-0.0321533290251609
-0.019952632033489036
-0.018189345136947865
-0.013859313252592782
0.00891487846518248
0.017400205772942184
0.02017030725545277
0.02779779181880018
-0.02913866781195925
-0.024752402604170554
-0.005664101949104019
0.01729459339753029
0.021411648431079316
-0.005314304698723212
0.004770162378224911
-0.00048495121748758
0.017177150221707196
0.022951699983056968
0.01286790555983499
-0.008273286911517398
-0.01654192118687744
-0.012903876412683632
0.008141874491867993
0.008780000583923243
-0.003009640839718355
-0.013528986763712449
-0.03234238026755979
-0.03034108419312935
0.019470190607768622
0.01105974735412186
0.013558313485490631
-0.022143017430627573
-0.00017749913363574452
-0.0021261122038495842
0.008906137811793877
0.018384746926846447
0.003757989739748828
0.010393716614270028
-0.0013256084131527033
0.024659362852905535
-0.0026866938669822746
0.008439108999237041
0.002298731172723173
-0.008770954753439357
-0.012256831278568827
-0.014479176117489886
-0.03197306303833218
-0.016785316465758995
-0.0016134555549865938
-0.0002055034082122521
0.010165157430621642
0.007554207125812783
-0.010291614526734723
-0.0032404750108620886
-0.006390259133550841
-0.005439295906840006
-0.015931691179011883
-0.02747355178376213
-0.026555914390936332
-0.003143679253800414
-0.014743175454509188
0.0062373182396366755
-0.009077977606679388
-0.018956290810965525
-0.02149545109212458
-0.022574642661630763
-0.02128809160569754
-0.039092053886273535
-0.05684040193530003
-0.038869650435609984
-0.03716569182484676
-0.0013840089991699403
-0.00943811040775314
-0.027972742074793767
-0.03891792859644092
-0.022486359911106
-0.022312350071222217
-0.026531607603002452
-0.011971112995392198
-0.015219505279132501
-0.0180663160691329
-0.012630147630713915
-0.020625031422680195
-0.04270059593519743
-0.00810444343117694
-0.010962714546148373
-0.010229090203892816
-0.012175225934142676
-0.006496177803141705
-0.022913185778008126
-0.008815365787567758
0.009759253908555568
-0.03080709492651073
-0.012213868883045598
-0.03243188998154721
-0.019129606408219202
-0.013443579974290855
