# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP254
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=6, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.002148160982709076
0.008847331125449099
0.0074632637628171995
0.0037879736773670175
0.0031881288108274544
0.005453120910942399
0.005137754902275753
0.0034487755631651615
0.005541574790986024
0.006962493836963383
0.009560521381954575
0.00679715057480728
-0.0028003628444472225
0.007280315481224451
0.007792681007098567
0.006297214611860839
0.0007496068910783957
0.0024707005118573926
0.004605539844230715
0.007948985371784968
0.005956558569314324
0.008209482947091819
0.002394506014603318
0.0006941202729624165
0.006752513837813096
0.005770133612832046
0.005701179509312447
0.002270063434238341
0.0003001540902807941
-0.0010854610193136247
0.009290193711646716
-0.0017485408777938739
0.00048077500285239943
-0.0018621281698010831
0.0051299483131409685
0.002469514184396606
0.000705962825453202
0.009897150912226805
0.006727785475439315
0.008304729817847977
0.0073473834629102
0.008596327825638312
0.003212323534252223
-0.0009158935792091358
0.005080466927206575
0.009307143768329432
0.006038831355391523
0.00322159502998707
0.006067530576679494
0.005895607747095733
0.003293743347946004
0.006189334030908733
0.008717643565542455
0.0059892475931761615
0.002538535619833234
0.00679863686942924
0.004359071795713366
0.005318288200112924
0.011552502745346303
0.00710743062363234
0.009776248419047999
0.011333211538545617
0.012664681682329969
0.007628923612945918
0.007892072388045596
0.012234617612505237
0.010152350922880578
0.011432775752972232
0.007277268334948513
0.008712618589066223
0.00903868091433069
0.007810932959366451
0.0007659818455444703
0.0056114644948801725
0.009961736071256631
0.006259478384334825
0.00890719585229764
0.005153453322336371
0.00257390053161815
0.015718100568579686
0.007521475201848704
0.014212868132279923
0.009742926044298826
0.007112021706770482
0.011808711274644642
0.007187667992431432
0.011715087922173024
0.011939511743738654
0.007462045499338157
0.010945808004917757
0.016920268031757144
0.004247643293793005
0.011849080947668986
0.01451461666267166
0.004605555016466391
0.008551744804339262
0.011815388311909284
0.0011479146329297291
0.0031047026083854744
0.003793478258132962
