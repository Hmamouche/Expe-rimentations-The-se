# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; HSFR
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=9, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.08112639190596593
0.048624647962818845
-0.04656670348956632
-0.15865433415539565
-0.060271131388498315
0.08749931417057626
0.01709806485834172
0.039266052734957445
0.004951302614745155
-0.02383150403187835
0.048748030955058405
0.06337149297551681
-0.06261016460312462
0.018274198647029255
-0.10407456259225169
-0.06312724630297535
0.09940955477119598
-0.03577196641461917
0.005295550651153132
-0.11461669130469276
-0.018871507257922707
0.03952538892096507
-0.0645021774296109
-0.016213956380946786
-0.0342725032726888
0.06565676384838837
0.002465800203939661
-0.056702839495899895
-0.027004580333285354
-0.020551034068818894
-0.021593553845048262
0.0455074593164072
0.07212800075846831
-0.013638330409328839
-0.06636802204866724
0.03526006028247802
-0.013105874435401732
-0.005149949546032276
0.07362535544973066
-0.0979819479047836
0.06751171921846097
0.05455041007767548
0.001957498981217543
-0.05759409506852661
0.11032749149158272
-0.10312092429274813
0.05801119408231513
-0.015633643344971145
0.03562218394252393
0.03462148519056194
-0.028650254072608957
0.04592926766217931
0.019747174805172803
-0.034654937577170364
0.04769951849136158
-0.021353849959351544
0.033751056989366715
0.003315442551175461
0.0026554528492978846
-0.012752008542292484
0.02489591839637179
0.0350869081802379
0.01907138018166986
-0.006277111332502558
0.00585058190190452
-0.002440663787001987
-0.06941987957337634
0.013950466712773724
-0.028247247767493648
0.046592749146272955
0.018721154152715476
-0.0022337897539602067
0.03490445558439649
-0.006658398163371066
0.11700354639325113
0.0560365603195542
-0.08401257377167579
0.0072090558014916515
-0.06392056066035448
0.0024835866333226455
0.07849695702881204
0.053048699226113036
0.0386825299807362
-0.030528439594961418
-0.017559318362701495
-0.04122617701496139
-0.0106834364226682
0.03489484961680585
0.013836550361492552
-0.021191810541594455
0.008516385898158282
-0.019272280937300316
-0.03766691664422123
-0.012540150284541206
-0.02263324011955487
-0.0339758986304167
-0.06968289500839218
-0.17353053131402268
-0.020061203398979262
-0.07804754909341022
