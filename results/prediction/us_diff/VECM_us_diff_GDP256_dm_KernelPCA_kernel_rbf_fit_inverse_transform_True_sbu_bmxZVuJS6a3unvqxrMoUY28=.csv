# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP256
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=1, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.024437761469542633
0.01211281845922919
0.0023483600702167776
0.022188854507753913
0.007132217316667233
0.0006060229365322056
0.0013268810367846073
-0.01218733952305177
-0.0009000838120478598
0.004415386419424484
0.0068066890131211295
0.007922161187352358
0.0045246316533348
-0.0022595809275366414
0.007882026693438921
0.012719465308869556
0.01375820680356328
-0.0049797612438192106
0.01130717500515076
0.010427807193399193
0.0007384106774426562
0.0032287112545882728
-0.00772620459759644
-0.006283412057409349
-0.0077272814599350335
0.00014495854406391755
0.004704554993535465
-0.001976608436246189
-0.006013626020789949
-0.007599216023284256
-0.018168550797160763
0.001727715503671576
0.010262322964236351
-0.012077146952385615
0.014426463863811159
0.0054419550612468375
-0.00045038207622385973
0.006124390551609527
0.012349229782383158
0.0037631127782701687
0.008134276368336713
0.011872613882116384
0.013539388944816006
0.021089709742621057
0.026437555314073977
0.012777036833857489
0.0010957704282918241
-0.006308504123120336
0.0006508111891521241
-0.011994456662564894
-0.003937894831782973
0.02137900924459287
0.019931804587091585
0.02883577090616785
0.01747908943923027
0.009945267174591314
0.028004346331850446
0.024667826087072228
0.011149667998262842
0.02264379779798371
0.009791161028528311
0.00712184410812209
0.027139187691657837
0.029761249052203908
0.018623769687597942
0.017996729289469545
0.02409078530349144
-0.011643608168289497
0.01808008538103147
0.013108230825779658
-0.00644507823923782
-0.012765712986066081
-0.015170406404773195
-0.025959708391671412
-0.01834122591378576
-0.00805346156483397
-0.015728625362520492
-0.001704726894122169
0.005381453696446301
0.0021855663991181243
0.009961730973637586
0.035947198735057175
0.030672860351788542
0.005946080168971266
0.011576703411823994
0.020264123237687153
0.021889726212386468
0.019487280819867787
0.015894276282188386
0.008002006691834797
0.01286102481486136
0.011456571481467979
0.008030434525959591
-0.00045678415138629674
-0.016931840425052108
-0.019446327003514507
-0.024290315227525568
-0.00864630242331855
-0.013597062396887908
-0.011447400756911242
