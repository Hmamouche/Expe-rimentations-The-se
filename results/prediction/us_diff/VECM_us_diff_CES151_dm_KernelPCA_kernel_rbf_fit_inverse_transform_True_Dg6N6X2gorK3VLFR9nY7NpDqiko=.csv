# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CES151
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=3, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.03407312693586371
0.01715613512299345
-0.03749962420362997
-0.03465365866836203
-0.08369831984445592
0.0031618976564009166
0.09259184081417307
-0.03544422570278395
0.004615250109442227
0.08968063458048249
0.0999483158299666
0.06988869835827832
-0.04497426007324274
-0.05302839162071975
-0.008910056607309156
0.08428367101605487
0.060717842419350326
-0.005413566729168245
-0.07956320222039495
-0.03338675302323936
0.014119140050292626
0.035485392726412546
-0.007246167021149786
-0.06973684661340276
-0.05770355119145095
0.037846478877152
0.08412396061831613
0.04506762023077614
-0.044064525287262686
-0.08258929398266936
-0.042260914606492624
0.04152286760706517
0.08972533288064378
-0.01319756255311241
0.005813666487485582
0.05448233804821944
0.018719534751893543
0.045561077785866405
0.018412383207940246
-0.0501017702485351
0.001588269035401697
0.10519864420448063
0.10690075542300026
0.00634382668048835
-0.0489705959042383
0.01664269662253767
0.013914666908958186
-0.008754406156358467
-0.039892127571399726
-0.04086462356711165
0.006470622934631853
-0.01935639579822935
-0.03371153141663203
0.031872871258377025
0.03825162279634399
0.05019597670293258
0.030242941450841037
0.019020249457036984
-0.030664245549604074
-0.009570104629334518
-0.06004125368318413
-0.04416741892295323
0.05769296700410991
0.024672461679326334
-0.012413113208392508
-0.005603443846476652
-0.056634166878690884
-0.033610194829245724
-0.02500139944989791
-0.027641402178812755
-0.03937605096001334
-0.04730493775183425
-0.020746820078803595
-0.04873673128787548
0.04078815894680038
0.038502915901710934
-0.03518096504879648
-0.037762546994152484
-0.06244240762339953
-0.0071797797065640025
0.029496827185027184
0.04671073006946801
-0.007633996814763488
-0.012355005343251813
-0.04364179032911006
-0.024454767102255297
-0.002389889752415955
-0.06943929357848352
0.00843838098009936
0.013845972934107569
0.004788451456961509
0.03845989613996907
0.024542605300002743
0.015289120656487114
0.1045753388270027
0.06457487014823302
-0.012490216190814741
-0.027335399524656696
-0.02442777292479218
0.06647491509878087
