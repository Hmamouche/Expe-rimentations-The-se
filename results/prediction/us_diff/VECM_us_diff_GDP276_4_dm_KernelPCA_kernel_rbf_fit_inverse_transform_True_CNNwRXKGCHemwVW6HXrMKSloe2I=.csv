# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP276_4
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=8, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.012504357898114986
0.005586673083001388
0.01621143171591489
0.010662139577516948
0.011161316558264661
0.007317711337503777
0.00433125513455903
0.005688389832772288
0.013376429677039989
0.01257200735824343
0.010303598820037289
0.006425844844516699
0.007109850985199432
0.004153576856557268
-0.0008184624520559987
0.0023037130782501986
0.0017481072985801583
0.0026220220635623445
0.0020363530363201945
-0.0004072621788863643
0.011544864059927652
0.002090853413200439
0.00715419758314063
0.003878941780052837
0.0037225035679541362
0.0022754869785348566
0.004924521311350782
0.004373461700726952
0.0060015942054800694
0.006385390729578909
0.006200784759044252
0.002126765876817551
0.019622712989605974
0.010143411510548863
0.005681922163322465
0.0029214231992264793
0.002676044161151795
0.005106876162819295
0.007310476370391411
0.006677032930976176
0.006839211229258386
0.007205099421677519
0.004162584324327236
0.009156263598906745
0.008347371492283956
0.0071728181740590225
0.006195595398702461
0.004763872153396284
0.0008348119818827595
0.0013991324279584334
0.0004782310277667997
0.007385875131439006
0.006037818732088139
0.0039109797375532435
0.008090927474031472
0.0012648822382625895
0.003374463904303606
-7.279439865389564e-07
-0.000606905834862114
0.0014835207812180877
0.0018217628397822253
0.004346297084043493
0.0001681499953846955
-0.0014395950010544956
0.0010743896776001986
0.002589778512125623
0.0028549478541625003
-0.0057965378677966245
-0.0009199032785484745
-0.00046852737373332374
0.0012281788845573856
0.0012976828458679697
0.0012404897149441718
0.006447347814190586
0.0059830392155610515
0.0050768584379704655
0.009654140406538635
0.005719767964670095
0.0052623227032700766
0.0042708154906476005
-0.0023135589180217305
0.00784801802629444
-0.0009529195651097099
0.0037670677047758607
0.0022621531550058084
0.0016960042814975292
0.003972598255527659
0.005175269014870034
0.005077339412403706
0.007675286631082899
0.00815808376916995
0.004386222900264468
0.00921219121514649
0.0058829287372854444
0.008970138534664123
0.012077788756076225
0.00766126165125765
0.0076902255992379424
0.007601223901807074
0.009500622594135163
