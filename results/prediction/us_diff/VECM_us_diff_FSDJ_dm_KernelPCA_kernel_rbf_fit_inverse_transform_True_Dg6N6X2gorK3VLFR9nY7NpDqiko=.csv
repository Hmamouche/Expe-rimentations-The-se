# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; FSDJ
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=3, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0008003669195532572
-0.002409754523941459
-0.00197822855237922
-0.006875757022431956
-0.0008533066004977159
0.0032923567574891966
0.002685759445368973
0.005577776475725891
0.0032855683003971997
0.006133582208596571
0.010457710745231988
0.00925136648179169
0.0024533932817971528
0.008854848108830148
0.015382323582427804
-0.00014816059069523062
0.008573303283686108
0.01488351537412721
0.0003943381044738646
0.028349713736061113
-0.004465955072239627
-0.020948723297424112
0.00423783157106098
0.0077207915737500035
0.012051949949643719
0.011201073937189283
0.00788784569858354
0.009999371930896927
0.0040582152994121205
-0.00029402689030245445
0.009576129633822159
0.004148416345654235
0.0005789486165981761
0.003710309295751403
0.009619413482377631
0.004965580871916453
0.0038575795911178546
0.007101614971171148
0.006107470216148844
0.0038016407595509363
0.002743494559860932
0.006714616693185019
0.006168520431254434
-0.006363443239114313
0.00147417799968651
0.001550649537968571
0.0009381410273084606
0.015711599071842004
0.01941825128451592
0.01975687944552737
0.02698094977056731
0.017970519986707668
0.01564679442313068
0.02406228780395334
0.02359733028540414
0.025690865171945222
0.044410190751479756
0.035185739680179455
0.04197387184328369
0.022290698591860517
0.046227744720143835
0.03558690494431818
-0.01139011332464064
0.029104188795363944
-0.0012314614837397007
0.046330847136269865
0.048449876781921676
0.031947735726604615
0.011516552063350265
-0.004916946707121709
0.00560940376416014
-0.0015910462799018288
-0.019867377882133445
-0.008933502356116422
-0.013019182480912769
-0.013377397365757255
-0.03391879201490436
0.012217664942605804
-0.044514850004387305
-0.023845645436875375
-0.0379387042532752
0.02106685316798135
0.03286776323106535
0.015114540178428372
0.019850796129916644
0.023013050736302228
0.018783690333984124
-0.006032297751004545
0.012004684649668262
0.0007595062227172603
0.01664212150067631
0.006075044175091113
0.011869211379647079
0.04062392410873949
0.029913336432644128
0.0414768127710312
0.025671687910542314
0.0348593564585382
-0.020176974953915613
0.01219713907120656
