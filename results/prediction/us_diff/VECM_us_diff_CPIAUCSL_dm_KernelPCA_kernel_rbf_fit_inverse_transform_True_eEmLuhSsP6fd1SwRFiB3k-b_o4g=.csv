# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CPIAUCSL
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=4, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0017472777278222332
0.0046003112894748704
0.007973027137194406
0.006905279692295055
0.006691968147974811
0.004001330341140318
0.004673950999268289
0.004911526162330453
0.004253259486384136
0.005481533800634335
0.0021354875094835818
-0.0010042711471708607
0.003179783479778666
-9.22230546993605e-06
0.008268266046570183
0.004366430074252481
0.007235537556414235
0.006543716884955368
0.005423887278181579
0.007838204277364768
0.006706127142641197
0.007636318623772432
0.007749540990772903
0.009356487623022375
0.0061461572602712665
0.007525970600655141
0.007751866372114555
0.007633822556720864
0.011686492292763933
0.009256421624420879
0.008883599669348848
0.004726345182852142
0.005278976617216212
0.006665719536266783
0.005162135088783631
0.005590130312242282
0.005681266143225174
0.007373654254476015
0.005516596141478523
0.004921275284625893
0.0030197686876740704
0.005109723987825145
0.004556400263482385
0.007780471922717205
0.0055885036676733965
0.005583492736609959
0.007039241254263404
0.005113502392349512
0.005556340386550064
0.004019838293301747
0.005216810605984718
0.007025689735600944
0.005358428866667875
0.007778974644506271
0.005605374061676261
0.004660264004403018
0.0037395809817980215
0.0037466154545296483
0.003357428077838423
0.003019729604598801
0.0026792619505330083
0.0035622893977701703
0.004529306190834736
0.00583144077388466
0.005702437821311904
0.007513200626541326
0.007515390203344812
0.00699481416419668
0.009667088588809457
0.00592750119297232
0.00731003137157219
0.00519040136163642
0.005217997373709046
0.0011334890139201405
0.0038964576740266594
0.0034591072160088726
0.005788198386183597
0.006780620384221248
0.007046701259225374
0.001256216952069073
0.007216413097342978
0.001110932695133699
0.00915186125319807
0.007287484788870339
0.007827286288335893
0.00823694398104839
0.007058746680799463
0.0077065495734467675
0.009007222473978525
0.011101919274605009
0.010638471414863224
0.009504935852078506
0.00910968237730751
0.0035342720681962063
0.007013739542453875
0.0032479705201978824
0.00886517005204102
0.012055602172298598
0.010103771404759255
0.014258843422125292
