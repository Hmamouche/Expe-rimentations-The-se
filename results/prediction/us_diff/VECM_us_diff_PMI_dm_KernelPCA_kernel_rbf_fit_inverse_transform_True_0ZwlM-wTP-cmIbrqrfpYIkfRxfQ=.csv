# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; PMI
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=13, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.24664146674282275
0.0773509880474399
-0.038438659091200936
-0.31107829845109347
-0.15709804409110495
0.03467304634703533
-0.07601279197011994
0.2728700815162347
-0.04470281485391591
0.33308851308529897
0.32627185112297336
-0.0214726738451977
-0.1769280248989978
-0.10798095514761594
0.007101016202615523
-0.0029246213135727395
-0.009254332160691194
-0.042759160869979815
-0.027016380381046867
-0.022104809494902157
0.15699067610654904
0.14657942020524395
-0.16586376227475486
-0.024108205949772615
-0.04275061774567516
-0.030534001606717962
0.011923415055256029
0.00037485400946355926
-0.14020663086743018
0.06631823863119132
0.10516013254013662
0.13648964550213388
-0.01845634224904634
-0.03331628706248127
0.04013869958669614
0.007164652458269508
0.06111711093823038
0.04074521756817488
-0.14810325056661544
-0.08753022813915969
0.10719760371400458
-0.007206057760098037
0.08613621625879961
-0.1591279522481885
0.09546479373582263
-0.028687844427314424
-0.15870774069874194
0.13939445833527314
-0.008181063473962722
-0.030922339730536468
-0.05686920760040366
-0.03720379010633302
0.008761056895087917
0.07488810057698081
0.04873349582024644
0.00418280237298599
0.013186106831517115
-0.04476172944579569
0.06197355648218249
-0.07318963226279077
-0.030930604826496063
-0.11753231155274696
0.060355322395963154
0.0615612876719274
0.07504767148912901
0.03546141251586403
-0.03639553330711599
0.011956321153219818
-0.10451606552423874
0.017508272783953137
-0.030068126740772607
0.05453246959521724
-0.001232465815825711
0.0727986788405555
0.22248316249881248
-0.03301543989258758
-0.04247357750645019
0.010932544822405604
-0.1141044778353388
0.1290054309045715
-0.020127289219491366
-0.0793147530725486
0.04573158458248444
0.012131319786781475
0.006635850958532665
-0.09640486917295191
-0.08428171613231102
0.021442620061796265
-0.039098309068223015
-0.07931649620964902
0.06517950643650172
-0.017905207946255823
-0.07684332647953115
0.0751813180925936
0.01839753900224858
-0.08382331882828332
0.05523235859865195
-0.03841656844855572
-0.0011516982802832303
-0.022102483698271527
