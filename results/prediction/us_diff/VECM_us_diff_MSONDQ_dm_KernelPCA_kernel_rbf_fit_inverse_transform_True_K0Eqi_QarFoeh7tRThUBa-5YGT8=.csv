# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; MSONDQ
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=6, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.01531512847980046
-0.012158217346972144
0.01323816805942414
0.054146210158108
-0.0010602938267906172
0.003627807707729915
-0.02494906972975066
0.02944909276844076
0.0032500362276182615
1.770352100328998e-05
0.025329651804998188
0.013224072622352714
-0.04246852417058955
-0.04502727719129334
-0.006918639578060364
0.01423996065671745
0.007996580393081602
0.025142689659312618
-0.010376770536539955
0.06358839528126355
-0.008358503419549874
0.05872777971843117
0.0008146789962376116
0.008120049965427768
-0.005091241648475535
-0.019988696822883623
0.02861053858196177
0.01030911009658472
-0.045299204431993145
-0.023141375405101264
0.0015378556874478082
0.016293589948781967
-0.02868865791150105
-0.027023001225778435
0.01461173681200455
0.020802129967824132
0.008920490193226677
-0.007575632337832067
-0.010375106777568234
-0.005224618902781319
0.012323113526089271
0.027439964015970226
0.02941687066250737
0.017753345992797587
0.0020970184852719728
0.026375350953629275
-0.0049932118572347355
-0.026701103796797312
0.012208521678917146
0.019066425604977996
0.06090490345355431
0.05900341168700349
0.006413023777267494
-0.00456082558864997
-0.011107275254211022
0.020011002396873683
0.03152207611194294
0.06296218565959691
0.06379952686351444
0.026498571724384117
-0.0070637158338481346
0.008648506311298751
-0.024079709147399462
0.0006511161059249179
-0.009902925165164738
0.04152932622883141
0.02830860594250111
0.005405554617600205
-0.010026445878637227
0.0219545354109853
0.024834268598825912
-0.022851969115691234
-0.05541972401529893
-0.08844469293395316
-0.07886932158101537
-0.03180433884927493
-0.02999313544259668
-0.014142292805097458
-0.0064924669512569175
-0.021746714794664775
0.035671117115914454
0.03478553522946862
0.04540488811308755
0.0012782258225321882
-0.017904287749213165
0.008304833891531777
0.004272479229870651
-4.1942515285539606e-08
0.04346584903964393
0.040580452229173274
0.06737925752743072
0.04278658683447442
-0.040642348299369795
0.001109277893386714
0.031205245842311526
0.020092427067531168
-0.009887918924952364
0.032081495490074115
-0.004236502716469455
-0.014437490754899904
