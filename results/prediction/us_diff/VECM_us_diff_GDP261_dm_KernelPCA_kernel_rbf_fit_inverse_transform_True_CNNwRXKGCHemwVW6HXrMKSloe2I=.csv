# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP261
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=8, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.010527803049040985
0.0008466541878022656
0.03871517923915413
-0.03621994224980473
-0.023599594714496047
-0.0021561542916508384
0.048109277215774085
0.030734152945443443
0.007422152131216121
0.005738265467965252
0.02573545081791136
0.025063821698475087
-0.006935089774458708
0.01040069300779482
0.015911627347681593
-0.0034497822465115614
0.006699870967568478
-0.024809421149524846
0.0058433099717498434
0.005898842099890079
0.016684761458169443
0.021618756960017197
-0.021124589337898583
-0.022380355132072496
-0.009844115207748728
0.006391053321409921
0.007945550909481229
-0.026535725044564494
-0.038311672576548376
-0.058715647101459
0.011885721544075356
0.006679622275783788
0.018062315264281273
0.009114404456168396
0.0005199199336695694
0.017444433242220173
0.006076655200291515
0.02399780170072188
0.008500093781495419
0.0024856337932491505
0.02211133031627232
0.03913306036362611
0.028911912907964174
-0.00843153010959738
0.013130250225946133
0.004545785380757692
-0.006286311878365897
-0.005753968253141832
0.010372260499140973
0.00813424281833446
0.01369495207273033
0.00836417402832354
0.006083075050071215
0.008120928097830911
0.009401051234916849
0.010054385860029571
0.01836657982833727
0.0047070209223791
0.011837601046454437
0.006661231627070117
0.01659286921699477
0.022359325098372407
0.02163258890388303
-0.004314470952556445
0.007063206102216177
0.008808306749714319
0.01110267840060438
-0.00705725413927334
-0.005523177986174294
0.0005187844160078566
0.0148185492907899
0.014485932008240273
-0.016106675436763813
-0.0037433153911597353
0.04571825499167234
0.019933095606862395
-0.009503506635816557
0.013047377307745873
0.0034004602972336007
0.031664962653788355
0.02572477172804717
0.05222578747655647
0.03358744617563472
-0.00462350399056936
0.018259976785860572
0.017226894710935973
0.02077176464231853
0.01916745748484945
0.021486160511279963
0.0038667784230988376
0.0174405998276404
-0.045353616142133506
-0.054262411688681775
-0.04394669567539782
-0.04519923512365026
-0.03582737699106522
-0.06001590605605617
-0.0872069031126515
-0.05383473673504919
-0.04781109497090375
