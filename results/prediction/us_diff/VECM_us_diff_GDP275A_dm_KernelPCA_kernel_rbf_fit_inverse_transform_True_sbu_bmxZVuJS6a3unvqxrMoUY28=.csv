# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP275A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=1, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.004931620670853625
0.004745026759772953
0.007788739262843062
0.003942277866681235
0.0038824067523300365
0.0020193829349147542
0.003357035472050409
0.00448698259030449
0.0030027013097821886
0.004635307777497506
0.0004521958464490794
-0.008663014346045161
-0.003252665252064712
-0.004163971188645579
0.009975834584175806
0.007523623637419493
0.007128096036120889
0.005943610619172121
0.004972937136566496
0.0073957107291886355
0.008935680187680702
0.00626060648846648
0.007616571606019649
0.013069970599264489
0.007231269328179272
0.006837885968299614
0.010640637097539839
0.007345946888863543
0.011847120866096659
0.011619567657083753
0.010851231837805543
0.007502469750024048
-0.00014747415599897142
0.004956252656611109
0.0010844077819710056
0.005548033603912715
0.0031891474749286934
0.003468393968495645
0.004594602453351251
0.0003892116952308168
-5.1085681176262616e-05
0.002631344041337311
-0.0003391375937506812
0.0024447290618161
0.0029367924815142713
0.0039712547167459564
0.0027544872897378595
9.271652830888846e-05
0.0031953040108938283
0.0027483210530205937
0.0028846343868961805
0.006381105455085522
0.0041654279318694976
0.005503620542562194
0.0032403587295488775
0.004964784767475984
0.0008371228105285329
0.0009209980684256446
-0.0009705432797259449
-0.0005914000624744714
-5.811541018915973e-05
0.0023143277791148344
0.0036501320280497513
0.006904586980808365
0.007383008518844688
0.01048227173149885
0.009811842026061472
0.00847368278419121
0.009987169403287182
0.005402323167528408
0.004656408505422262
0.005378361695505511
0.0017978383333534986
-0.003505191486689165
-0.0030104386258379755
0.004173057052571992
0.001067561992635959
0.0063976383634038216
0.00770556930184436
-0.0011142415276176902
0.01109128310368488
-0.0022108709115336426
0.010075787232634368
0.007900640201047786
0.010685459685190336
0.011181851166556761
0.005603328929724383
0.00866405734579076
0.012799420262235071
0.011802529613537435
0.014342969687181378
0.00507264840626189
0.01043590895804205
0.002095819202468936
0.007932668072734577
-0.0030432555436566825
0.01178031385459613
0.016144010649836695
0.013441400384045052
0.021744735777493758
