# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP252
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=13, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0032253864133822306
0.007254033469944269
0.01531661426238287
0.001162194454554944
-0.00016893539592164383
0.0037534658087021895
0.005743045259354174
0.008516053401858098
0.01204865380999464
0.010888338634100395
0.015287575915249468
0.00956163784540534
0.0067141159880943916
0.0008720395047284064
0.000736860711737462
0.004144584973608054
0.002531657662285105
0.007570690058494435
0.005810425725055221
0.006773169161972258
0.006937899380051869
0.013997164295125219
-0.001148796866006497
-0.0007431017435360749
0.004558076335488001
0.004198471960154503
-0.0005081856557913812
0.005515358365372495
-0.001690100276793213
-0.004241889732613972
0.009322951133433083
0.00708036867069986
0.004818336874073759
-0.0027419444157636957
0.004169264143887086
0.00399153627901223
0.0025431735270008836
0.010153060787017373
0.007380966807651283
-0.001153257259352157
0.010452641059022357
0.00750229037577661
0.011093114539187293
0.00011403182161707289
0.0051223621939928896
0.008376321661018513
0.006043296613497248
0.005813581338868687
0.00903519397312185
0.005680740211005661
0.0033056411950218387
0.0025930587666783676
0.008401375339961898
0.0033941466290428016
0.0077401519125825735
0.010314920372192
0.00829907457664415
0.006405021445455382
0.01336330081307151
0.008661047897646918
0.011411513335753496
0.012464587724959817
0.010519602768094305
0.007956930844641717
0.010587534692857342
0.013274512047706931
0.009568481851277939
0.01441961176802783
0.009850629907642608
0.008464474952089398
0.008874720311299482
0.00771809440432678
0.00130637492476816
0.007140984412910863
0.011018225827781076
0.01023144587682418
0.003924030438200213
0.006838036812772055
0.0018816719227446963
0.0093381074457357
0.009281052891561012
0.007831547605909126
0.013058941398236844
0.003336940246527652
0.010835500793287255
0.010115451383432065
0.00806898631854592
0.00847962258088157
0.008022333014909414
0.007857529701329765
0.010348087358522426
0.004755938614609495
0.007071208815859838
0.01351741271229853
0.007233347461313511
0.01031092615655256
0.013383511214056409
0.0021239957206197896
0.00042167744233634753
0.004339344275677181
