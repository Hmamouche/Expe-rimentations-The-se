# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP276_8
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=10, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0077507113482584555
0.0032836754174426384
0.004237622012872637
0.0042787063002644385
0.004996280186891211
0.003515783728763552
0.010465254484497227
0.005652743526596786
0.001673938655766017
0.010671371704784322
0.010103098586119758
0.007229606772256653
0.013590305015472795
0.010334898935735899
0.0036283175155597657
0.0024422546440854937
0.0027573466323222297
0.0003627879573234261
0.00910093631162088
0.007217234641241328
0.007547267100507503
0.0058458157144548615
0.008332135936820573
0.003207847492541968
0.0020910489875964697
0.004236554941288036
0.0035180074817613145
0.012609127728240464
0.00672166394992577
0.007567023114901583
0.008162209800879821
0.00247978785618615
0.010496674485511849
0.005615105339728167
0.0144790980097183
0.007409604125158356
0.007821553475252346
0.004426690349901985
0.0042139166826862685
0.0057831245346385025
0.006012299482492335
0.001785129463740711
0.0011937800640567774
0.005096150778166295
0.0064567646823751774
0.006114978393624387
0.002685705558515477
0.004908205651582156
0.010790729578188576
0.005926862471670521
0.0035016258766026646
0.007728825249051178
0.006585236742180796
0.005702420096478657
0.008626058131553496
0.005940670898423929
0.005816727399168412
0.007933098767931829
0.0027651987505919965
0.0021928565555286955
0.002431453274496633
0.006489317611124918
0.0030591135536022504
0.005949835412925231
0.004277444252856944
0.005496172588065864
0.006823402004056553
0.004331718530702789
-0.0003735949553531964
0.0036541204265839616
0.005707963955848774
0.001118657717835113
0.002796666966901705
0.012637992726070581
0.007211850566321062
0.009138651518949475
0.005328749939510457
0.007931328162967934
0.004536202586252414
0.005364447374451117
0.010370288163761919
0.009033866801807986
0.007700075698532888
0.009928249329829792
0.004956010705792534
0.007740075174399828
0.009551490525133337
0.009879657705597681
0.007215997507645865
0.011728017548806117
0.007626066696427209
0.012315603260313392
0.007110678336474448
0.008040971226165813
0.007721410076581724
0.012796171844052708
0.010889639757825493
0.011134675377730475
0.008520523835280984
0.010537174084723173
