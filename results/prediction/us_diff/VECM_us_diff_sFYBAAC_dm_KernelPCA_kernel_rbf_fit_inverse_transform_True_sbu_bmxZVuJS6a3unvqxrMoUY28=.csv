# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; sFYBAAC
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=1, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.03092437527977629
-0.05979015928551373
-0.09574341527982495
-0.0795079985159745
0.026363857727310536
0.006648542764158441
0.010227300315247776
0.03453321287279731
0.004808762288221618
-0.004179246636729427
0.01645981586277702
0.00036109398637755585
0.029514196218275533
0.033709178569496547
0.008604775951040696
0.003120029461523465
-0.029036500254559103
-0.03840582244678348
-0.038096188695087185
-0.0050059300953319355
0.027643872315869344
-0.01620044569294055
-0.008403259709815581
0.0031144566820094505
0.0005692328486611392
0.009615880120720116
-0.0011159411679768025
0.01621552552327205
0.0321812185626766
0.03144370104046606
0.027967091005841528
0.007054051106651348
0.017138363057268118
-0.011373665281308655
-0.04077633093784949
-0.005188916465741799
0.012516304503270927
-0.010833299685156922
-0.009353133523015393
0.019218413476963472
0.008467163612828305
-0.0057039483467859415
-0.03569450550958322
-0.043744565480248514
-0.013153487278601543
-0.04518437403683574
-0.008377676217053879
0.022978986536178567
0.020356091333485364
0.015434636732831377
0.013152582202732365
0.003615716400063527
-0.013357777053785873
-0.019225725201527828
-0.010827801129521161
-0.022460778552486904
-0.005851837745639552
-0.008134134257848287
0.0076985394866532705
0.015057535448698776
0.028054326219752235
0.04502615417096571
-0.004602584276874447
0.022846651141122172
0.04819872294867651
-0.01006577216093918
-0.03128549099405553
0.02463219895145426
0.00847070588640878
0.025899486344916886
0.06812843590103027
0.030972430669345033
0.03378262206826663
0.026219826164409207
-0.025513918392761306
0.008105850748329323
0.00043728593123857056
0.027211614636206343
0.0258627067242118
0.028234719737758197
-0.01139500190021779
-0.07038169058624885
-0.07084238719644106
-0.045803764813648555
-0.0013648951287408215
-0.01682281255124133
-0.02854587959396091
0.005653177506306872
-0.0295147252865402
-0.023687016491530245
-0.017519279897018274
0.010042479220437345
0.01682622401749841
0.0028578868905950504
-0.007671764662259634
-0.006639052633358568
0.010136598518328245
0.018659599482646283
0.07615967565038177
0.03762662113530596
