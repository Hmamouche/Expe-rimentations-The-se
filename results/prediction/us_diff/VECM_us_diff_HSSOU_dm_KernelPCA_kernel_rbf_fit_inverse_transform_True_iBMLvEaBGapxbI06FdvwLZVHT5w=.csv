# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; HSSOU
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=15, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.13517939865876347
-0.15932505447718895
-0.07759285710393243
-0.15622534729570675
-0.02400505464331773
-0.018766307254138942
-0.013995633591291558
-0.04189947393447313
0.05481338753930002
-0.07377796827452798
0.12410377077191319
0.13461997153848676
-0.07469783451315416
0.0642164921421153
-0.13882232037093678
-0.1503351172094266
0.11809859322964765
-0.05539260806567235
0.005915921326059791
-0.20518480456867727
-0.09016792098380108
0.035058528527255405
-0.02228728984308201
-0.013582568640810713
-0.007973634590440055
0.0264891729364244
0.03564697760878406
-0.07182503552691763
0.009853346898339645
0.021411322101486444
-0.0011795047740365315
0.0988571707466682
-0.03321562489444003
0.004025489744896131
0.05236879559090474
0.040940058511395525
0.011686680319246238
-0.0905942518064665
0.022256442041449755
-0.08919415181121038
0.10859064345677466
0.04334700430969511
0.018552097203912994
-0.05890756076680641
0.06938716052322164
-0.09678940112463107
-0.010731279918277385
-0.034738856404801295
0.08634537282815365
0.016935367147603825
0.02451013389178557
-0.034409877086665513
0.08931363983297107
-0.10268676786543944
0.055318606031264574
-0.03606143504339156
0.06666338148919265
0.0024341190011655904
0.01793575349226003
-0.0438454925963968
0.0684359498328669
0.04968501783308357
0.03420102984964245
-0.022065963923563976
-0.037520288375571295
-0.03832255498719492
-0.05977458721313767
0.05118343345279541
-0.010830540008782074
0.032802311337981824
0.0584568303302667
-0.014591458281979344
0.021960594181402816
0.08075588351193443
0.021107859548198993
0.11843362204912541
-0.05698882721889034
-0.02378018086831271
-0.0425721805082455
-0.05128803121721498
0.14826660266165415
-0.0331673224310428
-0.008217652958847686
0.005338149979914553
0.027478357686808653
-0.018642622983641607
0.013935289859705467
-0.013316911689611577
0.043918601507190166
-0.013936110954897975
0.04326906679079524
-0.0279537443559186
-0.022580066087143014
-0.06207392752082885
-0.00873614842074474
-0.02093316366630793
-0.13350882086208118
-0.1589798733124592
-0.06293252705956873
-0.07906246606513163
