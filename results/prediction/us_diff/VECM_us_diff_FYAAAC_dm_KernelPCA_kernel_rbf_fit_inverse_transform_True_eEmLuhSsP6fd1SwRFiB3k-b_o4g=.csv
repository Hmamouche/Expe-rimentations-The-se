# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; FYAAAC
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=4, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-7.646411298679878e-05
-0.009814064910799211
0.05256604425187425
0.03388698342794159
0.0010166454936363697
-0.03860559328989336
0.008361535852622181
-0.04443233844919638
-0.05253186404884585
-0.06393125761253893
-0.06257369402127276
-0.024625506319324225
-0.06900402139846519
-0.03325392455897537
-0.04266970104905873
0.012900329151584409
0.04911911082118627
0.053495343580748214
0.058561298049154616
-0.01909185440465714
0.017775085812334845
-0.00026450770705553715
0.007408614155944024
-0.03502976025346293
-0.027826272784179526
-0.018387288404216124
-0.01843167395084283
0.009803312882317058
-0.016165275246813476
-0.017943287325914426
-0.014744276263006438
-0.00997491660648057
0.02360064541339557
-0.014093489056296149
-0.017855436034262824
-0.010135175452251859
-0.014415388679838995
-0.012708901387633142
-0.008309878850044911
-0.03637699077436625
-0.03702856774593916
-0.011616450445245952
0.015795260047742257
0.04172382452229127
0.026421039232890884
0.05438868209844205
0.007627265500557611
-0.018221250705879655
-0.027610285847273354
-0.03439220650501537
-0.016036742179911894
-0.012153246466130502
0.020829843178458644
0.01726324553327691
0.000809505494192734
0.01792058165736988
0.02077762240257096
-0.014244299387787648
-0.012310751966786602
-0.028083031760567548
-0.02009859030213064
-0.03730021816808575
0.01849284377745666
0.004146837035946668
0.028368231798445307
0.033294778288866164
0.03784341560407725
0.004245706254233556
0.001092457604350009
-0.029707939431019036
-0.03432215273089263
-0.00504740438782826
-0.01752994377120661
-0.02880831760995556
-0.009785738268706285
-0.014708660957846953
-0.021349724829050364
-0.01959530016959364
-0.037858356489695946
-0.022616851955268108
0.0034990548981579314
0.01818050509766308
0.024216956454488108
0.0022141311623705695
-0.02420637497338196
0.011654807902078394
-0.03188561144251912
-0.021130686834957273
-0.010327759700595707
0.0026932854420522083
0.021683499816587737
0.01674258626028267
0.010387545145028607
-0.015447993817237696
0.018075543356648554
0.009935852094227348
0.01256391764129984
-0.016552374960266437
-0.020555503788246467
-0.02455185595243878
