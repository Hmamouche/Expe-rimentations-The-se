# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP276_3
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=5, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.009433578151537577
0.005957346780215004
0.002280532823131059
0.004949013599050945
0.011172129931085698
0.01294935862534135
0.0027622706083541434
0.002900100495701507
-0.0010957745276656478
-0.0026228933340669146
8.684291575403614e-05
-0.000537275491126244
0.0010721188723508451
-0.008030398962034023
-0.004151065281107805
-0.003240395897314085
0.0017791129403008218
0.0011626261982389764
-0.0033419244894627234
-0.00041882240331997937
0.003018301845564675
0.006008576415262751
0.0027304990869865308
0.0036513790599418307
0.0038658906447855633
0.003786324709028537
0.0038151699671053396
0.0026768995155529328
-0.0011303203646132378
0.0029011695434949594
0.008374476191893998
0.00135257098054133
0.0020429722732489865
0.0034230378258029727
0.001297198537086049
0.002147684943679348
0.0038879412594779563
0.006329253399610614
0.004481536895577919
0.00804634365131127
0.006777298275388022
0.003932205329309026
0.000850482040711938
0.0010973804859633726
0.0007807542067338528
-0.00021968905391550456
0.0006076761902925048
0.0007676746004926488
-0.0008163175269353714
0.0018370754719039563
0.0016146596768281468
0.0018300618580649334
0.004441357266359608
0.004196780501968565
0.005697575107723927
0.005880516497592837
0.0004086451661773528
7.418525593877717e-05
-0.0010757946498357453
-0.0051116764646538864
-0.007231804679048449
-0.0012795283590292918
-0.008118488392120147
-0.0017912401282960098
0.0015703821119333224
0.002214317408497979
0.003737563556666623
0.006458813818527418
0.014046917393414361
0.02150800785279246
0.04995597793511107
0.04395087940303205
0.010996685990903372
-0.014154566971442288
0.01567365896672971
0.0021354965569171593
0.0014616741934963175
-0.010103854619993434
0.019444528553800678
0.022506001279009816
0.006505637371591886
-0.005003038030881822
0.013923088332240891
0.011376315922206209
0.013275787255913772
0.011369519047526672
0.011546564000769251
0.02063305547086961
0.02669762821769745
0.06070531802207235
0.03351408840943544
-0.0010494779381316878
0.01922569484046477
0.021722009560140677
0.018356374347681444
0.0021568231751067975
-0.005801815345447384
0.0047395227997266
0.015446261693823096
0.04436074700905861
