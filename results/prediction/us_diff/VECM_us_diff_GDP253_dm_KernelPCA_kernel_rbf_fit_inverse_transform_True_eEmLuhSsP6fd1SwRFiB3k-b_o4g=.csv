# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP253
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=4, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0044477283951667775
-0.012088506165873562
0.011350199223576931
0.008472718806003584
0.0002764268746056255
0.007604403528231593
0.013307884045993843
0.007106041496190387
0.004370631766576606
0.023924332402282002
0.008917750356966243
0.004053192352091601
-0.005020006617275455
0.0011819801532967035
0.013478364202959954
0.01918924957669837
0.01348669242006192
-0.011951189744572002
-0.007838808930685958
0.018120266081941835
0.004720869904361402
0.0065406216483406675
0.006398669823728195
-0.003967741035337606
-0.0002572234600853628
0.009380566915931936
0.00013482484110546216
0.005516974573610589
-0.002937764093108886
-0.006230483235883313
0.001682763632631954
-0.007874424067180053
0.0011984905520759563
0.00033798295362516984
-0.004665874623799984
-0.000636231549602105
-0.0008586762675582929
0.00442317912109101
0.007237732834463498
0.0024055831731757587
0.00969890955590754
0.012356971950228227
0.012706924562758778
0.007704982015066865
0.007734235807247241
0.007204226148582182
0.008743873297317534
0.008718224477160587
0.005262975092105839
0.007473819959307241
0.004044163409722934
0.0049477247017842545
0.01084028495733692
0.013176665502476486
0.0083163860380922
0.015489118763626767
0.010380303890857825
0.010953746075997958
0.01809543724204139
0.00582243828096711
0.009444860415034017
0.013009155703633417
0.025310027256380246
0.018493040947518746
0.018937935323659366
0.02717264877861013
0.0075842930496523575
0.030541876766776985
0.015304200370578024
0.006729043791588259
0.011612543494410873
0.003339966728216827
0.005792310959779038
-0.010073006212438087
0.022500815994408143
0.029922027955908197
0.011135517504595146
0.027197258018432407
0.0017925495353509555
-0.0013965414288080859
0.009885889585096817
0.02630041150687261
0.027944989704487246
0.011864824341376574
0.007538610485384432
0.008139592979017004
0.012576431946966752
0.008480456666119948
0.013811314994864933
0.02443226690082005
0.004237031913292049
-0.0020167651486705258
0.006802271030946316
0.006322148156963541
0.01659154998626708
0.0142744923737909
0.020706394323335823
0.009841163131083309
0.01123506283064938
0.005104641646086708
