# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; HSSOU
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=2, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.03330706834300448
0.020589011279719217
-0.01858970032483951
-0.0260942949522638
-0.05558897328834567
-0.03838452469841652
0.01620979776156637
-0.0008494808552017372
-0.022652688312268618
-0.015002400305461794
0.021573579489792875
0.01399917713940415
-0.03222315557527331
-0.06784016930556724
-0.0980513482777093
-0.05547025290380582
-0.06408964223049515
-0.03434522232740642
-0.06195143490437403
-0.05223375168704278
0.0098169306672833
-0.028745825344333734
-0.003960973336624002
0.013493241823411344
0.02279108793665506
0.031161930390831698
0.025204107936641566
-0.00849202318632706
-0.026059699181367153
-0.0177507290117533
0.03307051040008834
0.01750113910443933
-0.009299020688913352
0.0006590413313800007
0.005783120641308981
-0.004532910050632673
-0.006329797768757629
0.011366725692595493
-0.013963856130403997
-0.0019598348614918194
0.012469402890086516
0.05134647361250601
0.022605904529952366
-0.011673015230788161
-0.01248299656577565
-0.03676871173945871
-0.041244238078632485
-0.008322997841735564
0.05250305393550027
0.0804640971476588
0.046604685329154356
0.03064688804394628
0.01684157711572577
-0.03717253696295581
-0.034877054262153304
-0.012728133545938448
-0.00746208331154684
-0.009895096179496618
0.006689027587621878
0.03244903736226419
0.05158050122875138
0.07087629955039428
0.04639101126487431
-0.010254216862149744
-0.049407922283004356
-0.033319666054019814
-0.011494684577497014
-0.05376384228846645
-0.015473362404816445
0.01203129372741279
0.08319643792689647
0.08489451347128779
0.05652880854099465
0.062132522494504586
0.019256205797097026
0.0035912609513868363
-0.07273887378063673
-0.017071561242453497
0.002280507927241212
0.008325389007195207
0.044975280122049696
0.02522819290761259
-0.0011496239568084196
-0.01908896821819209
-0.004840917714980037
-0.0011761457968459598
0.020699131759815376
0.04142057506195594
0.02232255491605742
0.028674856295265772
0.04401194996223974
-0.022895072147603356
-0.05543062909582988
-0.027923121027441045
-0.058361777034139445
-0.06830935914812558
-0.04117671564161904
-0.08473731431382556
-0.032125915579522504
-0.04449374346145607
