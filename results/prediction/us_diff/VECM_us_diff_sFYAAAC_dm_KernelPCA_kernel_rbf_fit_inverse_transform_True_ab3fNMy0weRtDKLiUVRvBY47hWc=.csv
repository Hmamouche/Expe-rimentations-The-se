# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; sFYAAAC
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=9, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.26340583790556704
-0.11057480189010474
-0.20713476462371094
-0.024847524680839173
-0.059816530734003406
-0.016059206103657783
0.006984181768161207
0.05476904777841898
0.03530170007512373
0.053056034235569545
0.06519582211821086
0.09121420803873638
0.08285212350933926
-0.002607222778735905
0.07207288151531656
-0.036775708102168306
-0.02269461647561572
0.019583629206551344
-0.08285097307160859
-0.08272021369555313
0.02154765150493365
-0.0959896312569001
-0.11830043415407318
0.08992172427225482
0.06349371493963914
-0.031229005618638034
0.0090611855912517
0.036233506694068475
0.05525647782730492
0.04105154199804727
0.1458037123351798
0.015677983878515787
-0.24517649518634957
-0.020504731655146213
0.033420496750838975
0.014343463376837298
0.13562507023953768
-0.019939925827233668
-0.00212109519459501
0.020168943651470556
-0.06859085767834733
-0.03133822785096767
0.013692956300243149
-0.01759244275085631
-0.06862895222700315
-0.059871855735033425
-0.0025456497672889794
-0.06673234111445443
0.010634763857899063
0.055735615234029395
0.07202077910662313
-0.029176554808234178
-0.05705421178300696
0.0033073351258560762
-0.051743272972538404
-0.003221677151450072
0.011373812819427348
-0.03657497657335838
0.03696228861765006
0.06738622703894519
0.032552105514257926
0.11246370485122775
-0.03089362972594492
0.05892274716380935
0.03381299125192528
-0.02983355378705588
-0.005179651437085375
0.048627686383075304
0.07384935799406588
-0.008695799384941414
0.05306415614429271
0.02556318431419443
0.03685377843095444
0.0752266979648637
-0.1281545930974622
-0.03975665734985174
0.06660703349500569
0.016622912997148576
0.0833392189940741
-0.1315585950881007
-0.02277042495237977
-0.07214817864859134
-0.021408363317678827
-0.024257035268993726
-0.011242789708481957
0.011913734912487192
-0.04965079844570994
-0.04122251687065763
-0.04045038649136324
-0.033546348671082526
-0.04745917020621574
0.03335154795477927
-0.021293689775268812
-0.013458521470071226
-0.027280302041833928
-0.041298869163747705
0.028160104656215615
0.09867734432894074
0.14681592456022433
0.05532118145403408
