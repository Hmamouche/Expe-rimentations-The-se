# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; FSDJ
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=6, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0007348217426310414
-0.0022257604790111864
-0.0029998540365674163
-0.006358596407948175
0.001809620147832018
0.003173102827172105
0.005507267778317686
0.006356212241005422
0.005489644272128126
0.005674283796764218
0.011497436802712214
0.008830400070514785
0.0033531922941180316
0.008524477840892036
0.015568113433931068
0.0006499442808648467
0.008225930892267622
0.014397539855839076
-0.002289436776659549
0.02875840927511363
-0.0038080023863585237
-0.019612890485535505
0.0028689317431048033
0.006201127378129086
0.010642635853687946
0.010620530401343864
0.008879232375818493
0.008335338147072434
0.00043175251843689854
0.0007946055007722155
0.013380767659051723
-0.006564718875713276
0.004348270928561925
0.002050425438973222
0.008091102607551259
0.0025443912225079955
0.0014026258712778708
0.009043811689547585
0.005142701629646514
0.012435927203252164
0.008043842951220645
0.005983485284271216
-0.0006359119855088502
-0.008671287356621272
0.0047156617801960305
0.0031041645462812047
-0.0005853459452394728
0.01854313288924236
0.022542488525609312
0.019436223455113543
0.02743761306302865
0.017165515797271276
0.012369223443138972
0.020764987312988314
0.025413542925093322
0.02722440757147319
0.04249092440503269
0.03538780990536108
0.04029796867780731
0.023302313925195037
0.05008883763053855
0.03353589676112946
-0.012297097515313164
0.025492511701499458
0.0057657022759551625
0.043979494266609874
0.043407482864689796
0.03526447890592228
0.015041464593528349
-0.005007477467639522
0.007636583330965879
0.0023539236577124383
-0.029262592032185796
-0.011166296832778583
-0.005462568807859246
-0.015069022160907726
-0.03292668007376601
0.012138931299192891
-0.04723275835748199
-0.019494487122958405
-0.052206105102378525
0.02322069137049903
0.02827734760192467
0.012408579116482752
0.024841913429242257
0.02150819901968596
0.026692504653597425
-0.0005208108490365789
0.006268959053175701
0.004910136442768114
0.014309804705599548
0.001843250181236166
0.014495205017767977
0.0387295155920696
0.026159483227744036
0.044112936177522585
0.023282331183490535
0.022224056572867447
-0.007638529417723428
0.014615507627888954
