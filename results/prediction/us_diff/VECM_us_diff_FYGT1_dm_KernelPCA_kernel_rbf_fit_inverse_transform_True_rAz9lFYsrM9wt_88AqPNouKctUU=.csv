# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; FYGT1
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=5, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.13190630834934358
-0.08344947440568476
0.1336179408513511
0.01801655760203881
-0.03385485317676645
-0.04245016733590061
0.059334178818952886
-0.06987250144254062
-0.07120744428040059
-0.0477036571700187
-0.039255825823711454
-0.021547906287676645
-0.0974841093193418
-0.046693820502592485
-0.0267752539198315
0.013180212891389112
0.04445366576788851
-0.01540422538819848
0.07763176052959275
-0.011227568346589287
0.030093003789343195
0.024073426100789164
0.03131511363604221
-0.019826255801736675
0.009351076882957655
0.009383718001575083
-0.023062418359504226
-0.013402492308167662
-0.08687196005942094
-0.033515233249277424
-0.029696229449481214
-0.012301010806267335
0.004421191509631956
0.021835554201346037
-0.007856143182445121
-0.05012920665110832
-0.08113775026014095
0.0048830801119075055
-0.005978331247323282
-0.06258378741604692
0.038944189807294805
0.002010353250679447
0.02569069361361933
0.031668934766242864
0.021274179199921705
0.07432309553422398
0.007268425728108589
0.009361376111988805
0.014919778221053396
-0.011924371998149441
-0.03203491604141436
0.0011229502553753296
-0.004153880871480883
0.02659447384827411
0.009498680602581355
0.030877868307556504
0.014898495821910359
0.0036144897941456063
0.005364498577178615
-0.03690440906826941
-0.03468793181085134
-0.04647030951039702
0.0479909696382251
-0.04872525329835768
0.005889267582606196
0.05045982056614029
0.021814545694659602
-0.004852311548045893
0.00024527407640370646
-0.016751867377461573
-0.0489609056873958
-0.025793580703743713
-0.043159617054998885
-0.10244010140898457
0.037559428554213736
-0.06159333014796434
-0.015699909078551528
-0.015070684479744745
-0.06911179335481005
0.004568717540960179
0.02743586141598189
0.043584470117544294
0.02868880502029773
0.010221898978579036
-0.019499408029667202
0.009451775077150743
0.012459501460841944
-1.2731659621932363e-05
0.0355628444531005
0.026223387423022042
0.05083715063430692
0.008802007349401491
0.005094043544601044
0.008799127078168123
0.034095531142325816
0.004624430889466791
0.001218692443657546
-0.04669049735620928
-0.07359899624458374
-0.02134712673783643
