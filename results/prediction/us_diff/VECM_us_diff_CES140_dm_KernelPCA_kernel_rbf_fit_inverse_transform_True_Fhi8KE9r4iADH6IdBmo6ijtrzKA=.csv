# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CES140
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=12, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.011253002898302817
0.0004255639911056328
-0.01320975602002709
0.004466671748564091
0.008970437616129366
0.00517374640116255
0.0046590823686351365
0.007233738618486246
0.01576285827422206
-0.0011360863315985751
0.002594838186032917
0.0008372415071531097
0.005883903420664308
0.012478694380565966
0.005464590909476934
0.0047068776398387115
0.0005288317573764231
0.006928712273663629
0.011513743949637315
0.007522240593210956
-0.0025072079664881794
0.006839126977656778
0.007512574649281094
0.01201594540292661
0.006826722396478078
0.00421231372018896
0.009288274468692258
0.016632450989208562
0.008532550952622618
0.0045794236280739435
-4.611830586072406e-05
0.009763966046545568
0.006749930825128482
-0.004782454771607438
0.003223969985365907
0.001591312829107877
0.008976726533630979
0.002631235609079439
0.008497236978594443
0.005165406812476701
0.004773068152823504
0.00334123481449223
0.0026876491781474303
0.0045012762262201635
0.00365296823473636
0.0017708685288535142
0.005812021008268711
0.0015241153305636562
0.0025347086116787702
0.00636737402154873
0.00645294302604967
0.00387434596638465
-0.002972768716252704
0.0011539513546637444
-0.0018852862710397277
0.0008207489484780466
0.002959955319351606
0.004593468682501918
0.0025373404638692667
0.006362091586855212
0.006187704299032691
0.006996790099012333
0.007234758341438405
0.0058730772001549265
0.0034017212293234837
0.0037495907420702374
0.010621346558969744
0.016220711125359437
0.007089991756727284
0.004760687564935762
0.003333710616045003
0.011140150644436764
0.0067021988449558895
0.0052747035257532035
0.007919562731131988
0.0065954428266246125
-0.00010745622067344753
0.004345832452228493
0.013594071390303452
0.0031019127456641963
-0.0032944018566843447
-0.0003929115527406021
-0.003402911157769937
0.004893236043431066
-0.001993102692536668
0.0022178614462865435
0.0028773963785805566
0.001405284679774424
0.0067764434842733
0.0004898052666687698
0.0052281377150702555
-0.0013587657627706642
0.007649737318311884
-2.4459456369656967e-05
0.005648217944328612
0.007367560068404075
-0.0007757547736591296
0.0098289866974419
0.004880446318085003
0.006932718759816219
