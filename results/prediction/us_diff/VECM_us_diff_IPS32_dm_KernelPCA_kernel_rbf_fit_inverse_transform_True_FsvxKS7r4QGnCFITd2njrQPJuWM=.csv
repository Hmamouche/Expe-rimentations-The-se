# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; IPS32
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=2, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.02367575396918869
0.0142848329167088
0.006117542190600399
0.008873324276614102
-0.0033631516155353982
0.0032224855886427406
0.004619984399806802
0.0009907113372044584
0.003228443035976918
0.004064248459776175
0.004968018528276712
0.005328097636634926
-0.0041553885013393636
-0.005926155805419022
0.00681853869085351
0.006340228173631281
0.017387134380013707
0.006932103060388991
0.003640789712435902
0.011378613959393217
0.008323030840672433
0.015588478348662926
0.0036764671042845897
-0.006272037929974718
-0.006527434256150411
-0.0024462910273611725
0.006052246680958237
0.002483974219394683
-0.00504847280629727
-0.011254579847120196
-0.01161590280708387
0.008046364032845215
0.011955903838096043
-0.002870070156865541
0.006305595267102223
0.0023014752195479157
-0.0006354084587904417
0.005778586607318999
0.005419349736995157
0.0016396814793883134
0.008425535913703765
0.01149576963869333
0.017271822967835235
0.018524167180131498
0.010239229616821575
0.014869606097972174
0.0022645054485240356
-0.0037068828901856664
0.007883958507581366
0.004054000468942003
0.01133829024535165
0.02024265008524053
0.01412208357812545
0.017882066725684424
0.01195853812260913
0.015935449700811344
0.01811730449520643
0.017991934650618827
0.01582030599679151
0.01389922128992958
0.009942333057867663
0.00943787433892686
0.01751608425935542
0.015529853265250486
0.021923682442094864
0.02116131645784236
0.016570489223225782
0.012128423119846476
0.008681887013016615
0.0008967266831633098
-0.0050741274367468
-0.0065730396128320144
-0.010604360214172865
-0.02127889427369146
0.005608123836674069
0.0011738596411614666
0.006706606909642544
-0.0035264317323525896
0.002726495021158997
0.003820061012595536
0.011632021812755107
0.018353558140682607
0.009264231652472543
0.004936382987561383
0.0019316232807550515
0.003855369986367721
0.012527970252492046
0.004111968216825927
0.006799005427103297
0.005419693799480383
0.012492645733607671
0.0032013270037562517
-0.0025931389270632344
0.00025743368847179113
0.00648999103035018
0.01336871972314201
0.004198588583135494
0.0047013772886118545
-0.0015070636600922472
-0.0006554260791826632
