# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP251
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=2, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.00856772545741847
0.006223998737450713
0.005980575387980837
0.00766413490324245
0.006555791077989074
0.006103877398479099
0.009444801614096042
0.0070478948607385185
0.007775327711975612
0.009534042934117998
0.007454494509941942
0.006497064139411327
0.004560339193827168
0.004393134141679794
0.006519749055416265
0.006110787845633175
0.006850275661348929
0.004463632578567689
0.005270470808440889
0.0073329697502951905
0.007802076086427762
0.0073827423268377325
0.006728356399729968
0.0036130053191126793
0.005370714648248143
0.007132767429570852
0.0074680181117707375
0.007004829049660245
0.0017216157860360712
-0.00023955020406476026
-0.002971230497345265
0.003011002065450814
0.004842601764593958
-0.0010576412502557003
0.003878488532583999
0.005854731870787992
0.0039478627207771054
0.007828013378754621
0.008116604961794463
0.003801095376077474
0.005209823314314915
0.006071649929997651
0.008706324304688031
0.009384381306409187
0.007274821250513598
0.008019081430299661
0.004832172357125545
6.358892402063475e-05
0.005268074634741651
0.0057467016577205
0.0060751201459339444
0.011385759203248417
0.010323421295417544
0.009085489882994227
0.009288340984637903
0.009213285765329936
0.011372150287331817
0.009654064377801209
0.008800615894140787
0.008631049258478228
0.007362309869350896
0.010205090185371232
0.013442873401900214
0.012015425190656787
0.011873537197546424
0.01189360455068565
0.010328319446947936
0.007962758532540018
0.010074284730998613
0.004057187684260459
0.005236042399568467
0.0038908261346435654
0.004648873817171439
-0.0013766765250354382
0.007090469929157779
0.004803869142468298
0.003321199184286805
0.0022063723172648687
0.0028709079200554405
0.004614571354434508
0.009338945501316556
0.015008835338778241
0.010894942367157106
0.009972249507353446
0.006945734724703091
0.006879213499671563
0.008693845501253131
0.00823749364244799
0.00943933161308258
0.010208576735000337
0.008433912319865176
0.008360988361407331
0.0053626643281066335
0.006322212998632577
0.006606392356970754
0.005830660003609045
0.006737911607729275
0.005803332445846463
0.005133675805839717
0.00853091939673482
