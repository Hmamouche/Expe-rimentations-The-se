# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP282A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=12, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.0009629207280531427
0.006523718337464407
0.005674434251840526
-0.0003876829049812799
0.004260551871220615
0.007877286798423054
0.001636227546014546
0.004223106236350475
0.002683004312433651
0.0038905458321440295
0.0050177954016421295
0.0042969682091139084
0.004608486401347403
0.00576205415871847
0.006638292501315613
0.005767927740982264
0.003963654146278693
0.006725047036205914
0.003796075026607939
0.005295286427986342
0.004593170265211844
0.004579132596122414
0.005950157593976166
0.006078882385069326
0.003571147680288681
0.005628305555067101
0.0023721792545597117
0.004886357205790077
0.001965672858649846
0.004548481772963132
0.0002862461256864731
0.0044194408836048076
-9.224722916097454e-05
0.0023815356705993948
0.0006380871236327705
0.0007393558348325896
0.0020806871135203198
0.004866377149640724
0.007559250041928141
0.00598182770178687
0.009563045407736812
0.0075242644577307
0.006520246685104916
0.0012033345520290483
0.0060982646350751435
0.006824667837418308
0.009833286112840272
0.009307922620185195
0.004342024563553957
0.00548614358485223
0.003360750668732942
0.000382360412756041
0.005363897551353393
0.006112221551339599
0.0027542745654821027
0.0046448166625799765
0.0058749902354381725
0.005047383571529404
0.004037988613779164
0.0037510978480217888
0.006191943907480938
0.005679221580364982
0.007049895879609348
0.007263288941986661
0.006478033175976347
0.007705104360633451
0.009670158283221904
0.010226388982285815
0.007707717590314013
0.006741030791853997
0.008122022432927983
0.01167257865603295
0.01206165990848725
0.008668795926572454
0.003277913640602294
0.005694508022595138
0.004156997329964442
0.010512323950616798
0.012223627368917214
0.005180075770990181
0.004950392151536261
0.013682082559849443
0.009626354243992226
0.013071903639065392
0.020560588453117534
0.017507608142258126
0.014114345111524595
0.020354921497689898
0.02174756475889681
0.017263142175393455
0.01632409296520968
0.01705428884555598
0.013485970535836373
0.014635538875639113
0.007944942527760053
0.0009854335535071854
0.008458330639019004
-0.0004201362215902405
-0.003086287242765901
-0.008706016505872032
