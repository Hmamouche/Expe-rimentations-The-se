# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; MZMSL
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=4, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.012258196200376603
0.0029751128584974253
0.011235470837876257
0.00024632554570480614
0.0031667059896430846
0.0030987491675772043
0.00690884998745452
0.007028372744977906
0.0033800310796411825
0.005706113083161893
0.006420320047118231
0.009720569196229984
0.0064360868890235325
0.005701206034751509
0.0031744336365308865
0.0037243008935861563
0.0052962605652754355
-0.0009845154641467543
0.0050233395883287615
0.0012262813471223609
0.0015557601793333177
0.001047876770160976
-0.0012857382590054536
0.0007193609897909876
0.0043517847086519896
0.0034206135808049487
0.0016661201637143573
0.0024290094712236636
0.0044014433395046905
0.003307620233488892
0.008618921687790597
0.0068385589402471525
0.004899692388358163
0.008194960530060373
0.010305269457701112
0.00629232918933765
0.007846836704019781
0.005231720066832191
0.0037543037575142944
0.006297100438291535
0.004036948935482978
0.00595199279835315
0.002089684604730059
0.0004279278333007482
0.0002509320467709047
-0.0035623134109219233
-0.000481031477208746
0.0031882424253238863
0.004490673773203899
0.0033777538680534406
0.005036872058018069
0.00234190505366826
0.0069063708119342085
0.005089251592485756
0.0054983779114953415
0.006348644743349407
0.009018921377955095
0.007111129945986619
0.011125893995531693
0.01172924597691447
0.012793849700133605
0.017355292421478756
0.012664774404732649
0.0114028127862198
0.010383032065799257
0.009357025426679377
0.011010618516229528
0.010538574356326732
0.010438827034091203
0.01056354863610008
0.02570427916735652
0.0255383794117207
0.01879007202798983
0.03120131062725332
0.01663195318884473
0.01547626917729944
0.012954442420238327
0.020525155636781124
0.012661686782657892
0.012862810019179724
0.01457871786060308
0.00018093493439846377
0.004708183879813474
0.008098184303415162
0.008982847470790204
0.007308072365087133
-0.0014325232419228839
0.007054679330209791
0.00517340297988551
0.006573555113137752
0.01010424125576705
0.002009688756903669
0.010651715787864328
0.012842533174976509
0.013219125624640903
0.017954541485361682
0.026194914973121708
0.03251464247369342
0.03607342041382547
0.029799991674873513
