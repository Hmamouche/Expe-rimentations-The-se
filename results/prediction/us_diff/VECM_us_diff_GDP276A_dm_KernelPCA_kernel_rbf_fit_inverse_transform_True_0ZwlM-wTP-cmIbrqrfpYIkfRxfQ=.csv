# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP276A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=13, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.008260311932962974
0.005061703501453248
0.004884037424805133
0.008495504117227555
0.006116087779699357
0.005633058458780832
0.00917770874694878
0.003458504685345481
0.005424156659074744
0.004720286982846756
0.007082436566033233
0.006015575423183856
0.005766761702799574
0.007258287941395729
0.0058358610939567915
0.003667233379567908
0.0064459458360994065
0.004854871637200219
0.0077676672114863655
0.006298176789900134
0.009498517125469227
0.006462076652269674
0.00671665485312163
0.0065033158291563226
0.005693322190981703
0.006495245402901039
0.006593276474859022
0.010053726886221553
0.008579426803033951
0.009495539227473761
0.0073934844020234255
0.004888587835259103
0.007433284319780374
0.005884825082656379
0.00958181548987053
0.006127430569875477
0.006288904375809486
0.005375217461597869
0.007624119184953101
0.005137327692218967
0.007654964528502143
0.004302757147298925
0.00502708746247121
0.0051271130432370285
0.006945232877252988
0.004520640847835619
0.006313084036919712
0.004175629279100873
0.00575464096372274
0.006979747096120126
0.004111910294356031
0.006231660848127262
0.006168612717905868
0.005920659874838112
0.006247111633300705
0.005718902022743489
0.004705365864395396
0.0050071452081748204
0.004341673754273969
0.0034756893199121043
0.004110116808072353
0.004778800881493054
0.004588539072976916
0.0051264637187937055
0.004146579126246221
0.006587074234499553
0.005785547691136494
0.005383544552159798
0.004363915149049097
0.004685912895290933
0.008053682331670415
0.0053505018936154955
0.006627413872806107
0.00703261896145573
0.008317205344541952
0.006721907283209636
0.004778738944731369
0.0064792795394398
0.00651647439906711
0.006077979076403511
0.00764364269455085
0.008284925064669584
0.008655263872793348
0.007884534618992219
0.008274727141465661
0.007084372642396268
0.00832180992809927
0.00843433847456088
0.008146924393265188
0.011243454271989287
0.008338148680685303
0.009086821870955433
0.008742123882515548
0.007840179910213834
0.009265769863534373
0.008428638670593952
0.00861235775670798
0.00919951924264439
0.0087797817207092
0.009755814665291985
