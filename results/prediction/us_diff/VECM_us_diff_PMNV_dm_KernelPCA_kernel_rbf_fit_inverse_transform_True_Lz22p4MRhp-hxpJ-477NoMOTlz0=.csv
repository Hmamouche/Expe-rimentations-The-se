# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; PMNV
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=11, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.3230461446094195
0.1444704386652751
-0.2411631275087741
-0.4188968205284718
-0.20521584962281256
0.027042408170905696
0.0766836089217711
0.11584728559212906
-0.022332311390480378
-0.0059972368959788636
0.023596237968505872
-0.020625457827848304
0.11406581381295937
-0.010466506687131345
0.09687668576557137
0.008200859765838286
0.0923876280538225
-0.016574751682352683
-0.1282832988197401
0.07154364996419987
-0.09709730603008412
0.10579972492759915
-0.17743393844683344
-0.08620848027583794
-0.03900001593936546
-0.06083080020334288
0.020219684894344385
0.07921733978889157
0.06153985722041617
-0.09421905357972456
-0.03565427068348448
-0.10272152948859903
-0.009109746583124877
0.2134939081438028
0.10473079573143967
-0.016824239892606202
0.027866101351252906
-0.08613478210210176
0.033918445792093806
-0.009965408116540442
0.1219539112732313
0.006819458380798407
0.03911793178655307
0.060316816323974426
0.08599141685110173
-0.020256779994108125
-0.035853294891013875
-0.033372262988461576
-0.09686803186026163
-0.0724925417725185
-0.059131544977731466
-0.00024359098883319774
0.030492629009698007
0.019128152132322728
0.05279829140034339
0.009554425934957533
0.004536925481334849
-0.042199557111338916
-0.01404413356965039
-0.0646464622218592
-0.039595083357423774
-0.06378245263254828
0.046668567988391335
0.0074730623401600485
0.12853598675831301
0.09700431365252836
-0.03617631734942095
-0.024922492646529792
-0.10093210308244081
-0.006678895765407415
0.0007115027279722304
-0.06718589037754831
-0.012067784512633687
-0.13727606011090854
0.12456705298153664
0.0644726473661313
-0.06127419283183408
0.059070049729410976
-0.01486302163570347
0.029141443159639915
-0.015224003576301133
0.10103103231327813
0.12030432521004596
-0.031927027282900214
-0.007540693701278772
-0.10519907469508044
-0.04521562115502309
-0.08932699552954097
0.004018904191898466
0.04673511709486661
0.09731099001144142
-0.09909979382846931
-0.05983187721176928
-0.014061587434061704
-0.03313537326791177
0.03785601033279497
0.04957379368216854
-0.007225920174774142
-0.03615621292680128
0.08560873050863724
