# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; PW561R
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=10, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.004869577585497074
-0.09556842702021556
-0.012985705347551564
-0.006902194261616563
-0.028551729115711695
-0.029663423316233256
0.007199127945989623
-0.005099119916564606
-0.01406940378002913
0.01507572904521639
-0.03826833374589536
-0.1153041046438536
-0.0015970112465573498
-0.053786905711173075
-0.01142990269631472
-0.023584592722781413
-0.026004273766700288
0.006728079695450667
-0.022456327532786098
0.0261653294231404
0.014487053871377269
-0.04660794520670697
0.04688002347059393
0.0038253783000502433
-0.02274141801308628
0.017304781357946473
0.012945822830057806
-0.052415063452535424
0.016759851437157795
0.028363357761239223
-0.017756169377917477
0.08795614545507896
0.01867751990728184
0.0014286611403372118
-0.11373570778154643
0.052653708305490106
-0.027301173957474605
0.011281618246872068
0.01566084155456758
-0.033101616900560384
-0.05341656989360356
0.02620018706749997
0.012965370628040627
0.02379893833449215
-0.03605089100942943
-0.033784825067236984
0.01968057323518258
0.025237302475349804
-0.025398246437053358
-0.01065504172435846
0.03910978436547577
0.020958806230742446
0.044404342429156404
0.002748080401710696
-0.02568947329131321
-0.01437931758030727
0.0070781008808881805
-0.03163643280640262
-0.029417235020332187
0.010698856702377775
-0.017287252137274903
-0.0008172691840220431
0.014002775182071263
0.03794857042668701
-0.007078327229568259
-0.008204141862359363
0.04651886203912011
-0.02568585641932542
0.044476058804965586
-0.01850406968767898
-0.03560951601469389
0.032540746877272826
0.02647408232237147
-0.050308437633108674
0.014669430703883653
0.017354016043080935
-0.023667224262461203
-0.027483790770611225
0.03746665296473214
0.00675133617480426
0.04754988807063111
-0.027792329326145532
0.023800469151813594
-0.011757257074236166
0.01950770818909359
0.006429858573702235
0.014366583684331902
0.03662737794617451
0.0691304075522986
-0.0013965304293825326
0.07855240364716036
0.03324462649100277
-0.0006705585627591187
0.0022153654032504586
0.007228008271266984
-0.042321753534718384
0.031353586569829915
0.038462354159358746
0.05002209951350158
0.19818407597571522
