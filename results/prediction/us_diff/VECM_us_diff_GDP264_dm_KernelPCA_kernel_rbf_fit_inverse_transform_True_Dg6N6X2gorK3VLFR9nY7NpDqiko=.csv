# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP264
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=3, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.003798282447039208
0.00873187588316761
0.00917581917658982
0.00977054987284138
0.0075770148767591045
0.004032725362814758
0.012322691536409889
0.002474049267555939
0.002339585861744809
0.00761275790431791
0.0037795554554841113
0.004551678684349236
0.002163518877173716
0.005278448756296019
0.007961774696533454
0.007819529317037367
0.004666842284174055
0.0032820424667298984
0.006770357101055013
0.0028100020782799843
0.0033843900379359275
-0.0018931826566919883
0.005034305991860792
-0.0008409194151326824
-7.553805991923298e-05
0.002927041114324647
0.0029709460362248785
0.004144566353964784
0.002535659775360363
-0.00015696509481808113
-0.003055444305867175
-0.0017528790974947839
0.004594226729080594
0.0010818877415208982
0.005277951708235361
0.006250576636676023
0.002633452473225757
0.003937969695556374
0.006763334363134052
0.003022567407507103
0.007462470190699838
0.011906501386122485
0.01072140817537188
0.011619963183312095
0.010327899441068874
0.012269837614134822
0.010823374488420134
0.005001342195895436
0.009149754967775207
0.005884694235901395
0.003248862202041669
0.010317545110410907
0.010972002515360344
0.012305026516064708
0.015480095584162953
0.012620189858827211
0.016701649887687006
0.018545139690084884
0.017774590659788387
0.014206021182701917
0.01466365795132469
0.012871082909013079
0.018934026208304672
0.015839448316674935
0.01792724865493587
0.023126226260613086
0.021040150942256263
0.017751451764779273
0.020431064611582186
0.021134741383739913
0.016811086466128992
-0.002221403802832864
-0.01391470685198028
-0.014004067393882918
0.008505442893335055
0.012238899355499225
0.0021160800329747156
0.013464935319626633
0.0005302832162130094
0.0038323190250464725
0.013374823148450432
0.027783066820074625
0.020018089818296718
0.022454071405083646
0.015500463110226558
0.02246986081139218
0.02119366085454569
0.002997117643881126
0.007482451660675487
0.02372232789915789
0.024257042968966254
0.003522408693770637
0.00906291666455754
0.010443820007813718
0.01578072435523272
0.0032534113806466317
0.0017441515828597169
0.004852752846109921
-0.004669534086640888
-0.009129555386823016
