# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; IPS11
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=4, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.012326492884526592
0.00268386912172816
0.019107850824825065
0.009324621305744484
0.0034675496079185726
0.006001530934834632
0.011649604878875897
0.009061116251058314
0.0032629489296314533
0.004062943452958491
0.00612670835251768
0.0017166224872857295
-0.0001293234145082607
-0.0003934417983615315
0.010747718064766633
0.01012232211402253
0.011417963498332497
0.01231620533746144
0.012420828926399698
0.015535227146432394
0.01193077679308994
0.007657209605686002
-0.0012884910999674017
-0.0012207484886168317
-0.002995597136372963
0.0009291611830930989
0.002765111942833986
0.0032068537738314485
0.001950781554715322
-0.006981209113476177
-0.0037003441899814797
-1.0325179791750329e-05
0.0035605873926885297
0.003685893759048679
0.004436030965345467
0.008524042644049386
-0.004414117752853744
0.008208025193535817
0.012651856712176935
0.0037309180041875207
0.007026353968901564
0.009901457367320635
0.010368195388540197
0.010659288608236414
0.010732082763092985
0.014392318456475133
0.002470693560311624
0.004532732514669285
0.011463003458218282
0.006583491140114006
0.008937940754871476
0.013848333676920238
0.008732041298053857
0.017492095370111232
0.014782352799538732
0.016479991775180256
0.023335481990563657
0.017680328701915205
0.016786842811013093
0.019634104553978918
0.011641274825511678
0.010194436165415006
0.012547206713487904
0.010766817328512828
0.011010404824929352
0.014311091489774334
0.005309566716730696
0.008972038184284692
0.0043870467328579145
0.005696639722554511
-0.0017101181952223288
-0.0033163454332823267
-0.009165257676001256
-0.017328197275442183
-0.001975344186269441
-0.002399135272163632
-0.0036166125164680384
-0.0020157090168865326
0.0015930106566453
-2.4427218380616042e-05
0.014659210473095914
0.013307345293965598
0.011155411037666192
0.0038647624410509123
0.00290268690171508
0.00483058991587973
0.004211781393396612
0.006665123237058381
0.014312940037887429
0.013841897595526495
0.010011867414666711
0.0053438500691250414
0.0035503859452539932
0.003131466350176403
0.0074708016745866435
0.007372630994424632
0.003492489188604559
-0.0048984190571925825
-0.0017019835596268336
-0.006065989871457879
