# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; HSFR
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=3, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.04049954982916238
-0.057000902032676354
-0.045544200211950985
-0.05006562839143382
0.030529718429288432
0.07900196665638878
0.06910918522004912
0.06165803275333605
-0.017273330305072027
-0.013954780819917153
0.07253599535755886
0.05687665685621922
-0.02271439296286945
-0.03682801576858783
-0.04354803176936746
-0.09744781596615813
-0.03777153879726555
-0.04782492230018417
-0.006232578096633815
-0.07898645577898711
0.023618169297240785
-0.019029116157440986
-0.020826879729931927
0.021109259826824336
0.01843866272260538
0.026531911645384116
-0.021777203838511727
-0.032267514155907596
-0.07216365394839
-0.060263936855580555
0.04328226828534022
0.02981986570421688
0.040702517045256396
-0.01644639902975461
-0.0016657910883877414
0.001811303689414609
-0.01332299454678701
-0.00631679173924224
-0.02390992310532694
-0.0653599784920144
0.003843953173213904
0.06934828765865714
0.03383875468090067
-0.03451799677259806
0.03759971069222968
-0.06276384229533177
0.0004985994346598261
0.038642879547607804
0.02754794711041704
0.04421028992339185
0.012670128014259499
0.007417833681297023
0.030371076736042134
0.004599243344115655
-0.011640912890127314
-0.011565877084458859
0.02941699871537732
-0.02907270462574371
0.042896562027615576
-0.01979872378711254
0.03008667057796531
0.0503245000706829
0.022139001906164038
0.02045270015387338
-0.027209087144668888
-0.016908805192413945
-0.038345886365248605
-0.020064333396610668
0.014627706450775005
-0.005307376531527423
0.03834448109776462
0.0554374547371978
0.07114477337487132
0.0446192431078212
-0.007947594033399785
0.02381984750624018
-0.09735559085456796
0.008206069605168315
-0.042166706783688696
0.03208199560018142
0.039824808152951925
0.039420521444909866
0.02577063069463931
-0.06015620882336909
0.011127331012500226
-0.0108536952830478
-0.02392827375276414
0.03383911600069545
0.016209283553132184
-0.002872203864232244
0.04352789835430179
-0.0458041911338858
-0.04560129249579023
0.0018585879632408812
-0.06717019764300844
-0.0520771420488218
-0.02773217490419275
-0.10716032030595968
-0.027101514681194712
-0.06352726562785993
