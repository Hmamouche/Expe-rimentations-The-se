# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; EXRSW
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=5, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.002069132218797367
-0.03288666522418987
-0.01607773447092554
0.04820536590621201
0.021210862603886594
0.012365962885759276
0.04722360063609626
-0.00039756214573820337
-0.02713905064587749
-0.05711864611847407
-0.021176110667268638
-0.024124395876092962
-0.056747657708008915
-0.03259317756041424
-0.041495956026729564
-0.03396609314128897
-0.01022292473017146
-0.014828523082981444
-0.021733911032303568
0.01708732313536773
0.015262802937435399
-0.009496020816646755
0.008577745016971053
0.027342439636183553
0.002235269611207919
-0.008209830178273394
-0.01797051468455211
-0.006107741431547398
-0.047568260806428016
-0.03536441608013577
-0.004437234511594388
0.0366284348919197
-0.004489702470911943
-0.02305612795612267
0.02276629802343284
0.016271593727090618
-0.039510485114083914
0.027825484794108287
0.0015993423188171672
-0.02410071813804965
-0.001286293999526466
-0.008075678460560377
0.01770484523493039
-0.010086774016196762
-0.008769170065568063
0.00463690091333945
-0.018019380898730168
-0.004227525461673187
0.00460809528758949
-0.024342759198954574
0.007894969257981964
-0.005613787060131504
-0.02327658142665337
0.03339491601310776
0.02371794728972124
0.013464155301144571
0.01926326558759864
0.004282903744447581
0.016478201749048738
0.006551440229466639
-0.009372490827094761
-0.022502431126486696
0.016595417463326576
0.0009008085020275726
-0.0043874255012148885
0.010203854412131664
0.018141385622649067
0.017555322724915133
0.017988343791614986
0.011895565998535997
-0.022909798059354745
0.017251650356333557
-0.011850338791915951
-0.0017432674385235345
0.00986816629193598
-0.028780046887141718
-0.02518899928135466
-0.004001579527187632
-0.0343394613508859
-0.013775750987034286
0.003555068313577694
-0.02360883926084556
-1.55418235156567e-05
-0.0011890215219456804
-0.006306099267755637
0.0017445127925214288
-0.009820804295175555
-0.003189068057808932
0.006337800012564146
-0.004600628805838202
0.00030387269529150076
0.009935697699288593
-0.010254480569705689
0.015035055643572348
0.0019971753900656086
-0.014511738228023
-0.007267839811620563
-0.007212800724015537
-0.023682992717026934
-0.012648001242605811
