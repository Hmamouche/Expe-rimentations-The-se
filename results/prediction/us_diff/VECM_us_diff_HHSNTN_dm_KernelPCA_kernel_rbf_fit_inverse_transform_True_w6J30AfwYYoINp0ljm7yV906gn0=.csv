# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; HHSNTN
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=14, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.17422391004499138
-0.19543306097274354
0.09230496522044482
-0.28408497853221815
-0.021350309546654667
0.17216432554034192
-0.11553590659961371
-0.06193615578630871
0.24583146003667927
0.14626095102020528
-0.043385909383690045
-0.0730953505971556
0.11946373478976804
0.0034252327935410665
-0.06548354347873256
-0.05344746424243993
-0.11211642746837387
-0.03761737414808097
-0.07490706697772315
0.2282015441335325
-0.0010861321290479321
-0.007643091748338993
-0.002353335304787905
0.007013584522440844
0.054785070586452475
-0.028563345915543315
0.09294743383907034
-0.06995660646269926
-0.09364646454717587
-0.039448398294223
-0.06259680283599559
-0.25443143225866727
0.0814795125536824
0.0030722893745197353
0.14161724488894128
-0.08250256121344238
-0.01627955469039826
0.09782628030475413
-0.13091777525700632
-0.022621637898740048
-0.015265937150435418
-0.060605163752173064
0.029997625405293576
-0.008060615877690261
0.013517024480991704
0.0748159693547022
-0.0445902702552507
0.003281388350779974
0.17674541668818036
0.03292620947819009
-0.07783263361955031
-0.08294897520241865
0.06491719838560861
0.04502487399989198
0.06413954601233747
-0.00644956244222665
-0.0002982059085622213
0.08117645683933628
0.06713258092064817
-0.03596158339011606
-0.010942516827479525
0.03539806650683908
0.04347258857031101
-0.18351594488494374
0.04247439936190271
0.0929065047940579
0.0211918671073831
0.04265532008434458
-0.029026203306370207
0.009991885305816038
-0.01026715062469528
0.069589422188237
-0.09362660131095048
-0.0010590048500578805
-0.058846657258761564
0.04904754373673574
0.05748722588869199
0.034098966796154206
-0.1957368913421584
-0.09431011287444403
0.025071878269790307
-0.021471716961373066
0.00920071250813409
0.012902861671681521
-0.012184170828533954
-0.04176163349570483
-0.0312978741508711
-0.06974950357153348
-0.029545723643931685
-0.014269932343262046
-0.059883432702633466
0.005260297004474827
0.057713775600918116
-0.0032542330790240465
-0.09193007975472103
0.12314763111579143
0.08843480126596087
-0.058970942875619985
0.02298338484070915
-0.03561644174666285
