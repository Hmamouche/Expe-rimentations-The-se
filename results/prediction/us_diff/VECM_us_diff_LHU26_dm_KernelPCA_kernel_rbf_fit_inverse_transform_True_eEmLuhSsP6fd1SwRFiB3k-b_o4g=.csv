# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; LHU26
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=4, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.07123561023089217
-0.05183184404867522
-0.09966924218576902
-0.005461741166173404
-0.007707622616031895
-0.0120104359452624
-0.01696018538416004
-0.0022531304714746916
-0.004387504933637658
-0.03694672777616048
-0.0002338367670247912
-0.024211195472591047
0.041856872011604866
0.005938505175181414
-0.011754021421987296
-0.0017203812347831074
-0.07038464767986709
-0.023884248935985532
0.018535078292417413
-0.06439811015642334
0.006098884467697831
-0.06089749211943534
-0.0010632917687410273
0.014517546225079146
0.05539099506153964
-0.0008807424961961859
-0.01104840498756706
0.016337707692501292
0.05643708797256715
0.07352663918910625
0.08019212505182256
0.040558292020819925
-0.039494842465205085
0.04207202417055071
0.022746310178760516
0.04738224921483134
0.0273659474564851
0.01935762847372772
-0.032269550138887104
0.02463092528888005
-0.03802821695559994
-0.049290184081443235
-0.020767988483039068
-0.08469101716994187
0.006675101715908521
-0.0591145522731948
0.02919495173448787
0.012958882771567981
-0.006240293779233833
0.03738025921054475
-0.01805235697280885
-0.01104521212901689
-0.023055662620052986
-0.03508301684865323
-0.017374879224163968
-0.020277842138176645
-0.05694121756194961
-0.023143141300501793
-0.009921209528808244
-0.01069573838785692
0.026516262203896954
-0.03449914068535066
0.006263144366456065
-0.05025497619844599
0.0015377980920283536
-0.04465945125505753
-0.01380116408516975
0.011576127256382135
0.009510001411726728
0.02427100380492904
0.060564931653438035
0.06472562295635897
0.062192240621520754
0.09415651172366912
0.030412740344520083
0.003489645732500401
0.031051191754128484
0.05497169043881661
0.04143094602956558
0.02173141353895929
-0.010371726079047459
-0.06444993535520055
-0.03770209706041573
-0.03094899532665926
0.01428642503742189
-0.02472900273138079
-0.013137632429763823
-0.015484776319676211
-0.0164600391158337
-0.013039323935016736
-0.02394652580478826
-0.032872306043164004
0.03915230998320065
-0.013418294738977436
0.008889038450919479
-0.02687821468861979
0.015455119100979754
0.05032971946446757
0.04194133403811818
0.07942077013210126
