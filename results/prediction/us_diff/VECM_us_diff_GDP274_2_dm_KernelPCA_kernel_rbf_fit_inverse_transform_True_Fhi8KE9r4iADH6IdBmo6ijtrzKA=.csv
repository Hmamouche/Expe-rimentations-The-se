# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP274_2
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=12, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.008312636070594256
0.0007794541205821976
-0.0006731530961042063
-0.0019494229160406961
-0.0008241030281085368
-0.0033664163203010414
0.0009674440826830263
0.0047482018348933555
-0.022155775772080485
-0.003269566007216251
0.0071409215621387676
-0.011062649757200197
0.007332620834480894
-0.004633468273648224
0.012059755301691016
0.006824419058978078
-0.013515041855204041
-0.0016971332547814832
-0.003357474371316723
0.006958626332015352
-0.005791194018001259
-0.0016082940943904448
0.008003028659033207
-0.015505912156969068
0.0014748936028392673
0.003885003638535226
-0.002970917311215597
-0.0009631575758386516
-0.004878461943593742
-0.003196046126365897
0.007716910841878599
-0.018145598831476456
-0.00015414456587190364
-0.00797412283537104
-0.008836847541255816
-0.004539250951582649
-0.008274842835098417
-0.0012977752025106534
-0.011418840493862445
-0.0050437757232750955
-0.005810152261635065
-0.011802523334151127
-0.007183395183493248
0.00416832753996157
0.0029317997835104186
-0.01419729295751885
-0.013528556373778455
-0.009443830137441628
-0.01312669877416617
-0.019696774018158888
-0.014916930876532895
-0.027211244411210277
-0.015499578941403847
-0.023590411077512207
-0.028230840642140265
-0.022865468773700614
-0.024770713506667635
-0.017956818083544206
-0.01987771279000672
-0.017969601559586282
-0.021881255638369214
-0.029255063285530094
-0.020527248776187626
-0.01856468283644833
-0.018962392558822143
-0.02330922457588189
-0.01808429023492544
-0.007412839193447337
-0.01480237248565773
-0.017790584954947463
-0.018162908140677492
-0.022905268752562345
-0.01645039187147223
-0.016894102133198398
-0.0169019413560355
-0.015311311116051463
-0.008048021445369487
-0.02375547987526596
-0.02155414676567951
-0.016084446006035372
-0.022214202055191885
-0.012770433954159366
-0.0025941057645759375
-0.017671498218407158
-0.013626674239478491
-0.008821386665959708
-0.006814092818996875
-0.00529264448200395
-0.015855725612241467
-0.01289741838508288
-0.0071981236802603436
-0.010532747187001886
-0.006242513224551926
-0.009495687141430426
-0.014629814922567926
-0.006205149750096129
-0.0067277404214173345
-0.01702252910899724
-0.007906083155913115
-0.0049853663118997575
