# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; FSDJ
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=10, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.0013574173100476044
-0.0032826301064955987
0.0009602465692118912
-0.01250407381863366
0.003042912131625008
0.002243378413494951
0.004483977527220727
0.0014380481017224063
0.00587161735939919
0.006918343896800009
0.013870611528976218
0.009260779160613937
0.0026624603558613284
0.011204349012233137
0.015682282902186494
0.000977892863218355
0.00567777354477054
0.006357242586547643
0.005938679485615023
0.04291722136808617
0.0055238555600201555
-0.026567328511693883
-0.0009270889877812879
0.0023433152311099835
0.007838500893229657
0.012258682520973188
0.005426349400196962
0.008536819306931084
0.0025155129440996523
0.002419643720106968
0.014865135367172943
-0.014129628159324455
0.006597967548624948
0.008016167420816844
0.013930547716492244
0.004219160255677079
0.0014366848952042646
0.005526955601256892
0.0004021910681781234
0.002974917068332674
0.006865803601374083
0.0045572221882088934
0.0007498649290429654
-0.001850586717013147
0.014181580527499755
0.00604731587261634
-0.005044443857206191
0.01195182383594644
0.031216078188278523
0.019908028371841403
0.027483589887053256
0.00835512665119145
0.016498379543462532
0.023571739808754134
0.026877617488227624
0.021353655330629984
0.04349766679501435
0.038446262041149225
0.04723688371044293
0.022921079924926237
0.05038877259127494
0.03245322591259252
-0.012876753287320462
0.018247557938166466
-0.001451688290180676
0.04613736924209185
0.03853943602609767
0.04041227404195156
0.014172927000886655
-0.00973126522020397
0.008396110092781248
0.0003363749476209925
-0.016082166252963128
-0.012262912535764503
0.004779323289128043
-0.017204967792779052
-0.040273174909811846
0.009954193586005312
-0.054834877415617794
-0.023283502525392533
-0.037485862785362124
0.016259896811144054
0.024582215215324166
0.014672448691545652
0.016418844771709844
0.02615496858528823
0.045094512544232024
0.0006518872340500401
0.0006385080430931587
0.006915303948294161
0.02555719515262936
-0.005895291065736279
0.021098123235193732
0.04615213048269745
0.01390392579473252
0.04074249765646509
0.03812910399966453
0.02837704020580706
-0.017508486875856592
0.0006261219529481738
