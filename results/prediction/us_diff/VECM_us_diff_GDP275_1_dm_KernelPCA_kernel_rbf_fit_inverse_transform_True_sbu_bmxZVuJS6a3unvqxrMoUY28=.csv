# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP275_1
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=1, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.002166859409354474
0.006041132617280255
0.008826234761402466
0.002972402432510849
0.008355948305913179
0.0012225371202367046
0.004966990014979957
0.0010026318548753417
0.0026404591614708267
0.003915757013432472
0.0028924744714088216
0.004393492463716048
0.00705424689710753
0.004181137130982826
0.007604599581115019
0.0045773097248401964
0.005193466668582557
0.0041431732946062335
0.004556729044369974
0.005893655790749348
0.00846854693132171
0.006005968485826256
0.009942111380919447
0.008673791786817235
0.00824267950274899
0.008402904816498647
0.0106355435612407
0.0049926303342542715
0.010746049558663727
0.006042575011509492
0.008644466440288748
0.0077736431973619785
0.003997874734422372
0.002384557002188738
0.0028264149161224576
0.0017687371299579344
0.002898555699924722
0.0025936695144680335
0.0031598187696898292
0.002856997748781951
0.0027780971020749225
0.004729335939327284
0.001944378299652502
0.0036236133748071115
0.004464205138958107
0.003739446826503643
0.0047991506940645145
0.004702526363065287
0.004718241983239116
0.004019520921583013
0.0038683159112618947
0.006094377306088051
0.006184055744117172
0.007826181166046019
0.006042417982327525
0.00500580193708853
0.0040015588164585
0.0034621655057853347
0.004139692928690282
0.0035470060600052366
0.004090194932858021
0.004167251885004094
0.0043503834666177655
0.003823441837760652
0.004054780442235563
0.004844874104613934
0.004723159207053419
0.005470089811846803
0.006919688042197741
0.0051016594859493855
0.006876863154883028
0.006018017720822765
0.007453006178357832
0.005551916760731767
0.006966645740941994
0.003382631473909736
0.002574518662404615
0.003942306114288167
0.003991830898988053
0.0044348200176645616
0.00561369242299265
0.007494571431746345
0.006754110807564558
0.00968385919548332
0.007963290191882055
0.007688461374101633
0.004723203996789496
0.00649250610064426
0.004696807776213177
0.006493039403654498
0.005684156439490451
0.005135641682805997
0.0072848475657552
0.0055973554094700395
0.009555329964005054
0.010065109793538257
0.011859728741519986
0.011751105833084578
0.01307078873195878
0.014729896882031376
