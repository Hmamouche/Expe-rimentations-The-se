# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; IPS11
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=14, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.015444278167335217
0.0028896813606757565
0.03132645636334491
-0.021455575080799944
0.009173008319648127
0.0054467274387080605
0.010097898754397336
0.003032269072645481
0.01745134670737608
0.0037208338524206998
0.01855920534687622
-0.00416985791322675
-0.005728716128910268
0.002928365246100168
0.004580024056410203
0.018009144900814806
0.011765579896753272
0.002285090827827554
0.007740955755455144
0.0068529631882372575
0.01220665664430089
0.010543730045902507
0.0005143441080016544
0.0020010357034723034
0.0007004184692388457
-0.0012687307209058667
0.005123344140936965
0.009826769423387428
-0.004300106208079857
-0.002630220284371829
-0.0011495082907831524
0.005471437685315622
0.0064637325088725914
0.002873498795041219
-0.0061210912673243184
0.005532321743142119
-0.0011657458951198337
0.023350263370648622
0.0030730896839313003
0.0037787574754244812
0.009581883166737202
0.007165278960973371
0.019820111642024837
0.002736248669635336
0.0036047235963248343
0.011662469284450498
0.007777691631965934
0.006505930779687735
0.010459415005769367
0.006610350429571935
0.005405400912783139
0.012926453195505129
0.01376223327085812
0.016850565282187528
0.012318279008406742
0.012563519582667076
0.021851493790144488
0.014520476642471362
0.018932162302358092
0.01760091466038485
0.00974887269371157
0.004150871271909125
0.017178382431695647
0.008199428230730985
0.01537815830258165
0.015168627211828125
-0.003565479904724683
0.012519368918155093
0.004494331867813431
0.0016617514991473783
-0.002019948422055242
0.0005835946575563902
-0.01745255730034374
-0.013400502160688369
-0.003788408515416172
0.011428488222513626
-0.0018226419712782556
-0.008520380905415785
-0.003844400897999411
0.01712866424426769
0.008121755870644419
0.014541513926309622
0.0078204945456289
-0.0003483617899796847
0.004915159171625135
0.0041599146906047425
0.005198063136568488
0.00973465067707709
0.012185623195874991
0.012840570346568818
0.008078380044318694
0.006962793546644757
0.005276546280744653
0.006727442345100869
0.007837803436638565
-0.001278442647626528
0.0013729875000831405
-0.013689000319238087
-0.003037644599104459
-0.003123542808341706
