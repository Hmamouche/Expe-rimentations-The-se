# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CPILFESL
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=6, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0064361299608335105
0.007686628818092371
0.008877980586041563
0.008989336756747079
0.005890042629570405
0.005086968895724513
0.007376341635754504
0.004367807571491882
0.005942522931873962
0.006289474910171306
0.006655810756049512
0.004650177446508589
0.0053467134629493745
0.006723453659280505
0.0054956578418296174
0.006312409448988629
0.006690425269176542
0.007283633778171397
0.00724615174681861
0.008868262173986924
0.007200870907236876
0.009144516082853368
0.008075212392334583
0.0068242987328585745
0.005913729244010953
0.007592689767366679
0.008526271419883397
0.008836162385838625
0.010268446369138658
0.009433585148386756
0.009479988861668861
0.006513429812782577
0.00836307289069877
0.007459945995214722
0.008562243311047178
0.005681918760967335
0.005110596376611374
0.009203774394760243
0.007099827349013343
0.006256959971321752
0.0065791401229666965
0.004680475835183887
0.005740823118983815
0.007221616917948059
0.006478316280105658
0.006917923863214261
0.005902305149536087
0.006930676335564228
0.006761200283447703
0.0043863669550651884
0.005133443262933546
0.0064449640521505895
0.004731889883714396
0.006297651717208003
0.006428890552713721
0.0052114564162697875
0.004636252790611288
0.004991063344198756
0.005199335224100258
0.005187682977817059
0.004871649512705462
0.004965967515613098
0.005620512311826716
0.003972386153091203
0.005035867257167771
0.006498457901576361
0.005947372662195053
0.0059471623670309575
0.00676234659496575
0.006244547336703434
0.004864425952205879
0.005444059801755581
0.0060060053797708355
0.005776699322205514
0.008766281941007387
0.0047201780957563215
0.005714300923093759
0.005463098619912362
0.0038913402250332647
0.001035615755680835
0.0035154994233456407
0.003480436443565001
0.004527235231489916
0.006878971300191259
0.00535051075923794
0.005737436390038432
0.007024754248128372
0.005605249708381567
0.004515827328567775
0.005706129990877667
0.00650292492635236
0.008781612837884752
0.008456302676817979
0.006075090214535749
0.005634857561630954
0.005993897456950335
0.005415419104518544
0.006743359469138089
0.006228828383395208
0.006467813011130871
