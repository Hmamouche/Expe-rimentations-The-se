# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP255
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=7, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.006453750775693651
0.007709950490295766
0.0034650457487918175
0.004123149275105871
0.0028842856964715283
0.004623657541893514
0.01219004057140207
0.009819217232255647
0.009334329683716633
0.007283238714509477
0.00517381611091543
0.0048213970924256165
0.004810821042803883
0.00362304288061536
0.006483052913275933
0.005764620436638036
0.005371550822487912
0.006534841115445253
0.007757007867317778
0.005810210655981884
0.0071380634040258545
0.006663695776914381
0.004401950450825018
0.005189958079437841
0.005291104404470677
0.007003883389995599
0.003707853582654254
0.00580251368044357
0.007134406856136836
0.003871800869079796
0.002026966104971652
0.005088967141212145
0.004025020227370082
0.005563849618675424
0.0053065387188195225
0.0040517406947193566
0.007050340475482982
0.007536190471752964
0.003932466761924688
0.005412020764701367
0.006665246629601398
0.005034629006143197
0.0060881459027152
0.004802976831867905
0.0035729050874720517
0.003835230936729488
0.00504705690321615
0.006765505693756346
0.007662592587719253
0.005956575535344861
0.008167720441569949
0.004688664520074974
0.004886161661774526
0.004947894805954313
0.006250471004209388
0.007685675284242298
0.007294831872668356
0.008508449879427926
0.010494679450834023
0.010159574768212488
0.009401069085728164
0.0075303104303823445
0.00838802352996362
0.008365231016743833
0.010437861370741491
0.007325830124390868
0.01152074759336941
0.0113663909671958
0.010505402372656179
0.011223544037302295
0.00903149121073428
0.006957679898415011
0.002603929009338061
0.0062275259996574855
0.005222541528523681
0.00306201885808894
0.005598401396619002
0.005178636297543163
0.0026725570752102025
0.0059739866679978364
0.004618298997618234
0.006552762175248129
0.010150378083568048
0.008157478472796598
0.007741991931497001
0.008440634717196983
0.006495675014306724
0.006678291153297658
0.006764371377931976
0.007097358519027207
0.008211010051536457
0.005686276836064051
0.006736860736547876
0.010257341439068956
0.007163997055379759
0.007245243707572176
0.009548064276769823
0.00438044846046784
0.006074669016911534
0.004109424083992473
