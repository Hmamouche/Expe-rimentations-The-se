# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; PW561R
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=9, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0013059432688446865
-0.0855315312071436
-0.02347164199189513
0.012392856912045773
-0.028992529195222584
-0.030922404244933227
0.009781672998614013
0.00571081208089109
-0.017177837158540432
-5.190454773046013e-05
-0.049167026285173325
-0.1205902133295179
-0.0066285742949549215
-0.052922177710700964
-0.025649507377822112
-0.02163586071374088
-0.004991523815460437
0.0024807149627062864
-0.020538422708191072
0.024773494195491602
0.006771947942080455
-0.051693598382707893
0.03958800619314029
0.011129676930898313
-0.01806301831995521
0.017139993801777564
0.024310064951669416
-0.06238824406762209
0.0066859725013971956
0.05096641020590657
-0.02899563950689943
0.0873263240288381
0.0022389035370402443
-0.011266059847530919
-0.0963284787814844
0.05397051630723184
-0.019384262050620056
0.005851561878732172
-0.024317554813511687
-0.03313871839688204
-0.05332390839648652
0.01902120005283684
0.0015259493958489755
0.021758798333165706
-0.029320871918715505
-0.03781594847015187
0.0010499584322158188
0.016443480138321944
-0.04261251790765725
0.028961262570945973
0.03364974198134511
0.020897662850043207
0.028514441088571534
0.030848475007993755
-0.03553698560041534
-0.008893781475949955
-0.0019168514951397736
-0.024212748199495007
-0.025456185512830354
0.009201014181348652
-0.012008976381441664
-0.01693624790401867
0.03472234296365293
0.0323279407292716
-0.012439378502457347
0.008735914127488413
0.013820984186766014
-0.021970189108422786
0.0419285581482489
-0.022170652658462197
-0.011600806724207501
0.020994306399195767
0.024709090429529998
-0.055799700249879514
0.017736649595799046
0.015017226902829233
-0.024884986078043535
0.006264511657996234
0.01452166322328935
0.007713211859996298
0.030454282899763437
-0.0190293557045366
0.007499185845177536
0.008172660770966136
0.019397551138279533
-0.013963743193692278
0.011686655285241938
0.03881539244130315
0.0586960343068742
-0.006309460403234334
0.07707328461478684
0.025175616728293482
-0.010494348780608127
0.00819390857735759
0.019032777349015418
-0.04003769418952942
0.030059317814547872
0.039100466957477695
0.05179297216230458
0.2048366328243989
