# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; MOCMQ
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=6, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.01287996282869098
-0.019829697160884667
0.046304464449572307
0.004718487629296457
-0.008220829415144338
0.014876157566726559
0.022010729135949855
0.004136618339080897
-0.009510493637424856
0.0005406669934334054
0.021201273481964954
0.024017822364561122
-0.01852540144619435
-0.026423310522667554
0.01102845484685656
0.00039433629281701837
0.02283500694429983
0.006401244123826573
0.015248719459218182
0.010147893313421755
0.012874999251032542
0.029709077794509577
-0.002717257993355598
0.0003155897051938285
-0.004003611722529525
0.009942158604095808
-0.006962276064013651
-0.009961342057273514
-0.036299812834863505
-0.027068699588819616
0.009963088313827069
0.026036826427919574
0.02928784356220008
0.007452335594591651
0.007820916325794715
0.007798952662988374
-0.00560309785012502
0.01994837907532439
0.003859936842953715
-0.006215295534228133
0.0012010021034778518
0.029505245267861246
0.029972490941867772
-1.1910623439584204e-05
0.021888112626463233
0.022776619662046728
0.002767731038844339
0.009141682482779537
0.010464792462989644
0.004137886581417083
0.007805980963407442
0.0004823319965209004
0.004404039963348649
0.04015092693324904
0.008346394032886834
0.028051469443781046
0.036460279464222235
0.01140104389484074
0.025110560184432744
0.001785227811886195
-0.0016304011855362097
-0.00832407688512103
0.016166526425385217
0.010086036917443947
0.021424407658327475
0.025288765407003533
0.004360227098824549
-0.00987727899396484
-0.008637576194124561
-0.01001296881417604
-0.017487318261114073
0.0010172054827775104
-0.013069889031799464
-0.0276529766971709
-0.0008234243515465138
-0.001574957671554085
-0.017202167284758374
-0.007005896655416033
-0.02066480012302304
0.015838030715064674
0.026409361074254078
0.023285932477481466
0.02039036807196828
-0.01570100850427843
-0.019845808697874667
-0.01086536009216713
-0.01765466388698841
0.00320937992621299
0.013614050547802448
0.013518055959934615
0.03269125452715435
-0.009784063489551366
-0.010658357131315476
0.005097370275878788
-0.013479382616658295
-0.004298274657349999
-0.009399084754672458
-0.03237978122784829
-0.014593281415009676
-0.008995621740583602
