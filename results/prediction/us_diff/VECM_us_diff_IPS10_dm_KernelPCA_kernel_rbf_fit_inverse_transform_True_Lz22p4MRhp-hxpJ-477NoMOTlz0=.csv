# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; IPS10
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=11, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.006715043062328929
0.011119774529780796
0.0067588263400345135
-0.009443694877738981
-0.0023393017793456776
0.001639435586059796
0.011917183557914404
0.006696253189103892
0.00602577516698531
0.003519033234640756
0.015386666781869134
0.0006451052919109771
-0.0009587692885063151
-0.0030390349283577704
0.005494825343522375
0.013867269458393061
0.011502167072154047
0.006060343137920166
0.013138681702845262
0.012060211772648245
0.008350522148504128
0.01648033481994888
-0.009122021556049437
0.0005270155885845778
-0.0058501412211610085
-0.0013349247005539717
0.005153684251552728
0.009922370073156748
-0.0009038374612250271
-0.00794938700988506
-0.0020535163430084307
0.0018071726682277194
0.009579210975491725
-0.002842474296978058
-0.0009736236639932335
0.0022542524799773474
-0.0011626544021369428
0.018493843409121625
0.015678263080531028
-0.0031137610239930905
0.009024443419123509
0.010019352835209673
0.017261979221239128
0.007998299794408895
0.011379475958967562
0.012430924230121428
0.0092934687368374
0.0046063881303592515
0.0027669814848781627
0.0024147284686680866
0.002361503453939077
0.018569502022699313
0.016979531295555954
0.019057177293048948
0.015920630616330998
0.01273451023142647
0.022120027859806577
0.015854245124787326
0.01761288257927943
0.01756072570354634
0.004469688109822264
0.007566371146525152
0.01792395039059217
0.012441231693341489
0.02061312888106198
0.019701722087104565
0.007506355598704729
0.010468902996789266
0.00513125025772602
0.0020252959103375843
-0.005554563843262323
-0.007149312039742426
-0.020083565988775063
-0.021236074284188812
0.01650978545507279
0.01117685479093907
0.0041363754880767096
-0.0019408346301467987
-0.00608308328522007
0.009934460647734338
0.006368386944107098
0.014728413289516948
0.0015024649919890363
0.00499533669530599
0.002375318747688626
0.0015184518840067282
0.002523605169816816
0.008332065113037669
0.014189709673606886
0.0058256601200307985
0.014209140016431254
0.002838989349705636
0.0018986298031311143
0.005068580844221999
0.014303331523646818
-0.00245223181990129
0.0030144261597430107
-0.005218068002786395
-0.006291221483849515
-0.0015351549084159759
