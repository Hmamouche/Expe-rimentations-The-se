# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CES003
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=7, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0452967003252678
0.05833263436444496
0.03636520120407751
0.017943290799960605
0.0033942311350155536
0.006777442250673678
0.029410322830957965
-0.007940613699086555
0.000639324517747647
-0.01289454017516175
0.011381212889562372
-0.009152338550230335
-0.036286385181850275
-0.02992083730649767
0.008777351201295719
0.027351987080738695
0.030621125235692586
0.018774570421507705
-0.00166174615960527
0.03220625675761242
0.034375211959723664
0.05824654235574425
-0.01466151357222447
-0.015133476307258288
-0.0331331111761015
0.010378622650935861
-0.001840271627295829
-0.016701426486831022
-0.06672088704293731
-0.087612909200442
-0.05479574798225397
-0.028316640517690422
0.02820439031930418
-0.011034178280228532
-0.025445906368241292
-0.02567714030425841
-0.029154180979075968
0.001637103304942579
0.016859207603272627
-0.024249116231567405
0.027453651262903216
0.03065518988926953
0.031036700219691397
0.02824388461868228
0.017236866688432488
0.02814492846620749
0.012503400849869018
-0.007733383383797851
0.021989414229758555
-0.004898389349154402
0.0017384029938336178
0.015004619868743803
0.0034545075133821865
0.02618420955461785
0.03028255652719479
0.02474288634761514
0.03267755372788113
0.019043396168198744
0.022137906043522296
0.00912089700017659
-0.009781000950912421
0.0028988476926283657
0.012087548930878876
-0.012320834871225957
0.023706390915577608
0.023751739540808198
0.004678168763223305
-0.004615505914883222
-0.0028486930634910126
-0.012132234483253616
-0.01983372599561897
-0.051673980524601204
-0.07428717790822637
-0.08394783746164015
0.012402566349285679
-0.05161646792520886
-0.03780348147265766
-0.038133520388433324
-0.05072650832071184
-0.0181614520653339
-0.003628604541965414
0.012605680275663458
0.0020977260672204474
-0.0007804423197828542
-0.0037375321563817444
0.013036650441170496
0.006631514371456369
0.011581666610519669
0.01849560617620449
0.007566134143442564
0.042057794413625796
-0.00679908288929139
-0.016467831651208586
-0.01056385911620775
0.009437324228296845
-0.011139855924014482
-0.021738234379237276
-0.046352144043512615
-0.043270598150945
-0.037721587930815856
