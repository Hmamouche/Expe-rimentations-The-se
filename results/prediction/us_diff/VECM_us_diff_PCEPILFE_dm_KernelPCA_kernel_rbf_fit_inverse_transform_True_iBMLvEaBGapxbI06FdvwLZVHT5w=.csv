# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; PCEPILFE
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=15, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.006944493731838159
0.007793322498213002
0.0038960472437494283
0.009124962194789704
0.0065067237920190925
0.0053658621181152276
0.011828878430943716
0.005608326062414085
0.0049646025440314885
0.0043292004368625184
0.00585740202197467
0.004425082661894235
0.0067320377196366625
0.0073829349865643205
0.007529086739678292
0.005271188779508574
0.0096740898960102
0.00843371572022697
0.010048885148920335
0.006997762532873351
0.007128672860312071
0.008518123824285968
0.008270551732201176
0.006753494037194859
0.004647378052726142
0.008573142200400083
0.00842138739036297
0.011030100823024313
0.008560502310742549
0.009672783560483305
0.006033849506516904
0.00487215487818988
0.011678442902158423
0.008899693235840885
0.00844931825481569
0.006532931528994202
0.00730525581862808
0.005991909627403914
0.008961111400632422
0.00436675989374074
0.0061922504467049585
0.004162925503460777
0.006480335870132534
0.0057954607096201245
0.007225277452986613
0.004497051077624469
0.005131157802315069
0.0026009981258208184
0.004105764890837282
0.005881092156506591
0.003002259650952912
0.006718991018363224
0.004949091777045564
0.003948970704532945
0.004805948860065353
0.005042931982798012
0.0030459214996673457
0.0027119245016191114
0.003011622880480207
0.0019604084212331433
0.0037152325588283176
0.004209982298374373
0.004610222068278202
0.003418916758440774
0.0044071188231702245
0.006706274557254767
0.003402852484269176
0.0045165309512992585
0.002564145439074344
0.004433988014227107
0.005047294266741846
0.0025254142850016092
0.005737783698424164
0.005694771139195486
0.007288119184291783
0.004645499521813315
0.0032562801045504953
0.005098448009856012
0.002924934832380115
0.0022520773849822083
0.002998149507544029
0.004714431786652171
0.006561136966013845
0.006271332210295532
0.004588179145772357
0.006149988008054838
0.006446612230113023
0.004939776838507239
0.00497047180784718
0.00889796581766626
0.00624131150340518
0.006536987374317606
0.00783574370446854
0.005331626300030142
0.007104657080774393
0.006090202668638988
0.00655009215217402
0.005764435822467098
0.006611687424712477
0.007002112741894588
