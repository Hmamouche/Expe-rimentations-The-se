# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; IPS11
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=7, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.010457366856237498
0.008790187411400082
0.020014307701966227
0.0035160053075780715
0.006956900092940864
0.001508268493974843
0.011419460006505665
0.005656084151659402
0.006209619767622628
0.0012378177837493792
0.00993724923424156
-0.0013533466533899867
-0.002166864100642289
0.0016483406291334698
0.011299401840897814
0.013635531748076008
0.010415808456994994
0.009752073842421027
0.009429896415778056
0.015161569610954398
0.014458599959427791
0.012823692540841345
-0.0036655073959300376
-0.0013305269984999536
-0.0062335958092949294
0.002963521277221016
0.003512408008540694
0.005611835711267239
-0.0010882674312568097
-0.01189264672076968
0.0003746748144448442
-0.0006063528580138686
0.010454040337242163
0.004212336037088805
-0.00217905524239105
0.006151250599826675
-0.0035715669807212407
0.014141713416280517
0.011852888059189635
0.001855479517021207
0.00931880269766358
0.01277690683875194
0.011022193558821156
0.00986566729431002
0.006493291176503739
0.012768289541792596
0.007547006679658473
0.001905616537138359
0.014646545620306605
0.007064264792739673
0.0069068882778711045
0.013293538040230379
0.010419487891530256
0.014690442145660456
0.016384443616988122
0.018167393907277788
0.022538872171118964
0.01757432432764108
0.018546568491029567
0.019242435890869505
0.008780026749894278
0.008148959599309138
0.01317620056324638
0.008075589881950703
0.013088779841662405
0.013012368691284516
0.00787981476285921
0.009164805092836601
0.0031535544508064116
0.004317098152232139
-0.003247201585832438
-0.0013728236189598808
-0.012915874148782104
-0.01991402678975382
0.0024367159033179815
-0.003481112223966019
-0.0021221178448350753
-0.0017224172462964853
0.0017022394634157638
0.008392434691177392
0.010354844890979369
0.01260762612506157
0.007260838646226734
0.004335108198953659
0.0026977956465092136
0.005999577767323149
0.006843401907069205
0.008793609484820683
0.01305837241906337
0.0113547696587495
0.014399554653278045
2.9892426640980565e-05
0.00467572053654703
0.005561030113911115
0.008808685184065529
0.0012153210059040018
0.004532845789213893
-0.010418490146140203
-0.0027783304525880715
-0.008401670511152069
