# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP252
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=6, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0016077733047476172
0.0038779116375393537
0.00983415151904607
0.0032884564942835225
0.002793852318301639
0.006244536988604638
0.010690034554024612
0.0067391058577358975
0.0071947917033126935
0.008212089439966187
0.005810988095421238
0.006025053528110074
0.0032845286668342502
0.006291833744186186
0.004754791803062766
0.0024853852883135433
0.005863059275616091
0.0049885232710491206
0.004401206210182007
0.009785616501296375
0.0057140560196845625
0.008876824950333392
0.004681027058441405
0.00290900624148588
0.005388472610086807
0.005513398318504048
0.003823189110154882
0.0024470829635819574
-0.0003182795462761571
-0.001074210422802562
0.006860979688396664
0.0031534409160184854
0.0049530165536981075
0.0024694180921204806
-7.639590510414261e-06
0.004182225306490135
0.004536948732137562
0.008596527782023787
0.00679095673844943
0.0030167319478074657
0.00648736123469699
0.008742153271471495
0.009062212774952585
0.003429186732156669
0.004677547150443417
0.006204548852054311
0.005214052042915567
0.006440194635887415
0.007734745538270073
0.008327212214870984
0.005649690050416779
0.004971983668158122
0.006952992063370668
0.007844969874065126
0.00506598584176177
0.009071446770395725
0.00795900968651785
0.008438272766585535
0.012370978113529116
0.009029259881403308
0.009896374221928485
0.01280019966104951
0.012610463015870581
0.008519004196809342
0.009632962863337693
0.013618805107952606
0.011071285613029919
0.012921883203075975
0.010553991402789962
0.008181771625212868
0.00957971424094281
0.008663491760486749
0.0035423273364260637
0.005701598938810996
0.00954078667653418
0.009751371251492924
0.0032733064245753264
0.007402047513579672
0.0015518848784652648
0.007631892085859875
0.010413753640103132
0.010935819465019272
0.012824575556281591
0.004805831187861589
0.009799975701245812
0.00861150403505093
0.009095895482700248
0.009386290896559825
0.006375156925535208
0.008521308553411738
0.010923477013706844
0.004969588011477781
0.007140946781562248
0.01303600626022649
0.007394652815913001
0.009420983238600427
0.011626599064009428
0.003188418706674074
0.003412072962503786
0.003164111370931629
