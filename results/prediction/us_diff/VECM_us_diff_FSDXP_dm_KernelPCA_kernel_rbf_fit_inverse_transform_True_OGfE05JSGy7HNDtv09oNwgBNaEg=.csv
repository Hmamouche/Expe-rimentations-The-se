# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; FSDXP
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=7, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.020950852437441814
0.13519519858135795
0.05830348466226986
0.0988034308821651
-0.04615991227487613
-0.007711847650880548
-0.10651174185806966
-0.03748134612762777
-0.07902576312778849
-0.03680124398431731
-0.06898965111752495
-0.03206694199201735
-0.0431222867788093
-0.013438161506430983
-0.036210165589644135
-0.02074011048104004
0.0400788873536423
0.044594861509795414
0.03243169073605498
0.010035632156623293
0.032119002333466755
0.027074905330133712
0.0002741830709010497
-0.020703690909516546
-0.04717015892642576
-0.031427871473989503
-0.019491563512036136
0.0036875585277771636
-0.0044119899861212175
-0.015767356042499237
-0.06881469499873444
0.019035510173923322
-0.02657747720126194
-0.008831912553657324
-0.013294474752747677
0.037044599245073334
-0.02589614077950146
-0.014008688577625042
0.008748052934246818
-0.08761954335192076
-0.007835104236105322
-0.024984302745956276
0.06297152732415785
0.06559124109304633
0.037796739832970064
0.035049801809247966
0.008181965179852025
-0.055814382183804884
-0.04506477709031099
-0.03647744640823613
-0.0398102053641687
-0.004255440420361592
0.011481283492580673
0.009663319797992854
-0.021750629925641952
0.0207080905297773
-0.003522345482456085
-0.012253747985987447
-0.008392332103794153
-0.03227636256315617
-0.01422253166499507
-0.056494843428057016
-0.021301950383148124
0.035209798346199105
-0.013943808347612018
0.032836832425277594
2.9067591694948054e-05
0.01035381606188817
-0.02985186946927437
-0.025571778280571358
-0.04634645849122658
-0.03477337700591795
0.038507202396765125
-0.0423313108546466
0.015194621651625072
0.01905166002424582
0.007656684994394572
0.010693448357986947
0.03126734984019436
-0.004667863724008426
0.03851105370953511
0.02146602674049747
0.05101692652731313
0.02442128186531467
0.03475493588819902
-0.026712453432001772
-0.011500693239428227
-0.012140323644559196
-0.011582332243630615
0.011142408220417503
0.00466826676890287
0.022434096571791393
-0.009164524779641074
0.007003294695757927
-0.020952699518026544
-0.0017548111909403072
0.009524963061491615
-0.003397801337171133
-0.03162192611321755
-0.011127897055987313
