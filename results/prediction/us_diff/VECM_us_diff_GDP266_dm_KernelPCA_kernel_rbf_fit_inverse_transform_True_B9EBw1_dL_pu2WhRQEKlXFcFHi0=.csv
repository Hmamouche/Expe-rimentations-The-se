# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP266
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=10, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.01306359367507303
-0.0063648434230984124
0.03052197548308036
-0.015646082353323536
-0.014823883646538064
0.014469968290199151
0.05900244092286695
-0.0003788559316431012
0.04135012263068048
0.011079944515198501
0.026356860773237824
0.012376023390427643
0.01483576256989187
0.02105929021944964
0.018862946647986996
0.0089680343258073
0.014791942528736165
0.013937189716511958
0.03171765500069773
-0.02202875614568008
0.001901137810677537
-0.030680270749453557
0.004519000462666944
-0.0044374501812145676
0.028353806206682604
-0.019534675050168596
0.029369815054503173
0.0016354468700691387
-0.0014330838904599054
0.0035658412885555472
0.017588551803320567
-0.006999485619332587
0.008407811296316523
0.005383130754867356
-0.0029450962839618826
0.0012420199715791561
-0.0012362946796513029
-0.017150254685968508
-0.0021915525041730378
-0.016905677561511005
-0.030176130293864213
0.0002605435184045001
-0.0326212975803861
-0.01574402151720884
-0.008197349890659665
-0.020000260203415443
0.020183259386014167
-0.030300139385018326
-0.018836369949810833
-0.012417539328033633
0.0012184143385590637
-0.002546613476669877
-0.0017907821643970913
-0.008229268226083122
0.014553119836582012
-0.02115523735970329
-0.008675549322265195
0.002429740909959145
0.010633444159989392
-0.010268703638407569
0.000431131362292011
-0.014135477909546123
0.015498693291933785
0.007943363409011365
0.006285007662073249
-0.01584964110396984
0.03000105059732687
0.011751878869073112
0.008929794294319273
-0.012955017870170345
0.013847414133121233
-0.015020942770345538
0.009745477341664619
0.03185229604124167
0.03210681949038734
0.03029471736762246
0.03084161847060372
-0.00645343056858837
0.04921438313445466
0.0001664289425861963
0.0017584092047976249
0.029416667745931973
0.04814586639572013
0.021435458597643363
0.004647546158481114
5.3563528681388126e-05
0.024835108118512045
0.0067776191004270325
0.0072146991771234155
-0.003924990415616717
0.018944563037055953
0.004243675946753202
0.011774553186406064
-0.00864348797107578
0.013377759881140299
0.0027666547885933203
0.0008654356686387276
0.030792830811341897
0.04778206570995326
0.023307653309980872
