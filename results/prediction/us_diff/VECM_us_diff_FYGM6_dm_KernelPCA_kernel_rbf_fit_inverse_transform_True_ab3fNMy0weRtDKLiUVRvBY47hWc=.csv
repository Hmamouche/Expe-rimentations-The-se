# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; FYGM6
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=9, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.1890225891713838
0.026074670355588553
0.15646400738181898
-0.019072650555039428
-0.010224357505330385
-0.15056515679519744
-0.04099485535750262
-0.038874023520894134
-0.0069271842121030325
-0.016683538591335534
-0.031848215090462415
-0.05153155726344839
-0.07605305038722089
0.006071968385882323
0.009911082337829037
0.04737238921163404
0.018219015843595004
-0.08592009210727056
0.03886797248328695
0.028650806492167898
0.0380398060075352
0.11037690884380909
0.057327773012562686
-0.03496120680750538
-0.04147955941636065
0.031532963771067624
0.0012348090653333619
0.014366297066614428
-0.06971473306827423
0.008673309312277083
-0.1234513392075875
-0.0614906216670637
0.02337045157647293
0.009835004818088036
0.038801446836946446
-0.029743675455383034
-0.11509035283129165
-0.04021948831586289
0.02750832321419128
-0.05108044329202071
0.09384322908866369
0.020668058618501
0.007071045885865617
-0.004403377855445711
0.01851574378551967
0.08156857954425212
-0.0002878420299490779
0.03346715111203396
0.03241143996252946
-0.005721663662166298
-0.04701866299978519
-0.012742787792121436
-0.01598394430080341
-0.015496614517288568
0.020635917281756427
0.02741561924035153
0.012159005717278015
0.0011241726354550338
-0.02335974275078235
-0.03609863164730051
-0.031738144272771385
-0.07595524512084896
0.02581750737788946
-0.04401451635390677
0.01233591167599532
0.08114834868690857
0.03407305917984231
-0.017445101031852282
-0.027073386485125594
0.025288678453383364
-0.016477369120818694
0.013819830513326513
-0.07624577711316763
-0.1389714082301869
0.06931256367871545
-0.056517864745999846
-0.04189080886990827
-0.03437567490979823
-0.020709925183859147
0.041803832405245614
0.012918997339383249
0.05396923470188853
0.00033246952488995285
-0.007839559906221153
0.016824891507011386
0.0006463844644595349
0.014902289929188677
0.001359131080326351
0.032694296836607545
0.03150241609806538
0.04107835233956713
0.03461484877684739
0.020834776092116064
-0.03072512973911494
0.045080329708905846
0.031793588387241375
-0.006409611318526429
-0.06686186538841929
-0.07003967535157167
0.006597089989117105
