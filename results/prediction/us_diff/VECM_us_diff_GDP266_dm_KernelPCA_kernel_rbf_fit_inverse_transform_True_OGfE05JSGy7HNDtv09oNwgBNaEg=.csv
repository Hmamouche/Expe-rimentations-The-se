# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP266
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=7, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.005251998823640365
0.007866984173591208
0.002579820184526925
0.009762990316573137
-0.0028240835997976436
0.018116381650283182
0.04535038934504577
0.004354739339273429
0.03713582220319592
0.023962215949370175
0.014706401130733605
0.028015980649101015
0.027699248316601102
0.010560293908559766
0.015390459901234652
0.011205280456760405
0.004944234681218428
0.006655772187783176
0.03520584634747323
-0.009522929532108863
-0.0037234821814908963
-0.022438983300726228
-0.0023316043413473073
0.00591190588092925
0.017072133476541584
0.0016499575512564143
0.010913984395179734
0.004873935250644211
0.005094730502141502
0.0038356184281578033
-0.00016400887218425992
0.013931604356118132
0.01832313222706263
0.001872576994140022
-0.004917222195178475
-0.010933064535170383
-0.002880080099944021
-0.025045508405759708
0.012001652301570125
-0.014854229025346504
-0.02894667267792244
-0.0010298462905768413
-0.034444728366778525
-0.01484758056754076
-0.004069875209210096
-0.031715321810276836
0.015367121988724735
-0.009113745067131755
-0.011499954960537885
-0.010911731911763395
-0.01845943574842626
-0.00912856632368465
-0.001017714941576357
0.003064089020169837
0.004052833381175382
-0.010678390044361209
-0.010046698053027705
0.001097747873747105
0.005985601208667025
-0.007315516282695105
-0.004732974764236703
-0.00978914456284472
0.013818810380402738
0.0030721105975692973
0.007379556785119689
-0.0017449805196431678
0.008693748600720138
0.018898112640386298
0.011896889635905811
-0.013999224081106957
0.015573525081332772
-0.0020999067512421227
0.019550765283897882
0.02540072490889258
0.009990486583436802
0.014029385214769647
0.03744540982917307
0.020754052621735516
0.031825783409874936
0.010922247625059757
0.01413866942040668
0.03444233156614759
0.018831376059150695
0.030161888913692363
0.013191859562341514
0.0071352098364462005
0.012409313561467216
0.0039016721426518297
-2.065664872939136e-05
0.010147263343921404
0.013340157695095589
0.013542328058231145
0.012076632325984996
-0.01396362795276191
0.017005050645024347
0.001817362028654049
0.013360140038367217
0.023374205999665408
0.02631253553912921
0.01906476200974403
