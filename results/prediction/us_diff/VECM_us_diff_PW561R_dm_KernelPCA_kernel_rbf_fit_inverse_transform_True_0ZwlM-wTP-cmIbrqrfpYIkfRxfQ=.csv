# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; PW561R
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=13, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.020633352773388444
-0.06096421168430262
-0.03456942854088335
0.005907850490557814
-0.010895704774560746
-0.03925710084712786
0.023174665134529093
-0.021986432508663563
-0.016258895128315493
-0.04591068455059489
-0.07142701782048497
-0.0943481755412837
0.04769555200296115
-0.056699624118593014
-0.017274542865860137
0.0071311133751727936
0.002809647679388036
-0.004089674074535907
0.025647296992490586
0.06344007496033434
-0.016278487448131266
-0.04293275681222655
0.05118243942039333
-0.07570527576762573
0.04932231874942067
0.04841206721537789
0.0019052627200635587
-0.05326948631701113
0.01816382277590841
0.01892399780785652
-0.08688982561082495
0.12547856846710745
0.005390710192983471
0.03312636632223014
-0.11677449985867705
0.06147515863915682
-0.04909310093309818
-0.025861865367181908
-0.013005423152048912
-0.02442062320103831
-0.07514884381936905
0.01741117007948514
0.012134945491338686
0.03920526355961748
-0.03199692849341747
-0.05270233499006241
0.008982331411369771
-0.007572129395378628
-0.03527972749040023
-0.010938542273820805
0.027365447885014344
0.024674610784897726
0.03975522288326068
0.013734234645445143
-0.01965605509440123
-0.0035843781087920574
0.020777889719505244
-0.043834198921194764
-0.04416859957427671
-0.015328182894198348
-0.0389164913481342
-0.013232145423678503
-2.6010038422170315e-05
0.0301351841273996
0.01747409006635775
0.025221587293123245
0.027903241056811613
-0.02621782282526035
0.045848431558116305
-0.005265632180448529
-0.010062054294263833
0.03825305141128072
0.016862108092923666
-0.043426552317319754
-0.021532635204971902
-0.017687636275449635
-0.01821959627930316
-0.04992368176367935
0.05211908671593726
0.0027744161613838785
0.03704512051166197
-0.02172569040189285
0.0734185499708963
0.028531630908007834
0.004510267739335044
0.0071710618204983805
-0.008392972326493341
0.030356151518178554
0.06931280538816527
0.04814355445828675
0.07366749891252744
0.033079452853003156
-0.012412523686316455
-0.0023403900739488357
0.005774597154946321
-0.05804063692873762
0.0714296957565865
0.021576548256871306
0.07101188661690735
0.14519531811819614
