# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP267
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=10, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.004924398869906808
0.011366136921993576
-0.003889021799566068
0.0005457459193770522
0.010578355821653609
0.005366128136932074
0.018061137994511617
0.0018719117740253852
0.010308676362938073
0.011971496409310441
0.01855219448827236
0.007403962176697811
0.01113881927228182
0.019009397758424494
0.001228429203547125
0.004197331190511082
0.007387676134718576
0.006343920328893558
0.004532487194865867
0.0006617884900883874
0.013721114344616274
0.006484284526169594
0.012276764207281916
0.008698803341866665
0.0038847593020467507
0.007216477818729122
0.010985718460337612
0.007091512431580213
0.004823512316524942
0.00919094203863524
0.010850675044539713
0.004042343050402396
0.0026355833084771717
0.0011662628540086751
0.002282378172381469
0.0014950590472592228
0.007853539568837891
0.0049010023216612296
0.008229919909459085
0.0005243557521011815
0.005925987482302508
0.0015229155029774582
0.002813003932480953
0.008740561294904439
0.007773220444256774
0.00046558410154829647
0.017866226294945827
0.005023000315455806
0.007429667642345138
0.008335306545443302
0.0011323404282593853
0.004674057492088193
0.0081904945982763
0.0015891794158010377
0.01165723417421204
0.009556684222989602
0.007489429590280761
0.007388395618549721
0.00766305895929431
0.0072689204925183975
0.017150116799351363
0.011918535314037967
0.011087909143339212
0.013075711759173426
0.013235318816449848
0.008671309118514714
0.013687324804748116
0.00775110701069273
0.005045459115542887
0.008132786272706322
0.008960648174329108
0.011399633176319741
0.008503057491893978
0.005644608114971342
0.010173798096406343
0.014596279681724396
0.005306444367171473
0.007551724822491774
0.0057883106152944366
-0.002200440887514514
0.007150802545859015
-0.0031129959522580987
-0.0002816542638396963
0.005239411877633831
-0.003803010171645991
-0.005809120468024281
0.003114102767997954
0.002392429762899234
-0.0007918661085893658
0.0006520273597317742
0.00338481682280615
0.00028817641131355376
0.00047999025102392606
0.009101133885390064
0.005688944879353374
0.00618142654788844
0.011088832417641704
0.0030400942457217296
0.0032802929373605817
0.007934451991203692
