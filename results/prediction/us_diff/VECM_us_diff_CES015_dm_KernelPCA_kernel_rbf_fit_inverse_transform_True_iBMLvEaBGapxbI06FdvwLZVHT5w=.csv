# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CES015
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=15, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.013190166715332949
0.09977800687806067
-0.003480880531751796
-0.043363969744818764
-0.044938529150352104
-0.00533522761320521
0.01967075282390899
-0.015647587338987128
0.04540007105335425
0.005804107519138071
0.039186516541751495
-0.036671319685696
-0.05253412150521637
-0.03781778347094202
0.025896627213939427
0.026000347061071228
0.005104633339964687
-0.003961832702927149
0.0277638394226953
0.030673302340388904
-0.002445172492573089
0.04133219448914882
-0.009118877890421167
-0.016440172033763165
-0.020740784753832658
-0.012909982375549066
-0.012225513179637363
-0.004906638743091997
-0.044810330712123675
-0.043605671259663054
-0.04030877337492211
0.009574776340606871
0.020269742726524105
-0.021488725507722507
-0.010970959082854642
-0.0010494838097394833
-0.021857017915386724
0.02417146350021038
-0.01011480977040557
-0.009559443160549935
0.03615608521164429
-0.009098495099126448
0.022616514139721856
0.0028422696783776263
0.00781779007638537
0.025051909266848266
-0.002893459427886127
0.001482563594395002
-0.005258002290018224
-0.02514025848612345
-0.009165395177827983
0.01648397831220327
0.009254125164572356
0.022351353367855074
0.010608509420388889
0.0042259726465631526
0.01564442511390838
0.008816297395488315
0.01332732242763562
-0.005709800236704053
-0.030945962100009543
-0.025615493154640786
0.017832762595608946
-0.022788527762415224
0.013230551052797414
-0.002018368289166189
-0.032349220446098406
0.009496107070917652
-0.017901610595231675
-0.012002901257995281
-0.037514564464507065
-0.03558251911027356
-0.06362403421605226
-0.058998052072484555
-0.021418201251460836
0.0028875293600775995
-0.02803004375287195
-0.06298141617345886
-0.03674678970280233
-0.008230306901699949
-0.013400939068408824
-0.004468197571274509
-0.011057610675990762
-0.010798715479164337
-0.013902335852808794
-0.008482707288110247
-0.018075636018997955
0.000294113701906064
0.004989979806523338
-0.008650065069930626
0.0019400626768665535
-0.014789296355680026
-0.018823239708611172
-0.000842464553704644
1.8682441350918386e-05
-0.022583000215919233
-0.024646603781989105
-0.03347047891742189
-0.04108933920532926
-0.004821354670552235
