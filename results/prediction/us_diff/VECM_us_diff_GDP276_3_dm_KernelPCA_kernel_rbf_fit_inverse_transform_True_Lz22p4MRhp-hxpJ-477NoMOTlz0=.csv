# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP276_3
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=11, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.013953343817263738
0.001882153186055599
0.0018338256090134524
0.004859349035375217
0.015139181221495646
0.010940978330707334
0.0032370041008426406
0.0004361318307161289
0.0013596826738221362
-0.0014755584027848429
0.0032968200589280267
0.002354662988239139
-0.00252090859696994
-0.00951276134517239
-0.0019569689594944005
0.0007807081253874421
0.0033712227873327074
-0.0005732889076323454
-0.005675856555390814
0.002148096699815147
0.007738915523102785
0.0006540959758617958
0.00639525056836515
0.003977466020163607
0.0025570599249430514
0.00260529321766301
0.003304476432389075
-0.0009614249741851111
0.0012378325776264435
0.002516017362486675
0.008258424325166193
0.0046300947593436725
-0.003258742026206697
0.0058347783240743955
0.0044259716078997105
0.0007537300038958928
0.005875944167331673
0.0013098730776019835
0.0037431538935070317
0.00844166779860112
0.009729523481163396
0.00292399982347735
0.0038398272748349726
0.0010735754567165045
0.0035884041335709025
0.00044694904522957343
0.0020042079172096538
0.0010233542127409507
-0.00024783462679010403
-0.00044397107107033845
0.002361847017189588
-0.003400019061670027
0.005817944421356217
0.0022000903813503827
0.008929116473143539
0.006127141559976398
0.0008430091952564514
0.0025919136926025052
-0.000495017625486825
-0.008339437732025876
-0.0064600667391804725
-0.0034954766449679523
-0.006819791404673929
-0.0013124874036765362
0.0017235144609622191
0.0021829057517600502
0.005208562701982064
0.006154922515155503
0.01424683349454353
0.022964258991949746
0.0493181470758695
0.04243800059552815
0.005669771826495089
-0.012986546485293087
0.019097988419500972
7.704641415166077e-05
0.005497332686036324
-0.019196526635801417
0.020640436222681892
0.01695382889220097
0.014920108231150132
-0.005161650962996936
0.009892550153236654
0.014990336285845667
0.016112710866771022
0.013051856386929434
0.010921349905452824
0.017816381865861763
0.029663965614971553
0.060537215121465385
0.030423810456267072
-0.0040815727924874146
0.013317663978794992
0.017210773105227457
0.030935005140252412
0.002258011076371384
-0.01719942615316825
0.011021827729112501
0.018675644911996865
0.042880976824274684
