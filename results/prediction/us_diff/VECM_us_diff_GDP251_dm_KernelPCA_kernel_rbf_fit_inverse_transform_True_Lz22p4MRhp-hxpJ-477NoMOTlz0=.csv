# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP251
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=11, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0017279096169500038
0.0018070761357881558
0.022942001051954184
-0.0018565931033807915
0.003827508614434827
0.001582210436787585
0.014270434832097213
0.001583041755858227
0.009214048478327385
0.008144963892911975
0.011690545879541662
0.006036086079985488
4.662834103757909e-05
0.0019182130789213857
0.006880879249636705
0.007952938577627383
0.003819217702709793
0.007841612457379615
0.009753746363994065
0.006596495223767745
0.009382428963329543
0.013225700316408236
0.007257976282158012
0.00175064227542968
0.003371193770862424
0.006416382556768841
0.003662372934303814
0.005564215616353733
0.0002548275273988065
-0.00581534442544454
0.001325251631223981
0.004339838750152916
0.005447146934498284
0.00017486099472299526
0.002822826152825273
0.005178935090259194
0.003524029911166086
0.013579816090071173
0.009431904518880398
-0.002990993791856512
0.009048551428088376
0.007585417602082168
0.010162410093759386
0.005039661532535574
0.008529648058512399
0.010047753050555065
0.007589838952346969
0.0009505430290223568
0.005985160936388357
0.004499721626356364
0.005534486485515467
0.007506479147632592
0.00753145286231067
0.007081954938430134
0.013428174056881258
0.0077149981963516735
0.015542346764041516
0.00987797333549919
0.010029581565851457
0.008380915175226695
0.006409096638461419
0.010925067334949136
0.013261976695874308
0.007824680747261809
0.008479413620767033
0.014461694974326235
0.014190499006492652
0.00759963096830868
0.010662017235180602
0.004934703156148966
0.004485841965429253
0.003988525123937626
-0.001734426038865832
-0.004149366416795749
0.012786183751775253
0.007198050117979057
0.00557849993637891
0.000838008167749022
0.004825987187977955
0.007016754661418179
0.0064573180420481584
0.011519944478313842
0.01442577182416156
0.00767362933766089
0.004272936858237582
0.010180373905018185
0.00812763025766386
0.005778206465300391
0.01132923855660686
0.007126654366959251
0.00947256556215563
0.00504929331216298
0.004465943622146512
0.0063247036378464416
0.00807415723159424
0.004792804422934201
0.004073379707005576
0.00027556232868501115
0.005424826032450198
0.009413040890393003
