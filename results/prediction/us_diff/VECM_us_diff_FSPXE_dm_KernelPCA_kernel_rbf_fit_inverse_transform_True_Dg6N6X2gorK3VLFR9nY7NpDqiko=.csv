# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; FSPXE
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=3, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.0075919124390850905
-0.03590559466957503
-0.029815276442121355
-0.05004370549218848
-0.02310227602992811
0.002834774612536118
0.015449896791044575
0.01945078901371225
0.022576679303421436
0.03242908790821275
0.04000254379552852
0.035719486134629455
0.009676824419230392
0.0193093223369642
0.05558103412142927
-0.008321392204438487
0.01117708510586711
-0.04418267574246667
-0.038148704805467976
0.0192051521874715
-0.06140814250687606
-0.03333576811889521
-0.002942587050374419
0.00090265884232924
0.01979432123936271
0.03683648877247577
0.01542255319542368
0.026184224879257652
0.016554228478380423
0.01162896088749829
0.05232531126997003
0.031070779760334944
0.008223345830912172
0.03344469398722733
0.05096742238262334
0.025030266761542543
0.022462861079519697
0.032426745275974105
-0.002680737753492408
-0.011136783374508168
-0.0026897183291129593
-0.011816846982857562
-0.033074600380564693
-0.05452791009661934
-0.03958056892084018
-0.049787450565282415
-0.03726949198840237
0.0030590472877194486
0.008596625052396698
0.016109687318216947
0.030787957539283282
0.011847962348767012
-0.007038260210206243
0.015839055805417293
0.00039678345328929754
-0.014949706421660165
0.020538238206069932
0.007473605641376758
0.024883626049257878
0.05340836585215977
0.019548927615411032
0.05288086443272504
0.06734753597164955
0.029093791533517096
0.0019688332713483398
0.008892682415365403
-0.016389859526496894
-0.03977079380542911
-0.013494578521951735
-0.026825804564896066
-0.0024406156275915037
0.006234336651053183
0.009435797795953499
0.09274012531192002
-0.01371475452300302
-0.0657219220350079
0.37462789158689014
0.18548639589591737
0.06087307246877429
-0.06197877927815286
-0.036400337477745515
-0.050006514755682796
-0.045599175390116375
-0.0388372939117861
-0.0969018112703789
-0.0714309242598678
-0.043555612814203684
-0.03563767697098118
0.007790946377222861
-0.007816496622692293
-0.01496420733153278
-0.030746844879572986
-0.003660638500228013
-0.0021570894885398016
0.020560165186821182
0.0020611567629240986
-0.004833002464200129
0.001405425021458304
0.025303055083699913
0.013203969414761065
