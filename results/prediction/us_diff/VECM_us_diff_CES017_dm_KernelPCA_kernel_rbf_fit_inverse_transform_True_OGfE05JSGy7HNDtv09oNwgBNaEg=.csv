# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CES017
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=7, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.044195468669961574
0.05383643948022246
0.04847007373793612
0.01443773083662032
-0.010606746689730526
0.030883578419392217
0.04330128123096915
-0.012459680786733134
-0.00725218848881851
-0.017910107822988956
0.014277163868335498
-0.005906810804730704
-0.04620733517901052
-0.044549083202804554
0.00911506125071743
0.013359243040326424
0.020375889200885223
0.006785566749940989
0.0028718141687477374
0.023821908111485823
0.018010904473484073
0.055333175286916655
-0.014850824523504955
-0.025198143116516327
-0.03856342830219758
-0.00627763788886063
-0.019020659562715415
-0.0170950826663559
-0.060793810202065736
-0.0812309438941523
-0.04443064544487198
-0.021410422783650174
0.03353789643854684
-0.004903841942204963
-0.008364468657641953
-0.02476335796427807
-0.0293895224210369
-0.0035646955780456804
0.004427881676695474
-0.02635906597242617
0.02153064063610796
0.02733962746151814
0.020728591116546846
0.020399933933171348
0.007775769091179922
0.03742761851760727
0.00512205854740215
-0.018998276579741666
0.012292321590090739
-0.0036187806136483277
0.004262370320199507
0.017446823445261425
0.016453965785545404
0.030654857649022697
0.010778545773505446
0.01757491429375755
0.03323558422979819
0.020663476976275776
0.019798920524402706
0.0014574703921587811
-0.020608803447320814
2.760384684663943e-05
0.014284863261577376
-0.02526763627117199
0.014386792416342817
0.0175006709178051
-0.0019513121737319678
-0.015126442742551682
-0.014215550252829393
-0.014119718137356737
-0.02885604867216828
-0.04373903222827319
-0.06689001221885116
-0.09608989841628561
-0.0025798820309203153
-0.0425246459481114
-0.020312932606085125
-0.046348145085336405
-0.05227502211178105
-0.021718401328013837
-0.012428557164825018
0.010353956992883676
0.0023415636039870995
-0.013368370983600808
-0.011668559769064616
0.00740322419309944
-0.00019187394644706087
-0.003252026795910386
0.00660868829676299
-0.0038909755810907017
0.02973797693816462
-0.016890062045387053
-0.025686490152514823
-0.0037633199160084794
-0.0014309272054861709
-0.015159505791776785
-0.015551989398621721
-0.0373499355862128
-0.03964354688470711
-0.020531283961629624
