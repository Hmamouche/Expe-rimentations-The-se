# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; EXRSW
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=11, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.02550637248760889
-0.020301361460974915
0.008332328936800776
-0.007728559789604367
0.06617327674690185
-0.027765419060098502
0.046404197028654295
0.02425559682346983
-0.021363300560573166
-0.0329682727115084
-0.010416579767065136
-0.046546910899198324
-0.06861791593431395
-0.021058270247992304
-0.05052524269237573
-0.01907006989997701
-0.02807789358958817
-0.048496294248550655
-0.023183749278392927
0.04929143203991286
0.017241283813510973
-0.005103426812852719
0.006684932522064611
0.01321652589010447
0.01339463261799438
-0.009355573409009927
-0.048448030550064226
0.01755181486315925
-0.07026750383484079
-0.009902491203855602
0.03261394539962084
-0.008595644534979609
-0.024401030245694958
-0.028432464578538937
0.04524605354453842
0.03202883606244575
-0.047934253890931325
0.02413370770402236
0.011554506990327215
-0.04674283669055929
0.04163089684357634
-0.01877799510468301
0.002241082759509119
-0.006649554821650434
-0.03183594099093183
0.023464305419954975
-0.008144863805625263
-0.030713232389867545
0.003773521362507737
-0.020507131646569636
0.013409282629793672
-0.031063878740642984
0.025673152568967916
0.03790592107800755
0.014499234072506008
0.004881118741294707
0.020769322896061353
-0.013674521434659852
0.02689161120054392
0.006188255216514799
-0.02966405271211932
-0.007894588495108532
0.031644284775936275
-0.015926458909223777
0.004194203130673226
0.015030180519841
0.009517371644514157
0.027057390435990127
0.009582384955390709
0.0009263506519310728
-0.021769742341216154
0.0043180336329352274
0.0018708325264794622
0.012558223152103759
0.026434186454746725
-0.03432637189954911
-0.006894799642177969
-0.017116777960757425
-0.047960719372673336
0.029359715350267296
-0.017417912336925634
-0.04070376961605476
-0.005327129280467628
-0.005485049745558881
0.00116669687537052
-0.015580814393249272
-0.0021610617884451123
0.009893124305397929
0.003652713597751975
-0.004782284222892199
0.02392016420625421
0.011540557625632724
-0.020746977674745218
0.03904834245873643
-0.01527576468451086
-0.03884262419696057
0.01209459255977828
-0.002735352843315794
-0.029536266610176266
-0.012100826046213457
