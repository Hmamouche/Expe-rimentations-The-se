# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; IPS25
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=12, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.016654244205963457
0.010240853473202582
0.018105332103436213
-0.011373888761212314
0.009014500088019713
0.001949262435087848
0.008138550304724702
0.002463237962823122
0.0011698023996198777
0.005687585171485189
0.00406996694883137
-0.005646713840609548
0.0006020423635798497
-0.0030469015871030553
0.003841845329452959
0.014298750026605146
0.01434451309732001
0.012577752720859075
0.013496301969439422
0.014430003149889141
0.004518912114188388
0.00825934355262434
0.0006345596264997516
-0.002541544557164881
-0.005100851355293247
0.0037438341073995933
0.013860977184551189
0.008525150228087225
0.007257868989432677
-0.008103797754686278
-0.011293962818015781
0.002647719260080497
0.007057186737494264
0.0011867865804688724
-0.00026795081260461975
0.012784564133907932
0.0033194607680384217
0.011896016494480879
0.007336532480583141
-0.0029226471591314524
0.007415975617384379
0.013006394370543671
0.00763661083436226
0.003969148150200917
0.012026837727007932
0.013632652658937738
0.010013423400241863
0.006224447155834726
0.01236432726722128
0.003797592685459168
0.010547002330319851
0.018505367200335684
0.021931549284463166
0.018413823757883876
0.026714686314864095
0.027105617673463516
0.02938577953363159
0.0289486407924784
0.023933440758569503
0.014270090791018271
0.013691529424317127
0.011073589341457232
0.01565950339553191
0.01332770311314947
0.01674429458233727
0.016313425450506555
0.01633473552373345
0.02315668974817225
0.01073829517136431
0.007688617320762428
-0.010815347762952216
-0.039530205735615324
-0.04327307526671311
-0.03501430270641191
0.01360453587869809
-0.003157292876314595
-0.0077335135862891
-0.010889473795403028
-0.013857031648132522
0.007174460301163866
0.008227824435348577
0.01335781031327193
0.016065348934401466
0.004072252004742458
0.012871057972639124
0.0062246089110247
0.014603161993447545
0.013826834881453854
0.0033444849397040715
0.03582346664818268
0.02646497276470588
0.027243374981082952
0.02398452452309963
0.003925277051167509
0.007285611805832216
-0.003126293665984441
0.012925310468024871
0.009215020225041228
0.004154378682080602
-0.011248889413491071
