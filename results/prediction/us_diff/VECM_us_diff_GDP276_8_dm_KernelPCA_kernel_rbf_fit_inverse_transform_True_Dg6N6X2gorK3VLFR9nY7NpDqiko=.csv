# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP276_8
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=3, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0085253452022803
0.0023565305863282484
0.0042840701287796545
0.0048983332168050335
0.003941565545547481
0.00314246403152772
0.007833124225921227
0.006262038548091418
0.0018175016654377173
0.009070394951751435
0.007020928791290408
0.008776152634512592
0.012036153906629873
0.009516761281413133
0.0040216472172219615
2.2399777084014093e-05
0.004950725484322287
0.0016726520855522994
0.009474673920131117
0.008209894626238392
0.007786104230097633
0.005114360356780827
0.006842863025869736
0.003160268853547946
0.0025407506352177825
0.004180093758593144
0.00379622048403208
0.011503448957938828
0.004666163221255107
0.005973634871591665
0.010576579050062134
0.00595827540186622
0.009127395651678487
0.0068808161643884565
0.013264232693852452
0.008116911941413079
0.009107963186807112
0.0072472868717688875
0.0032322796603079735
0.005594056620417515
0.0031456894162233333
0.0027819622677188456
0.0017879619289245471
0.00361866349857323
0.007765419292279702
0.0053213274033452294
0.004874109537139192
0.0057426814415950204
0.00732171023082823
0.005846843610127018
0.006011645708095553
0.006203404354063273
0.006333427608141654
0.0071996334050792535
0.0074223696573176715
0.007538856847021665
0.0057086189991579295
0.005960375175123224
0.0052517834228189356
0.002474156399048281
0.002762119819202791
0.0045515094500660075
0.003423046986122871
0.004954632067969071
0.0030714732930568547
0.0059061866175375895
0.008785788521151798
0.0029430519289650706
0.0013096365223854234
0.00034563743793532145
0.006572998976255637
0.0035831744844473513
0.0011530449151349715
0.012325470248522603
0.007504871742023989
0.00976349720650709
0.006058836142693347
0.007976792807071585
0.006442954976664373
0.007219417104040794
0.007207966439952971
0.008069997319753601
0.008353193666879588
0.009076560597329426
0.007788175410920557
0.008621636152629866
0.007965136617374613
0.009928751453938367
0.008030677840299963
0.008500055273390188
0.008223224417623878
0.010075855224215044
0.0076396821609882115
0.008894610930413015
0.007284007889107451
0.010718454387455528
0.009064443877387082
0.010407044217013316
0.00939144271666007
0.011538898563548852
