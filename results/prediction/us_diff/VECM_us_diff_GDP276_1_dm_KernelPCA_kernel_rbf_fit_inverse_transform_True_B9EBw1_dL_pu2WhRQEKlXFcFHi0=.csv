# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP276_1
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=10, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.005113162369546766
0.003789381517706014
0.006837675280096704
0.00777591877358646
0.007030488396441863
0.008381353027187807
0.006220159880063275
0.008437166131836612
0.007918495335319659
0.007385672140784415
0.0090693309271535
0.008291720274677807
0.005122252791079753
0.007591221332975569
0.0067351600628235316
0.004894055615497229
0.005421433596076667
0.008305806651003873
0.007888188341538442
0.006360316333097614
0.006974949569242499
0.008364493121427705
0.004981354604675923
0.006236235764440694
0.007894051339474243
0.007182276474342877
0.00623766496719598
0.007345853547929847
0.010721483058076227
0.006099261583986937
0.009010193152870511
0.004502414088371213
0.002758384891198997
0.006329737151540552
0.005018337987038338
0.0035213445303809974
0.004654709579855154
0.005555537608300744
0.004956682798733977
0.006531077244081469
0.0047853129797205615
0.0045142148173993295
0.004820197328686189
0.005979643667215479
0.004537642273970651
0.005644095630720173
0.005587300701714231
0.006323138233703071
0.0072944654417932304
0.007459741229971794
0.005495528718711556
0.0055628375301119805
0.0052693503677738686
0.004006994483467218
0.0060765205190929025
0.0071266681986293925
0.005237113957234182
0.0067222865176018495
0.006754180291462729
0.006607268704347365
0.0073334411618573465
0.007414059271292287
0.004445009279951509
0.005695554557154208
0.005831717072962666
0.006009644926352328
0.007336579639792654
0.007664791628702248
0.007254262331600792
0.00828392643784161
0.009191034019444324
0.008185621819181735
0.008995636097858752
0.008866289812314675
0.009876689196889608
0.008563158230110434
0.006883099571474227
0.009799094265408145
0.00623396907552893
0.0061401476057183005
0.004712353615832106
0.006601894866216028
0.005036419176321848
0.007026753230275754
0.007659945415974639
0.006196973985407502
0.006990577236101009
0.006950735588701835
0.005577638847231306
0.0067536327700535
0.007678574834801555
0.010654605872283307
0.010909173531337586
0.01297444682410139
0.011023993506430426
0.00949609025650213
0.008843299624174855
0.007660810377385251
0.00833351175024956
0.006949823673124905
