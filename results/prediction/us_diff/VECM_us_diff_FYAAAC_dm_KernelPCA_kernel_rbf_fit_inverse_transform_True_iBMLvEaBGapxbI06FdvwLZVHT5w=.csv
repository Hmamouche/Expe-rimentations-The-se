# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; FYAAAC
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=15, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.05213319295960146
0.13660587966509893
0.15539028741643093
-0.09230508722776617
0.0193732886228248
-0.042741302063247694
-0.009666886158006344
-0.010888705965030901
-0.05854916454413646
0.01343881904573263
-0.12152371723759753
-0.07773902335808566
-0.05981270501544311
-0.05799371357623519
0.03473473078990555
0.04506741365856921
0.0006463109593952583
0.04138112508648224
0.00947376597714088
0.04521855766802598
-0.01958436639206505
0.026145843076854882
0.0364951466410082
-0.07680001677497555
-0.01811052915250077
0.021284766449376866
-0.030745117603519143
0.011244573939395992
-0.026678664932141813
0.038945474936397995
-0.03820267675936006
-0.017355831811996656
0.06930128295918658
-0.05698935533492472
-0.05070490322350795
0.012213639645726162
-0.06893605964452912
-0.02577799321383645
0.00030214578370733186
-0.060496674895600976
0.01870106948456704
0.010354464291612363
0.02662325143669345
0.025601836922274978
0.017701976195899315
0.08559228495239143
-0.03729871445468802
-0.01422280487022412
-0.06540734227414727
-0.011918275170366099
-0.060607677924057864
0.07799541181083938
0.038883234950133516
0.025248229126209706
-0.0013199771766428912
-0.02928653413363999
-0.006353088463142179
-0.05183363098032152
-0.016496346829360492
-0.029437491492922796
-0.05247081841385085
-0.04357072283108693
0.0736533039210961
0.07815421217471338
0.02427032576748301
0.09540279025984752
-0.08399010018995208
-0.015990094426506063
-0.00044986096414757586
-0.045536229291043145
-0.04735807628399145
0.04928030371937356
0.010922879395921039
-0.008267953017295875
-0.021991229096891624
0.02176194227554579
-0.08498315411028663
0.015631451584900584
-0.06469574895893287
0.037770741191070864
0.0033834395088197106
0.04195738313485888
0.025100248716118493
-0.0475560623577843
-0.051698771954589384
0.01839983350070279
-0.03919752660322239
-0.023848414220636868
0.012104526271875856
0.028001402281432154
0.021417159405632432
0.042372365640054956
-0.0038445538874537595
-0.025831428991049732
-0.02872456949707107
0.016765561365602852
0.022022682988906687
-0.009669832401926584
-0.04554976280387108
-0.004494519005136239
