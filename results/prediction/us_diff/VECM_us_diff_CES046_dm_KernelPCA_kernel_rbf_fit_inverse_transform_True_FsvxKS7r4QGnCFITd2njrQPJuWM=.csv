# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CES046
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=2, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.00713842741212371
0.00899049148176108
0.009115904318447231
0.009034961055673895
0.007521938118816301
0.008998418876849929
0.00853003202057312
0.008961524545112785
0.008634321984754667
0.008017558198071656
0.005841017170619907
0.005637080353068628
0.006971600935405002
0.0076491466264830155
0.007482227602193659
0.008177998910799187
0.008185137306319284
0.008576896565779094
0.008208843954283182
0.009067893920191661
0.008055783937526111
0.009609282103141404
0.008965450578876445
0.0061144409900242775
0.004259721588600637
0.006278468710366409
0.008200634079464307
0.006336770196138917
0.002258688481088071
-0.0004140531640544257
-0.0007590696238264023
-0.00096281533239699
0.001864697054133761
0.0009635033086566076
0.0024928129870750173
0.0034588535745582786
0.0031409399624385066
0.004922678630998547
0.006120723974889488
0.006134349031234079
0.00786151211539555
0.008202473282492823
0.009166275585652703
0.010965713549113154
0.009737121001380425
0.00979534583965645
0.00840628154866921
0.004820902511799803
0.006241127334760323
0.005851697490332271
0.005705990508989724
0.008959759755663923
0.007501521616629442
0.00770952551956268
0.00770402397421264
0.00893354056687425
0.007576665563136399
0.009108264459251862
0.007424095928396641
0.007665892988083842
0.00828115001772924
0.00829551954694303
0.00974102067694841
0.009659900896163445
0.00914040928607872
0.010209493544355323
0.008520060813914031
0.008310585029895932
0.004329692203085332
0.0028416118423301934
0.003452144117334671
0.0016764580990008058
0.0006812572395996388
-0.003712421633414303
-0.0002039394039462214
0.0005122311662773388
7.532667272368952e-05
0.001509923677959657
0.0006549858235947177
-0.00016848484350341566
0.0022893711518753666
0.004949927634211286
0.004343793426957031
0.006135047377886107
0.00386670287278482
0.0048422193127580886
0.005736262595187767
0.0057597028925756456
0.00803323966210601
0.006056510727655657
0.006497444170214996
0.005553287244144536
0.0049643089999607745
0.005467051794773132
0.00694483487173532
0.00572267255246812
0.0021940880016175033
0.004799435009938343
0.0024388495688417444
-0.000345491470389932
