# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; sFYAAAC
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=1, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.055995638525137545
0.011794237270266513
-0.008562671618067166
-0.08527263179800539
0.007543018372753858
0.006877152785539373
0.011182119107846375
0.040533603929338524
-0.011311549370369892
-0.051598842309625186
0.008746057533606116
0.023562407566587784
0.05230309333231285
0.02033440105959515
-0.014197348409119754
-0.03610391145776291
0.022474083650219318
0.03343667262656093
0.009747989479776198
0.007260128393061921
0.018444496042491945
-0.01860403180958146
0.0029706859731755512
0.06359235309885333
0.0012812795020027863
0.019970165844484543
-0.00908179634189778
-0.003279076892797276
0.011298007090013605
0.008943325151176624
0.01998296076067335
-0.006592352561072509
0.025356712677185
0.009059396856204206
-0.039044750035788826
-0.006070522148329592
0.04184279298676574
-0.0633238768188807
0.005319439622665057
0.00845523643355515
-0.04942791184084193
0.02085269689170012
-0.005760537874296007
0.007394268609409464
0.033609293416676775
-0.0008285100524900854
0.02405999596332909
0.03126964026812481
-0.013496996405854705
0.0036620781229258614
0.002550796965053736
-0.029556641516827215
0.011131841885611287
0.01881613536873632
-0.0035752764216602094
0.017970555327169603
0.008582492504686783
-0.006986594587206637
0.00456137730373808
-0.009345048383995276
0.008448580847775604
0.020678795906358426
-0.044646384728770694
0.010118143412153564
-0.00117876981963886
-0.02816857515918926
0.02246484380234401
0.03419618568912336
-0.012470140173538827
0.004854870136953804
0.012284672721243199
-0.04304615230152762
0.004585003095926583
-0.006008630120980256
-0.05845320349404581
0.0473715142660172
0.00927974784956366
-0.01979427033816769
0.02271442807673468
-0.011575397134259053
-0.003255640785438621
0.01983415439850404
0.04004426440354202
0.011414943966129914
0.027502356776492112
0.013082072527089535
-0.018715282739178614
0.019608918494536408
-0.010051127409186346
0.010945601234775443
0.0027602577405760912
0.0004781893920602679
0.0001919085963002767
-0.0030743174589405705
-0.010760336555628917
0.0026226518412073643
0.016799313045897723
-0.002911000231452218
0.08238210129748204
-0.016658183423778672
