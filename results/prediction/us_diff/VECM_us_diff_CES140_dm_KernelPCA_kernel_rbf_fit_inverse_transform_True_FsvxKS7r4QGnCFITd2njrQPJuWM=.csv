# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CES140
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=2, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0001758613385337759
-0.0002475248163067619
0.0031647943219889193
0.0038689723298718343
0.007308094566134487
0.006659501202512495
0.004349201647382404
0.004948705695342293
0.008931728174487244
0.0055816009821013325
0.005792808187057306
0.0025067367783470854
0.004977627372230642
0.0071237584438064916
0.0051992344324739495
0.006117406070731404
0.0025577123255539295
0.008286319465448526
0.007264728061159708
0.008267557788519597
0.004679574441712321
0.00804321724153199
0.007187953476097479
0.007720765951544632
0.005808061098034518
0.005467944640016075
0.00730193697153843
0.012900675694430392
0.007712483398924542
0.00683876576009742
0.001057259421400251
0.004110475541437255
0.0013003346340879213
0.0012527229618492898
0.00428866305236937
0.0037946936382138837
0.006145563652437557
0.002752774019732589
0.003937072765215386
0.002390083741207761
0.0049000765418713375
0.0027941762701611627
0.0058608701791256065
0.005645860010337582
0.006212623057181326
0.0053041620057425855
0.004060004593361228
0.0030964051473587693
0.001899133082279863
0.0014612328055755462
0.001032128517366595
0.0017345138546550746
0.0006826716246996769
0.002047378202240166
0.002014458561291282
0.002382263816807031
0.0026741462438718356
0.004255581440548606
0.0029923648191586254
0.004574136963714066
0.004948110342819228
0.005765400707765229
0.005618213761288142
0.006357445221153522
0.007704236911460386
0.008417705773857703
0.009239426048902346
0.014654766485355457
0.005769967003716601
0.0056889645624473
0.0014126163623707341
0.00649977942919492
0.005462550233535294
0.00617780624625522
0.008513817314390616
0.0074777951757321335
0.00488472469465614
0.0037941101133926263
0.00423115366021638
0.0015231428851706925
0.0013995810795304844
-0.000599402151271255
0.00021573642369412363
0.0008166295414605471
0.00034190392019531747
0.0028866201205093337
0.0030849464490172304
0.0021608036466518594
0.003904327122454327
0.0017164892111724817
0.002791682912706112
0.0016964325456761257
0.003803984910115298
0.0029955976931163725
0.0036294669025606512
0.004869894492316777
0.0023921779846623912
0.0051908984513431705
0.004234041819498203
0.005168541941374021
