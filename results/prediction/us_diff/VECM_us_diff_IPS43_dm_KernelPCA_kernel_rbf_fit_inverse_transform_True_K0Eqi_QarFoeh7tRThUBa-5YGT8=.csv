# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; IPS43
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=6, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.010012687431439743
0.0039114531532155605
0.0189203109369403
0.007276120017213286
0.002308113193692246
0.006581724388970543
0.01261990538105336
0.004141139771711973
0.006021277233553616
0.0020128539481154882
0.007974342147147224
0.0015856088576715558
-0.008875140628800043
-0.0003556622845453829
0.011411724812409884
0.010209050039258049
0.011003256015300035
0.005131796810140689
0.013871984057800985
0.018155508851572653
0.01578601748530641
0.012471457568669323
-0.0004200863552395453
-0.0025450296208809633
-0.002549388079939563
-0.005011952532457086
7.684002435666068e-05
0.0019067349012359726
-0.004512969183092448
-0.006486714042414502
0.004576481472083408
-0.00037571171519760506
0.0059602913897224465
-0.0010163194155495838
0.0071344489723641005
0.005872106067736699
0.0009353136367981916
0.011697306540129423
0.01069988501455585
0.0029972601752782653
0.004729701381953042
0.012430543578768853
0.013181374656387735
0.00947374003523689
0.012146803957491598
0.01694018252769578
0.007829176951713587
0.0051479661978421475
0.01212441633004864
0.007220376538301685
0.007470042417637164
0.012754170908523087
0.015287012813639252
0.01980217402931767
0.01631384790727624
0.020322276923399787
0.02373715976479892
0.021335859868357843
0.020631366811037045
0.01810203297384598
0.010947094725973619
0.009354181272063557
0.01735116013853875
0.011813460465358307
0.020195700725922635
0.020323648272457875
0.012102945121476921
0.008146693358716298
0.011156024758466481
0.002164962323385928
-0.007178322031186109
-0.004525972869382626
-0.015575429008106496
-0.02027801701147424
0.004443110665676078
-0.0026908269046888164
0.0027573018591964425
-0.0007756221564266703
-0.0016408382427173232
0.006710366941353329
0.01088082114745153
0.018419988754047854
0.009635120938940792
0.004861338645538908
0.0026303344155475107
0.006642189921850909
0.008454904191221713
0.006746116886722425
0.011897040701514226
0.0117981509616177
0.01456222990293798
-0.0012462375044193456
0.006766148031521879
0.0038763487657769704
0.006195218819995477
0.0037358933970895658
0.006805072746227019
-0.0010031806028761951
-0.005946579238030048
-0.007529662523726048
