# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP264
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=14, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.000184431614904116
0.016222005896156768
0.013670035451459579
-0.006701687203410338
0.012414715884734709
0.004428507911517018
0.013594524291302913
0.009675895085756192
0.0030699137369131525
-0.014544162708381514
0.0039758405921294475
0.001459793968462319
0.007131628657761064
0.004957414593901094
0.008216787601103889
0.01483022416822391
0.00939295309178154
0.004872012209588709
-0.001641282147464727
-0.0009006424206576
0.004972503867081222
0.009499010549046125
-0.004192436741284963
-0.005104352995544446
0.006678614436513908
-0.00015819468192229983
-0.001640746854322001
0.004704019285992484
-0.00037364423942167976
0.00011486859149750393
0.010293620422053135
0.008419344311659421
0.008484900743802027
-0.015884790369447906
0.0015876797450590885
0.0063803280434966015
-0.0012729625197577096
0.014484808376562231
0.010396938597288484
-0.0002532401077505887
0.007919454958246048
0.01271439969998047
0.009325475687049984
0.011908802956382254
-0.00016063546020686286
0.010438707419159908
0.013271614473643303
0.007017283263717134
0.01773480787148841
0.008664948219027663
9.659181309870486e-05
0.011180919715701563
0.008454026230594094
0.006529571598727116
0.018215367820277963
0.012216766471387107
0.01459380875082996
0.018404362431166995
0.020053897929309925
0.0151244012663466
0.016853608280648694
0.008393780216027474
0.01639026991816259
0.015378921386354112
0.019246416139061525
0.024348575993774022
0.01802393155775159
0.01794509417826662
0.01758875789983649
0.02252673921668427
0.022328921174914234
-0.0017660774339965345
-0.013552850782452318
-0.013602609813216773
0.019109333195353607
0.017284424261011063
-0.001214161207501777
0.010764040035490273
-0.00919666805767555
0.010561928805139696
0.02317312317678408
0.01690221939973578
0.01899386256249335
0.019655957283118308
0.011298199814155231
0.018490466198405536
0.02964004404278689
0.006149985281741474
0.003634114317362837
0.021255168409063822
0.02917238416172038
0.008379693503141864
0.012994145637156531
0.013883315969165429
0.01499011698039302
-0.0005107955714663479
0.0009317565664994905
-0.0023487243497313055
-0.004077766292806083
-0.009896056275121379
