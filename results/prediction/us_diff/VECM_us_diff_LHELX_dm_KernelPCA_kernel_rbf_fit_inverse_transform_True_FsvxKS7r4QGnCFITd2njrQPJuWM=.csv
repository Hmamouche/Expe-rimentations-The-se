# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; LHELX
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=2, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.008629215906319335
0.042666877747306445
0.015092923183758822
0.02554519961941005
-0.013323215903130625
0.012273493941222898
0.027045728362190682
0.013463265974100625
0.014959812543763808
0.0011522802360956765
0.0010862737447360628
-0.000555379898364292
0.00753321160246391
0.002322428052615147
0.011724546703010923
0.03897813070617678
0.03813690359989436
0.02121444816626516
-0.001881157206519055
0.0032253404403412064
-0.004149352188226407
0.011800598052878041
0.000569686603315812
-0.018826054055553543
-0.01721854630485747
-0.005610760775671034
5.2529201202355935e-05
-0.01754153573286658
-0.052585645168836966
-0.08258479020071248
-0.05460571417938111
-0.0035161412935429725
0.0070788639705610945
-0.0035389963796879417
0.0025430524418706296
-0.018641377742941806
-0.017595487709366024
0.014879048056808234
-0.0004608118025435058
-0.0037427797218704765
0.01997677574967803
0.024767113782849737
0.030826215731156653
0.028913007656716543
0.01059507954476104
0.029464160152605626
-0.01181883030354896
-0.03319859845079113
0.00772505205473089
0.015260922528331613
0.015916756081017495
0.017614305153905795
0.006937519688909619
0.0016961487409251508
0.014030317463163515
0.00237352087456481
0.01920203633199886
0.022916112134906477
0.017063030885210627
0.021306337679795343
-0.022957538979072288
0.0048181414780992865
0.031425112531729665
-0.002647186317560737
-0.0073798159890462196
0.0003072092167973762
0.013234709147034592
-0.016376792998033095
-0.048372969795716966
-0.015354941799789405
-0.049790700413595006
-0.03747851058525075
-0.04826842289280613
-0.0656060004304148
-0.0066228024990222034
-0.02339794890106678
-0.022863619406826203
-0.028787392210863193
-0.01903502437423392
-0.02467650366999728
0.028498877456411564
0.00712008028330567
0.008617206916783077
-0.00558893976763033
-0.019030806331372215
-0.019656719619354765
0.016202897315936653
-0.003993613328359053
0.0036083220170102957
0.0012759377783798263
0.007116460159374395
-0.018605826144686696
-0.025529966444599265
0.0021460016668679465
0.00020344194282615694
0.007217441703335423
-0.007676765827655866
-0.018707195997494763
-0.008196177563343317
-0.01627132264535971
