# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; HSWST
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=5, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.036717090717020145
-0.029735929141102985
0.0019364142613568919
0.0018428975569455804
0.04621905648797465
0.040633007669326884
0.03671278467978621
0.0754558033453025
0.045067754648325034
-0.01743474791000719
0.08106968678495655
0.02700120892071138
0.011954957701670809
-0.11476026602971252
-0.05784273737825518
-0.06955813023385671
-0.08586302238562431
-0.0008668935035870406
-0.05892350450942077
-0.03661583780153369
-0.02498830027209021
0.031187288878247236
0.08499974897038362
0.016775166358179907
0.023007491924955045
0.02329358091108066
-0.031037917471440007
-0.03318084352967683
-0.0695336454600005
-0.09430804887621207
-0.019905382850338233
-0.029679398280708535
0.03204606292384228
0.03355741183747542
0.03179531753922484
-0.02980487933940424
-0.03580566254289703
0.006900174796931762
-0.04679046569893567
-0.10959409725101134
-0.01536296475510567
0.10418188343972523
-0.015076716564885056
0.021066194609378794
0.02377245465680114
-0.06702534263071752
0.018194806004872728
0.035342731390814626
0.06611190894404034
0.04131965529680828
-0.0032619774216620413
0.004196306380888673
0.026421011684025407
-0.012869166979195013
-0.022692957322671917
-0.026814366252362252
0.058838000990973145
-0.01619391431448373
0.07171583114660784
-0.0021721259019685775
-0.012273719909762976
0.1015114009087087
-0.036068290381103554
-0.02687094624845541
-0.058181374627790126
0.005650012240363298
-0.020868776803630563
-0.00874123494261659
0.006505109159376784
0.024296840720401787
0.07547477094171681
0.05265341279203421
0.06488345315185119
0.03743178156076901
-0.07798213947037091
-0.002022611031021925
-0.06803444910264216
0.007664693699763494
-0.012676795313046031
0.05256913955490284
0.10774429387882585
-0.017261713180118935
-0.000874630442362842
0.02137056670005459
-0.023645391713780654
0.03194737173114258
0.006579941656721177
0.01475673552507892
-0.007638635415400059
-0.02077771198529972
0.015168046904959126
-0.03220839909393114
-0.06166991426696189
-0.06577230255646628
-0.05881148021708913
-0.031014801372436895
-0.04003909342866355
-0.05497536639268609
-0.0845596608897215
-0.10213412662711475
