# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP276A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=1, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.007038370728190476
0.00599386717968302
0.005447765237958745
0.007801222260951358
0.006684155114707097
0.006260214556177097
0.006313899366505449
0.00501657412502902
0.005473521029353929
0.005522419349808684
0.005354620806350775
0.00669515617558618
0.006462953262044877
0.0063640381031856205
0.004189531655569707
0.004257429474434443
0.004746932602718651
0.0055311466821618156
0.007286706264556644
0.00778363612081949
0.008007203649487617
0.007429796805340658
0.007491951875211815
0.0070608883269183825
0.006588951360291349
0.0066514154757487025
0.0068825337194321195
0.008500973089924816
0.00853370726224219
0.007981116377367405
0.00806064806654537
0.006513944635979617
0.006808393185445324
0.006635267903869569
0.007330305079480725
0.007755011492921584
0.006711201265783594
0.006223705885178304
0.005774549311814356
0.006451347361144969
0.0056813040700395695
0.005222036988249762
0.0049884557117999655
0.004621775101365615
0.005933303116983091
0.005713535526157965
0.005805758593725044
0.005648471527822463
0.005625747839243756
0.005801579856278184
0.0049937422131198315
0.005486246876553875
0.005946883473030399
0.005893019831284688
0.005860296050100285
0.0055188797215455256
0.004926350861023531
0.004697525454959031
0.00450872587964799
0.004208378125548818
0.004166646604137984
0.00469134582225358
0.004366767215280729
0.004635232960213878
0.004462192000005828
0.005160684538643266
0.0068178982919903505
0.005740622789158926
0.005186489222986785
0.005188920299666243
0.007626792154491826
0.007499266557704272
0.006532517021135963
0.00779100867245537
0.0063320937646655345
0.006337655979804518
0.005827862801835982
0.0062790664586801935
0.007294680323751165
0.007498920148711847
0.007395209218299822
0.007499505452513076
0.007859926360911347
0.007818091941908915
0.007954705720562229
0.00767539358531132
0.00803162024633395
0.008228221412609855
0.008076103657852654
0.009851118946917986
0.00883548162297199
0.008981827518701498
0.008951014386989063
0.008632650654465753
0.008631872928986541
0.008761833404492776
0.008723935626255482
0.008736104129947507
0.008772407732796384
0.009742168714979573
