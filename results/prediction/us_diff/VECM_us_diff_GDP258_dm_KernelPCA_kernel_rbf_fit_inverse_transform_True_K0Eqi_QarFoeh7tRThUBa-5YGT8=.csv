# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP258
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=6, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.018558775678706344
0.009115420055961413
0.01602066342889487
0.01397513547983793
0.010990053430012222
0.007934352035224823
0.015438486562528563
0.006744754032838123
-0.002515400558044459
-0.00200332720795481
0.005071284009513132
-0.007046079789550748
-0.010322440952300286
-0.0062353519054367
-0.005943056422080675
0.0019413254372328298
0.0034719769831145506
0.007249479346192241
0.0045746843040254444
0.008255520355418367
0.003662357110046581
0.013911518130910808
0.003402259286640486
0.001402135608094985
0.006336612788082558
0.006192887276154515
0.007540219744330147
-0.004924384934452993
-0.014022670532024401
-0.007827906707347468
-0.006316492989323712
-0.00503369503384401
0.005397638736243688
-0.004380795037278539
-0.006187626167723118
0.0023505373928563353
0.005001865314961346
0.015668999847984182
0.013999525616949
0.008678378862182196
0.009128711030426563
0.01542575114034869
0.016512258980945844
0.01127650437021378
0.015452097530260025
0.0161856090350123
0.011607354605458794
0.011711513118840717
0.010132264356705127
0.010063113223011119
0.008166491797373094
0.01220973296705602
0.017941408845071085
0.021065943080003823
0.02103848496131466
0.022163320060069148
0.02500807859409648
0.02482814778433458
0.016006467465541487
0.025336465600134302
0.012863108228949503
0.012336572618020729
0.02318706598463649
0.01581124628396604
0.02144096705722559
0.027421857269140034
0.016148003955396412
0.015297072616763671
0.015978814098118094
0.015062687135100072
0.007717793404905414
-0.006112133066618528
-0.024465605857308753
-0.03213666011936441
-0.019202031636944936
-0.020141454504218136
-0.022046768868667743
-0.007865554132641311
-0.008190621583789966
-0.0012032577069931636
0.01785253184995569
0.021143380452443128
0.008805534965417399
0.009719099530937662
0.014109017481928093
0.02058433546965341
0.013835287847793202
0.011606577573567022
0.015785367934417326
0.011060741242526017
0.021916360363483676
0.015583547559926112
0.015117372916556368
0.012599753909185416
0.0066071817573628835
0.016370051413788132
0.01745509201427822
0.005562279450016419
0.004795545496978153
0.013549425973265476
