# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; FSPXE
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=9, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.0069768904327035045
-0.0273020427874631
-0.06524269259319043
-0.03943924235014479
0.013783388600717553
0.0018783764984157073
0.0254567071413384
0.020707096005094443
0.025066665975300224
0.022013491775268963
0.054682375227917315
0.04568588878404431
0.02048840987988519
0.005403001865946274
0.05771199555408372
0.0032348370587998807
0.023167039464782446
-0.03348852772654821
-0.058896957381000786
0.024263207654615725
-0.07913635682905504
-0.034989105379765205
-0.00790615531111447
-0.01742460287622439
-0.004413495744423709
0.026307830389194514
0.00356244668390188
0.027302874157650134
0.01466181667690222
0.0183564591291815
0.07356645667764061
0.0010853339150245361
0.03580801961893842
0.021089551402377435
0.0584290522772016
0.009604551686403073
0.013613881492510293
0.045761463140756194
-0.010339686586237032
-0.021010011443962442
-0.008895798195129406
0.0016384528535169174
-0.053304559066879344
-0.033307296559208346
-0.0035651431823775187
-0.06102199609892795
-0.056731303824522586
0.003976866879758085
0.01864246950909626
0.014682376427045781
0.025860544000521873
0.011568596877265216
-0.014825704386004574
0.015239905126535308
0.006402467844292624
-0.0070827521906887455
0.043311005534842156
0.020059779058582836
0.03735194808151052
0.06374224697358473
0.020670671655102765
0.07247545258272217
0.06580912004253903
0.017045791841482423
-0.0020182027211886207
0.01889268051366812
-0.015418792145952195
-0.022930392404474087
-0.008886386450067757
-0.039949912433837574
0.006994327504665837
0.015266600308709483
0.004124282721129608
0.0837035683512382
-0.06696774927793428
-0.11060257820974699
0.35748251272269704
0.18729113220701413
-0.02506145578611252
-0.009831333392369579
-0.04381672505584165
-0.032213059832235755
-0.0043748241820823555
-0.09439612079750566
-0.12004806212535815
-0.04342906187460528
-0.020200036787777043
-0.030138746740212025
-0.014025414063697698
-0.026879261056810218
0.005249556352833888
-0.07945072877860455
-0.005047176449430146
0.01126428194899527
-0.02530957321613563
0.013335401763399628
0.030272587983194946
-0.03355113762056455
0.013775680949573517
-0.0035557358374311166
