# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP258
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=10, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.017121669607426962
0.015393167164492245
0.015568049948460045
0.004888187554473224
0.00879191618523654
0.0017458823297741583
0.010530182304648524
0.007132324496058603
0.00017033660336337499
-0.0012467428049411746
0.008842940359305539
-0.011218018769348685
-0.010528132639259653
-0.004691859042771548
-0.008031889493156853
0.012714014597271
0.0025019946633324823
0.005704096799354342
0.006450876672694323
0.008452644134267061
0.005266522254709107
0.0181671177067151
-0.0012696638751129906
-0.0011993762905949143
0.0031182649276791157
0.010702356141518186
0.002639927394910503
-0.009431463303355118
-0.0016560394022189528
-0.012068207509303631
-0.014639246185393352
0.0009952028776102403
0.00430440211003488
-0.0010979595428753236
-0.005712509459211186
0.007006888867027129
0.0036098283922252525
0.01556427849718578
0.0172728529190295
0.005084727945569073
0.01429939738939699
0.014715884966993664
0.01866301673692519
0.011344311728335721
0.011902431847608638
0.012605962974445259
0.015175170942368466
0.010989694009373902
0.011022354826950022
0.0040240512611375715
0.007502248730878621
0.016430622373500688
0.020987529525251968
0.01533725624228778
0.02013957702716851
0.016103177438993314
0.027875630416416695
0.021322955318763367
0.011759308770870553
0.030605969110955002
0.011787427477843039
0.019075325651019576
0.021096321467806167
0.01683018964852316
0.024683000945311475
0.02396703744010241
0.009896438703167193
0.015938980640998832
0.015930339843201732
0.018653302273843035
0.00442493815240628
-0.01230976559549941
-0.03199633735732596
-0.0302440069844401
-0.0053356407530641085
-0.013415296782545588
-0.023052595586299594
-0.012796351440493216
-0.007356925107422314
0.0013671290330952686
0.02107548112743867
0.015123085135615931
0.01194363579656527
0.0017793837456117536
0.010835547810620511
0.0262313149669698
0.01104431220318863
0.0111591783447477
0.020292920520078816
0.012590917566599616
0.022138955047833385
0.01631748282801921
0.014477562769813417
0.008908096094938475
0.008044274726326654
0.016414078065286056
0.012856583507325388
0.0009102024051527071
0.005339576533804877
0.018402304103774372
