# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP274_3
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=12, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.021849491331768257
-0.007173555415863932
0.0010463370906724752
0.006409643387294702
0.011413440995206544
-0.004964939505744561
0.0049485498811181585
0.01917539659783629
0.00032458997127583745
-0.00804320649639795
0.01158717581478317
0.008468535941002884
0.014946413364199811
0.00734925617451766
0.02039131678329009
0.010756643454044798
0.002876754090396453
0.009793747150123065
0.014485601215250856
0.007893790255980566
0.0037859653893271266
0.01839200483255965
0.017062539953106238
0.0027286740727880633
0.010653864761597295
0.01211735423911909
0.02140423362748713
0.027058584724958822
-0.0014090166647656996
0.005949304845951863
0.025813171084469066
0.011907808451285298
0.009622698318521479
0.020010081625121325
7.869403279483795e-05
0.006331745393840937
0.005352987023760152
0.007348002102389405
0.004093929579115279
0.00796647648220803
0.005523418255485491
-5.991695082091411e-05
0.004597806046568335
0.002694181461628288
0.013449063389127503
-0.0016328968140526617
0.005525265374250087
-0.0017140760665753192
0.004569332811377356
0.0059055050863388615
0.003367043476405906
-0.008611644074319153
-0.012356265752164218
-0.0032863639987478666
-0.0011962226311834727
-0.007022835380964291
-0.0036608029705356595
-0.003252940490296382
-0.0020991120411588933
-0.004658978357153494
-0.0029059417975620073
-0.012223622625209494
-0.004090141240445443
-0.0013115329654884492
-0.007100610921945578
-0.002198242319811591
-0.0013300508403312713
-0.0016470802971498945
-0.0019273468279437191
0.0015230319156668
0.0029297112236601162
-0.0021557615573651987
-0.00031513626497607747
-0.0016814582909392235
0.0014387775365768884
-0.004931453447791459
-0.01387400584348777
0.0030488557221386953
-0.005481894644903184
-0.00422196058008348
-0.004495967636394409
-0.0020336204446399376
-0.008159784600510032
0.0013129047491115381
0.0022031962332336296
0.002402683332553889
-0.004883041179356611
-0.0016563927425632644
-0.001324066303460718
0.0012669400092939344
-0.00108533969809469
0.006765580241192693
0.011303205063412048
0.0019537904570687257
0.009110661939120069
0.00013120921005359623
-0.000580978520867279
-0.0021464378992339375
0.012367124016972203
0.00952244862112691
