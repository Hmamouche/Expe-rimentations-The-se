# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP276A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=10, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.006020988200657962
0.00448767962753694
0.005991089898108916
0.008168906036971237
0.006464189633704757
0.0055358418672280234
0.008156543171249166
0.003877869437606095
0.005920801036452433
0.006005559620993936
0.007255054996058959
0.007311912365450271
0.006017254858988923
0.0073360706713789785
0.004167601751526117
0.003528131377198997
0.006119882778814791
0.005540218840823942
0.008278677453599451
0.007557838543846405
0.009153831946691705
0.006628957741218666
0.005976967932035859
0.00481689737359988
0.005924029815028492
0.006848760105383867
0.006941529599218017
0.010033440484052348
0.008151832108612403
0.008899088226091397
0.007057210793776027
0.0057493665495532646
0.007463869339316133
0.006504346198179251
0.008228192530980625
0.006144427572660236
0.006332041590908805
0.005441865682011392
0.007535102866869056
0.005547120540310306
0.007404284449184264
0.0045017633782274006
0.004727684843575405
0.005158452062737989
0.00719607829473567
0.004660004756455797
0.006535323490822661
0.004612784342955676
0.006802476243012348
0.006809252927291172
0.003644291862798116
0.0056464824104974
0.005400922276175513
0.005138933517781009
0.006058263019737938
0.006010709107970097
0.004339240568770408
0.005100609971869498
0.004334623782852634
0.0033775037870821174
0.0046372870645256395
0.004316174931020017
0.004273854313497299
0.005240728677889966
0.00414259249716899
0.00645637616011158
0.0062606803864519575
0.006257676707139044
0.004313056317774321
0.005508479136571826
0.00876942800919558
0.0058295409379352185
0.006722340487970912
0.006884527232655562
0.008252725441455722
0.006281697315861781
0.004847172732774448
0.006959093656223374
0.006930913390649636
0.0064639641397156635
0.008089003005221657
0.007985549537283382
0.008162958221975283
0.007513935684020908
0.00838348538196747
0.007567527930278785
0.0084544215728805
0.008462040039298744
0.0074556852178416285
0.010604545787265315
0.008123524441396274
0.00948938158429703
0.008705823354548024
0.007911844188373296
0.00985924579442367
0.00910420271048581
0.008750501269706718
0.008529285902885155
0.008777374526977817
0.010088663642620779
