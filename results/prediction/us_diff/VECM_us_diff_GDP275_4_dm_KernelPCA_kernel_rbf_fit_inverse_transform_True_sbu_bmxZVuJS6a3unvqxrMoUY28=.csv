# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP275_4
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=1, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.007573567351111985
0.006196547326933805
0.007356434615475799
0.005531439847028287
0.007572546626518718
0.004526751425106599
0.0075088483743275284
0.006707826815246794
0.006248646493613159
0.007182726692903402
0.008771443501584725
0.0035586052002345176
0.007401516958473637
0.005700775084977785
0.007360985508611904
0.009869607143679012
0.004913201893885473
0.005509022608510425
0.009641716491419367
0.009742883210417497
0.0075798454138848725
0.009795519109399048
0.011823777059419742
0.010519417988223305
0.009212824754282747
0.00928856711190348
0.010460886313162918
0.012834207385473289
0.008417712536982567
0.009591575225926003
0.013175979008612879
0.012854293527053931
0.0055814203836435945
0.010198005767619285
0.009614380876293167
0.00915322978213948
0.007182075971743017
0.0031022587943744847
0.008456364294335376
0.006055611734925158
-0.005493956206931673
0.0015249362774525425
0.0011650730110090743
-6.25431309134322e-05
0.0035085064886959316
0.003103808992108285
0.003069626913137591
0.003673736009644395
0.005347794761448699
0.003966880876092243
0.003700739955838709
0.004244788232966226
0.0019651347490653405
0.00205122286821806
0.002021246264971622
0.004425776121021087
-0.0010045279445359033
0.0017866518347193579
0.00752616207965893
0.004377519222203507
0.005999668126451949
0.01062377708417533
0.019081503684326706
0.006703241295850204
0.010290106091748373
0.011616125420539998
0.003051439152560806
0.010992004368712739
0.0068697798946263395
0.005079819909553176
0.009380573957827439
0.008036379467934073
0.00858727694322517
0.006964268967575447
0.005073580457424774
0.009023973343385141
0.005866939107985306
0.0005630385168840328
0.0025544372207566882
0.0011393037592861315
0.0009244947162632076
-0.002902458483070193
0.003045181091233371
0.0035875115519299547
0.00030176794778719333
0.005636554135603728
0.004184487317960064
0.0032110168744775673
0.005198678814581284
0.005849679620087575
0.005894823126042508
0.005821148827786674
0.005118310526539364
0.0031972649948541817
0.005866583069720204
0.0015403285218165807
0.0023870406647229334
0.006101750641265602
0.006740186037815303
0.005115267302067142
