# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; IPS34
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=5, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.011416647548523506
0.0040692092591745315
0.014019385924649136
0.011646014967945439
-0.0019266835889281395
0.005394240434863276
0.00950955017449933
0.0028863334742554466
0.00154367205280591
0.0022020017887176505
0.0027244236247550265
0.004411482800590342
-0.005540158837413113
-0.007936842430637745
0.00524111869741602
0.005076975590727476
0.009163571635985227
0.005272554987985248
0.009374573962314836
0.01098508498720809
0.008252696313019897
0.013212242414880506
0.004922933568029131
-0.0027107755150264498
-0.006973159405698662
-0.002799088204429816
-0.0009810490339817873
-0.0011077931812081593
-0.005760624840881829
-0.006659746651690734
-0.0032177189589294207
0.0015562564841187692
0.00805281589007562
0.002961996979701919
0.00859386386138105
0.005333583144347785
0.002639018990299288
0.008958039098193232
0.0052532430545445446
0.0025152480426155277
0.009594940385638049
0.012499643521385394
0.015544852370579367
0.0108032733028628
0.012508707482271514
0.01703151613467331
0.006537208029569669
0.006267401592148995
0.011133663292753157
0.009056233477892379
0.015487884366602183
0.02003966321522155
0.017598779194410046
0.024344772577189935
0.016886146311184375
0.01957353072847022
0.02607294152963501
0.02428430927612178
0.024770933526111448
0.019027572282596855
0.01409927156716569
0.015121543563774594
0.021963080245254358
0.017013879059168173
0.025264945484010915
0.031268584055776295
0.02568018959508665
0.020022110771568825
0.019707766073686767
0.009585431987888034
-0.007612829917215839
-0.0006496828783742717
-0.015844715135495898
-0.023678256253490085
0.0033799031168232816
0.009123618146362698
0.009448441662977963
0.0031654227939816137
0.000686488245280243
0.008271260213479294
0.01591798245001345
0.022587838967813627
0.01578390245153948
0.008330958577538836
0.006934199043944749
0.01379684208862186
0.012096188707962276
0.005260220112732696
0.01597828377510394
0.018976452758529733
0.017323386146242806
0.004963363811429073
0.004084327729338106
-0.0022813752286099183
0.0074308172532468785
0.01285824482148034
0.011183624681368605
0.0020518942288235585
-0.0037306721871476494
-0.0029979213147823644
