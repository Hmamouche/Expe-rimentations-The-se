# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP261
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=1, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.04494061170162754
0.020702689288379553
0.019827396822886735
0.018853540163947663
0.006919540170953606
0.01880925837612251
0.014902591929365092
0.017519883255290754
0.019795390501137225
0.01636918675472839
0.021256168099187595
0.03629158721446193
0.02436234615958714
0.014957607333615036
0.014074662410250944
0.00508883818841627
-0.005122467653755059
-0.012568017685074782
-0.01829996140923558
-0.0023519557504474192
-0.007169377061895644
0.005781084968754611
-0.00653497011707012
-0.012480837315778622
-0.00166830581905522
-0.0027382280520640923
0.003060227182986021
-0.01582866659078411
-0.031201569752499565
-0.03372642943506833
-0.02822654219958577
-0.0034649910531652775
0.00330396210501188
0.0008451810365378764
0.019441611932552248
0.017645638155202103
0.01347664475106471
0.02614229795214342
0.012463942522966127
0.011044605943700108
0.02411405637142477
0.030571613706690974
0.016589357620227663
0.02147229374197174
-0.002474833219575547
-0.008605886311295394
-0.0223388556334315
-0.014057546453693535
0.012459909687198917
0.01799437686338838
0.03097605599591092
0.03094769017850641
0.008908700252341748
0.00022614875892796888
-0.004447940326968005
0.00704838464007561
-0.0018773170237245578
-0.0013990345814638167
0.012786625902287485
0.026663765345057266
0.030029449318873677
0.033251960255127624
0.023159190666633325
0.01216573299837143
0.011583243685565124
0.007469543103393206
0.0028331733978169634
-0.002329084195300829
-0.011260967236952845
0.001846530978345134
0.018622638782406133
0.02410011553317515
0.009796304018672456
0.007222433138643338
0.02537698675506809
0.010173698532342828
0.0140472406753751
0.011986572182809413
0.01310746142352341
0.03079687203789895
0.049520852468989025
0.0317999221707185
0.00902482307128755
0.03803885027105963
0.026604500363345034
0.015817009007494054
0.02555492430473271
0.0391663417633249
0.026523956019277144
0.004447618687012294
-0.0006456004914213581
-0.03940577262409492
-0.06604831505456196
-0.0663838937822068
-0.05601369576733605
-0.05246872332886509
-0.06887323886926715
-0.07325786154626585
-0.07312456823017137
-0.04068552988229716
