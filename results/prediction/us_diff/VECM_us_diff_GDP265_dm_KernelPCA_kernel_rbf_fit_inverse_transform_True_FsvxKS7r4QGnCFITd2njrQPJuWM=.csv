# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP265
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=2, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.009939061635774673
0.0036066265596850916
-0.00027232497502147936
0.013848355402458584
0.004037858699881081
0.007497821649036887
0.01602633115408813
0.012151701072007637
0.01842500054198653
0.017174283752290707
0.013340178300464753
0.015424382091969153
0.017193848118899565
0.011732389711769648
0.013764212508357132
0.011817088689992459
0.002033925266582203
0.004618606791086133
0.003604364515813285
0.005213168054550928
0.005612229467102369
0.003200753365478167
0.002147760960471712
0.003388146850758943
0.009710480912885056
0.009185146547465408
0.010082453623149306
0.009180606994059306
0.004311404559477122
0.008603721748588384
0.008109186925410766
0.005520944627380717
0.004273392099532535
-0.0015933517734811286
0.0004699726753406619
0.0029601389004572723
-0.0008573863971013247
0.0024597162603520024
0.002924476002894528
-0.0014554011886615012
-0.002312954480790608
-0.00126231557989847
-0.005534815260269266
-0.003491724591576948
0.003755128398892286
0.0002854118396219971
0.002555486140711389
0.00380825333280905
0.004110218100754176
-0.0003574733884257552
-0.0017542398026319463
0.001537402487538145
-0.00014992065963324907
0.003063484549218468
0.00805571971527746
0.007102388717356453
0.004885788086782982
0.005725906879323089
0.0027294444446624632
0.003735980129509906
0.004019575291303943
0.006727668504822859
0.011140556727739389
0.012948005858654578
0.009323039666296057
0.011517473411165777
0.009592023581213216
0.01037713912534389
0.009070242420582693
0.005219686328850918
0.003256358994756699
0.007985109689995117
0.009034581714507458
0.013222712270848586
0.01443578530234616
0.01596642698173217
0.01244541140571198
0.01314622085800058
0.014478301746626185
0.009021791349258585
0.010094949671208883
0.006490921701813217
0.00798278102957849
0.003956608652235882
0.004701728894264681
0.004277467615827567
0.0032434179301367664
0.0016329739251279098
-0.0006822177562704541
0.0030572381627825733
0.002846825955191226
0.00566071334689186
0.0037881944569141106
0.007692027131162171
0.006756931061727173
0.00600115260068896
0.008742322727018303
0.006691704423188992
0.010470812178871546
0.011356651304572344
