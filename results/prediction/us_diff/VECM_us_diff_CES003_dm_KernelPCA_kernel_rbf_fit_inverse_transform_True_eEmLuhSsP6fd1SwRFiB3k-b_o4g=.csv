# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CES003
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=4, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.05640342445301399
0.015902793202117668
0.03632038363614567
0.03186126339021425
-0.005980404311728557
0.011371741497639646
0.02848480697883831
0.005468606763595724
-0.009913910919206943
-0.00023081169884633826
0.007341419739080037
-0.007894719135851007
-0.03470471533747081
-0.027064794597446075
0.01241356282961732
0.0009350829342166063
0.02547051841981293
0.017827135403233274
0.015005356927695897
0.02094518392877813
0.011266552756017033
0.02153590494981062
-0.00019028740273826757
-0.018137871723492845
-0.021824032745136186
-0.0008556991619093736
0.006853727360092574
-0.013016042247834305
-0.05553484775238704
-0.06441301678438445
-0.05548303205740407
-0.02504821539465331
0.008556152555931631
-0.024356257458981196
-0.016602709614054426
-0.01893602185445877
-0.025780361895199607
0.001956161980205726
0.011860795654918092
-0.026235198283992303
0.0068795505248011365
0.027960342820158725
0.0304563086330991
0.030020571703378796
0.026547997623110466
0.036174297074103204
-0.005811531936003601
-0.000706098549523337
0.010538016540041792
-0.006757763304047033
0.005890504430831436
0.01897954433654859
0.00985537015388685
0.04063303677772958
0.017785814496923503
0.027342188615361758
0.037736117314574324
0.022306850333196432
0.023797475322489752
0.0037655626660868698
-0.011753188027488648
0.004503631960086198
0.02380012010233658
-0.0043119328240961985
0.01665489534671622
0.021343417081787556
0.008835000815672962
-0.005245340748863686
-0.0054359052277312735
-0.019152110660459572
-0.0344513079528607
-0.041842668742149064
-0.06437357318172365
-0.06741822309565176
-0.011487971334704302
-0.04867969919678297
-0.03196240299302913
-0.0435111300344303
-0.05113720820847845
-0.03785944055009255
-0.0011241881216179582
0.014631772434001362
0.007396868815252092
-0.0011629222303597636
0.001666027820487997
0.0013290850378102504
0.002803156326731776
0.006454098216154329
0.019524822555233752
0.01031294492238349
0.03790596556581497
0.004147391173158441
-0.015905741192024283
-0.009329831652945176
0.004439424577735978
-0.004240231891267068
-0.029860066275675272
-0.02538683816006681
-0.04216707048113642
-0.03974486128991787
