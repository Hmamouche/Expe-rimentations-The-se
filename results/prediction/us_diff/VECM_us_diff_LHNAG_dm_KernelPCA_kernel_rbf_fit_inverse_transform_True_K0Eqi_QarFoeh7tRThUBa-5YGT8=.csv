# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; LHNAG
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=6, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.002133835373737975
0.00942435496062783
0.017931306296794083
0.011307673687572968
0.006495665363713233
0.0037247362922102683
0.013249201573498057
0.0015375966634886503
0.005781091434610306
0.008082244314546292
0.008836197403780305
0.008089855025452033
0.0029159801323466305
0.005460986842757978
0.010530841411963384
0.009003165633427856
0.008011479676380244
0.008317068508421567
0.009526672017769355
0.009619469022760903
0.007734626911994734
0.011208919541983995
0.0061016478631962055
0.004514682940208685
0.003944748445565374
0.003812587037392695
0.008704569225553589
0.00159205880540511
-0.0007678763798304906
-0.0029000151140740737
-0.00028469202357661615
-0.001333266184859907
0.004873716252670123
-0.00020125954726902835
-0.0031060709632637663
0.0019407660662016865
0.0020421218458816976
0.007175052607519615
0.005424422924942801
0.004541386156237197
0.0062837981631156505
0.00942981477004666
0.008172787020398607
0.0058097842848984565
0.005493473220293829
0.011190548147155276
0.005527151585007591
0.004167394691487167
0.0076966591532817525
0.001950326143738138
-7.78570749343792e-05
0.004588129669719329
0.00775162120359592
0.008270165547503977
0.009504183579333159
0.011369965507329787
0.008681055730914086
0.008971553494508896
0.007001801009647342
0.003434948393853993
0.00032099802776210996
0.005676013872951584
0.008133751048080423
0.001720100797063339
0.009076803317279943
0.00859970063790201
0.014411343332881665
0.007748053216246684
0.010637821276450467
0.016517247892046262
0.003494512595263809
-0.001979078909765877
-0.002064665034787653
-0.004931344655797687
0.0024599247388057926
0.0011221473144215907
0.0005973535164957376
0.0003973291765384313
0.002084803836101487
0.0036505548500141588
0.006581954167791373
0.009463891793588553
0.005795962634165635
0.00041017142900373876
0.006966402944915654
0.004568564997631636
0.005166314996640369
0.007297361317168235
0.006889441749085235
0.006970706938668833
0.011310296464527657
0.003948329749439513
0.0034302582801429447
0.010301750066211441
0.005905072015171384
0.008812410607811134
0.004965599542760066
-0.003254032141918289
-0.0022950159053729854
-0.00012285423884027464
