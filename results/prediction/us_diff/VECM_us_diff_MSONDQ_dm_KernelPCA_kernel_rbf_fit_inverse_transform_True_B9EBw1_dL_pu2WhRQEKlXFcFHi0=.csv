# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; MSONDQ
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=10, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.008423211883477222
0.006961955091092903
-0.00991681388223892
0.08393547861951686
-0.012694401586589639
-0.006582021623066273
-0.0009980449403588082
0.04136540795827019
0.025320402378466597
0.00881586789964918
0.041716627816033754
-0.012072760739555103
-0.028942090108257882
-0.03328780545368898
-0.009729425753297972
0.024370157499396722
-0.004297966962392783
-0.029687686252720703
-0.005249638880206098
0.0896217471441413
-0.026330048484981917
0.02847813225676473
-0.02227071032550125
0.010071400228700808
0.009843298706246227
-0.008282111221649315
0.044199562832063014
0.009298029385925291
-0.026151850821423694
-0.039467568255047304
-0.05532706560889787
0.054640411334928585
0.0003155040937679737
-0.02844884985207595
0.013338335074397592
-0.02352409187875166
-0.01841167804603129
-0.0021840248533674528
0.03663948792780901
0.025843183066161915
0.027574360350398078
0.019516913486617632
0.023780443677166904
0.0176179480152778
-0.007638466168771875
0.008838923319201174
-0.007911302158463737
-0.02454356200258674
-0.007461373357444272
-0.01321363250447099
0.04286705700848585
0.08594915269865457
0.02189474637869955
0.012076486696760551
0.004062255719682886
0.004903124012180692
0.01755882161714905
0.048237988539379946
0.05686861524397437
0.02881686594493038
-0.019063308116874303
0.008060544153231496
-0.019082209650957756
0.006475414069617977
0.01824031644903258
0.02993141555612666
-0.0004446741981554772
-0.020758098464885324
-0.002885782186702512
0.04538259136281679
0.016165968455269714
-0.022997882773048997
-0.0514092453837295
-0.07719641193150684
-0.06538842275574916
-0.05059536117256396
-0.04081362255873545
-0.024322739124562176
0.012667933026197408
0.028754164214722454
0.03022723912437756
0.0027477501366569724
0.04310113644218098
0.017840558847334643
-0.03351872701069304
0.007831903983087203
-0.014608007811111958
-0.029456541437718718
0.06479630932806353
0.06190283662862415
0.0928704934285213
0.048616805780363266
-0.041585017096516894
-0.011634335838639667
0.053756953342971224
0.011163606000889488
-0.028175200729545095
0.003689779854183774
-0.016824152959622068
-0.0010573365718225271
