# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP255
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=6, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.005854663542960856
0.006203835862889837
0.004201081366863734
0.0041220284200700775
0.003756879600313652
0.005531881004310167
0.01188716495643008
0.00956953698033874
0.00913609520166162
0.0072808532264754
0.004459755268439529
0.005801205767485884
0.0047761666509732155
0.0034028980527570397
0.005571381613987963
0.005642919283119029
0.005819259716920972
0.007079913093788441
0.008062116212712425
0.0054241159799783695
0.0068689343881423864
0.00645275738637538
0.005658091078313723
0.004858771616651652
0.005468917815493918
0.006235356565057849
0.0037905437868079326
0.006016548000063162
0.007294682296085111
0.003617263975498603
0.00205391749575235
0.005427904422319046
0.0033700928273478403
0.005371227582391803
0.005452323333380261
0.0047685339638427445
0.007588288921808267
0.007303780765996944
0.0032276033955220573
0.004759418882350009
0.005115243486123385
0.005387271587574362
0.006957768530306491
0.005209259886488421
0.0044773783764481484
0.0034829885221524938
0.004921836349532572
0.007759348493686639
0.0071223018202492975
0.006254144206882524
0.00852304718455796
0.0040184546119243275
0.0050002220744884245
0.0052773267130311555
0.005628970294707342
0.008144392989301514
0.007542921522775447
0.00904180325887327
0.010486029142898225
0.010298397353493818
0.009435453357602775
0.00733265416548263
0.009031928457157237
0.008293597718418248
0.010000920140808223
0.007783065617175866
0.011782136310099663
0.011565116638117772
0.010651261389016488
0.010741550004126584
0.008962556599535591
0.0076028117657641996
0.0031542377221579487
0.006750849745648811
0.0037661652325986592
0.0034841536896981513
0.005534924445852043
0.0051697581217054495
0.0021367149394062365
0.005556634416692196
0.004741272854796343
0.006749374627515847
0.01014620450179812
0.008401037930607945
0.007955325462979827
0.00807188646758398
0.006387110334841437
0.0062658409246185865
0.006600468211504129
0.007045912647062496
0.007643668674771238
0.006310031544685384
0.0067583052385313475
0.009763201482080553
0.007135960915083213
0.00764053371347387
0.00932056825752605
0.005314604225514633
0.005620478046348224
0.0037445915042478533
