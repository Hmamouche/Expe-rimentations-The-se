# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; FMRRA
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=13, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0014247478975096092
-0.000269351133174478
-0.0008712372444263953
0.000598605438075601
0.0003381648936980211
0.0013352124205216807
0.000644379197137684
0.0012218801750062307
0.0017202766791502347
0.0017932375128015072
0.0016352804071733161
0.0021276297763055145
0.0033490189061551393
0.003059359218459319
0.0013384777861711536
0.0009269672002209894
-0.0006633808524143788
0.0032563343475968736
0.0006852961538601224
0.0013100087735440323
0.0007617865020981575
0.0011727570090204992
-0.0009993801448012932
-0.0005434292399105136
0.0014220752676130837
0.0008822637758769871
0.0005490739928151689
-0.0006151464800598516
0.00031767400624548763
0.0008156204955169551
0.0011630028964177861
0.0008645970939776164
0.0010185917877728865
0.0017441475789258722
0.0034653087978929577
0.002352180568353173
0.0020404399045240696
0.004458557208185967
0.0031082597593419165
0.0037840884475333764
0.001771292859897905
0.0024542400968569794
0.001663245335790603
0.0011526324618302492
0.00024399599511870293
-0.0016665081084483334
-0.0003347396372761492
-0.0005817487053416525
-0.0002509135973115401
-0.0009136152717275175
-0.002119563351679642
-0.0022200730148613187
-0.0035323464618116076
-0.0036928758335497713
-0.002343652523043007
-0.003110436757822523
-0.0012764747215223337
-0.0005611316010774701
0.00010264842880903519
-0.0010190987745781997
-0.0009301962257569475
-0.00044638295411575954
-0.001350167885621977
-0.001958441492063441
-0.0024822977793207274
-0.0007810045460582334
-0.0019849028139696787
-0.0002932022113545801
-0.0005539825896358301
-0.0007718661812851972
-0.0008315482728598624
-0.0019453799932813876
0.011614770413518048
0.004161887925115492
0.00708127164659183
0.0013894380033723727
-6.246107793273956e-05
0.0010652660954242358
-2.1909351018015405e-05
-0.0031099894570341038
-0.0004815397699531205
0.0027795311053404447
0.0015063333969423658
0.001664490140278041
0.0016477807157502281
0.0009476880619289446
4.321974007800793e-05
0.0012970053738556363
0.00033740851755712127
2.8240293485043655e-05
-0.0010922406714638825
-0.001723823764451753
-0.0012203603664536259
-0.0003630472084309423
-0.0022805996149905822
0.00028643272827382534
0.0009811893209685455
-0.000667222939740006
0.0011864830841253264
-0.00030902482376177345
