# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CES033
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=9, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.02129136346537122
0.032342654677193675
0.013361545287602245
0.0010257163009816331
-0.03573206725465394
-0.027837603956819015
0.012160382873111247
0.003248444400291873
-0.007138142544784683
-0.0027499080912501937
0.005551198543490367
-0.02080935464447281
-0.01918434091552523
-0.003273682672912656
0.018813239212965762
0.028118199064495718
0.00895480486908374
0.003560273199512553
0.008491999051761246
0.015530779311925844
0.011580549563163258
0.01011956943000057
-0.0060528483388251975
-0.010963068869354728
-0.01734061834260712
0.014061769798557566
0.006517752000351202
-0.015078216657279946
-0.0004765881388337674
-0.03930922589382861
-0.029513423794657205
0.01984991736624115
0.0029844792503605985
0.014601703344341422
-0.006389059400752347
-0.0035486117438786047
-0.022527545845003546
0.018155178227877745
0.019265886056843325
-0.0069494091808422545
0.016059953312760323
0.005045165071891252
0.011790485498402215
0.002678482210813089
0.007920943496659174
-0.006435221224561244
-0.0009990791230937365
-0.018356374233860624
-0.00864715584068654
-0.0341655692394437
-0.014895160322332662
0.007082419101128208
-0.004012906075464719
0.011454620089431555
0.008477408695007536
-0.01519837643095389
-0.0035901856564561916
-0.009136239432741649
-0.007538395043331947
-0.011234656831306707
-0.028093124758350473
-0.01977595122430434
-0.0010919039000801484
-0.013687566907651353
0.00818128838308697
-0.008629675530828723
-0.014342036488479757
-0.03393233734968938
-0.014755750552027363
-0.02567125621510307
-0.03307890353273363
-0.04684582278768983
-0.05108207737764836
-0.04009484612618309
0.002500061412812296
-0.02793456783354108
-0.02650566511996335
-0.02543927460381823
-0.02682489980201113
-0.03390861773466887
-0.010744607129996581
-0.014212022313842937
-0.01858773258001012
-0.002315960801337227
-0.017076260325266948
-0.023952078471488163
-0.03698906560587516
-0.012074289961724924
-0.006908427165583839
-0.00905543558461525
-0.0036325338652024915
-0.011324220479834585
-0.026551923091410683
-0.01724529655456889
0.013861843574902583
-0.02659688839767944
-0.01261122007439235
-0.026292662845859228
-0.020292052300781002
-0.008070768004822978
