# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP275A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=13, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.001102327110836771
0.004232486379030434
0.0033459856307557043
0.006898952216860579
0.003686386356546344
0.004024653068815296
0.005030840177303235
0.00497515612204363
0.004767557486592965
0.005622078452779171
0.001328478534927507
-0.016907838796665263
0.0032791131430666897
-0.00585018960945669
0.00267434593041645
0.007947301447832948
0.011366722062713488
0.00397257619794044
0.008210703639683799
0.007841863672957741
0.004446196588357274
0.00507868008477307
0.00969108779133352
0.00863816868343613
0.010124354307899073
0.013231827907818022
0.009643910548261306
0.005771666605639864
0.013882979892632668
0.015063494612104246
9.346509490512373e-05
0.010368802364446986
0.00504626251400621
0.01070145617001758
-0.005148286505133082
0.006165937019754741
0.004423841925898339
0.002232944478156371
0.006165234093100856
0.0001856533173108255
-0.002091918328066269
-0.0012204345150322194
0.000968441485199408
0.006432481875815129
0.0027273444503589646
0.0011483233517736156
0.005381825966624174
-0.003888130165326009
0.0013547799350904755
0.0002458050379418573
0.0034523255945213913
0.008551253850827986
0.006593641940437196
0.006734163895359788
0.002848462307228711
0.0024371108146816443
0.003223713793511272
0.00066781771407213
-0.0025602306310839084
-0.0013033913175376504
-0.000489010225895971
0.002983780447958621
0.005579051727749565
0.006368925191065662
0.007342893947088629
0.01323523022813456
0.006609984907681465
0.0063902937491359104
0.009662237296980281
0.007965082508565974
0.005265906209836654
0.006692874873106202
0.0037792149143055617
-0.0017833129104050075
-0.003158890111898055
0.0028746427604048157
0.002541655173825019
0.003124377287090462
0.003897803969535799
0.000793455730990998
0.008231096780684871
-0.0017423803332677567
0.01446430269492014
0.010177875754742834
0.008384557624867946
0.008662828698683619
0.004337511757611085
0.011048481931969658
0.011078903010935231
0.015514235672750546
0.019152752104333506
0.006346604790185068
0.009421568833919702
0.006297647968901032
0.011198425746653393
-0.006763432772209674
0.017538237202860518
0.015649615832030027
0.016472661058833743
0.015803298474071165
