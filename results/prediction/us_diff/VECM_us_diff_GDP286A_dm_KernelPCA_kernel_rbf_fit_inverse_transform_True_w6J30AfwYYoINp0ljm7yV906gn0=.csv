# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP286A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=14, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.004497839381394595
0.001352881809285519
0.005796457424076062
0.008364300005643983
0.008257167168666646
0.0047171526354749275
0.00647121340131478
0.004397682396728176
0.002582166196914889
0.0034697839275505435
-0.0006724772276891936
-0.003968051746490916
0.006530758068731141
0.003245478383805016
0.004866653215915991
0.005549685892037259
0.005141313842858958
0.007794388099750299
0.004590956998655195
0.002531680756877379
0.0028602813353475237
0.005038152513836238
0.001441412902281412
0.001559757899128628
0.0032108812895138028
0.006507023857830993
0.005950067382776575
0.0025183300006416578
0.008285746499452682
0.007476821429286086
0.0004447373283040924
0.005833033698685884
0.010622631776525993
0.0022111150811204715
0.0023402995401115905
0.0057424531642828016
0.0037344034443172916
0.0029049465366887163
0.0053425816431132206
0.0031829731381452587
0.004551273855379824
0.003500877793140924
0.0035401193188092403
0.007360914747159977
0.006609671409741471
0.002756941409355552
0.00371679149220299
0.0018548882161127007
0.004707419637304141
0.004299969889111101
0.004900868226248582
0.006065336072359987
0.0052389967716690656
0.0055787818910630164
0.0007486076434329205
0.003971425002670952
0.0044562400218386995
0.0036909550644318423
-0.00039002260982095693
0.002973829240004492
0.0021882383484256563
0.0059387992091589755
0.002438973930734056
0.0019453241953118969
0.008190661038441318
0.009874400411042438
0.006812497100859702
0.0052064474404220065
0.007384715571595517
0.008373783915408651
0.005362765350753212
0.008069288019138617
0.004749710717296991
0.0030378149031296438
0.004158021564471842
0.003565224629507245
0.0067636303695996726
0.010520735670512284
0.00650982512880786
0.005831153496743964
0.00845034405374458
0.012951498033995552
0.0029443400762105797
0.012424131909863955
0.010398725159715126
0.011986901630355828
0.010119064775363607
0.012176722718171164
0.014907182227387539
0.017568712988019885
0.009935497170290512
0.015681021901072806
0.008825639157440333
0.010118969597113657
0.010138879281167152
0.008965645933995712
0.015029255694771761
0.014641059872067413
0.012684023381206045
0.011166768399300833
