# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP256
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=10, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.01656543356546976
-0.000945665777208466
0.041662214921024655
0.025151525792207696
0.006290261445464915
0.004374829507780323
0.025075192706440236
-0.006235920906991271
0.001887294801865099
-0.007782528230638814
0.028699622998899586
-0.001364431699859156
-0.006190174873501444
-0.017565414153451787
0.010830476626334972
0.012861855046998643
0.0038779672499493264
0.006907452222910728
0.014954033997967858
-0.0029700475120518714
-0.002734467873170888
0.02021764730234452
-0.011404219410003094
-0.0011988902426241302
-0.012078204367492976
0.002854922821402001
0.010313239733300653
-0.006444111743196758
-0.007873055465759615
-0.030188234919473114
-0.01680315876652136
-0.004164528565941832
0.01004337971332899
-0.008480670274029578
-0.0027266869520263352
0.005945208173559178
-0.002608792482998228
0.031885516559675545
0.026971944605404002
-0.001527190306627636
0.022039094837848848
0.019395221780749542
0.01832617454453069
0.025444905540648093
0.020368332190608674
0.017773175439870715
0.01018446064287472
-0.005865382380312831
0.00035991408413626374
-0.0036298219099374337
0.0017608087282341136
0.028053373158919766
0.00766793134497096
0.02916762622433257
0.03145041316667942
0.015420047015331315
0.0400643890089549
0.023802563754999468
0.01658216503567251
0.03983261738473161
0.0008131376395361387
0.0010062501612323014
0.024074610860615013
0.028107713949719372
0.008034569041992755
0.029658935678426247
0.03402969035572015
-0.014602893688023701
0.02047235902911871
0.011660264214069196
-0.0014179135307325259
-0.0032583232974413923
-0.026685918349624846
-0.03953836990407261
0.0030133909578999966
0.0024711471209254
-0.0319149674128449
-0.0075417765411470395
0.011204343102732973
0.012101255866163103
0.0017986340317916703
0.037282384388086086
0.03506797124511842
0.003734341846180645
0.0033575431994689164
0.016911353451002996
0.03244303292855155
0.015841680195237365
0.016634953326627823
0.0015099622068393973
0.01488051066581807
0.006873204943956603
0.008349355489156166
-0.0036086552244693412
-0.007466420201785715
-0.01931007666937666
-0.04537874122569688
-0.023470665341560518
-0.013188194223509805
-0.004645616559293841
