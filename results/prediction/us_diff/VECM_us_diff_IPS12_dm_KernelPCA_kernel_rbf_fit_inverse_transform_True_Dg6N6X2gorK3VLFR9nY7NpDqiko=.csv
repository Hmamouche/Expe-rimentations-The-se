# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; IPS12
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=3, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0045156607368058346
-0.002342608505595133
0.011351656629667636
0.0014871602445279829
-0.003594463319907042
0.005442820608322748
0.0028747781222107126
0.005672615321247209
0.008372834334306172
0.00554461487085311
0.006796073358410135
0.005343494557306401
0.00599125049694473
0.004662414366074822
0.012695860729179198
0.014514645566315404
0.008657222109551022
0.005755322706483613
0.003567863321349818
0.013464239672048505
0.013422157984408588
0.0103971659941155
-0.00019369040501361103
-0.0023221170490167367
-0.00030808808188329
0.0023458691227266565
-0.0023007638848436948
0.0056394568695238715
0.00011314746201547391
-0.005295382762319638
0.0008339110677331642
0.005741278157717147
0.005633722878446795
0.0032681859829662564
0.007385575268102601
0.007950655375112536
-0.006895035089626574
0.006081150655272246
0.012763079143291757
0.00956818913760763
0.008927847252553054
0.00875507179982777
0.01401829365987989
0.009917825672928107
0.009325931002142653
0.013235831881510021
0.0031523526894769584
0.0005575729447771351
0.009777054853968438
0.006860493828068311
0.010520949320182849
0.013670267129050357
0.005465633790711152
0.01105453034820935
0.0049085061149672605
0.008282435953377864
0.012417007862457856
0.004876625105596385
0.007214459990124222
0.018079053711085303
0.01060062161463372
0.009772809967186658
0.007547224620590936
0.008034476481024642
0.010730478478980727
0.00897952166787615
-0.0011669112901443685
0.006744512795246825
-0.0009402682613634302
0.0034890839477444008
-0.0005175159645882419
0.0026126740203340475
0.0007986981653873919
-0.0033202461441374457
0.0030907361919050914
0.003773894200293673
0.0042286406237383375
-0.0011189574435146203
0.0015140521575782745
0.006694573159939071
0.01857069893607734
0.014338180902096768
0.0074427645706427095
0.00042371154618733604
-0.0011668037840615428
-0.002215303707759075
-0.0021038234692968786
0.0030317378907039156
0.01554487534584747
0.012411511757845137
0.010618090925517703
-0.0012405521922477375
-0.008733253002939383
-0.0014508679180638747
0.0013409310587589349
0.009011915964483894
0.005878992839176714
-0.003008301434886715
-0.002877273444049182
-0.0034429261721125497
