# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; PCEPILFE
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=5, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.008363750736202834
0.006566529657876968
0.007102878265604573
0.00641830465167172
0.00790156915724564
0.004296322529651017
0.008602269597216177
0.0062087142955252516
0.005860430504723867
0.004880614916343078
0.006277800974089679
0.006796278565765643
0.007044864314283527
0.006931580004602681
0.0062506442559271715
0.0059147583857573054
0.007523700041083422
0.006979457272410243
0.00905694453611453
0.007798700745854434
0.00984827106405872
0.008689000571993101
0.009086665064581155
0.007865222759507334
0.006309707479580527
0.006624751761452272
0.008020899105327385
0.010395735393160608
0.008782966285390692
0.007561503053966855
0.008310688527110754
0.007317490672890529
0.009221684254348793
0.0074257485405486955
0.00859027900179058
0.0067537613827861435
0.006286919479989509
0.006418029420402039
0.00588457977567269
0.0051972374016488986
0.005617638738870498
0.004075899761878511
0.004820332521649122
0.006281408470351966
0.007144907788617125
0.0051216311171618425
0.005698584090467607
0.004633272333186236
0.00550844449355344
0.0052698942170544445
0.003951818976003181
0.004308808058513045
0.0042291174277321025
0.004465385168781879
0.004580553753510566
0.004990758045004849
0.0030580467126431862
0.0030705020131225297
0.003418975772955812
0.0025535295297012717
0.0033297304591094383
0.0033922734401241783
0.0036745825255426554
0.004395082502208705
0.0036875398573937733
0.00480259244882456
0.004801447377590362
0.004627103366334998
0.0032829131262837115
0.0034233893617767676
0.0052132117382452615
0.004639358866054891
0.005200307487180426
0.005739330963703732
0.005160847340689149
0.004890722129489676
0.0033120261257562796
0.0040854525842653165
0.003094130376893005
0.0027371942483618216
0.005262752581318749
0.004578928842750915
0.006056478684189024
0.006045425908814557
0.0057276217575309395
0.005181709618750371
0.006600962949706341
0.006154756000539177
0.005102937389303003
0.006346024316571033
0.005900728143899014
0.007523290798358455
0.007115523169689858
0.0069604651433159675
0.006844191354140158
0.006056896791435045
0.006393965518091227
0.005788490520957488
0.00637185237890273
0.0065887212637505774
