# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP276_6
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=9, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.008688516310016771
0.006440070994964493
0.008537809371804202
0.009002245415502664
0.006141409951876884
0.005241469208973899
0.004816991543465984
0.004784589009209511
0.0038775810549165107
0.004638618767962271
0.003531152136578057
0.0046056017748207344
0.0032797667858580626
0.004097929865646236
0.002765188299255481
0.006331454750160657
0.007020675356266553
0.006582546198976105
0.00781594245483874
0.009343778692670932
0.010657427001705095
0.010866610599722337
0.011963471769626248
0.009059280281383413
0.010303818689649582
0.009554593073360285
0.010031737148612208
0.010624599355567544
0.009642852390362406
0.009907544955951982
0.00861042995589173
0.00912199281951954
0.008209859173761627
0.007677865384852496
0.007048997050420887
0.008413373756018961
0.008846743623790242
0.008015181250836738
0.008777938004884089
0.007230314441306143
0.007231580625346378
0.006229350179028259
0.008019271528407968
0.006962551907430866
0.006451531348410193
0.008055286258578591
0.007316390612867183
0.0056640003925959624
0.004859646293781753
0.005560253190015152
0.0035917358126909232
0.006005965946352068
0.004924295830846212
0.0050209777877375785
0.004244661147083149
0.005204025455746535
0.0041915183105356
0.003732959741848471
0.004522691692182423
0.005377837017038809
0.005324918038104412
0.004316949242437516
0.004564608610446844
0.004378654109611761
0.005025834890187181
0.006167323776466711
0.005017561904506436
0.006359324975487075
0.0063644962008225
0.006380498567598366
0.009139517247238523
0.007213500279884721
0.007726353891885077
0.005024212668254349
0.004980178014674051
0.00561175821667304
0.005051814712211733
0.006431815116414172
0.007679560088993279
0.009841182586260874
0.009870689423045267
0.011312155541326639
0.010551544222630646
0.008768389493370232
0.008942237493205742
0.006926783390600492
0.009926857862446088
0.007627500781442294
0.007917084895606444
0.00826333534337322
0.005428527983738293
0.007646910851823825
0.00752347864734326
0.008393782545243473
0.011388428279278488
0.008379135310368244
0.010317343719922331
0.0045479147440577366
0.006155029627490557
0.005789644527103426
