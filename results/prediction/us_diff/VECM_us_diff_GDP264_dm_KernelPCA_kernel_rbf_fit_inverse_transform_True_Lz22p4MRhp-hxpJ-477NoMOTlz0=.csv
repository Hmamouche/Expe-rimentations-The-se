# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP264
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=11, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.0016390624903901644
0.001710031233061432
0.010905183816582667
0.001135437056115747
0.008468201533671237
0.007012596389691716
0.014651136844416155
0.006376597568908223
0.0025096175203941046
-0.0007696666003398295
0.007543141640926834
0.0029555019698703994
0.002735494976251527
0.004742251438946824
0.006519295291140533
0.013919363698124156
0.008263987770663315
0.006097333490608158
0.0011258362127421354
0.004836600226190634
0.006052974345801548
0.009644159664000633
-0.0030796612690465234
-0.007045333242516291
0.0029472036146581428
0.0012302800055203167
3.1692479289490956e-05
0.0042765581073418765
0.0007954499462316882
-0.0001058908598833095
0.0058602295306245476
0.005132820518424636
0.007084502713290039
-0.011810766785159684
-0.0006433535440854758
0.006928759327527959
0.005960836952635574
0.009942043593576862
0.011335691025944956
0.003316522753207914
0.007333867238925212
0.01087872712048395
0.008715013886582024
0.013221766852844636
0.003978025556960986
0.012711284944970548
0.014109103888572146
0.009691919427721575
0.012909658484092926
0.0062839773930138
-0.00035983817037952507
0.010266937092178532
0.008983409364733097
0.008870634297720774
0.01886178001692436
0.012821035686539306
0.014539871071362443
0.01893667574369071
0.020388999637244852
0.016321889569585815
0.016585098951170957
0.007656208455105816
0.016117649964532636
0.016233577876974797
0.01742641475569738
0.023352735476925447
0.019935053683774656
0.019163538947527054
0.017830885244802794
0.020718864509980672
0.019957437889967615
-0.004409974099407933
-0.013043802331248178
-0.01664578364701195
0.020391961738808646
0.01619390947651361
-0.003323365848098227
0.010462978854342424
-0.0029569981214253895
0.010192003065543158
0.022961911764945067
0.018086677468376236
0.015439760400191078
0.019976121729102132
0.01598988283408957
0.01913284839822956
0.028228160431234644
0.005787371151812516
0.004018090990573493
0.01856307547084965
0.030821190023744872
0.0073612130138230765
0.014111699309396337
0.01819611882890096
0.017056301246124773
0.0008126280077699229
-0.0014145115717862813
0.002200483379468491
-0.008684029593272559
-0.00883057947649422
