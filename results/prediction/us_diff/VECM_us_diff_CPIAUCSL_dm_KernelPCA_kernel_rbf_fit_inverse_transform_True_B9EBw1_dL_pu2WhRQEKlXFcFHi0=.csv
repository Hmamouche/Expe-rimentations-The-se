# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CPIAUCSL
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=10, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.00045477522658004524
0.006944345612770077
0.007023962494326303
0.008193201047215205
0.005587324268165356
0.004611878733062606
0.0060610957303423455
0.004537434852718479
0.004163735916465482
0.006058563846110757
0.003974625417449296
-0.003774539580361812
0.0021055278520353358
-0.0008022251746999623
0.008781412857623804
0.004762601735357015
0.008434403024619421
0.005803524822002572
0.005374222973173123
0.007415608767274347
0.005922034597502155
0.008471956733132875
0.007717535999055172
0.010125741135827631
0.0055771100511539835
0.007744114090513314
0.007792924560621415
0.007911885061090444
0.011522833191584318
0.008544253709455496
0.009301996167822898
0.0061561697450312775
0.006169291193026982
0.006611287525136013
0.0036837020479622102
0.005277884902856116
0.00605223682082502
0.0076440850320558355
0.007074026330847215
0.005149732893572561
0.0033060707011335184
0.004819173478387798
0.005227153642040107
0.008131180451443027
0.0045463999889387265
0.005350603705938172
0.0077545613505085815
0.003915678218633048
0.006097786785114768
0.0037763883592521743
0.004644109269467883
0.007741635537600737
0.005657137104850277
0.006507347728893117
0.0060614051083701095
0.004672840684234126
0.0031083025374243492
0.00424437816787129
0.002870660710121556
0.002853399625515518
0.0030343662882063886
0.003587475972011789
0.004986407503864375
0.0055605637477619905
0.005085562888227205
0.007668381042079665
0.007042360928622719
0.0075150691681597675
0.008494838107708569
0.0068873139960491875
0.0074967590174991995
0.0052681566002355405
0.00645580166789437
-0.0005238369104953502
0.005115731701064203
0.003954459926534084
0.005302098475115208
0.0063065749937693295
0.00676363133632854
0.0029136275157961443
0.008005527945108193
0.0005950298609350595
0.008328929567632678
0.006384303805395595
0.007664713831487704
0.008103584226281772
0.0075145677929525714
0.008570439979771362
0.008145638481931198
0.010667502293437544
0.011477332432155417
0.009231276268659269
0.008744016130068307
0.003420529013493704
0.007961535942533774
0.0020501972020315644
0.009124777230566853
0.011670306765989676
0.009187235675807804
0.014981423542824708
