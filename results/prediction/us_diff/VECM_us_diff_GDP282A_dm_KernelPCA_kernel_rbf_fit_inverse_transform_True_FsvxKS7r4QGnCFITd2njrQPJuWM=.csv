# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP282A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=2, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.00169715505613899
0.003989340661472907
0.005139828877921631
0.004327552051112148
0.005094779971569
0.0037310525652218323
0.003573045264039178
0.002986422568510434
0.0023566111780578083
0.0027169945891473172
0.004102394708269605
0.00490578617431579
0.006128441365109707
0.006664157534823207
0.005958997429941522
0.005482847386097918
0.0059147387394711355
0.005633892966670422
0.005796073425023284
0.005054825727907037
0.0047180691505300295
0.004895405627824632
0.005073611739938503
0.0050551220656514335
0.004963216763426674
0.0031638340860479664
0.004241580261985758
0.00405725036045914
0.0029904865744123355
0.002588697423007677
0.0011352179530602984
0.0014037395428928732
0.00262292469729232
0.0018287610167761138
-0.00012185932462157234
0.0017601412868833662
0.002458389753480553
0.003039548104278359
0.006169836790300509
0.0065506967650890684
0.006473748012519582
0.0054506972837453154
0.0059990991038700705
0.006422734108656308
0.0058284216208545295
0.0077447843764626104
0.008394899087287728
0.006693746821418742
0.004954724041777386
0.004631215978970896
0.003502089807313883
0.0028221062113393596
0.004521052684072264
0.005482723261137974
0.004265385178768129
0.004601879555492605
0.00542215450067295
0.005453319724104752
0.004324882592813891
0.004330651491006811
0.005720781387254393
0.005784148464800057
0.006149142849933558
0.007417847591193666
0.007776925791618537
0.007373499047358038
0.009453389398301676
0.009830787662010223
0.007961439597951741
0.007863962281324806
0.008244434998097242
0.008619869720136442
0.010517380512547234
0.009563160639237706
0.00615379476126926
0.00562708068384103
0.005794687208593136
0.007179730969429164
0.012879179832867968
0.005081894818072249
0.004767754572979536
0.013936078653621415
0.01664665375476358
0.012562262285710462
0.017103325429437325
0.01794144867235911
0.01759525402712551
0.017731923616979554
0.022641627482972153
0.017751101624940945
0.0169849492043777
0.01696232611603484
0.014322519457192633
0.013934425597325825
0.009751667444287078
0.0019517433435824409
0.002181643515828946
0.0028988515283199295
-0.0034032992649340645
-0.007708184544770663
