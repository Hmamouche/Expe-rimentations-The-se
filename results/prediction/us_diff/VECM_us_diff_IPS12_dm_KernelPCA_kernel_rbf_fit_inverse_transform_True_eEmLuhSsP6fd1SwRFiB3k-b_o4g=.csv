# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; IPS12
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=4, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.007124104615027033
-0.007424154350348784
0.014342711611076968
0.0023128388839992273
-0.005635276635304988
0.00444971294201127
0.006911278854414803
0.005829324525731132
0.009554692604202202
0.0055588588827763
0.0065241661675500846
0.002527834710533771
0.005631972117165792
0.0072135056028036154
0.015444610224485882
0.012179824855985764
0.0066510742702595
0.0074158077567605014
0.003706180221768252
0.014331308979363435
0.012193239566505209
0.0108385958968302
-0.0010552322044739674
-0.0016194770076461114
4.124918428000037e-06
0.00233649921201596
-0.0026296066638941116
0.0038233016983239164
0.002951290120457148
-0.0048910648460877195
0.0008081079874145542
0.002625036330292343
0.006547873514291634
0.005425484577779935
0.006801320629675919
0.00764718445514438
-0.008026690688295597
0.006904704460274199
0.01378084768308041
0.00974438018617356
0.009345788531433329
0.007654480207121499
0.013027768950423197
0.009726991511528999
0.008936862215798412
0.013772847640558214
0.0024371931215343137
0.0023350949163974057
0.010478845434793133
0.008006332482667453
0.010948625184719276
0.013525604484819731
0.004801637096407158
0.011861570027520018
0.004947482300832296
0.008058813376929595
0.013623709475569817
0.004987406584429747
0.008214581280758899
0.0189404834570323
0.01044103532153194
0.009320120110625729
0.008323392609370853
0.008211058463220603
0.010316334640902253
0.010259075204087484
-0.0023537961684469556
0.006015695393287622
0.0007073659825891804
0.0044392487038100855
-0.0006751920411909847
0.0019877535596828193
-0.0002503064231282567
-0.003493276521984998
0.004572555649837237
0.004063312474203971
0.00391602442758565
-0.0007403455682213587
0.0001006788227090852
0.007441394250603053
0.018915644948433168
0.014532721800672749
0.007591593690052176
-0.0013913067582060254
-0.0018918476642037184
-0.0034075177412784662
-0.0046890179447111055
0.0042669800239022075
0.016178587592673804
0.012213507549092657
0.011191023428889255
-0.0008073233222936414
-0.007852819075148395
-0.00028120202423340124
0.004353371208561895
0.009211376797586783
0.006322176310347752
-0.004037352311845065
-0.0029079101791001866
-0.0048310132055355125
