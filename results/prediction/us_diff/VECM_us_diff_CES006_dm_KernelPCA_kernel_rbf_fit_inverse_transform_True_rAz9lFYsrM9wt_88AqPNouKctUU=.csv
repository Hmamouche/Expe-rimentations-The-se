# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CES006
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=5, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.006158457372607111
-0.014374758034789388
-0.02715393958330862
0.025327526087650404
-0.005871683363887169
0.008598027468316637
-0.007657840025844194
-0.03499539749482531
-0.02319821345049794
-0.02193074182456777
-0.05564207312202865
-0.0525127786743079
-0.04013657778925124
-0.04130655835562809
-0.05372351830141713
-0.04809540832495787
-0.0006867113938258543
0.024223869947598994
-0.021661619238831777
0.014673912957135257
-0.02623960577875783
0.006916405924377929
0.0015782555272505962
-0.0043273573256501245
-0.014123932954500401
-0.01462044338973062
-0.0030031971050723224
0.011605293048302545
0.012582002230840836
-0.0010255052772028973
-0.026666507007630406
-0.030902129998840372
-0.015299856027979262
-0.0029481307204529406
-0.005982371248252176
-0.023487030882576816
-0.056389622519706
0.029720442022528593
0.0011499679198882472
-0.03333911353340867
0.006618510485995176
-0.03548651402893674
0.00048508627723778484
0.04922081516276007
0.012406291650353014
0.004253601890626251
-0.01965207991089075
-0.023284703826439844
0.0030196853264421696
-0.01762137124231031
-0.022996211490162517
0.03182256482324777
-0.018338941895473374
-0.007258352484587003
0.02988384606911016
0.017261939844629554
0.005951204350352622
0.0010924679574272158
0.00286137558916175
0.009096216225467798
-0.015614311104752698
-0.02067194277522255
-0.009798172071436951
-0.0059041591752395615
-0.017116152917471858
0.017390127246388724
-0.02978598349677732
-0.0042414975448459395
0.008577658361461467
0.008406950713448384
-0.028042371601241515
-0.001735418577707701
-0.01585478182005509
-0.028869146856425422
0.042786622359215196
-0.00810555163491598
-0.04661688291651325
0.013374568991063939
-0.00421778669716927
-0.02900373316058732
0.013255206751558786
0.004615334064084391
0.03265622681228886
0.01998942909542363
0.014741722552963682
-0.01088361676462221
0.014319830568264962
0.016755582393377023
0.015441321509179588
0.028275499115620006
0.009786912091009504
0.0409855860491806
0.037098723535052135
0.030425911328187474
-0.002871319320128222
0.0383229479725698
0.007023009797789804
-0.0007025735412839896
0.008921308351181226
0.010938232814271842
