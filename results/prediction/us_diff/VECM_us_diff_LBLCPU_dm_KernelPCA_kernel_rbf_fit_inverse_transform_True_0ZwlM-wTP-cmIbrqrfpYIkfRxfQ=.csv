# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; LBLCPU
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=13, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.0007501864435880672
0.02233858679793472
0.006203920537863294
0.009950661804226602
0.011857008117762436
0.006783558355473604
0.0009384680495102674
0.006361381935381324
0.0011541424351557091
-0.00425840753719292
-0.00475696575674967
-0.0026784502311788987
0.003839897925904068
0.01896545032112582
0.009025660195026113
0.006202580544578783
0.006411464885979043
0.005725259999923712
0.01436098299697522
0.004626474123153635
0.00381013961148139
0.007234323481711901
0.004632782408736026
0.00330053909973489
0.006921520591669855
0.005168609297944704
0.008465335917487778
0.006122110632668077
0.014593192386291523
0.01025034108309089
-0.0027320594401933503
0.013316690126262281
0.01287848488741866
0.0017606939543141464
-0.0008787968751939254
0.005977130950464436
0.008185567972908004
-0.00614342507773662
0.0007148220790009411
0.013561673130496573
0.0009526633974749549
-0.0002163355504357036
0.0022537730751411886
0.008010746199590267
0.002014479780662496
-0.0008151497670642689
-0.00015653898909200525
0.0019127319907912745
0.003145220808062767
0.007683007500694309
0.0021251431932008094
0.003145203178603999
0.004128069807843474
0.00723834515524674
-0.0018472845130985311
0.005442491154080162
0.001612358673968025
0.003478085172906442
0.0021851186548705803
0.01270362354451347
0.0037642748530523126
0.00989261848988567
0.008040038800219654
0.005528613495394685
0.004423781527188472
0.0068781064353432946
0.010714161252531112
0.012460437936118184
0.0031302640397942723
0.024159013866646192
-0.000916997853293776
0.013262054900539976
-0.0013206070145854879
0.009560641446505118
-0.008419956475174031
-0.008231913044128125
0.003234817746171275
0.004899286002579749
-0.0032752673239225204
-0.007105122188973824
0.006724838889491824
-1.496967569679028e-05
0.004235596585268307
0.004846192016233092
0.008345459059938718
0.0025427531893398663
0.004079798393264297
0.0036935690344946192
0.007663145387672222
0.008437945610116163
0.008740524978356678
0.015982165103802164
0.003987727695944892
0.01361141839912415
0.009190603652227533
0.01072565740304446
0.016928291214804936
0.01729454957600302
-0.0024931388535011424
-0.0067613450206393646
