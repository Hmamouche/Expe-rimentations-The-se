# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; MSONDQ
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=1, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.043818510678501094
0.0036297303331904304
0.0182419665520047
0.028465906308669908
0.016723400074346324
0.008370311238030961
-0.01921572344495643
0.010853856420722681
-0.0004899518222329395
0.014012195085842581
0.012176021865661411
0.0062469078552554085
-0.024192349952760414
-0.026237151845188343
0.017539807832205226
0.007213455661329456
0.02900541400743608
0.00633191706889584
0.004471762870178557
0.04643416255639798
0.014171295228677435
0.04765642076461671
0.009858000378011093
-0.0008051492417920779
-0.008604331299819551
-0.0170371072493592
0.009438189193322575
0.010133802979007046
-0.03900155815050059
-0.045660027892963265
-4.880937731880047e-05
0.041954991422214885
-0.02138342752521631
-0.04294358380076747
-0.023099971622900332
-0.0031199520249910566
0.030937646951167904
0.018155863485525617
0.011997825519983928
-0.011621881172150744
0.0033402615163205746
0.02713928240890013
0.03399963623166663
0.026113383129748726
0.010812052399331648
0.02864833100769327
0.0027303395451396015
-0.008503487413835869
0.004200155484180878
0.004540341287938156
0.046670868670656354
0.053634200874758245
0.016503221721905312
0.010997035475736557
-0.008820791858399148
0.018010800310499748
0.02212723836246676
0.0389070576813107
0.062287700199484396
0.017871347997861456
-0.0034552212474630497
0.004287248197522402
-0.0028969412235704903
0.004121942198891147
0.0024780224554687125
0.032876091157465155
0.037354754828759475
-0.013778885125021437
0.006912806619548094
0.016688663735681713
-0.0016065982593339886
-0.01868404685446211
-0.05780676160808334
-0.08236029951715232
-0.042452556773059966
-0.04762715519612635
-0.029708360919046387
-0.014252050714106313
-0.0005609978325239497
0.0007216066583102063
0.016294253138978965
0.03543972220429055
0.03221458977112656
0.007819960994377045
-0.012075567248853222
0.014550996351751451
0.019336381366271985
-0.006165679683254394
0.04996175689468949
0.029035164278010984
0.07814139699049762
0.03763867232324471
-0.018227781024413366
0.013008421739966735
0.012620783477820485
-0.005357635583429751
-0.010025455625598458
0.0007972931477443533
-0.012226574822655645
-0.0002923246920282837
