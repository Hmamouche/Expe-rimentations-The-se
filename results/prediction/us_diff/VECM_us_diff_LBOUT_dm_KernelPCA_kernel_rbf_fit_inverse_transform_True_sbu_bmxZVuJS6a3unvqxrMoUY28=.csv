# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; LBOUT
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=1, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.009432821415326214
0.005180905208507525
0.005112740561516551
0.006993681130861489
0.0032593685035335355
0.005554225042314461
0.005792742733687915
0.004960669495194272
0.00768835965855084
0.009475699035123594
0.005425059284365815
0.008563813261297836
0.00825413002852199
0.004842924100375204
0.003160022614700892
0.00019354760331485974
0.0011235658322807586
-0.0013888037429449205
0.0013623129629614286
0.0046996562108508385
0.002299404388047632
0.003783349425753325
0.0019878324198395253
0.0004395546773542598
0.003623983865503378
0.004763679390271811
0.005602726543301938
0.0072171328032104715
0.005648457423216279
0.0045615339948330315
0.0034344272297437833
0.009305496555064671
0.00750242035373699
0.001063480616348822
0.010103670986112381
0.011412030595099387
0.006752002997773168
0.011730934896081534
0.008093038634747985
-0.0004306771200449207
0.001265384778402509
0.0019464642398563416
0.0020716596637620553
0.0018756786875248005
-0.001019539864412051
0.00030157676280132776
-0.00037096524033774234
-0.003420187063475802
0.00297959223231655
0.00460351440139836
0.006733586407696787
0.00988835141112948
0.00666168603806331
0.00547876572124288
0.0037571290330571925
0.0023060508641173792
0.005604055463844863
0.00402097019077157
0.005087413732347904
0.007663349201042068
0.007566120118826625
0.009167540957799003
0.009529439172556485
0.008292723337286713
0.0069623758591118405
0.009338924092597164
0.007002416595278016
0.004330933921636963
0.01204624992305571
0.008006133164170226
0.009333955191028366
0.010664991879335338
0.011584841494154969
0.009154552354990832
0.016164915614516228
0.013389142032621502
0.007839215080155405
0.013348763641831098
0.006493686141767437
0.010532251785040803
0.01731165203178927
0.014027121697222868
0.008179951043679034
0.012647698821588614
0.00852429295169664
0.004071083816868605
0.008637752139367245
0.007871532619818784
0.006181340618453072
0.008109188590360193
0.0023300216009680755
0.004847733278854948
0.004456286359629514
0.0006104315898839792
0.003535335007456072
0.00301018416599759
0.007398620530444362
0.00859748485045192
0.008630922818610153
0.01693081485833868
