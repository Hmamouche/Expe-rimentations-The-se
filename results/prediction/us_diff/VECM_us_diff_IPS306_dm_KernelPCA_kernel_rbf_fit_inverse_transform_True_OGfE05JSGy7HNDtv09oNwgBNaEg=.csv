# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; IPS306
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=7, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.010473224793128996
0.020951585691138516
0.015598892556218278
0.01045468219432373
-0.0066700852004403614
-0.01741547537427496
0.04299910418844974
-0.03945187142996543
0.022227067091165117
-0.02082340485434243
0.016734232612560004
-0.05329525597060344
0.01409550088964276
0.008727979658041233
0.0005818918705353098
0.020998147606927718
0.00677570889266675
0.03033322497969679
0.034670279273808786
0.021666091729378383
-0.018685616393011036
0.00695968742165047
-0.018154071664623433
-0.011805923802547465
-0.006354042716692934
0.0035395940017711198
0.0024272867384163063
-0.023144563681693812
0.001614859604466252
-0.01110544522645666
0.029555980463784798
-0.021849678579929536
0.009515623059027135
-0.01091747476972028
0.018181672757830565
0.008984118852184579
-0.03918000785946205
0.014035885020891061
0.012839636756097294
-0.033515010959286995
-0.0005062130392030355
0.028837026878669167
0.0001789566097601641
0.011371259444371076
0.012650127338267297
0.01841046519531464
0.012413839697968372
-0.01767596072507947
0.011791000048908451
0.0039513090566151605
-0.02123562766241182
0.03513981585824349
0.019358588880689427
-0.014064618315591144
0.03524707628465111
0.006531058471245504
0.0173338370761509
0.0011105809066287297
-0.011658399688906912
-0.022373789228234957
-0.0312667278852956
0.010888948347382094
0.013276837422347351
0.025580330072001323
0.02711771343881121
0.03460259530354094
0.009055493472957782
-0.013634105736012134
-0.0030311771635100817
0.013714958664088742
-0.018925475137396102
0.005914219544261122
0.013202786209503128
-0.016902988137172045
0.041836217522002256
0.017293256747829517
0.0041109268495142706
-0.009920348717997721
-0.017593630465600384
-0.015952258648815436
-0.007922908524070457
0.009302139966798326
0.030554085731378494
0.02839954987147435
0.028694561226896478
0.014064896657279165
0.04803078169239601
0.029447094758248825
-0.0012029082584033273
-0.008345738452778051
0.026323483425118706
-0.013555009711674284
0.0011442433048539265
0.042537890905727654
-0.029276250365508488
0.00255149021240785
0.0320957807605624
-0.01705836766539617
0.012146568964603479
0.020475075750003263
