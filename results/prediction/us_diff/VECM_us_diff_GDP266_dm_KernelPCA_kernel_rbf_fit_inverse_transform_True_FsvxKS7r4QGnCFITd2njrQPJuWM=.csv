# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP266
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=2, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.03134897636933347
0.012540050268968095
0.0010513039562903065
0.014617755642124692
-0.011488657626991342
0.018695077114799095
0.02310641177660851
0.017151985274125155
0.031999358604249815
0.031111857718067994
0.021261781664844215
0.01682357560328882
0.016558618774420532
0.01875677479119524
0.032796642080651944
0.020049169702388226
0.0009063715765596347
0.012377417175921534
0.005395934240577084
0.005679108602865443
-0.0063430948667424795
-0.013621976215134207
-0.009724261721480477
0.0032430976680238696
0.010309677176124597
0.010451928407734477
0.014783560891961728
0.008735633786752982
0.0023455743147307866
0.00534746098555578
0.004930852914746072
0.006777843433465946
0.005575817764755719
-0.004660672648008705
-0.010925613932990214
-0.014280242817457421
-0.011763391253138755
-0.00012220376391084298
0.0032839621459099053
-0.0042347473423902555
-0.017030617675916085
-0.01673732097963859
-0.026876482648914235
-0.018679619016124163
-0.007932064103234918
-0.014888417574461018
-0.0030769450144278866
-0.0058858069910931446
-0.005557267195396586
-0.012290545047031726
-0.011632721425214921
-0.013164293603066885
-0.007073389039531876
0.004580663474206578
0.00027468559451591544
-0.006900718933245894
-0.0087215376828307
0.002544617464274183
-0.00029269058520424007
-0.003972404424836906
-0.009637417668998487
-0.0022842383694200693
0.004568430417950714
0.005281907765825482
0.0006841059692680293
0.007105077718144848
0.010453312101352193
0.012572024856499726
0.007646591233478615
0.0009356000279919707
0.0010466984009607659
0.0017388398763057084
0.010400896364896706
0.0209347626792788
0.01721242692813635
0.02393576838193873
0.019005820504678042
0.026141427013829245
0.030753203256617512
0.022384463140834317
0.028290449623409583
0.02555082553118872
0.026652370989656917
0.013572249267234176
0.013646281699807847
0.019595500055730818
0.013554845483105229
0.006337724965526445
-0.0020728650270826474
0.010686459959393801
0.006299289021025187
0.01192140966596699
0.004177346481356108
0.01294074973640424
0.009424646855290318
0.001355056488921804
0.004771333273754232
0.006496916442307121
0.018854519888235874
0.022271988327891006
