# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP258
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=15, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.000971733043020416
0.03108524148681971
0.004116945704524793
-0.0025197906998610502
0.013453293926655185
0.005130823888413849
0.010712987981244242
0.005185018601261922
0.004392133890300499
0.0007277674240964787
0.0167901319488679
-0.008379937985434424
-0.01336716324035602
-0.008011756782257184
-0.005308833473334364
0.013551390129196168
-0.0005152692979808271
0.010980341908233618
0.003047172625181173
0.012641029777521153
0.0017081961915806285
0.019320861152944055
0.0037898465442146893
-0.003951003638359584
0.004374569414811554
0.013146338209328782
0.006820007388773823
-0.007767097810695755
-0.006253679198654478
-0.007997025581759541
-0.00582869112007527
0.003409070708786606
-0.0013328172354995578
-0.011236528751179736
-0.005404717515929011
0.009580622448082263
-0.0024950443743181148
0.021320821837166083
0.010294738791460058
-0.0005747072031222602
0.013593853150729052
0.01140573552014514
0.01892462019728937
0.009687005002467046
0.01384488144998563
0.016157236586905564
0.01151587389488476
0.013459377729333592
0.01618377851983863
-0.0028031720787158607
0.00893758246443634
0.01747622684583682
0.018254731979846988
0.01718169312419317
0.02398954544675122
0.013839797356239959
0.02433579174623593
0.02920993579290802
0.016734307410508333
0.021218067034073494
0.010950499961805762
0.014457937751009172
0.018961562506790125
0.027171303716772045
0.0220706834882765
0.020619239200336342
0.002471460303312096
0.02655803598173351
0.01315849877819204
0.02319202471048164
0.006275153987437566
-0.003749410229743963
-0.033761683457515256
-0.039436839917438155
-0.016687539249180837
-0.010150692991573953
-0.021885025237946942
-0.012988257459670765
-0.010425693427440024
0.0062581973417049335
0.011961792242479532
0.016754407383568797
0.010182673120713928
0.007867006115613173
0.01280471843256858
0.030602777255535965
0.014069706066890368
0.004996650112382688
0.015842818324076333
0.012156048685113965
0.021037305571429053
0.0159782702261598
0.018914376616603064
0.010098712633321578
0.00323583995818555
0.01404508257901569
0.021643885179206304
0.0022868535628409598
0.0011187423367556015
0.01850239757860482
