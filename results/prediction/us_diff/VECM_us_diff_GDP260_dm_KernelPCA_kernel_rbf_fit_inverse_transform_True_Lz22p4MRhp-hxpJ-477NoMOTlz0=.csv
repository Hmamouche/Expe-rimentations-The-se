# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP260
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=11, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.012465960643994248
0.015710669634260335
0.01608743909733855
-0.002408573669839346
0.008744427990464867
0.0035154847594535722
0.004737658585522742
0.00850917239618151
0.00391575956538002
-0.0024725238704795876
0.010490268485768237
-0.0036984037802558207
0.003695481323511393
-0.003446310073701776
-8.765224969033603e-05
0.001088461782111516
0.001590659903060111
0.0002829981444908633
0.002832752044118367
0.008461379504333472
0.009347277624231532
0.022629094100874964
-0.002356054034747538
0.0001328939202754913
0.002360839510171692
0.011100338128194628
0.0010133984919802712
-0.004612870352006941
-0.004474997351061755
-0.0066493701099101365
-0.008754078106322363
0.0038627572159907458
0.00556525148140158
-0.0012219774892426438
-0.0002151481527997714
0.007327094726673762
0.006407472880724087
0.011867383721418882
0.015328962564430075
0.005332911544234896
0.01321454868222907
0.015018667999377166
0.022612781415849364
0.013579018681283764
0.011509311326194697
0.013990345435163722
0.008650038761286862
0.011778305288567187
0.01451932080613753
0.011096548062040665
0.007890185999716616
0.006062276337133224
0.021458407268104638
0.017252224722341947
0.019114925227373146
0.01778857704578947
0.025713147309337027
0.01757556129397183
0.016444717869057837
0.03565764107336508
0.011017275829744861
0.02018179906651873
0.02153647381026226
0.01994432780609533
0.028235707295389115
0.03056809145347921
0.018376444500646787
0.017172400659762294
0.017866160947071427
0.019552362586850402
0.01075472978609252
-0.012158133064793917
-0.03199648662922659
-0.026409623519302206
-0.0065965797896845955
-0.0018655668452640544
-0.015035725096252379
-0.009333254342726822
-0.0011987721641473527
0.0009618766589641024
0.018090929110793505
0.015229495821602055
0.01907872416830915
0.00744237558720352
0.0053947266747043955
0.029757948550568306
0.014243860007003816
0.019221012241315828
0.026659723808791582
0.014981476883850948
0.029765655127730946
0.018048456314149402
0.013320689171744345
0.007103227930442096
0.004146605621676477
0.003000819189589235
0.000645217755996567
-0.0022305107771068144
-0.0019187672829473652
0.0066732478483597975
