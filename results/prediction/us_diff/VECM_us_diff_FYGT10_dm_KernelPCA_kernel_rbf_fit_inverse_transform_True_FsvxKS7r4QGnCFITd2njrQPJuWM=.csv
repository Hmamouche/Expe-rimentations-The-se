# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; FYGT10
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=2, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.023988923102060626
-0.005732001261687441
0.03367118904593536
0.067866402895356
0.02286423421700983
-0.011710748894717217
0.006308796314620651
-0.0618507218564404
-0.04981341764504189
-0.04669134512493006
-0.06765298930894233
-0.0654727543397326
-0.06630386334045713
-0.06378993766910893
-0.03039603855258644
0.027261264618879722
0.050809136993379966
0.04036560181496987
0.01744669121568556
0.024242965897276553
-0.009566182882721838
0.013545536496650233
0.010648025593511292
-0.01762348045814953
-0.03289497142220848
-0.027174693133106984
-0.005787979826257175
0.0019723725707710667
0.004672654490857246
-0.011818521456576437
-0.027375141721874836
0.00473342490587406
-0.003862051331931251
-0.02899135814569558
-0.006984018523750612
-0.019998135660059632
-0.03547061590817374
-0.0007969290004892866
-0.03213298131877247
-0.02830537236948468
-0.019510202966353356
-0.026295134964669585
0.017485833583804913
0.04841082496235124
0.023680074001020856
0.06681224671986412
0.007630912794852241
-0.030346346314165617
-0.025752025263145215
-0.04685497990412522
-0.017939927844299118
0.020864881455835524
0.00964535692014121
0.01356118376276567
0.006577369372022685
0.008716728685518475
-0.011293907578057958
-0.013520595369496548
-0.025109732290393108
-0.020518217452608907
-0.03633723550754694
-0.03170709449432893
0.004406167367966275
0.008255603576172766
0.026454353619275096
0.029227799452909195
0.030441445519596173
0.0025575676244370027
-0.014796992049321086
-0.03102500382042836
-0.03749413113685489
-0.0018082338912233835
-0.02211580219267362
-0.016054971918691326
0.022892316978138403
-0.016812377327068088
-0.007387402303661973
-0.04129618354588748
-0.03095804924317242
-0.029833413002518037
0.024798675891244168
0.012378322538674533
0.0005389992967626965
0.027387681596031655
-0.020675981303542302
-0.006558641209498846
0.002449657043676326
-0.009848673592494948
0.005983870377144358
0.0066994481841767435
0.013510069454784926
0.023510771483740343
-0.0060985259131550165
-0.004606724764930895
0.008008063564718209
0.002238374096136484
-0.003288871724596622
-0.010784695243119473
-0.04870625699041354
-0.0029351530088228247
