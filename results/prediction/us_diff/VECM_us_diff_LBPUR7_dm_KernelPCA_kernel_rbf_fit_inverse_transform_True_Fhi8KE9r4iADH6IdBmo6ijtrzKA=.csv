# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; LBPUR7
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=12, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.01267330681056433
0.01295395346080929
0.013357756416101546
-0.009804020437744356
-0.0005887792660009238
0.005421001551320652
-0.010617733104952802
0.0025568282928684575
0.007467489098471456
7.838524918029775e-05
0.007016499675114219
0.022638942553707117
0.009010321588902309
0.006201676579268133
0.020088270728912134
-0.004217340652256938
-0.007796116395012969
0.004391995373117323
0.002122261335103316
0.0013750253938120544
-0.00441842519094132
0.014830671612196686
-0.00190919552116806
-0.01748085859483898
0.0021705407060773393
-0.0003928184631690275
-0.00628934457248961
0.007635790639950062
0.010494866254146218
0.00389903064533866
-0.004625766365685239
0.018181080350602834
0.005514589222740951
0.004945804476619646
0.013296629472926449
0.006696352626581436
0.002703895591330067
0.004213298549435465
0.006871936462587572
0.0022063986112966
0.011256323210020819
0.0003293322641976389
-0.002601727071808544
-0.009315996905265458
-0.0015564576980910763
-0.008448674380632152
-0.0053302782892833845
0.002008111405884692
0.008898486918299718
0.011697650185048826
0.005148804601741112
0.0005697904750991143
-0.005807072918180972
-0.0018898105518129818
-0.009949070607521083
0.010494108005725426
0.004748537797039902
0.006646966614515939
0.018863062817765813
0.024324232476524328
0.01965451920091228
0.017450252369564042
0.015075971498326539
0.0008113474843896736
0.0024157875155951646
0.014809532235134475
0.026763140160374007
0.008253931962140939
0.0162016627014954
0.00957107248285171
0.015564245484838516
0.009384141683301397
-0.001690333946118045
0.011296766360861287
0.011207555150802302
0.0031785563262978767
0.005715006961110306
0.012537479319406884
-0.0075528630287165985
0.004252063956341678
0.020079194725786224
0.019044032817103637
0.002258475699603541
-0.005921016665535933
0.014588195009878183
0.006173801843330744
0.0008424928389165404
0.00083410957837538
-4.130455643620249e-05
0.002933957028138358
-0.0030136504012145348
0.0036270622207616233
-0.011820458572946132
0.018200832378908155
-0.00246450394790573
0.017955585073441648
0.011256669447631748
0.00393511940680131
0.005610300126497955
-0.008089340243420388
