# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; EXRSW
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=6, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0010610029115690756
-0.043942466084937015
-0.0030718223602310586
0.03847109699051746
0.03581352692612664
0.016926241862767075
0.04139839852246474
0.013786697697101235
-0.027199148104671812
-0.065540769790947
-0.01256080572195762
-0.003206531916055768
-0.06338091757468305
-0.03754136033659028
-0.038405157292939196
-0.040622909273714064
-0.012605213251075614
-0.016330230574346447
-0.016926821319959512
0.022543469771668382
0.008708076066677865
-0.008178929818855103
-0.0021974854955219628
0.033968999010264865
0.021138716004157322
-0.01584196587732073
-0.02796589898274463
0.0056428917484362216
-0.04975141282222022
-0.04707838301095495
0.021457470575161546
0.02268673854584257
-0.03761470044174602
-0.029107211982150608
0.03832487262453015
0.027139617530272254
-0.04120230170412022
0.02723431002059965
-0.0013570622895594797
-0.02396013194481674
-0.010721408830263813
-0.005023116005772189
0.017771992745621037
-0.011050688365972254
-0.009056544934952124
0.011452203607344991
-0.010330547403590122
-0.008260193815852855
0.004432176748557959
-0.02341208789756327
0.0052510208678369875
-0.009712222895236603
-0.010122361515472494
0.03812305670466089
0.019127861110768196
0.0202302298098608
0.020000583802470415
0.00608578370853194
0.018763607326588334
0.0107638578230401
-0.015773381260544554
-0.02221812693191514
0.02033731958304555
-0.004887377146709061
-0.0033882626314726263
0.013819367514188177
0.01759435630259587
0.01488142994173047
0.01476289896643929
0.00512511625126879
-0.02577668267925291
0.021380864382412476
-0.01468095493657087
-0.0014592353397184024
0.01048790993726792
-0.03105427073777615
-0.02116244560871284
-0.0031036063908388006
-0.04267005329649206
-0.01156442184641448
-0.008391727646399724
-0.020022776708898717
0.0038778025536235173
-0.000937426964629345
0.003939779919077258
-0.005469859469133018
-0.01361791577379256
-0.005042265892163995
0.0007001752901782936
-0.003941675404256929
0.010910145409933633
-0.001851049213149378
-0.011194370409040783
0.03002830706725939
-0.016491128985883636
-0.016030837182294647
0.009187910267488336
-0.004374666993161549
-0.03282619824718419
-0.01863943267434964
