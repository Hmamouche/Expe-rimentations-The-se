# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CES049
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=12, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.009724907485951116
0.021273836314054988
0.012450480610090173
-0.00023521204105618346
0.01205130827889606
0.008076689485754476
0.010107835950441867
0.0058481913671172316
0.011315848137804736
0.010154376851888379
0.001922348529386519
-0.006129126580502792
0.005341105776290204
-0.0029307435913472693
0.006445706034782372
0.013907329938269087
0.007808441911946585
0.007448823436328076
0.012969056131132872
0.012926330034121008
0.011452809598682548
0.013924225520044065
0.012455456234463806
0.0035714273565717516
0.0036782707959057016
-0.00019692159631439984
0.0021550140585906764
-0.0049383616038479496
1.0382412970238054e-05
-0.010385583009134424
-0.006617838144854623
-0.0002693015783142411
0.0005734912736866114
-0.008508581613036817
-0.00759713636003688
-0.0015501272435129586
-0.013643160529749688
-3.5628123850603714e-05
0.0023886113077108573
-0.0022676689849557875
0.0070756868351134535
0.007960759850809629
0.010288839101831714
0.009855220766185228
0.01938214850523741
0.016522109915240293
0.015695358788124607
0.010543523171983961
0.0068795007764955824
-0.00036761878786408094
0.00240629486064904
0.010193365262522344
0.01262604874455898
0.014214156134697032
0.010335918942216974
0.00952387229508873
0.014372501061356034
0.00926627897262778
0.007500621875906724
0.01013897239810792
0.0023386564186459657
0.001162220706218143
0.01218098659818067
0.005657347084712371
0.01353906482172767
0.010850503745329601
0.008338009720305267
-0.004580168813655433
-0.009583051482820378
-0.0043863468137642705
-0.021524727239548607
-0.01381861224841975
-0.01584013485657297
-0.01542334889802155
-0.0017841901354434773
-0.00655344607684873
-0.00622986481426662
-0.003580551225254862
-0.0022021723111717165
-0.0025679236763529083
-0.004481815015923512
0.0035619610120963064
0.0069028022383295015
0.002881190262926759
0.005199974203554038
0.006288496266860547
0.00017873098075549092
0.008486724022958502
0.009247781132062581
0.009669807794447557
0.012829777376678456
0.009675418401568103
0.006155070650662808
0.012125149282689021
0.01018909346576468
0.00986490375170208
0.004704881796616674
-0.00021064788197565235
-0.006874499013413927
-0.009724374747988498
