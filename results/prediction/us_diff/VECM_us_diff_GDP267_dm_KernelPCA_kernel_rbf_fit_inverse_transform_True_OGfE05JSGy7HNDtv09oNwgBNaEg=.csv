# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP267
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=7, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.003927368327434254
0.011226918128665993
-0.00232198586216692
0.004810374265114275
0.009473319034111647
0.003592719099893161
0.009710049311713941
0.00726815506053932
0.015300563389002335
0.010158289231121637
0.015921256572216817
0.007526083200275691
0.013034517387409118
0.015765679992969933
0.005009674921019662
0.004413671394492587
0.003857075661308999
0.0036338708376604783
0.006898202866597169
0.002934931975881976
0.009607071054756649
0.010808885690684451
0.009952631058471302
0.006183087046350519
0.0036602488572595082
0.009149461209567182
0.011111777082804392
0.005998507382343305
0.008838152676095898
0.012809384985364125
0.0031006101276602046
0.0032483481468930753
0.007734723584097347
0.0012481088785204475
0.007276638512042796
0.0038504722319055744
0.0030245583125154078
0.004370756332261775
0.0058073755265246356
-0.0006751039227952412
0.006842259017736411
0.0020533224712109555
0.0030625375623357046
0.010769647338539988
0.011141442416672292
0.0006002956217993547
0.008984468326402428
0.0067680321413715275
0.0063829384865776145
0.006984825245513981
-0.00018724284778789827
0.008618030051618234
0.008504715575202751
0.0023721800981779846
0.01206655549533282
0.009169333688986588
0.007142517519378901
0.007673219980236708
0.00496121590069143
0.00846516241115211
0.015748750780015988
0.011585532233857984
0.010781618955666455
0.013174096329747045
0.013648163996013405
0.013383322248042392
0.010077600109159975
0.00739872850419433
0.00499564766139333
0.009233038095123495
0.007465535933802156
0.010143839210740904
0.008003836966485552
0.006746654901016631
0.016397277541445165
0.015166110827233611
0.003256276805367257
0.009023610131192246
0.003386474154959899
-0.0013464964493954965
0.005488391203641956
0.002309752536065054
-0.005209892431461912
-0.0008866386864996599
0.0007913021842475719
-0.00383008119424947
0.0010036487120796598
0.0018324748262564733
-0.0017090926970802938
0.0017030901464779092
-2.770964854253901e-05
0.003551987088391125
0.0035790764718529743
0.006243144714275843
0.006295590342536483
0.0076480444581753515
0.009030641772789342
0.00449265425195011
0.004095404890648387
0.00455948497490976
