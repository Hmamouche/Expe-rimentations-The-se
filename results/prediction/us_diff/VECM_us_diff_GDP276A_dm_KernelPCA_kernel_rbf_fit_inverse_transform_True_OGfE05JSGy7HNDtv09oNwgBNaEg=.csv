# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP276A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=7, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.006281047793790226
0.0050210812395318286
0.006215097758094138
0.007890200349453506
0.0065655840542548
0.0050337000233664254
0.0070501426624690975
0.0042915850591478885
0.005620630520473077
0.005284729960836352
0.005743837499357859
0.006828435053692004
0.006258993610134994
0.00655571742538018
0.003848937302963149
0.003938210964695163
0.005842184157601852
0.005192716319203766
0.008527208582337617
0.0066738390074763815
0.009254521186403564
0.00724391451724294
0.007488393736370965
0.006703090735854168
0.005961235568327315
0.006639633274855989
0.006806072301048792
0.009385928739456664
0.009377418837328016
0.008024271008666234
0.006803022127651031
0.0063214431182461546
0.007058715825825772
0.006746845803115094
0.008053077400921538
0.006775567827772359
0.006212796244533844
0.006000736214183453
0.006839777322281316
0.005485431714519772
0.006789974753945618
0.00441221327265084
0.005086734935300458
0.005433013561856562
0.007026361501508668
0.004345686017536312
0.0063164688209078074
0.00492696331832971
0.0059006468110941335
0.0062161512818499996
0.004285370758842928
0.006021304312506098
0.005842119404949288
0.005634856393683685
0.0061032175814290605
0.0058595431521913845
0.0047187416332525834
0.004493108193626575
0.004651971309141755
0.0037442786199877406
0.004479312755563361
0.004676452352664505
0.003929198421013678
0.005222590999696706
0.004639967909634138
0.005885468764456119
0.005988974726947533
0.00597722881977358
0.004902375701162976
0.005029729256174878
0.008535227841516583
0.006156179305952194
0.00721070771061561
0.006975348595353527
0.007470333311217269
0.00654269938493636
0.005341977204009989
0.0062054988104548155
0.006980509890818393
0.0064240495101402706
0.008961666709435084
0.007218396243158881
0.008043759660703897
0.00793069984048771
0.0079753415609902
0.007151160768333138
0.00818972597632842
0.008579936568996688
0.00824597185042296
0.01012695258980775
0.008445684885950386
0.009618503451192615
0.008310243649585174
0.007915066143108775
0.009822768004176346
0.008770404259128109
0.00872118239575343
0.008363821440877137
0.008329143142190975
0.010065901274393121
