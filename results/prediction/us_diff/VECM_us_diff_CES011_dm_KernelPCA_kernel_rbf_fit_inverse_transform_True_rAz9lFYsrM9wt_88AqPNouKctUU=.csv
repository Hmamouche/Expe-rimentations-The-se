# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CES011
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=5, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0015287336840816717
0.01218686835352502
0.015388052487134497
0.014387585053712983
0.02717819166081029
0.005953761756983884
0.025289746380643886
0.015978931836630923
0.011007911619149173
0.013097003045448035
0.013827792464576029
0.010179702173645777
0.004999182709667574
-0.0004913627297009606
0.005458116840824863
0.010805274221307502
0.007743018106688677
0.006947455619859678
0.01582349181237273
0.0011401490927217238
0.02349290734599282
0.0003589992436408996
0.008287573370620055
0.006070316864762245
-0.002363977762956715
0.0009261408160654899
0.01074984653883477
-0.007869821258429499
-0.02019495134042202
-0.020995317760184536
-0.03268168812092316
-0.026780593242773074
-0.0007485454949650247
-0.015401494918907202
-0.01535164215043381
-0.013344769401219932
-0.009280720776652672
-0.001628287813903684
0.008517982645326204
0.005672020937405957
0.00690484521395214
0.019506368390955358
0.016123336890513876
0.02447571125589873
0.02263188816812121
0.010537766540890054
0.010902837702604442
0.007846912464306445
0.013216636760685407
0.01304020936699785
0.0070095357224562935
0.012357594482602
0.013491353564990517
0.016068905215771787
0.01930762793304569
0.017873654713119032
0.02048904290822101
0.014287828915756822
0.01810648279183877
0.014750178891485092
0.02003567192018427
0.018079991563884207
0.021623528755770685
0.017733459900669966
0.021461558270907358
0.016951302683661428
0.021571834420175552
0.00699744969441083
0.009421005646123151
0.0049939484862056216
0.0017400328680019163
0.0008928716468374132
-0.0076982456537917476
-0.008168168703241569
0.004762316857798239
-0.011320612231099359
-0.006647462957837207
-0.004149557227503146
-0.008134406572120228
0.0032876075398020925
0.00997590139206746
0.018644776592230714
0.01518227487306954
0.009375712986338228
0.009271683865698451
0.016804938441477228
0.016251923797031463
0.020217275010419398
0.02352785783112744
0.02044203122720875
0.030736535715551558
0.01045963044426813
0.011255833273703058
-0.001787120964595123
0.004425425909746157
0.008657657006651293
-0.012951996433255293
-0.02013931548468085
-0.01729338644925753
-0.033403860194927096
