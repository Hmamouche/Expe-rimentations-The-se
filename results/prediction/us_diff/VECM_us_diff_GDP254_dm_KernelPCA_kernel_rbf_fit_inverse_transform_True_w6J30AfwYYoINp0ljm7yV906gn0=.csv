# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP254
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=14, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.008268021586354691
-0.0017164084822054524
0.0016461141579280879
0.0048387275490703345
-0.002565628036301386
0.00044131405273022464
0.002448558332412371
0.004334860300502948
0.01036631201742537
0.007614070751122255
0.028192286980481877
0.0122945098645889
-0.005802019863570901
0.0058408204357155045
0.011539342141518085
0.00948054748400352
-0.005779783954788797
-0.0013728721632115446
0.003106449060606459
0.004982996414356703
0.010869097446967797
0.009045232290477132
-0.004944299139365327
0.0017613445320677035
0.004924694816664875
0.005698316500213641
0.0028548438988251702
0.0040723541006681616
0.0052655946747955104
-0.00522456669533605
0.009128602120891524
0.00501844712531289
0.004481408712852633
-0.00871705711427256
0.009542289111280092
0.0017288216419379977
-0.003419160085797837
0.009187061280858815
0.008126702238303297
0.006755879753143927
0.008467113043566314
0.0056029349415673965
0.006587225904906328
0.00021404983296776162
0.007126095302056722
0.01178896917646154
0.007203621036204531
0.002549181418385764
0.0074459547495216724
0.0044030966155495154
0.00495958621175081
0.0024943879137664642
0.012424269717426599
0.001569830271706776
0.005777470211591982
0.008456967224770504
0.005928085639179566
0.004569088471555599
0.013393740490606446
0.006780272035366107
0.012622545365379
0.00750954621905964
0.011769750529131545
0.010460580179550413
0.006872005579814387
0.012645567317882196
0.010819431459639836
0.01225252781037696
0.006912028097990099
0.009141643462063594
0.007961946126182796
0.004453371407363022
0.004621087344179199
0.007584160824681568
0.011484071121699272
0.009372778679722275
0.005725698099118852
0.00014006918880610448
0.007283510643470446
0.01414232056234748
0.006075662024856811
0.014009973548046242
0.013241546532975407
0.005332317900082479
0.012234334122068816
0.008071481716143601
0.010384849732035675
0.011472506739728286
0.00884041413970396
0.009650225725407415
0.01743114292196761
0.0025942194148505992
0.012924528094637558
0.013540597569968168
0.003486035164984318
0.010169677939055531
0.0127203643351325
-0.00034983877633144075
0.00012470791578552591
0.0033308479405566756
