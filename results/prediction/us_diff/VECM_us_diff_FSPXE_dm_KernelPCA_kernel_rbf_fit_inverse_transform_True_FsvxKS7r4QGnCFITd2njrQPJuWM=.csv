# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; FSPXE
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=2, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0020792677953644055
-0.043393060372848416
-0.03142137702651568
-0.038108317032736407
-0.01430033037756943
0.0018706715549944635
0.007691925185436554
0.01736693128871606
0.017837716808593248
0.026990938776772454
0.03389426208637656
0.030350158398487145
0.008704367569435937
0.01863728913352011
0.05620741603224256
-0.0008640489561961089
0.019915655397373857
-0.037798232088877344
-0.035484098495231896
0.028120865202930105
-0.06560682970489015
-0.04045521217968312
-0.012230106577524958
-0.00046190836623394554
0.012418694598766265
0.028845632321872657
0.013623734733355552
0.02959884992336934
0.02156650422304617
0.009884520132860538
0.05904075615804753
0.03755318865412641
0.0073374042830510345
0.03714665032894904
0.05641055793134463
0.02584978414857563
0.022140682748955996
0.028206676287894986
-0.003044316569660489
-0.012747397039498926
-0.004410487556441564
-0.01159860061828903
-0.03797930184935455
-0.049468779054302955
-0.032424004325215805
-0.0519480692757141
-0.03692917311206057
0.00025265137063180954
-0.00099612013838266
0.010507734461341345
0.02952735536641784
0.013622005640164043
-0.00458159191479233
0.01610302131994348
0.00408661001325062
-0.010803462218003499
0.022443824857872594
0.003964678664846044
0.021245796452024242
0.05459728352280054
0.021105045959457804
0.04470420115212249
0.07275794006352135
0.038249109257849946
0.0037104307174426875
0.00419453333942495
-0.016339516606575608
-0.04368052142616874
-0.017755566694349252
-0.03396642072809528
-0.008157475749539837
0.011947746333987002
0.014778466194896131
0.09405093018672059
-0.009567299464071076
-0.02922400275960641
0.342205811603659
0.1697796568586369
0.034488678282744115
-0.07040102022872727
-0.033398779220160976
-0.053587580770133585
-0.042641907822875656
-0.04097373183831185
-0.09619852683275905
-0.06854200564148191
-0.045278256559463895
-0.03681248342584908
0.0014536022276039114
-0.006751366702097011
-0.023197491005762957
-0.01944216778903026
-0.010882524779038253
0.007882043512282876
0.017859302575462362
0.006879370133459621
-0.0003898849841581665
0.008131260528907213
0.027020593356976697
0.03232994730239862
