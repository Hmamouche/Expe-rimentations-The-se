# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP277A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=12, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.005240764964208076
0.0028664938258421754
0.006300973623287356
-0.0011698542153971122
0.008133301046278234
0.0018270814219793427
0.0024171929964649985
0.002352247461275201
-0.0009028337849493573
0.002660323993594343
0.004264438080859526
0.005429115049620301
0.008433187858801657
0.007214458417742807
0.005302983988383853
0.002180806459651488
0.0019096996584222986
0.012347849959340167
0.006585265912841
0.004878869694222235
0.0037258980033244
0.010884750011854365
0.009454655283032439
0.00527187763713338
0.004132239734990524
0.0034853485162778266
0.0026399033224277207
0.00801588274701644
0.0029920636443546097
0.0031495772059237145
0.0069635239050905165
0.0029319523299664836
0.0009349943146256625
0.00017075636282166192
-0.007591196831873497
-0.0016082418405501796
0.003092081988910827
0.002543158325471583
0.006329255514522602
0.006786739935583489
0.005125940526108782
0.0027487341822842043
0.004640520993747177
0.002971738159127155
0.004976546554697094
0.0025454591122755187
0.00605532061141064
0.006680320087386549
0.0005483038832080056
0.0005477412487421575
-0.005961804879673011
-0.006136121194079804
0.003989859441232203
-0.00048233724336282707
-0.0022593993448316784
0.0010624875827144132
-0.002041302034375236
-0.00222553699600795
-0.005710249649152465
-0.0045582697162146885
0.0007215772279968624
-0.0022034746236298383
5.986561437810599e-05
0.00169743615997976
0.0002889131225004123
0.0015830329480477324
0.0040765217718933145
0.0038304332207672147
0.004623622203477102
0.0020763856157435664
0.0005968289091875638
0.004254124353369019
0.006070280394248432
-0.0022238236454020927
-0.004706781345012534
0.0027323084930828793
0.003038040374569119
0.008163219316546531
0.006159738651506891
0.00040601035592457936
0.0034941603182629477
0.007425722656113443
0.006655138056160828
0.014549933109792565
0.013419887244897729
0.012302774289593008
0.01080929441529772
0.014157033867300599
0.013295795184895896
0.015211250713718608
0.014242679249244133
0.013851225972567728
0.007829272259743017
0.008621119148648134
0.005820977349696615
-0.0006748905103636594
0.005060951707204079
-0.0004168359246017484
-0.001915223780210595
0.0008751233976442303
