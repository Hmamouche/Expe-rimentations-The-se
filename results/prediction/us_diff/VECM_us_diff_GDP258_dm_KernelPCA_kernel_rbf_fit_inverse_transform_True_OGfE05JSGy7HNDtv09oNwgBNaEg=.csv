# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP258
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=7, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.01957224611015821
0.01521590677083182
0.013293184003024861
0.011343630802311846
0.007193410278288528
0.0045555148942778186
0.014557189326182983
0.006499493089111667
-0.0010646500752307768
-0.001292317020456067
0.006398373942584018
-0.00749833115109605
-0.012002675072887206
-0.006186395204540203
-0.005536796888095007
0.006370484293641412
0.00495127800807434
0.0070114706262625155
0.0024018128845321503
0.007117861190954818
0.006628848033137195
0.01825007554195213
-0.00017114790567952353
0.0008219121294892962
0.0049940053838904335
0.008312824871959192
0.007172076727226492
-0.006150156650508891
-0.012356253282067083
-0.008725044698641663
-0.006090092496912499
-0.005754485665297246
0.004366892565795248
-0.0018345228330852543
-0.0061866828714491106
0.004066863028408698
0.00641128302828196
0.015660599636094133
0.015812917402991743
0.005640613802506455
0.013503333659277979
0.01607389609598941
0.01179539239573655
0.008407945260041624
0.00762700718761625
0.013540221529204395
0.016702387490365077
0.011178428252569515
0.012480333577050667
0.010222107895692618
0.0077610195677305545
0.014200744328797726
0.016664426262815626
0.017987206309885918
0.022850475920834414
0.021919341930274155
0.025929258928445643
0.023942458122272945
0.016485649647533386
0.025428508662879268
0.013563356724670154
0.014019369242284445
0.020989779571925972
0.016506967447768816
0.023190291426017837
0.027674368495506543
0.015815492011961686
0.016529578516587283
0.015419303945708129
0.015897400590163636
0.008456336181570087
-0.008755444244407334
-0.026152718328082726
-0.036164950135445
-0.016036982828459907
-0.020139965737774483
-0.022211049390686338
-0.007463261064335915
-0.007320869978257421
0.0020289312462667877
0.019389216791153942
0.019536219620912884
0.007584493867085734
0.009558779407085733
0.013410631701612958
0.021848299726681245
0.01515655987152382
0.012029783935200385
0.015147656709610742
0.011441818301862054
0.0230492310190889
0.013981671811332181
0.014932729985715106
0.01255775091028633
0.005953809862799385
0.01653709342693626
0.01861841675169867
0.002127733294922625
0.004672907635642444
0.015878736246029777
