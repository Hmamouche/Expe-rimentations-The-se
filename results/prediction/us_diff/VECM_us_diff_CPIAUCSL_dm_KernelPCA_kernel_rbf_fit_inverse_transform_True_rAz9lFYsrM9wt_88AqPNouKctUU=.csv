# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CPIAUCSL
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=5, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.001903139269481035
0.00526746918001186
0.008377394344093122
0.007251356843956516
0.0065969665315549686
0.003879273223145325
0.004661579725602331
0.004771893301253667
0.003921014230122258
0.00541877966926393
0.0022903776182495606
-0.0007115554837183667
0.003015176297662571
-0.0002023894842780728
0.008029141243311997
0.004343944092702455
0.00723966419271696
0.0062307181891437385
0.005605431106308369
0.007531377811768035
0.006914432191160711
0.007811534654443656
0.007936744385116445
0.00934395557796458
0.006092388675080935
0.007315433830351986
0.007679390967967937
0.007685264146576807
0.011083821345476653
0.00881000717139211
0.009318992885364346
0.005104422923067683
0.005669604247319448
0.006797100564095864
0.0049800249578644505
0.0052249927740684755
0.005567996373779748
0.00805052886754064
0.005482811089220419
0.004877971072679415
0.003298698971677099
0.004949773333039626
0.004862932269341098
0.00789361419614145
0.005621977294039117
0.005512973488030256
0.006720166716250315
0.004941653991543458
0.005631246925250949
0.004001816048187284
0.005222128791609926
0.007156774017591738
0.005330493317008377
0.007673556482295841
0.005664493636919935
0.004633985777890771
0.003731603157917168
0.003796872974607692
0.003412461771039729
0.003025199509498943
0.002695006772978171
0.0033105539921692933
0.004505000571807409
0.005731423384091057
0.0056054909492598975
0.0077536251310421755
0.00740352261655827
0.007080694174878185
0.009532099757436626
0.00606579298825264
0.006934379038187236
0.005196071925626036
0.0055123458307571645
0.0010893289928123702
0.004319720051420436
0.003211339982196325
0.005217778019411053
0.006945790812197613
0.006615523907292093
0.002021349882555311
0.00809767869472915
0.0014502702204379288
0.008979529474895847
0.006994393124742163
0.007467157343498506
0.008662510940075004
0.007572902681173645
0.007746304518466431
0.00912502864743384
0.010732316201606076
0.010574309292515304
0.00879653574384746
0.00918470945792934
0.0038336640976415546
0.006931399521632476
0.003452808617747012
0.008385318356007341
0.011095477699053825
0.009097466319694816
0.013808554083905336
