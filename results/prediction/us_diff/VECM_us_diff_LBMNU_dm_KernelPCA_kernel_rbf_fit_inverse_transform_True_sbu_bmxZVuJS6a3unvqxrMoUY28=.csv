# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; LBMNU
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=1, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.019029977999372543
0.016659523563577038
0.013526734115070344
0.015643390127902557
0.008390568368340845
0.00904798494860786
0.00971865421260074
0.00504401735340096
0.008368224537801446
0.014341934723572862
0.011370865728981478
0.006933983056330086
0.003503087148723973
0.0015193545911908973
0.007325021776158985
0.008741213345924703
0.01625997817180649
0.015713088738273418
0.0061534792536257505
0.01182279315174175
0.008531096947069312
0.011987748954570398
0.008634863567376905
0.00488044382318018
-0.0012153969990903425
0.006518219013890134
0.01017996292789714
0.00442989823387492
-0.0035385355196476402
-0.010216670569982449
-0.014287596295733486
-0.005999164709549851
0.001532221339313215
-0.0045520214624141155
-0.0031490463169077183
-0.0004152494719460893
-0.0025446792069360362
0.0035083241181726454
0.005309841544362062
0.007162487645019403
0.010285849061762326
0.016652080677551712
0.016622154961772672
0.022801030590536085
0.017301804904005888
0.017205024280158375
0.008555151362718588
0.004488910236033121
0.008586308351507635
0.0028329223827886175
0.003136877132927293
0.013853225299006285
0.013700927248237207
0.011416182971971264
0.012609566240636113
0.015591052878662807
0.016269996313239887
0.01680125350914782
0.011109419430538682
0.0057507517943946726
0.003593531023392401
0.007737124005511679
0.013812459442146076
0.01091146365982247
0.014359884132793965
0.019826689484751376
0.007607426070598068
0.004626168632074798
0.0009840816945556434
-0.0053164399334641715
-0.009023854384834468
-0.007707223337521551
-0.011256362505639229
-0.01798630669823635
-0.0025346070433476587
-0.007147886039783672
-0.011150319134727296
-0.009093994399540273
-0.008977810746839654
-0.002979553828127101
0.004315122701683794
0.012630401156749701
0.007011804135465217
0.005074176542710417
0.0039995448052525424
0.006576320058070702
0.006232299445484521
0.0023586846012319082
0.010937871594667813
0.011280278523183997
0.011619983837553
0.007248781864380927
0.00290647979305963
0.005177109230872337
0.005824828730398293
0.005877501731892916
-0.0005116639130718242
-0.0022140534141055213
-0.007646742945864129
-0.006783906414179408
