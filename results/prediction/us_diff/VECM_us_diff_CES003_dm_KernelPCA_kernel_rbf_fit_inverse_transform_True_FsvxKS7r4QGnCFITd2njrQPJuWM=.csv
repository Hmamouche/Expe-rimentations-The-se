# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CES003
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=2, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0699213367101213
0.04815024603421717
0.034047863321260634
0.031209382329039866
-8.522654295713226e-05
0.005271913450262591
0.00882641898848081
0.002377829741166922
0.0026256107424086766
0.00920198742857271
0.006500035959810337
-0.009067968156578433
-0.020048133221760692
-0.012915611277788489
0.018821955569126882
0.013582715246115372
0.03804620248082644
0.017188765924468705
-0.0014429583502874822
0.019888708571676614
0.009561645882014335
0.025547511066169003
0.00705354180795746
-0.019422269709995485
-0.018712837607227258
-0.007668863173642978
0.014868395890646535
-0.004726501805294801
-0.040720851050981555
-0.05699445663634373
-0.0673464005141951
-0.01865242175836162
-0.0028530392792689334
-0.034425755672737125
-0.01504711280362108
-0.019964135052916665
-0.023480729404419694
-0.002263808680092799
0.005655655164142978
-0.010302053233120483
0.011209753885017965
0.03008940959749213
0.03615535741678896
0.046735880377967165
0.024465673335259695
0.03766488275790757
-0.0014518901113263513
-0.017270580540834326
0.005557889582768781
-0.008446216651687292
0.011044977892010156
0.034586269394815745
0.013938286024386506
0.02851717373630315
0.014684443020378801
0.02206671305309812
0.02741817801859266
0.0219143743367757
0.016183003290892457
0.006747331944443173
-0.005964091118941826
0.005418275983344553
0.020090543147106257
0.007403283610330181
0.023590753251013542
0.018932567672460498
0.009776834796933757
-0.003828551112302844
-0.013150408460977751
-0.02404286083095637
-0.03356477057176658
-0.03496173253637256
-0.05556162209550675
-0.06489973606193744
-0.009721483196721233
-0.0481420707459297
-0.02663949929017089
-0.04493665650813029
-0.043097734311347426
-0.034006862499715074
0.0024092633729379718
0.019038453663812363
0.00709573175827721
0.012736562784785398
0.0035868631575756674
-0.006963918126462621
0.007241819007960479
0.006772816239241786
0.021466270582897184
0.017298180839723343
0.03102536220782489
0.007733226842463347
-0.014455317482336723
-0.014265384944532875
-0.0026146942887485115
-0.001380813603836203
-0.02745168875098695
-0.020275528150996203
-0.042156017229687176
-0.04123533716216914
