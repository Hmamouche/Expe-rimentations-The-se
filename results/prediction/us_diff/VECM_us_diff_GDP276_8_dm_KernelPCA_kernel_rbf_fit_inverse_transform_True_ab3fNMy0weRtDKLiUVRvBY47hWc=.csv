# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP276_8
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=9, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.007026231290037334
0.004160793789878888
0.003300112201311701
0.0050272137571383485
0.004787079691891748
0.003308351705406087
0.01057478910651013
0.006475162119042386
0.0008513255344584109
0.009458108636186183
0.008735880662023195
0.006769390582442046
0.014001445222291124
0.00918089314925978
0.0029981518379060042
0.0012551650535850643
0.004818070738771038
0.000404668907309131
0.008479304173669315
0.007231216478684346
0.007557813550489372
0.006373172232100873
0.00784910282001038
0.003286873450777498
0.0028915184576144503
0.0033649288524858867
0.004389571544982323
0.013235590240214777
0.005592714009651676
0.007255119109683829
0.00981446109239012
0.001258236498397394
0.010779191616193161
0.0049756377672886725
0.014981913130001339
0.007716489614383551
0.0077777060607516855
0.005956121483195785
0.003311200952855723
0.005708381495855674
0.004001938923745995
0.003118229796082188
0.0020321894188301353
0.00404026197647709
0.0068034889614434204
0.006537421836413648
0.003007690567878438
0.0066603122704399125
0.008739890630502192
0.006008013712790232
0.004763521426034334
0.00792864564219424
0.004617086419333167
0.005552969987685724
0.009024333678420088
0.006376564744321982
0.005958748816973144
0.006952291051502321
0.00337886610127759
0.002506739197685368
0.003169691836362236
0.005784516825791287
0.002437100670695246
0.006596647928519638
0.003395427408301594
0.005066388758190418
0.007569679429072046
0.0040923159117840936
0.0009845695912055784
0.0031189006645569927
0.005903338687907794
0.001634349266469607
0.002407164969547586
0.012211464339034224
0.00574459754868684
0.009044565600367488
0.005126688626517703
0.008605885259820072
0.0061984057839775675
0.003999679743664905
0.008628948463370013
0.009124586973538722
0.009274475519969877
0.009435029005743726
0.006324121854522427
0.007983603739488742
0.007723921202523366
0.009981154913277383
0.008797154805097554
0.01053825736942588
0.007433432685401548
0.011680530657309784
0.006563200651441418
0.007206237466973258
0.00826884922784812
0.012926529943462616
0.010086871040299419
0.010678547784356014
0.008828480226496894
0.012134535112553052
