# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; IPS12
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=13, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.01524432780016584
-0.011670225514658041
0.034409013143688626
-0.01627811914829054
-0.0041620126261080245
0.010448801239540853
-0.00486041824536504
0.008066091421212654
0.008014341407800562
0.011584326200980141
0.019040328461934153
-0.010446997423661541
-0.012235703985910302
0.007437703185314603
0.006305844739855891
0.014356618940000608
0.0086820369758787
0.012818228500224021
-0.005969327724908397
0.0028317514782687106
0.026335043723088015
0.024768718512288054
-0.011772997742038913
0.0038631236741042893
-0.006812465909797501
-0.006986422988432865
-0.003869754932719368
0.008873836068630252
-0.012994015121152638
-0.002728139384676553
0.006207975872852373
0.009505627717531506
0.011446187205947428
0.0032742989422093723
-0.004216701818263561
0.0040378479845224234
0.006291863149157603
0.02277899652337234
0.008120912760069304
0.012987675208784709
0.013689615789633316
0.004537080026007352
0.024446868667223835
-0.000981696868864148
0.0037474635266814132
0.015582244796941468
0.0004342773970399546
0.006203477263454552
0.0037440397203905656
0.00704752212296274
0.007227131040361437
0.011800946006789107
0.013094610600359833
0.011449449971531836
0.0038382656535970523
0.010023943895330047
0.01046455034544417
0.0031273653295614
0.01133100759767655
0.015627496245241648
0.014773262713796512
0.004681351365936767
0.00953374318648693
0.00579065765704951
0.013226760337824548
0.009942179778437369
-0.004291144327655408
0.009302225942807305
0.002920052383688104
1.2635470222517597e-05
-0.0037881754961336606
0.004654879961893975
-0.002138847389146917
-0.00044375961399911214
0.0001253041049081795
0.013554751557445564
0.013106064076813556
-0.006990399810978391
-0.009102274864437133
0.038302932293793626
0.0011701670779459476
0.017072626948622487
0.005940572970558801
-0.0021523218394406156
0.009884429225650398
-0.006673007583461231
-0.008942041869953853
0.0032593767134002118
0.008833636973159078
0.004989230823201523
0.009999473217948482
0.0003266440703876758
-0.006926332797888023
0.010647475429149162
0.0014464677619055954
-0.002646201372986644
0.004658231946822619
-0.011579061713308421
-0.010515314292453837
0.001718634794048954
