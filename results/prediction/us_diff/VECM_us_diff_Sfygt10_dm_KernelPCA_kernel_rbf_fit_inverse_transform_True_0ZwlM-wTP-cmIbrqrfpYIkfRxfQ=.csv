# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; Sfygt10
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=13, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.018019624957653357
0.0917773749044138
0.07731451268014082
-0.09144996019827102
0.05884620921487928
0.2555103758376879
0.18247526334448627
0.1754121684069303
-0.34198233716741233
-0.14340415173501433
0.017744456109520287
-0.022797461468061296
0.02307450884611717
0.07616601175357345
-0.04690955201619741
-0.11717252455615348
0.08064752816979026
0.08108116539924108
-0.04108804348216084
0.06368055337036738
-0.06360312713144158
-0.13916339669227779
0.0201978178102711
-0.15721400797964497
-0.06599866303594608
-0.10821562971322272
-0.11488943159948076
0.08809397339308185
0.12330937697175043
-0.09523308188765414
0.05680565710269425
0.11607370105468719
0.1082059742485619
0.033823199957735306
-0.16329021548198785
0.09004006153347174
-0.004399743998187294
0.24136523000547885
0.2761720006677244
0.04264916628305899
-0.1747118003372923
-0.0687063044257773
-0.01618635710993501
0.02178363423059356
-0.03912650520648279
0.00248620208827164
-0.03614817923623527
-0.10804353786411722
-0.23971614545364045
-0.04907991951054388
-0.012505150200528434
0.11671007575761018
0.04448684666533257
0.017929343468765152
0.00842384735250025
-0.0012369963591371824
-0.0967717387493695
-0.1356299408642594
-0.007210969457768059
-0.051426008181894085
0.03390012303054219
-0.06921242803009114
0.03204598343330379
0.18881614461420876
-0.03597214131649878
0.06977294308809484
-0.04824920591232337
-0.03637647213129845
0.05136003272331104
-0.126772437848453
0.006315412313424904
0.025941390612302547
0.1545856390950555
0.3106473433133408
0.006405239071582761
0.10828667250990386
-0.2906371864321102
0.19413926406896906
0.006494583074889294
0.039206531254667776
-0.14912095716215412
-0.057587320625557624
0.15018375562179026
0.007901646511216644
-0.07685756201279195
-0.05146264533488739
-0.09395612615021826
0.07653252137226518
-0.10374527993057607
0.002769916634013478
-0.11764233850890714
-0.04675346794767555
-0.15863316907482355
-0.12363205742643787
-0.10127772147791199
-0.0472516513260228
0.08860557380488662
0.030739218423339314
0.12784510032577096
0.01631887445791667
