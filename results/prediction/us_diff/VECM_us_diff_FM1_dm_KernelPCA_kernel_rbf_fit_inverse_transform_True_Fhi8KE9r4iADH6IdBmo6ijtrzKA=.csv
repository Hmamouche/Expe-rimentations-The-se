# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; FM1
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=12, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0052172008809693495
0.01085219618406605
9.545281115769287e-05
0.006437580936281144
0.008720829622270488
0.006394820783108882
0.007979238159699248
0.008802629056024695
0.010019153747701334
0.009647835251607194
0.012306910043210788
0.013495668323393172
0.018068379527546734
0.018419269363112716
0.012983362789913487
0.012374009239378824
-0.0004963775205869487
0.012235982564157317
0.007087138116478985
0.009751809009255456
0.005579143409753841
0.00527654284512267
-0.002363179051072652
-0.0013632011085733405
0.006012005412707479
0.00910689399376114
0.0051571013497763935
0.004124749502995945
0.0025991521886105117
0.00648803161224783
0.012574367910124189
0.00952481201075469
0.006430504858162719
0.012700787634481755
0.021514868258210012
0.019507401844937912
0.016257960267171512
0.024096386915811934
0.020886674203109284
0.017987002803621525
0.014730922504314813
0.022196692297390005
0.012461454381104931
0.007684937564096696
0.00635727386793645
-0.0009841675167140264
0.0036720209668633977
0.00010470208051466126
0.0011527093063099139
-0.003610076753032105
-0.007999896409986482
-0.006866384804810549
-0.008314944116342217
-0.011313237238771166
-0.00825444490755906
-0.010479128709388282
0.0008067540105244598
-0.0017382022237283795
0.006978331516875266
0.0019346578865511407
0.0011696872019688123
0.0074969429003697375
0.004259838763144699
0.004291381295672169
-0.003838701555668321
0.003534498669012581
0.0005673186221908028
0.002746064882774477
-0.0027271653613072924
-0.0029981005243154397
0.005489228013910754
0.007083907321813143
0.026512233583306108
0.015539535508363502
0.008011097796009073
0.004341894618730963
0.008845939723058301
0.011841046716744377
0.014432348566115024
0.011342161710290347
0.009722561491404668
0.014153145439060998
0.015088888189258956
0.013251115583733049
0.012011133686929664
0.009821076912165935
0.0018350844112698357
0.003549100450678195
0.002660370848292399
0.006387633774002421
0.0030716803481936005
-0.00273017511566946
-0.005809887264826276
-0.0009907912345966123
-0.0006935248584594832
0.004786664351422547
0.0016864081116779552
-0.0016635719298094948
0.010097246149897269
0.0006012902216648314
