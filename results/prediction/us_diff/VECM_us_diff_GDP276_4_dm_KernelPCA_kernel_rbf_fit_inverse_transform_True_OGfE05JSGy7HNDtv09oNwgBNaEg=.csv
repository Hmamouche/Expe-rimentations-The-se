# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP276_4
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=7, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.011239732174703788
0.0052550783606594865
0.014967616859400516
0.010224716838679914
0.009410267494428713
0.006794288065757757
0.0057854515635190965
0.004826715183127965
0.012241476340412685
0.012096077076229762
0.010632610647525362
0.007065592151779177
0.006853854416096409
0.003872290593981637
-0.0002898917808002641
0.00261406763143469
0.0024623945692640887
0.0032727829398346564
0.0007179447148952559
0.0012107587368515582
0.009564610810182343
0.0038326476034375497
0.007071725268271144
0.004451293049619385
0.0031553282636046353
0.0024617670379154947
0.004475888010772971
0.005790497187236673
0.0038187915310095993
0.006414669828620045
0.007870524282696748
0.001498419638380555
0.019370649817798055
0.009926299583235343
0.006374280525945251
0.0023378562865631306
0.003908200018998676
0.003652657579420351
0.00724318392064139
0.006663398500176665
0.007466359611744047
0.006684389590631034
0.003653020373568404
0.009047148398242291
0.005521228585897043
0.0065698866771865105
0.006614947843197553
0.0031499516760406607
0.00173653554811513
0.0020351258302209437
0.0011745905025871816
0.007115184491816277
0.007533715115821923
0.0039735928512345245
0.006918309722326821
0.0014238407473157549
0.0018404428831091245
9.408230905951854e-05
7.085443943204617e-06
0.0010675926178438638
0.001971448584281119
0.003798763741708287
0.00032641285667149686
-0.0009499298761018928
0.0009531913666335338
0.0022218833644617724
0.0016357671800683957
-0.0038505711218440523
-0.0016408707003170435
-0.0004722727884074544
0.0018117189581358154
0.0004943631642407286
0.001353325532818688
0.005140209727823312
0.0055330452544993655
0.0059744876514750125
0.009639913611865338
0.0058281544542935285
0.005874421571164595
0.006014731310647121
-0.0027804576665646846
0.006789065423920231
1.4283803639804794e-07
0.0032448937350251037
0.0020877114007056595
0.002295859827904061
0.004386360683336116
0.005556309555706751
0.004793504083898999
0.007824223283656414
0.008380084042662429
0.004258060227932681
0.009556450563616552
0.0059168708336943595
0.008870276910455738
0.012078179445539697
0.007534757492355017
0.007414554075403675
0.008657754655744037
0.009908452256402776
