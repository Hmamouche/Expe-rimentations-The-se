# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CES006
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=11, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.034696927063541105
-0.078893677728192
0.051048570256078334
-0.06099872378212537
0.02262708972656397
0.03968565841735407
0.023902020052451754
-0.09098295484876244
-0.026179950885414242
-0.056838855157182316
0.011525176438293141
-0.010305356338249708
-0.06822034276491948
-0.01926767992396389
-0.05911927631931727
-0.04990152767878745
0.010359724752084399
0.04083061880244668
-0.0535602576573615
0.005597060086297083
-0.017982092370221914
0.03153726085737741
0.007825533486832912
-0.004126496286014506
-0.019956561990718335
-0.028936328913010692
-0.005063420575328725
0.02617807922768569
-0.01622447717503264
-0.047576908544978896
0.048828301653465245
-0.049199511268469276
-0.008053201271416614
0.00011987924400058692
-0.029855787750957777
-0.006618658421300341
-0.03968835937577721
0.06277632016451555
0.016167688279714387
-0.030002066016604188
0.013364635212276354
-0.029284345226378954
0.0069785363424963165
0.03503095303812795
-0.0033198251235769345
0.020487668209655138
0.0176945805882598
-0.02922339105539096
0.0024908714637503215
-0.016086592616945408
-0.02584238473989216
0.01733926750636282
-0.01642287896701948
-0.04180017631855251
0.03896669271955214
0.005805377266833862
-0.0008655965344143246
0.0009411637749621865
-0.0002964095510356486
0.0193750582859775
-0.011492636064779842
-0.03136029769331511
0.0014298677182523344
-0.015684900456859316
-0.018573705050845202
0.005461877942211594
-0.020616232199562913
-0.001991062828215263
0.011031341936462897
0.010247026560784238
-0.01127239384273027
-0.015217120729739679
-0.03443102307066459
-0.04448530196061247
0.06621836929110703
0.014645979168599887
-0.025502455876721786
0.007305996033491373
0.0014621466741187757
-0.009964420238458416
-0.005192042337795112
-0.02315809373830014
0.03286245749488906
0.02958847187468073
0.009777943239080822
-0.03403554099862566
0.033535696920017274
0.022657141991157217
0.028165544443551654
0.01109761822196427
0.014119903113755366
0.027974516441261636
0.026195955979383494
0.04208223700575682
-0.010218785109291452
0.019267138174867568
-0.004564062467303082
-0.006527389439197166
0.007623175282063204
0.023913455824546563
