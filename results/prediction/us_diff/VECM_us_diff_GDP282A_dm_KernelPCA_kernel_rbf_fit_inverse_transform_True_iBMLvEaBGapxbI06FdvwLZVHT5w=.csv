# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP282A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=15, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.0006733593889005438
0.005567319832458659
-0.002823677674064763
0.003966448811762091
0.004237550449882455
0.0070676211277261565
0.00272922974648929
0.005873617609155047
-0.0031889897390507175
0.006513380994061958
0.004832170408713811
0.013367360177223718
0.003580612708845247
0.008282117243033063
0.0035422719460214223
0.005045648598710063
0.004826647890463242
0.004772360389596271
0.008074905625323595
0.007812703095851262
0.002983524569701075
0.0030752652887714926
0.004931732528971396
0.005665873177877177
0.0015610321194152858
0.007051077906331557
0.0015032239299876714
0.006056475688759036
0.001969933727112415
0.0037799065333134403
-0.0021562540686951314
0.004276283929634219
-0.0006335633462463879
0.0024571382955456984
0.0030319579841883437
0.0007617682842503675
-0.0018088759863450505
0.009035274330018757
0.004553350351964497
0.005968879364460108
0.010260691721173896
0.00545439682805797
0.005649642363131127
0.002989073827257191
0.007331881267541881
0.006503411339411018
0.008712060919457467
0.009218740790506634
0.0028234008808849407
0.0037286664899421874
0.005911311027810195
-4.701140944285637e-05
0.004725776985827375
0.006716699650015532
0.0021415835972488943
0.0044813483532724005
0.00608406769272826
0.005590877167331781
0.003839007277869994
0.0036226169533768904
0.007526693805221397
0.005444177785924323
0.0077782953722994016
0.007220518033488028
0.0056082920240347785
0.005562969187938256
0.01130330740607398
0.010088335541030256
0.007662073428115076
0.007116313294416113
0.009138847654579693
0.010070100490728713
0.009559917375590641
0.009287766990895637
0.006001961556923358
0.005108810225968966
0.006249811518615301
0.013106250606819584
0.010988504015358726
0.003480207526322261
0.0038399806464274396
0.01404943448273105
0.010943282369030777
0.013055845752512642
0.020025045078404878
0.018519227044951424
0.012304860397379814
0.020745244268337973
0.02176823414581183
0.017798697001643642
0.014977030944775507
0.0199770913507269
0.010688491577944968
0.013615659215000329
0.012314985106329153
-0.0010364635849027868
0.010157417057064567
-0.0009145615036354434
-0.0015334174699142896
-0.0091620540851216
