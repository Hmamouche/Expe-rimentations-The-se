# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP254
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=2, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.007086136955859156
0.00426425551868325
0.003092070620655674
0.007634707276143661
0.0023744790234106914
0.006860551445232926
0.00477796090821473
0.005722451634697877
0.005167423572252887
0.006189750681498263
0.007377352822671097
0.0071302581079632785
0.005022560409398154
0.007077733271751505
0.0038865262264784926
0.0061289514112983345
0.0033273828794475003
0.0033000645095869305
0.003661490000137945
0.0055772307410485115
0.007285895243788811
0.00890676015876129
0.00571592223708759
0.00415237080581543
0.005670373481343568
0.005527505808297471
0.005550848902172496
0.005387729292984696
0.0032721073771339705
-0.0032685803384237605
0.00036590765106461775
0.001781108604604577
0.0004570533082521454
-0.0006104813987547692
0.006325864212898362
-0.0021560488787632404
0.005863372175329385
0.007323271830188903
0.0038520020817225786
0.009356891367323084
0.004175329233620551
0.005973297049956775
0.007749027079424972
0.005704181440106633
0.006725694423044654
0.007829935688038277
0.004588597744893404
0.005401790764689927
0.0030910618677508633
0.004903766226151757
0.005061002074646458
0.007059355658447639
0.0065581202487221355
0.008504928012850002
0.00536748597884164
0.004835192533659155
0.007552519609021896
0.0036529437310116168
0.010242543740459078
0.007984121056983907
0.010592358022598839
0.011913816830187635
0.011595025689474521
0.013445823188249502
0.00972687171811666
0.012665579694507167
0.007926383975801076
0.012952434256686272
0.00795977150156052
0.00924410487997241
0.009012639463371013
0.006274797531374935
0.004145284389341762
0.005453452158506602
0.008839934508188752
0.009618621092276753
0.005695493434076694
0.0032866238250209272
0.004306852980265238
0.008849995527617623
0.012748414905531908
0.012897880181649418
0.013317739592530551
0.009707324023203848
0.007383104134842377
0.008851827796374147
0.009828349321477551
0.0108015505319857
0.01110830273952198
0.011567259168095298
0.012856729305295073
0.01198537554058121
0.010878445054770553
0.009951954004394444
0.010527434610121771
0.01058397561911084
0.008413063564162722
0.005558184646076094
0.0020645297699317003
0.004143137272927863
