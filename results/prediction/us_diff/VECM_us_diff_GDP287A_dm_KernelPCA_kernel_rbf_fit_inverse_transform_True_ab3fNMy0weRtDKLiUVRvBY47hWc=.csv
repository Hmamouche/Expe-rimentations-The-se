# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP287A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=9, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.008584451224648211
0.0056126501297851655
0.010460753286789488
0.007347266508435131
0.0042449428765404425
0.013796652057739481
0.006992706197895815
-0.0008510474974133047
0.0036218766732124155
0.00524509370332136
0.0035407870225027597
-0.0034685371343073004
0.0034679883685903882
0.0018381941088097898
0.0004804633203178189
0.006330685681913966
0.00305008585621959
0.00457992768782729
0.0012822075078919187
-0.0016580066751702796
0.0037625704785104403
0.005919021220126703
0.004519863864203763
0.00043997172950191183
0.0025357438267741613
0.0064692855859684924
0.0014613037614640573
0.0037946251865307095
0.004277253924758232
0.008163658392030468
0.005482459103802134
0.006975563649394644
0.011222871802886435
0.0035966351654780383
0.0033907506004621428
0.006876622587724545
0.004200103947686592
0.008726693201012497
0.005231037011113063
0.004245858186790466
0.005638296688949647
0.005604650680678798
0.0015327786171019525
0.007996122184980425
0.010251930119668911
0.004502369873226474
0.005186664445059334
0.0023375379237671867
0.005801540906935692
0.006040537430566842
0.0027857437138924662
0.0051474115753916225
0.005086863634679013
0.0030240973958569044
0.0005303014043573523
0.0025822078491199284
0.005689795605669444
0.005939423213806918
0.00011478656747284603
0.00373941660657914
0.0019379048135746693
0.002483940393161357
-0.0018129524971860532
-0.0017938091994886365
0.006339542720784037
0.01129588173947917
0.008004254520825874
0.005318716184356392
0.004631877460339745
0.011663955291163416
0.002549915577208236
0.008070453564148903
0.004499457111056647
0.0015489801714597747
0.0042564629557771865
0.0037960606470652664
0.006977009855919337
0.013727519053799504
0.004765203362150903
0.0032043961540304264
0.013594158254694875
0.019895234675178307
-0.00011650481086342731
0.007493873442084313
0.011322436019387674
0.017048555884061053
0.014237666506820824
0.009464342395961556
0.009362688727818522
0.019653013916778726
0.00562295673200773
0.011766438392799679
0.004818039558363474
0.01935758219163617
0.010841474554211944
0.00486573820740108
0.007361052827716622
0.01710537247711063
0.008424486321164881
0.0037833063838476158
