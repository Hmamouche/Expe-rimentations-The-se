# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; FSPIN
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=8, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.001924793815541215
-0.00536118072196539
0.00019508885586409525
-0.007023152072819331
0.0019484243521463878
0.002769177492705544
0.00818166226616713
0.007692256050594707
0.004958639089481021
0.004337717359576148
0.00973956143073635
0.01231266113730593
0.004792552532079778
0.0048283683679455885
0.013558287287809433
-0.0014975216510525052
0.009292462662674205
0.006376913493643138
0.0031990687113904355
0.04576289293816115
-0.001848202735518569
-0.02909752173672608
0.001720718992643035
0.007513358331541665
0.013082565672036587
0.011901671082019389
0.007553219667312417
0.007679720844879204
0.003375999579912627
0.00465715373507214
0.013288387763062081
-0.00892858561429373
0.007417943713721105
0.004433330860292525
0.01516469245051301
0.00017687896299620805
0.00010842383574256615
0.01264458576842398
0.006514919652504161
0.014123006653162688
0.009351168242713993
0.0037965419536210017
-0.008094827919937533
-0.010611959874015397
0.00908406732528339
0.004860499202019655
0.0023484751248449105
0.01758690272579324
0.0307261590743591
0.020398363233618134
0.01819788682355123
0.011389145019986216
0.005488349406133184
0.019307408390708394
0.019939911471136804
0.030589264638601114
0.03953984272244591
0.04125074666541234
0.05124640428622268
0.028843218262776568
0.056308020723402276
0.03696821598310066
0.010416685022688499
0.035138295086926966
0.05064932438602336
0.05034189165532888
0.057458717042403476
0.03495868723071855
0.03899245151731927
-0.042704059473594506
-0.04129745387639877
-0.06418118941168524
-0.05907254429474323
-0.02669448683154826
-0.030668391588767753
-0.024389823708450067
-0.0812745781748641
-0.021878312455866036
-0.06553431072517396
0.02004357517525478
-0.003844679558063134
0.032635559783120605
0.03048469159047985
0.015117033336596308
0.015146425656630524
0.031453785214024435
0.032746414352951926
0.01570809765535256
0.006277508585185449
0.004200702737055367
0.033458053844211355
-0.005866077351804494
0.007114098665369172
0.039031121568141876
0.013055425015407072
0.058011695349059436
0.031729991561747696
0.0439832278373719
-0.049250395028433286
0.007901419753848409
