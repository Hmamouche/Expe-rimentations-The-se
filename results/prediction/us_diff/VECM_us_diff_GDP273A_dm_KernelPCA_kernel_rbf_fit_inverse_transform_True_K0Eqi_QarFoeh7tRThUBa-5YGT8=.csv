# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP273A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=6, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.00501041800384247
0.004021930127002549
0.006851514799800471
0.007182919134173134
0.006786988070282811
0.0037445722586534726
0.007248050098224108
0.004999132047400651
0.004510484991094375
0.004769593501030614
0.0037653328874730613
0.0020767627716552902
0.0046607169987022195
0.0019206116334119295
0.006012119345436276
0.006256655509569286
0.007416561972093376
0.007354984361224724
0.00675723063738287
0.00692712828385351
0.008019848474460505
0.00780213868658282
0.008934579545531491
0.009779117509368659
0.006757328344695305
0.007177223541315654
0.007548766241939347
0.00726799903897142
0.010904901658127367
0.010758718139584351
0.007072798678159796
0.006198935857577314
0.006394772370676387
0.005989936980783867
0.005424201691277672
0.0059943125079130275
0.005762649314213716
0.005226866764109304
0.005822030384986843
0.0035726670098712317
0.003560985446370981
0.0033764040756976304
0.004075896421635054
0.006033041510397821
0.006912815898606851
0.004822408184079349
0.005841497913012233
0.0038365082370009026
0.004218118891599942
0.004586716185621666
0.0039037663854749587
0.005536551504748411
0.004388274490124808
0.005881434989534584
0.004950155627154421
0.0042830371945543145
0.0027780889414694794
0.001962736360576697
0.00181865313164689
0.0013372187724021766
0.0017980913635480802
0.002556505752017128
0.0030678703915993735
0.005887921930756594
0.004400770786282992
0.007064872528283994
0.006527387619229115
0.005948725716185226
0.00633331120588274
0.004302403840186686
0.005430956292126281
0.0049422408896714455
0.005355035060799651
0.0027882966908686947
0.0021634168748806363
0.004535301050951904
0.003186944236772039
0.0052958448713804245
0.005798369154393967
0.002318650026588042
0.007039334119607013
0.0040782502393845056
0.007702479481998107
0.00807251749922186
0.0074724605678225765
0.007654870717668376
0.0062595804718828035
0.007575469321677402
0.009026340816673152
0.009780680701855853
0.008231995213117235
0.008398931799358524
0.007988767019277615
0.004209379117966549
0.007100293659623403
0.004745245287177168
0.009032579330716207
0.009786782672383827
0.008331799454191328
0.012017159991973782
