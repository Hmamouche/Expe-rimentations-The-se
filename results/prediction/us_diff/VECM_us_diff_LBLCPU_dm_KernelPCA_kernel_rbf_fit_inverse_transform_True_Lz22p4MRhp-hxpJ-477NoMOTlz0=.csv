# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; LBLCPU
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=11, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0015063614369249974
0.010312043308133519
-0.005352180498884192
0.011227904831554688
0.007072188290843639
0.000982046089431688
0.002695410041163631
0.0068978904293481485
0.0007347979215616609
0.008671805677868204
0.0009370717756089415
0.0023539644657025256
0.003084203343400017
0.011797347230820602
0.005467992199154691
0.00879556928370505
0.009729081270620606
0.0044311816371107315
0.008153524374345938
0.006439455907519288
0.005549579370259692
0.004990932541126453
0.004977938169200141
0.007139290773433541
0.0031421841040838415
0.004271422591484818
0.008169460832053275
0.008682385700293928
0.011181872613704154
0.013531900695967651
0.00211471025029044
0.010957082086631084
0.012809791375535385
0.001754401413735446
0.0007742617989120962
0.003471327995689606
0.004328755755884307
-0.0030211245646605237
0.002895412196063688
0.014279969797036069
0.0038344386820910546
-0.0015918809077437226
0.001756007899803013
0.005579436432871481
0.0031369991924104002
0.0003655990935511618
0.0003896479208121092
0.003381253532525035
0.004856406485190973
0.006029022854383613
0.001159456299429
0.001179099616137083
0.004406043439444257
0.006090156991666159
-0.001984543330648997
0.006178732589177342
0.0006288879279736419
0.004039305932308915
0.002531880232132363
0.012636694847629845
0.006243909710220543
0.008185006275913419
0.006501710729742687
0.007856432257300601
0.0038876708010829254
0.0037808077345231244
0.012123576669851142
0.014372747239182184
0.005590818530117053
0.020282419452884195
0.003162347778776225
0.012019778252949448
0.0036483645842218734
0.005709909307222738
-0.008882179128777264
-0.004405265667209612
0.0015238871196293561
0.0022307628247846614
-0.003104613855822778
-0.0012401518847345418
0.006956397025830891
0.002129663986168353
0.0019128161467549909
-0.0013788164424326517
0.00801206179084908
0.0034745694911908842
0.0069847060894912116
0.006277126744710449
0.0033104628169188625
0.006345121119831077
0.00590203804055272
0.017579673736503064
0.0047656722330967835
0.011005138757286679
0.0055074212198983645
0.013612423201969589
0.0194050306626819
0.01256638166772141
-0.0037002887262580367
-0.0068002315636990895
