# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP276_8
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=6, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.007547310353364288
0.0023536876880215145
0.002668793224278771
0.005768273291592554
0.0047273448993645694
0.0024746914682341817
0.009284615293028502
0.006286117076614892
0.0017179574404104724
0.008830775652290972
0.007934925857012602
0.007700608818195743
0.012631403363119511
0.009569546812649212
0.004003418406486993
0.001635034415791121
0.004894988782414964
0.0012066017811364026
0.008818794300064037
0.007477587081692763
0.007012335143368251
0.005141918566579387
0.0066626848463585886
0.004348637851476613
0.0025694424371191225
0.0037656582454507993
0.004230363513760847
0.012206140410512253
0.00651155548492325
0.00680932531692951
0.009531395358767578
0.0025941559828752624
0.010031969030417108
0.005565560467904225
0.014131840493559762
0.006533668984047441
0.009287193333461822
0.006256248340486776
0.0037135803350027983
0.005692495703824611
0.003260493095598004
0.002357267403546558
0.0027870267239031854
0.005121733447514986
0.006217263755718609
0.005786295062170597
0.003309720383793073
0.006799870714951359
0.006910047484851712
0.005213411350889624
0.005853787152584105
0.0076573615753417566
0.005484838017306383
0.007250047027466539
0.00856194052279846
0.006309379490722276
0.006157431278052146
0.006442692355052955
0.004286874533227852
0.0021872365703582445
0.003368788560055946
0.005460140530018321
0.002177736160130345
0.007723883745921601
0.0034031322838031356
0.0051597566406198095
0.006966432676242386
0.003422935134032028
0.0023535069140348803
0.0019058835140748534
0.00712248502387351
0.0008034943730285508
0.001999315524394154
0.012638979284837083
0.006797232633002019
0.01122673032943776
0.005544386777495503
0.0058396104584482675
0.006665124417963424
0.003316571130313037
0.010012144035659226
0.007645330720757505
0.01062222925465422
0.009668439030142428
0.005387560710022727
0.00788529243661354
0.008385075213648438
0.009723139486184924
0.008929980831518402
0.010492386220565558
0.007012146804430483
0.011912051173587105
0.007753708799561602
0.007396900613830359
0.007732117166845242
0.013649784062288891
0.008802319870440918
0.010553754699907377
0.008874384981825642
0.013016101108357013
