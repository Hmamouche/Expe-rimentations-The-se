# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; sFYBAAC
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=7, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.031240655176087845
-0.045342845721145414
-0.01774060663130061
0.03689256379579588
0.009998224666412717
-0.05072851282039463
-0.09001011930677447
0.02983856461233319
0.0456035216919439
-0.026208762514904723
0.03638363620088042
-0.016574445860379258
0.07261442301406511
0.0763409587917262
0.02050710968812288
-0.0004137054168703788
-0.008159348147540598
0.02089896809533772
-0.05987802017125667
0.00482768067205868
-0.033824842422048494
-0.09156237137848625
-0.031472417397583
-0.023189605345476226
-0.01758992800819569
0.0012770733507570173
0.01892455175997391
0.0016924981027935798
0.08728599976340654
0.04487043017736979
0.0047607234262728865
0.002654717999038589
-0.07446170478326802
-0.13201540628662056
0.017880121525801346
0.033509637055073635
0.05844516832007695
-0.00789562651684584
-0.01051531844005752
-0.0008773165838512817
-0.06652086009249596
-0.00896556798098299
0.02926480119120964
0.029676345736537713
-0.004935423893198381
0.004860319064714635
-0.050525319029843016
-0.021039600019160297
-0.027575382545181593
0.001560821077818974
0.014719477788246168
0.016183319831321267
0.005862563873385955
0.002395450003930339
-0.008896173894364529
-0.034109982157735835
-0.008855074060901684
0.004553001368660447
-0.010680420116942577
0.04716213487890038
0.020116184482513108
0.053123103067602775
0.014049376790866597
0.04472710402022852
0.027517263891824253
0.005338718925696239
-0.03607124974982232
0.045678005423400864
0.012438797886304658
-0.03200778805082279
0.056210438434509666
-0.013889779794940504
0.082907417624017
0.04865150877582533
-0.05944374400886504
0.022156023761237414
-0.001994558223151248
0.03142223529171276
0.05225105852921131
-0.07463369182035295
-0.0021621055566773953
-0.06375145426767483
-0.07158456495122612
0.021038580387397095
0.003352820508205564
-0.01764223870999644
-0.042943771718626914
-0.03454703164163804
0.010085438167096946
-0.01911842800892994
-0.025474682555051444
0.048644887975044196
-0.009338176536435823
-0.03783449438321105
0.004596368387052942
-0.025597613872165786
-0.0182592299717469
0.1232819759189826
0.0606612361479513
0.02910363706688484
