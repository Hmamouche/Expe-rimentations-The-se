# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; FSPIN
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=3, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.00398725366426555
-0.002404994205916466
-0.0014658591376204976
-0.005261624123653247
-0.0003375169483441642
0.003263307322048527
0.004417949827179946
0.006258004976885525
0.0034970216266464503
0.005581526467838579
0.009631949220599144
0.01050488829337481
0.0016748362073931169
0.005075293044576412
0.01546540636246166
0.0007814750830964449
0.00911258852253031
0.010262954685503778
0.005267035094714292
0.041499308147041
-0.003068124421524779
-0.02522735210848769
0.005014775802837754
0.007219922922530089
0.012088742632963455
0.01181369789952057
0.008442701295876523
0.010780219050085426
0.00490930536402817
0.00023094917111317142
0.008927030050165844
0.005245222850890442
0.0015908842278443084
0.006370351070696823
0.013506971645256277
0.0037976735851086916
0.004390007037150083
0.007242602339233944
0.0049215776590996055
0.004160550088494187
0.004258963529258837
0.005522372339768015
0.00042865947492183663
-0.008464227658917375
0.0007393804745510844
-0.0002831912516269089
0.0008158829210059102
0.015534978207708851
0.021087456681221528
0.020741157503945208
0.024135412374709658
0.018262700925128824
0.012050671874386095
0.02155384055213085
0.019791622500951154
0.025117029240732267
0.041796448539073286
0.03688930431945177
0.048885171309578146
0.031558784330795626
0.052876662725726845
0.041718274386834606
0.015267461908629303
0.03445609972372294
0.05734132213013336
0.04831403420568875
0.05446713636483579
0.02904687318443376
0.041621180699968036
-0.028917923444136188
-0.042910891824206154
-0.06379334333723392
-0.06334068038238079
-0.020902096759119287
-0.031668027092120694
-0.02611997918379659
-0.07671410963079138
-0.022288879050135334
-0.06295357183473385
0.020049596776013687
-0.005457374525970258
0.03127256277122032
0.0367492492311963
0.011635361964162344
0.004565591941581905
0.029125402897050404
0.01815355146823916
0.013795991902298167
0.017009672036575635
0.0027205507214901133
0.030141113483640805
0.0010396739574897442
0.008914856232015819
0.037936863230783484
0.03000361054667644
0.04549730621524521
0.015789724478519052
0.04357491213619539
-0.03678007700912963
0.013196341609000819
