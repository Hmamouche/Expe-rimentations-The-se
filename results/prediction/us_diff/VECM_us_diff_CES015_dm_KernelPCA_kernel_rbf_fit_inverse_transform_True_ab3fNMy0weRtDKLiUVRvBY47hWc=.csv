# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CES015
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=9, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.06849928281693249
0.046479491095273
0.023070164051389373
-0.010568030946234944
-0.03862442336868273
-0.0221684958561465
0.02593096707732013
-0.0012426187840912147
-0.0018832127449364723
-0.007195115360820124
0.01455391956983203
-0.0333689785881212
-0.03414702979917056
-0.009055344988407762
0.02252160086635005
0.023720290954150385
0.013679742622146081
-0.003742555046924289
0.013175162871483896
0.01794015511185276
0.01185480592200163
0.03969319794888683
-0.022479286402845956
-0.016562539795045385
-0.03256321766259313
0.004305701503062289
-0.004975265073419993
-0.01805760912417842
-0.0187992900131384
-0.07209902570361267
-0.06536058099105913
-0.0008450502736523403
0.036183901831492005
-0.010796585481052081
-0.0025020635793415917
-0.014719942653057573
-0.02782287574033332
0.016308833949734022
0.009625916114342898
-0.024986310515719257
0.01806477123747347
0.010371571302611248
0.0214303946540782
0.020281093530534554
0.013152115895836097
0.020688394192305334
-0.007257632573725619
-0.009253575622158169
-0.009685514598353505
-0.041706044349224376
0.002294252896070239
0.026540775656864038
0.012988064122305739
0.032491458884108496
0.012646938350454637
-0.0013246833491641248
0.019690702925295366
0.00419825921701485
0.002754048610373592
0.0019789488788301895
-0.03341620192284538
-0.006839284023070929
0.011309683160748395
-0.01419134139184805
0.026403648356951196
0.0033006421944593543
-0.013073120766573501
-0.02544596549108223
-0.0109800339546276
-0.017108678083489683
-0.04119095206090761
-0.047523642138001296
-0.07797886428483743
-0.06575031809712735
0.012426903377025771
-0.024839288036984663
-0.01563852078398899
-0.0501609721352009
-0.046468554581148125
-0.022097683134520214
-0.009130930112596407
-0.005481357829484838
-0.008555889840854584
-0.004069786201245518
-0.009704158366723052
-0.012302185267413349
-0.019731076870104204
-0.01449264133721901
0.007480238216865594
-0.006550460081221456
0.015635041991060954
-0.007776787139137118
-0.027461524441979145
-0.01209247009889582
0.012815623650427571
-0.014663053361132078
-0.024928488986657758
-0.029881174502604996
-0.032022743637563085
-0.011130575282270733
