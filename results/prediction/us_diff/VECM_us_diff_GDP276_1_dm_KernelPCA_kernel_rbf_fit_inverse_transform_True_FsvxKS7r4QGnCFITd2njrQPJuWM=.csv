# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP276_1
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=2, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.005247864590644798
0.005028721938213207
0.006180200089990953
0.007400031271702141
0.0069916995838499646
0.006640522778168654
0.008070567729753396
0.008012127959102708
0.00772674933990816
0.00819348814988393
0.008405716201368346
0.008719456067367763
0.005953347649908071
0.007710741570697831
0.0066207287984755905
0.006203247041131746
0.00576930851629469
0.007248180257479508
0.008255747344019132
0.00517144331459758
0.007660390380012445
0.006360708595487439
0.0054962730814473535
0.006753344224830127
0.007134263252669146
0.007695175517637743
0.006602251544474748
0.008188394286417041
0.009599998506135252
0.005314376398939504
0.007942277464759957
0.005501617329126663
0.0027971808635751877
0.005297301053271261
0.004726868917308513
0.0051199012451165656
0.0045528918789778244
0.004701785674250184
0.00476398642519633
0.005545309708389762
0.004362371925773541
0.005414818611252159
0.005417388629461674
0.005478186262771542
0.0048848025231140535
0.005634276004639727
0.005395257979064986
0.006202673889072433
0.006169907926451269
0.006833839516118318
0.005987821032518049
0.00622162590842767
0.005992349738069245
0.005306871795762323
0.005741741294995842
0.006153529043748495
0.005802297224311108
0.006392538562186332
0.006419418445731648
0.00696425295061637
0.006809489772634529
0.007386705751295067
0.005601430480028896
0.006452831950463247
0.005594601097049466
0.005453147818058497
0.007368268259662428
0.006536042915514724
0.0074382096790249356
0.007882871716445819
0.008045178324186457
0.009278197902440031
0.009324270415740814
0.009510395744605035
0.009893522134156143
0.008635353742602306
0.007888502762041455
0.007669731008835394
0.006824413026671431
0.005030787614537378
0.005941077662234171
0.006055878106296353
0.0051906117524737425
0.00768548119653658
0.006447660067481838
0.0064336274246106434
0.007203341286142671
0.006136120108608426
0.00616311573760022
0.007095947174477442
0.00786381304594276
0.01078193340450705
0.011339143633414308
0.011719602313497066
0.010478023633477307
0.009522456511096568
0.008733317523082344
0.00869571117130053
0.008336176063476981
0.006646113204587109
