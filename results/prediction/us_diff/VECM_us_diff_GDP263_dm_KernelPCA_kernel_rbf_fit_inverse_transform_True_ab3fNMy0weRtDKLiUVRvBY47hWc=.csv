# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP263
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=9, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.004184407883832041
0.008779693084850614
0.001824700504153249
-0.001312389949421303
0.007312081059166913
0.0011302306416271807
0.0022761196270566107
-0.0005519392435797835
0.004105147644354934
0.0013401275478237432
0.0035745203278964703
6.642319742041565e-05
0.0045827160191735114
0.0029791688170005435
0.007483587346086352
0.007834800999120293
0.0060569180874078775
0.009457439797167747
0.005980497900047178
0.010472671386140376
0.01777559822305535
0.011168293710828416
0.01049885662689089
0.004455111621189874
0.006689241431704673
0.008307172141834093
0.00552683040199529
0.011783365662864857
0.010804030752677638
0.007375226938176227
-0.0009761316605155137
0.006110270071662736
0.01072888813942656
0.0005311690459502908
0.004760850179579887
0.012420535594711242
0.011896482379458617
0.00458277515999219
0.006931128343568061
0.0023149893518062945
0.0026382314338493215
0.004431652126872133
0.008231763408272164
0.0053718573865698775
0.009988865489562947
0.015651361350762862
0.01718261176741207
0.011573641714166015
0.008662843722203578
0.013886835493079371
0.005487200620349684
0.00796720304402698
0.011715088773745084
0.009574738463990803
0.018403013829717776
0.014741310837262454
0.021396546154637833
0.022235105363287634
0.007995320775975647
0.004395354467393299
0.0004963711616368396
-0.002457811981441808
0.008816596764615632
0.0014898371088053436
0.008497654888235472
0.021470045965791634
0.008874758379632704
0.013851314396088856
0.016551585266966096
0.010219125134529971
0.0008871839348410207
-0.012770305233287267
-0.018257678301299006
-0.02890603165563713
-0.0030350559470582773
0.01869750456634418
-0.0003965904055259219
-0.01058657088084338
-0.013103537668888398
0.008878089300734682
0.0069433951437617505
0.01820726828522429
0.012455578964381616
0.012170793536699448
0.012183452275583626
0.02211528486049157
0.011141425699364734
0.012325599915917793
0.005438021679511415
0.012947720540730717
0.026937792590466948
0.021411835577689074
0.014117311943224761
0.019214780599278374
0.025325780727925976
0.015690961988328686
0.014300939188756296
0.010130946646913495
0.019134498627348707
0.022007902328743424
