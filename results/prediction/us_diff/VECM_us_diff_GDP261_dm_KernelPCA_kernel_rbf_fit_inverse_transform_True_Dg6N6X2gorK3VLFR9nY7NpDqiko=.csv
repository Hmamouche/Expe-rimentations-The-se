# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP261
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=3, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.005518580243677554
0.0018622170173297412
0.027127703742725322
-0.005435485974121724
-0.006921400571898972
0.021685155852802465
0.03366291272942671
0.02736447018471535
-0.003832470764007582
0.003055928996052339
0.024722516028868505
0.033774741560915644
0.0072925941077784245
-0.007344629017378261
0.0012072363537581551
-0.023480177396489783
0.009235563589221766
-0.016320845900992927
0.012269341890563525
0.0012312270679997513
0.010151777657626997
0.011963123931446638
-0.007907916221211205
-0.011079721108362603
-0.005247497709799959
0.002185489245079346
-0.004164610504787012
-0.027211216735873938
-0.03949977617391587
-0.0453197755498496
-0.01735735521744162
0.017859068704477662
0.023785950409693557
0.01213995672183044
0.023656058408339828
0.0016534246818509513
0.014240579036763158
0.006686590987825041
0.0008359762146343368
-0.00588922070186719
0.0047204552015967256
0.03900470869704835
0.03257776354796129
0.011628720126384913
0.01249650081862111
-0.004611560102482022
-0.0075309877216721095
0.0015517961555107686
0.012575881136696297
0.007959103494306296
0.010685793361985461
0.007603449552022723
0.01388712894388339
0.012989644998605885
0.0075957008547036155
0.008206290257610764
0.01657327529204708
0.011125560519551408
0.01925266408940231
-0.000863226335825867
0.015137288527857885
0.024310445184018488
0.021063862155234845
0.0032484868052215566
0.0037246197425865463
0.0015487082242514804
0.007339802742679061
0.0018813971925013382
-0.002794367810759062
-0.0034958348246996417
0.007369976757463874
0.013797503388905336
0.014411428036802126
0.0030272407052338176
0.010310176148576922
0.0035812018635940504
-0.004557840077703381
0.009691287504801714
-0.005777672820293593
0.023246040033413323
0.0371954736408049
0.047430315178481494
0.018615987187568003
0.008252191195132394
0.01319604217793691
0.012661140249029472
0.024069801625343033
0.016479844778479046
0.019648809485955453
0.0041020627320465745
0.020626332856790365
-0.038451964057986586
-0.049242797415647944
-0.04816769066282292
-0.04811894692755251
-0.03578422541295211
-0.05123241586181099
-0.06956392299449808
-0.061653692736418374
-0.05077430991659212
