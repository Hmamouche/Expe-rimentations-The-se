# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP259
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=15, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0036690290070650992
0.06167432071895039
-0.014284794450342704
0.02103919121742163
0.02336135851402503
-0.023368344107873154
0.06235897680229303
-0.008601557031018451
-0.011866501753770613
-0.020272943131224894
0.07889204471436097
-0.09072168803175956
-0.07705348164482433
0.02444982858864263
-0.004173134696914299
0.03776736723244141
-0.01657397715124849
-0.04416269592297925
0.01469668316171173
-0.02430940703216497
-0.013788063502383742
0.009060029712184505
0.0449017617006546
-0.006752010209014352
-0.009460850737329229
0.011720141953321814
0.036884259461140656
-0.023407110749042247
0.004202231398782197
-0.05392875043609889
-0.031063991251212272
-0.033018355153455206
0.0231709626361276
-0.049246251304523606
-0.06849372319676547
-0.02292965255493474
-0.024219973999054595
0.010583622936882588
0.010987858916698201
-0.008297709375092662
0.00310620662248588
-0.003553064980101675
0.015290100051145172
0.012752308957566901
0.01946188014079358
0.028486811137674473
0.0294560202686817
-0.049552442003452254
0.03189613201173373
-0.005637453916753625
0.022664165007618517
0.04353370269022565
0.022053658703286516
0.005807603990234977
0.04372788194622165
-7.431131653948047e-05
0.029104711599424894
0.025394003795071535
0.005111026397315279
0.01028110248020919
-0.0020901315371789544
-0.007160147634295399
0.0206339501009178
0.010446129890425059
0.03195035141878758
0.010394948665470426
-0.025590076013379596
-0.009604246820675828
0.0002067146641156689
0.021709260250487368
0.025444858010685016
-0.011278022575641438
-0.04320376766429538
-0.04570116907827387
-0.048306758728133434
-0.010268295034295738
-0.07807033496386656
-0.08340827029843614
-0.04651158595646346
0.018539748740223808
0.014487605340041003
0.008245018762795302
0.03997092192068377
0.016615291334964827
0.007653081472113413
0.003952644832574206
0.020089097247946167
0.01643149382323484
0.0037221229632088196
0.02995058755301675
0.00752792024808011
5.1190081866258784e-05
0.06053656500428486
0.0325902399088696
-0.029539999076346354
0.038078980675333884
0.05873177236916221
0.03527388439005473
0.021815548209203704
0.020804131936782454
