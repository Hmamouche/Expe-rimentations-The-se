# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; IPS25
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=8, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.012911179958298808
0.009885460621690413
0.01775802719438009
0.0012076394152347996
0.006818773627392119
-0.00031186478995728906
0.011878332957549725
0.004242815373209926
0.0009904356780667091
-0.0005782637350818492
0.0014859572081956085
-0.00472568297351682
-0.004558002984264509
-0.0012426783140071195
0.007710280887078367
0.01132744511811907
0.013381156404119172
0.013902493322627933
0.01309580684575843
0.009710829130655211
0.009351452301949809
0.008624019545913403
0.0005537956196992647
-0.0030830000054571432
-0.0027029123676926216
0.002726324429093999
0.012663031366814369
0.008470275762250411
0.007070298316833789
-0.012019133565190914
-0.0069888702992621215
0.0020166726774510555
0.0062105079765643004
0.001431194551436028
0.001466553336294262
0.011605190769345663
0.0023649861127407303
0.008341112801906705
0.01002254330391387
0.0006311651318494059
0.004620131552018075
0.015611387587853914
0.00759037378701166
0.005905514381254463
0.010866633989540181
0.011639080764637995
0.011174038983147904
0.005833021459174086
0.012278910519938825
0.00697789730524454
0.009252874019317604
0.02007462887623033
0.020582835358252494
0.018594387623791696
0.02778253633761339
0.027948769487677966
0.03088914733426602
0.028691530306542156
0.026292160406328688
0.018049972956336723
0.01404746451489315
0.011119173864805727
0.017102210089606162
0.011883117899003696
0.01890156677604643
0.015139128839228543
0.019039355594882297
0.01851688203522245
0.013783239205963846
0.007247856985049804
-0.00816510984388234
-0.03388493438838256
-0.041218081698623
-0.0427758317676361
0.010462169693107854
-0.00444461264458879
-0.007296740440436381
-0.006263609338292392
-0.010970552077203157
0.00023568984321207815
0.009132507851974609
0.015292299903902035
0.011516858900180057
0.0097202084406623
0.01343037698755345
0.005347051039671636
0.012736860630673759
0.01455076053125056
0.005383647118396115
0.02988501834690147
0.0307515874889537
0.020431778622963723
0.021150867478876605
0.010020907989593634
0.007411204945475885
-9.771714111322775e-05
0.014753396680470545
0.008158101399324276
0.006726673472991834
-0.011966525068487785
