# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; FYFF
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=3, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.05430203045719781
-0.08602135223043643
0.021106256902046885
0.017590612126951937
-0.031202516179673748
-0.028425234309280893
0.0402710419873701
-0.03076898447864948
-0.06148080765355705
-0.08798190306204595
-0.019397136703835763
-0.009453443753331068
-0.020479123502237608
-0.054925991220993266
0.0009630704378263168
-0.042692287266749236
0.03461314534723597
-0.00243134444554796
0.02325527317837211
0.05151464575281193
-0.017516544530163956
0.050948432302292956
-0.009053603519804937
-0.0028542270005636854
-0.003548262180413677
0.003859413664580485
0.025733593435552284
-0.023133101499258523
-0.07791219005770778
-0.08400767806018439
-0.09553650652798255
-0.0008121555804974667
0.016651528303413897
-0.04237140299001256
-0.00572606068477087
-0.04436960308358931
-0.0538083087332618
-0.004420451194118012
-0.02875487065700972
-0.024383035841069114
0.01799200550231947
-0.010293108054309679
0.0408890419075477
0.03609804963626953
0.0006565279997421932
0.08305903602320179
0.01613788182742782
0.007457412631883136
0.01688867162124885
-0.018604396254973593
0.002918756818832066
0.025419216504542597
-0.016263487110063833
0.04422569107316439
-0.0007766452926994492
0.014335465776803946
0.026173765877927038
0.01744057765890961
0.00894687816857919
-0.019694743538193296
-0.05272994511205786
-0.013814278943110945
0.024741355419980057
-0.0035733604415409807
0.009842245853723274
0.008748135866191442
0.01601452097293628
0.010383324636510548
-0.015026761141976572
-0.026690433244920944
-0.04223761073117391
-0.05026641894256098
-0.06488051461952038
-0.10355964033290412
0.014012882955581354
-0.07005546392800208
0.03151399846565313
-0.0754211683344389
-0.007275944289978376
-0.048577900874710644
0.023409593484136383
0.034922453131267316
0.05202264498985703
0.028571895663404217
0.0019341570457365575
-0.021381715609272142
0.01779261430774786
-0.004858806940096643
0.03899064556357789
0.045507994613419825
0.04463533498766212
0.04197156778372802
-0.011042742313510611
0.00955601366693257
0.014415731694481607
0.007905914719112459
-0.02339634140341946
-0.019314425631394436
-0.053678585838944436
-0.01096542585394394
