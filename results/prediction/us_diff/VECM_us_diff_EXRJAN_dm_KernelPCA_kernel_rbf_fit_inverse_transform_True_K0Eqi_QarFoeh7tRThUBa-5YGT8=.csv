# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; EXRJAN
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=6, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.047778308416676005
-0.05768296433743444
0.010464913691512019
0.048032870160537144
0.011181623705485793
0.029457036285394242
0.026004419687489417
-0.002240973615123633
-0.025808333887000347
-0.10918925230876352
-0.06319968839784193
-0.013043171796862927
-0.05027859225122434
-0.00435939698090625
-0.04565746439987053
-0.04891288486087579
-0.010379262104478992
-0.005585702453122681
-0.010192354452908187
-0.0026135955369513356
0.008756861978313104
-0.0335787203364037
0.022230938843702558
0.02706842924354273
0.024150499811677877
0.0021381643505370036
-0.006865266710395468
0.032890549329150365
-0.047252787721299455
-0.04110644584209393
-0.001034723511192985
-0.01991386996379472
-0.03485278403990506
0.00730776519433126
0.02809075781015843
0.006533910107275267
-0.02146133371339415
0.0005092630752259256
-0.021175964304596305
-0.04595975723491055
-0.01627483762642748
-0.015665607962238162
0.013300346482730669
-0.012743603728892683
0.0009981595886227289
0.01011359157209276
0.004984647169268231
-0.024627646141012403
0.03337747485857903
-0.002867662305184076
0.010073641999931087
-0.01661920777708286
-0.014823233453601863
0.03771415949187445
0.019274037950702816
0.01573045250324314
0.009369954077317378
0.03303209613623949
0.016411086935462883
0.023356884612425327
-0.004720622672695237
-0.0480426665551184
0.0035461339559240976
-0.014011560169919671
-0.03915576519700216
-0.0004136816110144881
0.004447275536754875
-0.002714771281947491
0.006718280492374501
0.0039386023465063265
0.009671381971275463
-0.00455820439202767
-0.024158804170467035
0.0036149003950372207
0.012182950163398192
-0.0246208637589505
-0.01393522292462587
0.01974984702826782
-0.03755200652958719
-0.01700179179909287
-0.010914678822306418
-0.028927124595639536
0.029589419936056283
0.008492341226423701
-0.003911737245877884
0.0006069905897724479
-0.01257057827984906
-0.007627538820652295
-0.003903092805804368
0.010175740688635299
-0.002985571954779163
0.02078307230041735
-0.015141138736759223
0.021575604572070323
0.0015463592153389157
0.000604208755256228
0.010996706516130774
0.0060611003408613424
-0.037308567846167914
-0.017910833820510744
