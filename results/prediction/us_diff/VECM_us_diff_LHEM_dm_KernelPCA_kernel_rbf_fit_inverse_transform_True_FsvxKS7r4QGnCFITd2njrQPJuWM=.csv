# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; LHEM
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=2, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.012679382288840163
0.008881478616500361
0.012166317438114629
0.013456121976273525
0.006361088966837212
0.008178547330749682
0.007378431727667074
0.005474354094324884
0.00710678281734883
0.008090543892316275
0.007097243882485362
0.0068904199747473974
0.007799665554571526
0.006280041933855131
0.010711260515159223
0.010661160084935012
0.010470567249631236
0.008909910588256117
0.006407737923296953
0.007633717052526517
0.007405383722872377
0.00869324490693262
0.007490718332072453
0.004441656246916621
0.00451161644360895
0.00470657724576029
0.01006834337641353
0.005013683305480145
0.004921305030581378
-0.0019336725517003737
-0.007199741706670097
-0.0005980462125854579
0.0009117878595369428
-0.002023437472918544
-0.00019927197756767562
0.002186334542521145
0.002105801304275008
0.0030291150815344257
0.005424738844970329
0.003969694735659919
0.005966362136069558
0.008590275657555364
0.011204207345581592
0.009886183739374898
0.008437499367381753
0.011259987620397661
0.005440342542594821
0.0018660199345220793
0.004387532143058179
0.0016508939379661454
0.0030291190861407875
0.007956496438624313
0.008366760754502277
0.008360061334015328
0.009102614957378198
0.009850790187410348
0.009082000093285223
0.008517915382906187
0.005356969641890074
0.004856181733959609
0.0028482770264880507
0.005766970306144637
0.007666803737824543
0.007826544806690651
0.0077125639500075765
0.007752083164190985
0.013426642330330347
0.003841000826923501
0.00813413628957641
0.007761797482574806
0.001987253454231186
-0.0009080935635318296
0.0018082279121766785
-0.004800800620612784
0.0010987339930313507
0.00022303205494899996
-0.0012915659163291865
-0.0023866212000098292
0.0027475465619005122
0.0017530121594304473
0.006716705049907477
0.010612585354367696
0.0054520857412911575
0.005936983956189889
0.0030814744140254847
0.003706497482206339
0.005375621638218577
0.006556310178770461
0.007741432867794322
0.00977466515830658
0.01023279961044311
0.006390587725816372
0.0053426210184535205
0.0067420750282672385
0.0055204646481299855
0.007828780754620212
0.004033081726212548
0.0006975851507176225
-0.0019289642972896712
-0.001037996213677916
