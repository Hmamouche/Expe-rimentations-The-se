# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP274_2
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=8, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.003564790268164372
0.00531780960513001
-0.007213036651766079
0.0035365803694903395
-0.004103412963088312
-0.0077329018424777685
0.004561328720949664
0.004534620788215314
-0.02013099233849022
-0.011234598883851431
0.00018684226742991296
-0.009248506738630893
0.0031244529298753727
-0.0027864822980803823
0.004868274129072524
0.005497133625272663
-0.009479086428403106
-6.623270573082258e-05
0.0024507004363132556
0.0020512007725300633
-0.003118858703220673
-0.0005395843142722762
0.0013772658696076768
-0.008139204282752364
0.0005939139929456735
0.003804930395577101
-0.002920786801379655
-0.0055688639835402955
-0.003895227528879658
-0.005214633365580219
0.0003616936221081293
-0.012903857503622197
-0.0020263284081261713
-0.00853017425462334
-0.0033556986677512157
-0.004638110455008766
-0.01374592412728787
-0.005494264687142513
-0.012218901792112494
-0.007617249018084681
-0.006121822839566717
-0.009491098969097183
-0.003960705683548026
0.00453184427602538
0.0028279332473678436
-0.013410602449400337
-0.015793543053794688
-0.009915637024192953
-0.014755752754903532
-0.018897002785732538
-0.014985424447057404
-0.021708434365078768
-0.016442478017874903
-0.02093947003707412
-0.025588743768574642
-0.024588262705810427
-0.02274553327050793
-0.018994897671781787
-0.019986921821529554
-0.018557246072357897
-0.02431422128834692
-0.025712272519087587
-0.01980791894546687
-0.016566324700006498
-0.020962524018251685
-0.022216083377807058
-0.017315910985742512
-0.006449231122074347
-0.015025268484671471
-0.016719070081530826
-0.018124545441718376
-0.01998411569144419
-0.017082446219157575
-0.016547237544917687
-0.019906355511935002
-0.019415023588098955
-0.010215518074455041
-0.021497140376443846
-0.016948848587412767
-0.01496120356907358
-0.02346093158841761
-0.014771196465832699
-0.001548923494466744
-0.012043602118244855
-0.013828125393904612
-0.00866435119134678
-0.007867836655292166
-0.005373107006807434
-0.014116495252849009
-0.010113299426046036
-0.008044851300935935
-0.010001705332619194
-0.00916692948745612
-0.010466954953324606
-0.013646374868463033
-0.007166568416288369
-0.00732891922043603
-0.014387928209079151
-0.00859495700717448
-0.009954600981652795
