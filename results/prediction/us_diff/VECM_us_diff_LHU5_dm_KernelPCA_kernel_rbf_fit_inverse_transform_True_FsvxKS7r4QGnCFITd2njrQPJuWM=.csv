# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; LHU5
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=2, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.009649747871790779
-0.009715770217400683
0.010344714798414575
-0.003790834450757177
0.0221996225119483
-0.02584982866211613
0.02729232771868107
-0.02829200446980022
0.0021240517350661486
0.003877545174827695
-0.008413690778912825
-0.002926431785139956
-0.017887311079462547
0.010277675992595605
0.0014997808557272927
-0.04110327187401583
-0.025486237713105597
-0.0003709160736637511
-0.03205324236095313
0.01724872828354926
-0.009284613631649554
-0.02873554472902093
0.01746518184232486
0.0024530556353192868
0.005452130188121067
0.01252101838663176
-0.021696294033560652
-0.01502655845830366
0.00793353248432295
0.031197964672137632
0.03249486967008449
-0.007375524383160174
-0.007270273842891382
-0.009347728798414454
-0.010540117270247323
0.02869362794562475
-0.012823970035860492
-0.011770213990949137
0.0268755265758003
-0.023570529538707724
-0.007605846814404966
0.006816054025423915
-0.08473460018258834
-0.026088836242226
-0.05893933726935526
-0.04061690859866707
-0.000729528429015941
-0.01864786404249215
0.022241976533069228
-0.01792255336496433
-0.019313671683098783
-0.026623229077033718
-0.023972385897904167
-0.005726707912396856
0.0025639794045714385
0.010374797556219728
-0.01715999929346536
-0.0013161674310694076
0.007945645275091819
0.0003582980392325859
0.0261453146382223
-0.002448121113422781
-0.01977161030760841
0.0031716176303285912
-0.034065544587350616
0.02707943755544072
0.010897289384200568
0.006843239958323303
0.028440882225813716
-0.012594880943397758
0.012296823805780208
-0.03603818085167454
0.00697925316580808
0.026603120115018898
-0.00025213756338008514
0.04932837804255756
-0.008000836137639522
0.018901094437717494
0.019395332389860714
-0.01179371420680371
-0.046214594852787796
-0.018969974420621125
-0.04085248165354075
0.017538963806236697
0.00618450244898818
0.04122510499643781
-0.00698801660176957
0.015839231777941352
-0.028374448851161874
0.011896823704544115
-0.032423408376837035
0.021357262358432688
-0.002331298044050285
0.008099180134985808
-0.026348127517576425
-0.030990828607023378
-0.021078866988554372
-0.00990293346048015
0.031836425803346155
0.015509401761626603
