# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP255
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=14, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.0009237512229917392
0.0014498161745289144
0.000981906569151753
0.005401794455695441
-0.0002841639522541744
0.0043428594756198344
0.009928874023611658
0.009839248956681363
0.010697450952094732
0.008836824726228605
0.00928797595709824
0.007281335457241979
0.0045274972314409976
0.0012664937797972205
0.005625602617511461
0.006707325055100355
0.005113694409952877
0.006556852624941921
0.009419719021365042
0.008072443342147996
0.00889190010083485
0.009366909995217367
0.002537526800787191
0.005149151538616954
0.003582367845580013
0.006937280162266678
0.0022790881832557403
0.0072677266880394175
0.004729353014915692
0.0054591596800823775
0.004296067660214849
0.0035203914584036457
0.005588528765627273
0.0037346569404119053
0.007259768363142412
0.006703180868072146
0.008288490608863372
0.006996575926398384
0.0035737478084810577
0.0014850362691945617
0.0022712675946369018
0.005357476905874989
0.008190991172897859
0.00646358497818343
0.002207698254938252
0.004412942871213851
0.002232093664123265
0.005137697832195943
0.007985170444286954
0.009161161370424257
0.008108233126466595
0.00605480384954189
0.004790271616157881
0.0033149488655853368
0.0050534599350262775
0.009952548170896637
0.006971954648793618
0.00994346396666224
0.010503109177503977
0.010461791062201228
0.008950792706717206
0.00554271717851984
0.009982751115825611
0.0071543234385056925
0.01022374347723582
0.008745320739685666
0.01127559011239888
0.01004722679169092
0.010907191250495007
0.010728366666617438
0.009378310172122605
0.005660321411127628
0.0020765078255312115
0.00862913893246529
0.007246270027055726
0.004947036272363329
0.0020416673129107967
0.004525050511972916
0.000875651453444256
0.007644425765453888
0.0028312707375654582
0.007886997680876005
0.009416723044195845
0.007378026626941234
0.00720569825752064
0.008984785379508382
0.006039434573376497
0.007108129234197475
0.006393015289189407
0.006113005589891823
0.008199571268284217
0.006303583517672291
0.009133494694544227
0.011595038857724864
0.007707383098353284
0.00665356561614547
0.010866317213858544
0.006039618630437593
0.004253111483285149
0.005822838213219887
