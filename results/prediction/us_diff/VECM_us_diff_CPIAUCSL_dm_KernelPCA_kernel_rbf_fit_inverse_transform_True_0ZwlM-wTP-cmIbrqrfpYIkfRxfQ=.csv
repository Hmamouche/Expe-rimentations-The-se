# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CPIAUCSL
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=13, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.004223532710909788
0.00813405463235958
0.0075502407901144805
0.0074202124235831345
0.005109029370829056
0.0038151646769138048
0.0067776547588974025
0.0046451691931077834
0.004548400708794623
0.005652383125523688
0.002995209446924557
-0.004077295907620006
0.004057259171018446
0.0005036080759332083
0.008987316519728441
0.006578125845458561
0.009577338407437323
0.005115445959219667
0.0058866792798425065
0.007357926002441136
0.004415679101326514
0.008443634229399985
0.00805660145372957
0.007521844402560764
0.006341534862136112
0.010009912995783412
0.00801539946602771
0.00698288765170957
0.011884943254772417
0.009670945064674856
0.006004486513284202
0.007560900259997206
0.006786298866017726
0.007875938354547219
0.0037844145893803347
0.005256225509862293
0.004389301211759958
0.007783616517233773
0.006878044533196846
0.006118538730433605
0.003439718997024282
0.004121868817136858
0.004690427444546121
0.009248320838303363
0.005276201312655436
0.004106936231549524
0.007629242852634649
0.0017261114476272378
0.0051046227762824555
0.0038178455051213703
0.005829849220885304
0.008448312680117453
0.007129943508404633
0.007574243031849923
0.00458964023155369
0.004055396668362954
0.004612960124131482
0.002226988806411382
0.0030155353938367403
0.0029805799023638457
0.0030469595989790653
0.004340297537056615
0.00595961095416034
0.006186100134256869
0.0057470267217590385
0.008851153249129922
0.005419500695688112
0.005738850466498495
0.00821960828106671
0.007584240220846217
0.008682711315762495
0.006483386594595482
0.006407804946451045
0.0004371974657201036
0.003987371341249721
0.0021400360289813214
0.005460507465291914
0.004924172672875988
0.006324941372246467
0.003151461391447183
0.007632104062711127
0.0009473343797906506
0.009604738695008943
0.008209901220676136
0.0063812911061444
0.007505676388920214
0.007099967055868047
0.008902503558839044
0.008542870295187986
0.012219662042066044
0.012428821140715973
0.010183510051175872
0.007322013893647409
0.003555774354794139
0.00763486976594082
0.0019424090280245707
0.011898906673950223
0.011176163263535616
0.01082249997739066
0.012505513506392242
