# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP265
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=7, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.0026156508699629166
0.00862940748210018
-0.0008979823625151727
0.01242733979180441
0.00826184956966052
0.0061985762263312896
0.023011490269245524
0.0065631784702331625
0.024898809105552686
0.014391179575801568
0.011383048149763797
0.014437529231482012
0.022338665402994798
0.012881507837867526
0.008647284782314746
0.011953252277507948
0.0038515821368947383
0.0017004756339919782
0.012777494992473947
-0.0027665733197804916
0.006423151174316031
0.001912009988793057
0.005536139714093259
0.004311430980747213
0.012691314752546888
0.006942618220263078
0.008113968180562496
0.007154364777898018
0.008622826637935383
0.010779874044511764
0.004964335501318317
0.006716984977057943
0.010259403786005577
-0.00221529623760175
-0.0009667996110979491
-0.0010267988905804841
0.0012475754679779462
-0.0037275456770463652
0.012656658126543735
-0.001047841241792444
-0.001514164981325881
0.006160399930464776
-0.008794209085973479
0.001190300404343818
0.0036232876735790035
-0.010231270386986237
0.010834734005964658
0.002129103578008994
0.003807989317025177
0.0015563428838742382
-0.004281362180971204
0.006317488603461986
0.0037008024370839988
-0.0018016513736703011
0.010064372374725322
0.003453887494114223
0.003098194766682573
0.005353717324081729
0.0042701063236724205
0.0028165101074627127
0.006703137800884852
0.004442903416550097
0.013476376244723443
0.010861972179740696
0.011961514374019301
0.00890449123561614
0.006590730077456286
0.012013489771305366
0.012245200259957055
0.0015452773801501738
0.007263499018447181
0.004553036624679463
0.011636141863715203
0.013223339797266987
0.01497790241080596
0.010819760067645096
0.02044047021886038
0.011683966985672334
0.013545515754399051
0.0037710621614337496
0.008086730566889506
0.009446823462942441
0.0012539229016229445
0.010263519732727532
0.004615957637794574
-0.0008031987041416946
0.004641044680979712
0.002683291409127175
0.0009097127908381591
0.002216734156836319
0.004363479933332643
0.0057676695927863855
0.00612363455302051
-0.0019647225748469577
0.010297834735833813
0.004705165241692489
0.011656806088088143
0.0127149949299914
0.012324745700016017
0.009885057068779513
