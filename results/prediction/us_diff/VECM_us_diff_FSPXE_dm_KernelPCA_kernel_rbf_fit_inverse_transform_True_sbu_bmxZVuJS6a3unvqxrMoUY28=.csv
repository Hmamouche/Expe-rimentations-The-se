# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; FSPXE
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=1, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.003758737700191114
-0.042446569623170886
-0.027130647232107983
-0.03368115859997124
-0.009556799676895853
0.002693421014207556
0.011924762872253879
0.014867897235806352
0.012633699595826128
0.018240575433035224
0.024281186797106242
0.021273300477715716
-0.003415687135502804
0.004131087027980238
0.0493084721057613
-0.007860161785675656
0.01819855077390965
-0.036088581247996854
-0.03524671521795881
0.03922462572865696
-0.06533031774171341
-0.022404601811925363
-0.0008552671614429118
0.000518678004361678
0.008454117041098635
0.024344733224183027
0.011280157436285515
0.02900878533180659
0.011346613374833739
-0.007747982186469149
0.04228313704787275
0.029332327027886625
0.008556982976037743
0.032554006882894955
0.04013602510190579
0.009415549994002535
0.006987004320758782
0.018487142145543006
-0.012314892854576378
-0.013763025364107201
-0.000548149043318001
-0.008708724909325687
-0.024533358967064402
-0.03601520184559764
-0.024992249911964706
-0.04577663275253502
-0.03188513077958851
0.0012564425166670242
-0.0013986810690373662
0.014794565542558648
0.03195822283745896
0.016105454108803742
-0.004961260775893093
0.016852562035710766
0.00036245012058910516
-0.015213627849742901
0.02506973686951944
0.003172128332509595
0.016731018152663767
0.05339863597950057
0.014852223928067362
0.04006774205221634
0.07402835402623666
0.03653486204786152
0.0009066053138443698
0.004368544098670528
-0.013256835626088296
-0.03924300085485837
-0.01811364119285791
-0.03464943548056149
-0.006504382791948367
0.018984310081202844
0.020624891439347745
0.08758019587479565
-0.012051891164405597
-0.028069350628328434
0.3311558090604607
0.12784525347629822
0.03122081893438938
-0.07275948141431433
-0.02350785984961156
-0.044537677307218956
-0.02843420242627861
-0.03663485049985255
-0.09208547020205374
-0.0623863130000042
-0.04542948294479246
-0.033123445580081214
0.002679572766014689
-0.0058745963697338505
-0.017785395940154533
-0.012146486680418284
-0.011268902678393429
0.002259367865090965
0.01775275081036296
0.009609067643009261
0.0073656748010515645
0.014588365166689378
0.022283402267213086
0.019282042098662047
