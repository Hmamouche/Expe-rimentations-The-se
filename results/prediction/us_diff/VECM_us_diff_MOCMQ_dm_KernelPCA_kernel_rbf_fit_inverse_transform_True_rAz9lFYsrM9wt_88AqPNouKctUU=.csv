# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; MOCMQ
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=5, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.02169237802794182
-0.016707498368883945
0.03048931114463159
0.0039548358813316035
-0.006891259734068414
0.011667593722472667
0.02620855923277915
0.005307987042584389
-0.0010797229543815573
0.006126629418722057
0.029219684853389286
0.016884820702664324
-0.017179839274273617
-0.023201023718232898
0.013948891220568136
0.0031587223563579125
0.016604462181030986
0.006187428439565874
0.014648504189702885
0.0063389383380606686
0.009396945196703754
0.02404981578310875
-0.0032426116066917457
0.001619912770877403
-0.005482604392208117
0.009081483292248674
-0.001892171761762488
-0.006176680635269698
-0.02560343746691871
-0.01670387879186709
0.005179395115067994
0.017732686870039042
0.023127511111268748
0.0004662724341683005
0.014411658171341019
0.010294026180092368
-0.004309280157967143
0.019913752838564926
0.008140485810278882
0.005998578936220911
0.007917253029575683
0.030304484180103532
0.022068534817689844
-0.002386787901898617
0.018516344552523385
0.02287186783612156
0.0007314052553597759
0.00976874180384071
0.014055357091952169
0.004359403478145738
0.008054573387554744
0.005271727722032223
0.003995758726021325
0.032094829769003304
0.009063867471569776
0.024233034198706916
0.03164426565292372
0.01125847638935469
0.02299923917263575
0.0011347451901177518
-0.0010576998494046556
-0.004716023413504687
0.015572480240512035
0.01068080525020939
0.021780736024154763
0.02356598445308919
0.005102074263876198
-0.010950881433680653
-0.0094378425226789
-0.009556953063931187
-0.015585251163544622
0.0008868442289479736
-0.013555374196704547
-0.027544388879098963
-0.0025549773775962866
-0.00012592148494539393
-0.014841765060837746
-0.006936698738035704
-0.018387513969906677
0.015971272246656773
0.024895126066448774
0.02278655207123032
0.01621771592054578
-0.012581908420603145
-0.021576119688593673
-0.010443479086789859
-0.014063477610891086
0.00039962588718559
0.01681056225199422
0.01410132342484828
0.030252808029781215
-0.010944659141378993
-0.009625025854498353
8.315378118041797e-05
-0.013466844723454578
-0.00048822218549868387
-0.007624914035080017
-0.02897845375250089
-0.015602841760392411
-0.009172559257217135
