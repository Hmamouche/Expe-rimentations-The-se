# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; IPS32
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=15, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.003483437580190595
0.024615288437781026
0.028477527455459672
-0.023864047764161636
-0.009127007783604365
0.008028665070880802
0.019969141061000995
0.004740904018126666
0.011000088705214607
-0.00010013529342647702
0.00998221293327814
-0.010367242118418963
-0.016117969899743474
-0.015719594285654313
0.01228454165379864
0.019463432654055087
0.021711521371075147
5.004658282064395e-05
0.0026234000732620077
0.008414109158862426
-0.0069957011188627165
0.02143197416193338
0.0018791371465272785
-0.0034180029911883413
-0.0009166943756105982
-0.002451853982170578
0.005264675455253159
0.00646189516248702
-0.00345891748679182
-0.0075894918432278064
0.005422271711729541
0.009170143663005267
0.006926989392812449
-0.004978699995952546
0.00039126284546780153
0.01329557328998358
-0.008452563168674675
0.018824691487228
0.00694459077682345
-0.006724996388565759
0.015462524427547905
0.01111314590918996
0.019111962302791493
0.006596178135707686
0.010086367167538458
0.009376171806125983
0.015445996370023637
0.007681017254984738
0.003996032900088729
0.007512943499066855
0.0022213992575472376
0.030939930644097505
0.01741178283613658
0.01581699973791062
0.01977165098034506
0.011238049929203029
0.018247986302575785
0.02072536433575943
0.01965708962397827
0.015027814996321014
0.002865736244186297
0.0022267290740219233
0.02795091688867616
0.012811562003945698
0.028355418292494772
0.02060188180311414
0.003570342306880827
0.015234127952184469
0.004872485825867716
0.0014506939076817187
-0.011982737534063502
0.0014734411205166208
-0.014771095171265477
-0.02653562245320828
0.00926647103900687
0.02107904553428346
-0.0015528119968432914
-0.006427420801920855
-0.006317102319079093
0.013108792909996381
0.016688406687056144
0.021221884047332447
0.009193597659931274
-0.0007590202835197893
-0.004396590329833629
0.006137839279706513
0.008504552490045114
0.006932950586864339
0.0006182854141134715
0.003393388001330336
0.021644857938523665
0.0004555998724682167
0.005296191251023588
0.007710611073711379
0.012199332997578093
9.6579382353793e-06
0.014373941675198832
-0.002726326813365627
-0.006044026544165342
0.002668125292748566
