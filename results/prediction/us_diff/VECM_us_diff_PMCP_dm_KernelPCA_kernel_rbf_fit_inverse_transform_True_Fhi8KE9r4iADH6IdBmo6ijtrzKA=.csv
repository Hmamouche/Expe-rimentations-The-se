# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; PMCP
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=12, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.018202873264369396
0.24103643468411554
0.21159541654061673
-0.24058947802614775
-0.04411409797620516
-0.025325047096202466
-0.03187338057471435
-0.01848939314977746
0.05489622456165003
0.044590125126724015
0.06272467294592249
-0.1489580568639456
0.07389216569278792
0.09811516296422354
-0.03776343723708597
0.07457089286855334
0.14354643480948132
-0.03289514384566905
-0.038947704823381085
0.11903398555945785
0.03123812797927332
0.051398342353798185
-0.08419680794446288
-0.18568959888879236
-0.055638488455210175
-0.12250152987562976
0.06585377446343607
-0.10964010632485713
0.046686483168572546
0.16893014405048068
-0.1624843716538389
0.11639401123330013
0.086250626391399
0.0435343460898594
-0.10751993176337749
0.10351899842095492
-0.10870331302206604
-0.029484794911352884
0.0013011847644069097
-0.010500013712502095
-0.007784875203985275
0.046513910539178235
0.10292265451372234
0.12534628352458618
0.08727495058519243
-0.02643297486820451
0.03951754676041579
0.014891727820073652
-0.087271591184911
-0.16787793565052928
-0.1605991605711454
0.18683874916257617
-0.10337194378778958
0.0193531333676656
0.09567359218336866
-0.03877346044438435
0.030924034461772734
-0.023164530828613687
-0.11400846418531542
-0.03296386227790323
-0.11445440738104641
-0.10180056113557676
0.09619782327209585
0.05485621652656625
0.1855667174919356
0.13084112823874255
0.025145925614563802
-0.12751906073650204
-0.021969024431588824
-0.10406725080953641
-0.05024584577042679
0.04391600682871338
-0.05693901402830323
-0.03406637351316373
0.21877737567319794
0.12124080709042831
-0.1730066623623379
0.00840218108539903
0.021817849852457456
0.16334926848249048
-0.013682156959780638
0.19828377960522928
0.06941137076432528
-0.047307826066122396
-0.05029022328278307
-0.05076175332351209
-0.10467024460666152
-0.04522136524050982
-0.007872214437711633
0.051534452170817105
-0.024174989481809288
0.016154097597242806
-0.026254230332351802
-0.04686995803606611
0.04998474301258754
-0.011371880928207737
0.05808317806865808
-0.04491286186639022
0.004184724299592234
0.07216251925791047
