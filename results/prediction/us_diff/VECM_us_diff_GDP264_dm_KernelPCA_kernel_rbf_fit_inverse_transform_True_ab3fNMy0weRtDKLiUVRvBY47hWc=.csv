# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP264
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=9, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.002440983843033994
0.010356495714685388
0.013002243694168194
0.005374981111420568
0.003219660259297239
0.005637579536568257
0.00814260167447811
0.0027690422746857023
0.008965451301706428
0.0031649178714940177
0.00598605989071393
0.002215595895445395
0.001612535658750753
0.0041318011194321795
0.007141221483755492
0.014530127551952217
0.007199178689495349
0.0035451742799176796
0.00258392064810667
0.006503918670199166
0.005935506921185687
0.007238360562101403
-0.0008526621691454786
-0.006952950206578826
0.001451785131509624
0.0034379548270356552
-0.0006042579005458106
0.0023034517370476354
0.003245007347985597
-0.0020821517367564865
0.004183742643477836
0.0071021825903562
0.005924177928972428
-0.010525681305298264
0.002299226319313598
0.008276741770251993
0.005442716871297829
0.006975994090688277
0.011007247056756701
0.00254762057388747
0.008826588781632902
0.012278570829302837
0.008987107187784683
0.013643131893495801
0.0034255127310425975
0.012629397618575594
0.013070564445437367
0.007894846929204788
0.012691932425007324
0.007034634339776276
0.0008689478013295133
0.010713419144065183
0.011854228417303122
0.009440139987918187
0.017688462394383993
0.012768583287959179
0.016645251888044454
0.018537448361321807
0.01952111206219851
0.016656841476336393
0.014643704680717306
0.010379109098117673
0.017757208690661684
0.01432022721672796
0.017553254980589083
0.022602476402599464
0.019876170116138896
0.020343187162064593
0.016089774420701662
0.021556064803741497
0.017965639774333984
0.0002161706587990326
-0.01135508080813034
-0.01829961110740528
0.015903010126365944
0.01366843322006558
-0.0032473012089196105
0.009047255290009704
0.0016591643800298549
0.011807592335991272
0.016606989794847052
0.017997807091971015
0.01867545236735588
0.023477886023145163
0.017034768634227086
0.019733868181787996
0.02542938169134475
0.0037796085680950556
0.00445645881250018
0.021949778600051817
0.03026358705988562
0.0037757842497694637
0.009993799157519228
0.0192396800918235
0.016728376459160296
0.000872876776670864
0.0007058612544775526
0.0019097411934328643
-0.008167558799398103
-0.005720917806690415
