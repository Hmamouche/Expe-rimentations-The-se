# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; EXRUK
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=5, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.04289523781344175
0.04062020849640668
0.05449384900655406
-0.05372349011008526
-0.03557627335667213
-0.02420078392288392
-0.034972095560549005
-0.012692521506684951
-0.006024405527717514
0.028349114705491476
0.03535623964204773
0.03962783223134776
-0.0026755480241679903
0.002673847163765104
0.06081401754039609
0.0321704530496833
-0.013067337553832986
0.08023105441585372
0.04232194082516191
0.028620995087060015
-0.01943424955272851
0.017118050743732578
-0.015112244146441717
-0.05076818897294889
-0.007340765229572794
-0.014036027583990678
0.0011367389879406529
-0.024268738903497154
0.09392331433278328
0.06676239131473365
0.05340104203786041
-0.03969469387373192
0.008852091018536694
-0.011700127144515345
-0.062043369515160846
0.0009613456399411311
0.0588695600046943
-0.08060463105490225
-0.028398648807875057
-0.03896214417317999
-0.052500260896693476
-0.01708608716962484
-0.02940808355559462
0.01891959723621911
0.016262047658628827
0.011925145291624265
0.0024019052545359645
0.001093248750805154
-0.008660081374315905
-0.00031209386906677454
-0.03170350230153386
0.006373126766027616
0.03791000014136932
0.010352056055683387
0.011430518073952359
0.007170879550898278
-0.0024536339319697086
0.008643571731929638
-0.012521527203900424
-0.008416858142066955
0.0005905743726020984
0.005530288310730132
-0.008289977343809873
-0.00309514546894293
0.01987002340156873
0.015371921388887851
-0.008932893307010735
-0.04087656223165911
-0.026381313896576414
-0.024847531612484326
-0.017992993723411423
-0.02559806825951686
0.007683864964374625
0.011436522125097633
0.004439611328011007
0.017859580050890285
0.013105898984238707
0.008321045919257121
0.018882259674497182
0.02522067850252583
0.009342891142051852
0.03694527140155006
0.010298651997003718
0.010626073772305112
0.0371121778115414
0.019702759264084994
0.006097134648336335
-0.0026803653820572006
-0.012743375598679028
-0.011790819049513318
0.009764763474080295
-0.011799355265948858
0.024956014646026266
0.019506929186874435
0.043562004553530834
0.003902238632962036
0.015197329415062646
0.012225827949633524
-0.008183012384129853
0.013885713233458996
