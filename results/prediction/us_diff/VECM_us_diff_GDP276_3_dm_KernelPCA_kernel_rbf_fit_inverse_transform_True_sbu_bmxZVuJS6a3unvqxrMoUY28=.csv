# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP276_3
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=1, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0029428104563906316
0.00802832186477683
0.00566826982733327
0.0055755869924154254
0.00885941836721301
0.008106806981318266
0.006271343710280373
0.003568144112343202
-0.0007143368354025396
-0.0002959503500002278
-0.00016688806147169716
-0.00019496558387931844
0.0004965468337170775
-0.006124893906553837
-0.00518302925605375
-0.005223517617411914
0.0013651096776901297
-0.0006240057340727035
-3.7948556549744275e-05
-0.0003338736553611855
0.001950939273493504
0.003897638978989225
0.0030135088143555845
0.004331905406161031
0.004747996821324358
0.0037918350352955685
0.0031224341263347125
0.00250290499198204
0.0013822096949749456
0.002494649099464218
0.006918641467056975
0.002470054223835855
0.0021523716405638786
0.005374180891473407
0.0028585343836293377
0.002282538736275589
0.0038517705867338295
0.00423648663921446
0.003201751692703372
0.005744130080044622
0.005475299759981905
0.00462843592343922
0.003508925434816529
0.0013673709527092892
0.00024693056884457845
-0.0009018854506685145
0.0007950925881839786
0.0009587467493942445
-2.5376198159549102e-05
0.0012178612006201052
0.0018119394840544656
0.0015657306296178724
0.004646163432815101
0.004471939066816978
0.006670818199579275
0.005679431216158357
0.0020554257372229576
0.0014067326131241944
-0.0007098010634187172
-0.0047128880372584985
-0.007838146611023321
-0.003953487283268349
-0.006604757327916839
-0.0020437288052399484
0.00038857481606667315
0.0018028121398121861
0.004640323728562218
0.006784692529630409
0.01267063382765233
0.020769870979455173
0.04673237821386483
0.043934993796743
0.017298602202147323
-0.01482059606088397
0.013252473875042301
0.0009044877656124888
-0.0025422656025826237
-0.007461651876879806
0.01875307976016584
0.025087261364899232
0.0031357420577510188
-0.0032127297348057207
0.01613644427614229
0.013165778131423198
0.009148579568802799
0.00905326599408972
0.01144694685446308
0.01882815869465447
0.027352785081526925
0.06441279749604326
0.03144902258840122
-0.007862550913959465
0.022671382457330892
0.01992048357003147
0.01781365903536667
0.0015341468376919194
-0.0008436843940186614
0.004948130967149961
0.01431122608733445
0.047549988557458914
