# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; FM2
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=11, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.01300402897605647
0.0072894471992930535
0.00487929710689845
0.0035050429997800303
0.006475181898569452
0.005461603743953799
0.005392939678755788
0.008265219973304972
0.005702976389457239
0.007879734938582161
0.006523505821131991
0.007327044128586384
0.006270808826267044
0.005461683918806004
0.004349119185171978
0.005602837857563898
0.00691696574689278
0.003729517854622613
0.005624958104093345
0.004377429715130271
0.0030724979635744546
0.005960319221770217
0.003635903266058969
0.00567098902881197
0.0065916155449766605
0.005177111854985068
0.0036593552017504024
0.003961506160777859
0.00596071368039252
0.003480499981461679
0.007279760627406892
0.00411131069861455
0.004751266093546786
0.003933859555042243
0.0036775874026872962
0.0017089629899050853
0.0019508107233205331
0.002099721884182388
0.0004164787910396809
0.0007975833369163367
0.0002556511860488784
0.002723713761943431
0.0003089129198732824
0.0013057134533695012
0.001916806906831044
-0.0007214486790293628
0.0022976674510092835
0.004118973134021079
0.0047152823270600755
0.0034777122289340115
0.0048595305633908435
0.002925530978153842
0.006156542231984119
0.006420504780781265
0.004575571971108534
0.00620157079944007
0.0077276822747642925
0.006648979324217572
0.009924441263547001
0.00844999550121494
0.009416408151843116
0.012529449637988438
0.009564689205455808
0.009239514019591152
0.007931611134133227
0.009098339099415851
0.008220660079425034
0.010990074396611926
0.008496642999583618
0.008483628571827257
0.015295930098213945
0.012664790159809506
0.013623479710789331
0.013359823741310069
0.01223881815379289
0.009039337411625182
0.015460517021478827
0.014573966076564585
0.012420868606660824
0.012175101537465233
0.011967084174855896
0.006903638434823053
0.014694142590356344
0.008857337797111418
0.00815792683226922
0.012356489437674973
0.002600769241499388
0.012750631992285443
0.00868183761332321
0.010454164507033702
0.011355292360133032
0.00602873844972474
0.010478854876776054
0.011996031180557223
0.011082640346334948
0.013959898325386735
0.013050866379355685
0.014805523525382842
0.019523474268304183
0.011561413035980765
