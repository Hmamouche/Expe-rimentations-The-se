# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; IPS306
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=9, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0025569770765402275
0.019668695054650548
0.013712535596514858
0.003526643277970698
-0.007666235848138767
-0.031499900244015354
0.049906240925498585
-0.043195600250937376
0.02457058734808726
-0.032902782541682996
0.010871922850871574
-0.04963087127697846
0.013961339084822541
0.008651961250369593
-0.0048165181416867505
0.015458189887333953
0.014722842375099575
0.03433372545415852
0.03908897948508306
0.01902545013198797
-0.015078484388701673
-0.009472406479724627
-0.018274067210458766
-0.01468424191189564
-0.002678449380918135
-0.0010284734927504986
-0.00015550023953531415
-0.0136352290076084
0.008261896975264386
-0.018922556960179852
0.041231826199351264
-0.01353285029685557
-0.0006599899533583382
-0.02176590321366393
0.015827107326393048
0.016301697615752692
-0.018664529569790346
0.020181420498643576
0.006392817646618693
-0.035675224770001866
-0.004481575558235622
0.01770923772677367
0.009935641782536555
0.014777780871775276
0.02180480812547073
0.020747482082320034
0.03534294500486383
-0.0036282334501593324
0.005528313276583161
-0.02054331190141269
-0.041580080472911146
0.022892958870947833
0.02536173301243253
-0.010517684472705827
0.03504810987813491
0.011973828452274318
0.008506650142896038
0.006101207535964993
-0.007274507315717091
-0.026100742160337465
-0.031888297087657516
-0.0022113167753021563
0.0024947129967985322
0.02402264017248146
0.027388092582123845
0.03904767406367746
0.01144489645343749
-0.0018727083705323963
-0.009536897871154587
0.008186504282246302
-0.013442141260149
0.0065304824263877435
0.01140319437382889
-0.03430839457836949
0.028153766842793557
0.020408932370763244
0.017750890292401247
-0.00016104956984934818
-0.01187594809879779
-0.011967216297831056
0.0013877534952807563
0.011889456413191092
0.03627656258300126
0.0391537568501259
0.032414673082311815
0.004117717872578364
0.036164665830630424
0.022455469008798683
-0.00969704903855761
-0.010943570664183777
0.0285295411226264
-0.009744799837412036
0.003725134576652861
0.03397623376149154
-0.033347313312511846
0.0005370730743829589
0.03099750223724596
-0.028481009506800718
0.012906457325112388
0.027244047378522745
