# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CES048
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=8, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.005441833427644987
0.01772062052682537
0.017425603231880644
0.010794659338341266
0.010085736197181325
0.008629148969307238
0.014681087510650353
0.010952049029239751
0.01121369930034731
0.0060377565825759025
0.008825236797398427
0.004459268952755511
0.004212556274470165
0.0028352677275239593
0.009420816683874303
0.014617141696184426
0.008609125068582468
0.009509862154123614
0.012048508916528314
0.011611867054738009
0.014635007841693835
0.012512110630775841
0.006363144146887692
0.007558407719159636
0.0032483367394848315
0.004158398475286304
0.006327086293205334
-0.00032856795531711533
-0.0034570011931640584
-0.008412285002397147
-0.0070185942095487355
-0.004471586916895304
0.006609477333994595
-0.00543730902115153
-0.006750336114690785
-0.0014516826407548525
-0.006089650175122606
0.003038781094556223
0.007193023242689463
0.0002775466392403764
0.010557779948760775
0.0077280792320117125
0.010736879237057004
0.013674806465243858
0.014003530459534534
0.017232087135434837
0.01238468230825535
0.008738290469079568
0.005117822928124848
0.0026293641505154685
0.0027857761743586285
0.010520268887005621
0.010222780053574963
0.01285596176207793
0.009337552889598049
0.004575815882635828
0.00684009332280094
0.008307285242938056
0.006183348490615868
0.007610186507454554
0.004121951121936337
0.006712959551460602
0.01184171885847327
0.009656066265102167
0.012195139129471205
0.013322837924468364
0.0069209755281808725
0.0018704960054267174
0.002353218231178568
0.0004582755261953701
-0.005373012640327329
-0.008266782487708256
-0.009834720486481707
-0.01333445824756563
-0.0011818663759400362
-0.004888156928800795
-0.0038593504198878442
-0.003775254927752017
-0.00672763620767745
-0.005910570884332869
0.0021275257980462644
0.0042340056717617095
0.0034588908912768757
0.0037171277919577257
0.003703138178954237
0.005339824035933147
0.0039295559317165775
0.0054636630016990494
0.010957802201143682
0.004789465006788647
0.006624298686090715
-3.119263487300658e-05
-0.001001504390628971
0.0065486036231675055
0.011906925736849521
0.005970151183934936
0.0012043274923517386
-0.001242264153007887
-0.005748251318786306
-0.0071669686690723974
