# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP280A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=4, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.0008938383475026047
0.0021964591673687382
0.0014659109791890594
0.0040140461686005244
0.0022701714447354734
0.002155376268486995
0.003145964644100053
0.0006269701399916297
0.0008837298938242308
0.0016613315122576365
0.001997245366634483
0.0021618652370171353
0.002521935587412984
0.0023726154979231916
0.00028179787845851055
0.0009423081732587136
0.002589964106311087
0.005396363403633282
0.0063949425961935666
0.0061876463839132985
0.004289364345012957
0.004847575060135063
0.004502553258505518
0.004702648399608501
0.0037565586702481787
0.0035011878642870705
0.003802416965075926
0.0030476382599970426
0.0033423978623087617
0.002146749946633952
0.0026116204251366024
0.0018393797615836832
0.001306528694904253
-0.004381102321905396
-0.0017778632772611422
0.002409799634702543
0.002766957725400131
0.0036124538914810945
0.003877309520743263
0.0044540022781346745
0.003522933861016751
0.004294335273370907
0.004626227587601155
0.004941761112776387
0.006657015059974432
0.007827326093014463
0.006914290073687101
0.0034619920758910535
0.005399146330397479
0.004812063491315992
0.0005710509342269384
0.0018421773712463815
0.0064037309883200975
0.005121462352556914
0.006897304792273766
0.005742732987005692
0.006687952275734883
0.007341164500426461
0.008279501077549408
0.007042471988514963
0.005025047930268197
0.00481260500993377
0.0034435589645166785
0.00432788505288817
0.004930929583454579
0.006191743829635794
0.007078784948031132
0.005857668348447577
0.0068392966941483125
0.00778735457001783
0.008186826953171161
0.009436331365602312
0.010345638411457877
0.005159815662280828
0.0066054588504020776
0.00869855185304278
0.007808436230582765
0.009752560676712409
0.008112800190817039
0.0008852726183175481
0.004133991637901153
0.006927468829416987
0.013257927065022814
0.014827986679378633
0.018396008010478467
0.022058616137251824
0.02340202989959955
0.02089947297219905
0.029038236333570725
0.03549331647363501
0.03341365138408297
0.031007668251831336
0.011597877118824304
0.017189554065617167
0.010930407014747973
0.0029955624191337882
-0.000322057593906029
0.010041000999697739
0.00723884304602908
0.006903992037118732
