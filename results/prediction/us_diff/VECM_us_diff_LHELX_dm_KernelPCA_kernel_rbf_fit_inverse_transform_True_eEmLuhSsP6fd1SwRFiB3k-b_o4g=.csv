# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; LHELX
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=4, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.07409517403130292
0.0074328433959351195
0.025606608278364876
0.004334758600341977
-0.006987467037066968
0.03731556153137982
0.0435666697300776
0.012973441970265315
0.0013092673603116237
-0.002186440227793099
0.013144818902925244
0.006114098787347708
-0.004340654132465328
-0.01841536589073547
0.0026785484383561172
0.023087431110996294
0.04575895791506702
0.023571801193733186
0.014826591745038933
0.009608908786876223
0.0018248280596962485
0.021279561913491632
-0.0027523318921779637
-0.01868588331742275
-0.015062668947372841
-0.008080454760377975
-0.012142184514895444
-0.03418968586116851
-0.05962463892988732
-0.09642775155716116
-0.0519543501644587
0.005296514634067948
0.022071084016987222
0.0034059230011756238
-0.0019855409557013614
-0.024065243969526376
-0.015283179656560555
0.010326385318667908
-0.0024750966217372983
-0.009453082277213462
0.017926489123761997
0.03502543470212638
0.034690037088745275
0.017032255422430177
0.01052032075257658
0.032203824440634486
1.4221595717421598e-05
-0.009856705295241264
0.0153132220840357
0.00779558376826566
0.0025054346614030495
0.00047708883852718396
0.005382280472620635
0.008731028622486078
0.02023920706993527
0.006281061556580737
0.03091185358424519
0.02811459034886758
0.022655174296336945
0.010781063646913848
-0.024264559388713244
0.005620940430146205
0.02468295500526326
-0.015148092888790921
-0.003418712074850887
0.0036948870501649534
0.009194295342826599
-0.010059009399400343
-0.03465527531945557
-0.012595446477359152
-0.05751032871257735
-0.05428559153953772
-0.05156935412785591
-0.07347496214429966
-0.008792818868098736
-0.01704426970594694
-0.018599616979866552
-0.02327455432881763
-0.03323769852425753
-0.020563114270194423
0.0315416505527433
0.014229459693868237
0.007707283253473527
-0.018551331205335246
-0.012771729553159472
-0.013920903681359833
0.012815496423966505
-0.0022861338321873027
0.0029951013483151137
-0.005400414202068065
0.017793497198928494
-0.030896519393855876
-0.027536957971372407
0.014184163005493612
0.006104566955710084
0.007667910613143508
-0.01140362570246578
-0.034849978203291894
-0.008128208026339036
-0.020970930242214112
