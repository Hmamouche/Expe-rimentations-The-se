# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; FSPIN
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=9, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.001902024838728933
-0.006326771928822217
-0.0009662381680053084
-0.007381380581329384
0.003957496469719636
0.0036683817348458184
0.007684071705214051
0.006223368981329086
0.005187611263562562
0.006049992220180547
0.010294648455055712
0.012265489993665148
0.0019246091750364743
0.004389411829912371
0.0153234856291698
-0.0025067151769218613
0.00532857137835452
0.007063561297525991
0.007572861064902327
0.04744321465901556
0.005431457795070739
-0.03397590843678537
-0.0018170882121660917
0.005175078567159661
0.010652217615444267
0.011818254487827856
0.005988575560048558
0.008810034255680946
0.0037928337346391566
0.004789813826524655
0.014274883507491558
-0.008676964741912874
0.00502322832362678
0.003878625077432
0.01649028786716107
0.0011595053453373172
0.001853255700075007
0.013425781613404263
0.005996488698307941
0.012232933492232222
0.007981188993232226
0.002515490143883263
-0.006517971749306106
-0.00899839595363644
0.01304324469218224
0.0024557567778569606
-0.0032598654743655506
0.013737047315239143
0.029067738382492467
0.021463701400989035
0.02383402811833351
0.014444878147123896
0.011521328932911393
0.020133931816237852
0.01990933558537368
0.02925843538521675
0.03912752350931006
0.04035698264992744
0.05070791471351346
0.0298404021733535
0.056200330800101145
0.036154867132598696
0.01287971767754185
0.03583193959931854
0.04808268669743184
0.05123660229314084
0.05335135033122062
0.034778498570690895
0.038935392760322055
-0.04442753527717797
-0.0404045607852606
-0.05989134196287886
-0.06229301634567856
-0.030180765949231712
-0.03126403724555847
-0.026087539714847046
-0.07598114283915171
-0.017323081219285434
-0.05901022571039322
0.009524081104408687
0.0023143552800416814
0.039628609162706774
0.0358564563409962
0.01610857273946765
0.007914261633579115
0.028157458100282577
0.03017358555741793
0.0240544301566334
0.004144036855519182
0.004700580361766115
0.031439079058249664
-0.010471259342635191
0.00993350420982058
0.04247820938726377
0.010672495276797313
0.06433771319871204
0.031231156584079357
0.05015978117138989
-0.05445010434718099
0.0006401828996667521
