# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CES140
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=1, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.00245414253028673
-0.00035173174724076545
0.0029589572605757918
0.0030517252931038736
0.006909540945618967
0.00629207518605499
0.004948739639048208
0.005126402387957782
0.007784262231691562
0.005863962419648954
0.006459818979939387
0.0026376773473916967
0.0045511230874607424
0.006948574542775896
0.005446737897314728
0.006789954594234907
0.002701778467423539
0.007834594936948807
0.00668478833641026
0.008214244779428089
0.0050463107000176975
0.008365917447201379
0.006583306818220077
0.007654220817640777
0.005839468068636909
0.0057560715429634535
0.007402411476902829
0.012681624907215376
0.007006099188228564
0.006664244236665758
0.001754100816748705
0.004668200477907966
0.00127733793983219
0.0007274201208213639
0.004204918381488065
0.00452318274852356
0.0061402776670180315
0.0025360662160365615
0.004815270799302206
0.002726241098637644
0.005175896708516528
0.0033470932286539692
0.005623410006883884
0.004966400666158546
0.005659835980627591
0.005502299632528164
0.004117682722499974
0.003211885781287411
0.002104656474777655
0.0017574963037749352
0.0007080842318472982
0.0015696360234652633
0.0009914285431754583
0.0017468792013037374
0.002031741380417215
0.0028155985244606076
0.002528336507202301
0.004171813765778862
0.0029468860959790968
0.004629395080593518
0.004887430069950551
0.005782192149452565
0.00577433360844473
0.0063512894082536
0.007620612021008343
0.008322483845416704
0.009220562171261345
0.014597643639038793
0.00560333867340193
0.005433550603493124
0.0017636017156517111
0.006294205461137559
0.004980879566239894
0.00535305811300295
0.008424235957584566
0.007831646132513978
0.0054164668143446846
0.003683795005361394
0.005237381512471509
0.001525812200078771
0.0004360493741629448
-0.0006655970710158106
-0.00020908452276576542
0.0006664306630398381
0.0009857836774789146
0.0034125930998805095
0.003447838028996217
0.002708902970565444
0.004041641357599102
0.00190229615160301
0.0028565331479153497
0.0017250833896125793
0.004261054538706278
0.0033853147572551795
0.004032282465874824
0.004580423632258554
0.0019425107951229902
0.005092445079608224
0.004335775134988251
0.005824389762940311
