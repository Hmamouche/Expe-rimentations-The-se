# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP287A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=4, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0079200182511257
0.002890638529521143
0.006556153513730876
0.009166438321960565
0.004625951720442905
0.016282414583889387
0.007511179627423857
0.001921721610302611
0.003620095964033365
0.005267236789886161
-0.0006858937688379153
-0.00028427440352531803
0.0031976468510643897
0.0006256749014498999
0.002566428017590822
0.002849828548215874
0.002323712701214164
0.005294042859144267
0.0010865923744029326
0.0004181821980516298
0.0017004563158453578
0.003119883788957643
0.0037801710300650803
0.001647736669213339
0.003974082470984437
0.0074335371484637305
0.002125305949800824
0.004832070637266904
0.004163516761168681
0.009083563759483186
0.0048677093966301085
0.005220048348366093
0.008743064569871496
0.006948066137236038
0.0037610025558716506
0.005445940650534363
0.005896170385758773
0.007926929795099392
0.00316297273936012
0.004576551329161501
0.0035171642019253824
0.0046782674575266536
0.0038444054258957665
0.007750046796716729
0.006917857242636748
0.00633930392614058
0.004102302470023867
0.0010997368234264674
0.003949227927837489
0.00419392807935611
0.004254509102049064
0.008584492609716013
0.010924928000209725
0.006380152589710886
-0.0017183910601806034
0.0030605847233180247
0.005272109414401027
0.005481433109179239
0.0016129697487130867
0.002472949077675347
0.002909082631425067
0.0031333457038331316
0.0004641738676758846
0.0011550671233198427
0.005177190725318068
0.009672063876498322
0.005517211041842987
0.005517875248082134
0.005894520418591672
0.00940524045102762
0.002610704600488465
0.006583468616208548
0.003129042035102697
0.003984789817969072
0.004351305483352994
0.006071604367536516
0.009494517708389359
0.010974731745235292
0.0032492248677637257
0.0038161749931108603
0.013339844440185489
0.015587908082136077
0.00568566711798461
0.006441755989602685
0.007842911721390695
0.019229180525689962
0.012759318938119124
0.00798304885025936
0.009290022350184278
0.02125530878406428
0.00585582190626749
0.010629076221573209
0.005761740881501629
0.020270311069944102
0.011528646791186089
0.0037112180114434214
0.005652823141727825
0.01771487920462167
0.010686415097295711
0.004534541914405521
