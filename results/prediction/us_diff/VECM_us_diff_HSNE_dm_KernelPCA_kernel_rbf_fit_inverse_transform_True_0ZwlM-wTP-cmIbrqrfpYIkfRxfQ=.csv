# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; HSNE
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=13, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.18659402759803936
0.03763326169632353
0.08177314148081198
-0.21170961888180478
0.22876533269847238
0.030948852217819303
-0.11068464540499762
0.1483433863018244
-0.04446665309126385
0.027287721838307723
0.26561897287534153
0.14222688970558225
-0.1222473389394137
-0.024215244168978092
-0.03506600534800924
0.039115163334459746
0.15588266977420537
0.02414979818114267
-0.1482353475894377
0.020100656576114297
0.30169786117484393
-0.06659090646549237
-0.030487221715379487
-0.02007751167935632
-0.08688057278715648
-0.13409354651870392
-0.04077483785370066
-0.055808290877364414
-0.13268862280200563
-0.18673297858466256
0.08003776773214703
-0.01912721651301314
0.17007659056326246
-0.04723473642594471
-0.028570657441797404
0.03937675603756413
0.07322672829915194
-0.054263987708280025
-0.032116032646385274
-0.09642713810206058
-0.08934787688449153
0.10125937451210663
0.05907415895285378
-0.009114821392823155
0.005413421934942632
-0.03340145240135449
0.03664847185260797
0.06290965554165479
-0.055491831513022026
0.026034008414265945
-0.09175682479906207
0.0354863781934415
0.04166302628467051
0.0064380712481471
0.0315265672783365
0.04441937478467687
0.0293757949535234
0.02897347852771493
-0.05907669889314303
-0.03470292073686791
0.07900639180595395
-0.02074292062716807
-0.017943756404331754
-0.02508915179489249
0.03134668048804756
-0.007507257486791725
-0.016824702380174465
0.06897946140996544
-0.04711521690730812
-0.06807788784565327
0.04296297237204295
-0.09676335245429062
0.06259955420321296
-0.020646413080195204
0.031308434426655436
0.14456781682501865
-0.09062810565142435
-0.02996074510629153
-0.15314686736553557
0.12544317137711164
0.03239668735403026
0.04983547839436851
0.07467238114887942
-0.014531143612145813
-0.04136475282371055
-0.014758998537429496
0.09273762596192864
0.02393618740014465
0.035492717535418376
0.03513117099632153
-0.0158490745555087
-0.04865687361291669
0.05456075532698011
-0.04213305436410958
-0.05100181142352077
0.02562021364140986
0.002808785389483183
-0.0761842445742154
-0.04637274684390572
-0.08851100509285398
