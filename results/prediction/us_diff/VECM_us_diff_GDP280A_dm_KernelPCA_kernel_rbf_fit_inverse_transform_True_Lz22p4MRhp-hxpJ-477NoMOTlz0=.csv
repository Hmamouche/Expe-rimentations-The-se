# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP280A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=11, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
7.250992267076906e-05
0.0010314001135574128
-0.0016129811965962784
0.0008671379357629554
0.002823446552230118
0.0033121669567581736
0.0029302773533515657
0.0004041183959587311
0.0012196088478432774
0.0010781319532566632
0.0033300507292083168
0.0012154420236922883
0.0021505205156465987
0.0020582093934110634
0.0003330559482634446
0.0019435542061080982
0.0013344868984631253
0.00655874104970414
0.006725732164013029
0.006155822431602833
0.004277181498684468
0.008830933554913233
0.004122109033188949
0.004156306876620443
0.0035480930868060515
0.004338569834522777
0.0018279786771911149
0.0043661313382858235
0.002355857235072542
0.0022247569632573277
0.00465023729745117
0.003041663305618411
0.00040311107381251203
-0.004628689285079772
-0.0007481407305806658
0.0030209093529621565
0.0021494016481120536
0.0018815601059631285
0.005517904828743432
0.0032839686347818954
0.005827425523879923
0.004911613216945644
0.0034440243009068285
0.0038990879987048374
0.007871302140938858
0.007855422580787492
0.008030551488491423
0.0025873175807880774
0.006343803551465917
0.004229719344840035
-0.0015689007683317058
0.0013243533721868945
0.007220120634900724
0.003673830640071874
0.0077281656204734525
0.00628471137024127
0.006455853908678339
0.006141313018721437
0.008341351387119207
0.006814411808073377
0.0051519348169829565
0.0046385040991141525
0.002790365865959292
0.004240169654496508
0.005413302188857563
0.007383030504436662
0.0070459982802271665
0.005840592994412492
0.006709902056682378
0.007940336016093667
0.00894652673513773
0.009829432735100653
0.01006999323071458
0.0032719735449294974
0.007309597720738067
0.00913403862881168
0.009373792056807318
0.01114162667811662
0.007790122251611821
0.001374910471501173
0.004514738904589263
0.006124192218046734
0.011713349150886898
0.013528195195187484
0.02062190394982347
0.02306305907356466
0.022240270316194417
0.020540700430936386
0.02821761021486336
0.03661757768342899
0.03305429179931096
0.031106731252605914
0.012273032373672815
0.016623768566632207
0.011607261064775904
0.0054217848746453585
0.0012174250873849609
0.006612233867306208
0.007274570036954468
0.010209296523627821
