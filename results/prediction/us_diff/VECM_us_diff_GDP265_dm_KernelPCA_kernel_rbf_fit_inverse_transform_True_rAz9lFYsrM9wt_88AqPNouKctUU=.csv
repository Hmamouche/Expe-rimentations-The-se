# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP265
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=5, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.007813445620697947
0.004011199701452053
-0.002077550139600536
0.011151164735838352
0.006212811627349208
0.0017463996645059095
0.02110458031921951
0.008014160768628157
0.02151612958543391
0.018274914540256388
0.010679440284015905
0.01680128791221283
0.01948450892040332
0.010026289522992563
0.0121515289412139
0.011803419639728016
0.004486542135697575
0.0013810688574808568
0.010158580378018428
-0.001248096423464477
0.011120299574766656
-0.00033023661068835365
0.004553099376406604
0.0025201399272241887
0.011073020721891692
0.006952316888253006
0.010222303902406643
0.006689659072090105
0.006830993202061786
0.012431525972013626
0.004868993546543321
0.005209341006396489
0.008848159919363607
-0.0027762767276238165
0.0010609041042303128
-0.000686141690244101
0.002673371987387632
-0.0006788163524593776
0.005624780707232921
-0.00042921176111902694
-0.00297956863863785
-0.002132151927902434
-0.00928404238039696
-0.0005271700726661874
0.0034642260031559277
-0.003670179326622061
0.006880222201815328
0.004005582042906009
0.0036798922106239646
-0.0013876156901468499
-0.0029870181130297203
0.004148214885371879
0.00029175155830204124
0.0018248890236096163
0.011156760016119125
0.004348035488091973
0.0032592012034185084
0.004768153783647983
0.0031192869071638924
0.0023601556023756377
0.008218051756638317
0.0035580159914369194
0.011839380283182615
0.012528619982364278
0.01132971537560339
0.009497042142624432
0.008546077550206177
0.01074512707266282
0.010786125141413692
0.0030171809367953847
0.00701121437919274
0.005393341139396209
0.008535603719675686
0.016107040566437487
0.016368301126857887
0.01142553831621949
0.018323223090567914
0.01016183587489573
0.015486090619831857
0.006354751335537959
0.007545080619828249
0.009084067065730828
0.00220134235847454
0.007572485493548454
0.004793876966438275
-0.0001267525327153375
0.006182631608586114
0.0012967277960403843
0.00041844597564283967
0.003271559960042961
0.003386341200661712
0.0059744997796070025
0.00793429672090478
-0.0008492870389920745
0.011086675797802363
0.005546916541366505
0.006030251865395729
0.012035799814746877
0.01243480482231471
0.008478189063862197
