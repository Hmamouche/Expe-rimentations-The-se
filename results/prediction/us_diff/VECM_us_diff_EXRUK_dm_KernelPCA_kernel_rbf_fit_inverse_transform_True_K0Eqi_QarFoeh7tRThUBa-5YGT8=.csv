# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; EXRUK
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=6, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.03886728363080928
0.05688280897563499
0.030159846879181697
-0.027179848055048826
-0.04938263808800544
-0.04295366221395728
-0.020841789018061913
-0.02182525807468965
0.025814127719784922
0.038813299564599404
0.05091647072463233
0.011801660385799433
0.013346974006469052
0.002399293398572401
0.07235263500749115
0.04726541726911486
-0.03135130665361809
0.08399664008123586
0.030983197320497435
0.01841177085540846
-0.013944195784405795
0.013057800571263864
-0.009350337424014369
-0.05857007239267228
-0.022424340010649583
-0.0014334393860213103
0.018590247579278293
-0.04515718277153473
0.11694948810419417
0.08396669956771853
0.017708166747678188
-0.028772702748254733
0.05347231437414003
-0.025103178590379575
-0.06561541623989717
-0.011121908432950878
0.0575543274235687
-0.10471875603271741
-0.015685877776893536
-0.04592720193734308
-0.042609445276293456
-0.012485406195531077
-0.034086797902912316
0.024716584791355488
0.026745127007131067
0.004392987295875787
-0.015587739561166297
0.0024216000824694144
-0.01856277523219633
-0.0005903231811294988
-0.021483212997726715
0.02522512152170061
0.019482450459776417
0.0015226068540366774
0.021747206572861406
-0.002913909396650106
0.0028896856575814154
0.0084503981132639
-0.01569332955497106
-0.013060695381085822
0.014572909065085808
0.011357919469282527
-0.013023784710514996
0.013568819352922507
0.02266173562414926
0.005355018815577522
-0.010399626217865682
-0.04673573397345367
-0.026259084826673218
-0.014397174279167127
-0.005834084156159356
-0.037011742973819865
0.009320719909831448
0.005489661636501024
0.0009311685866713708
0.028665541676312543
0.009527135754526449
-0.0019845540769375045
0.03256523623202555
0.002699559951727701
0.020884686170898035
0.03853502151355724
0.004189211549979935
0.027903378581486466
0.016023714303682726
0.027710936952268624
0.005249533516273379
-0.007106883982116832
0.005448305070073815
-0.00930681198536928
-0.01849273703418603
-0.00022216665975726205
0.02904229045459257
-0.027249050362488477
0.07949548344097232
0.032826250593642865
-0.0013459322445103627
0.005528483749364741
0.004393577650105396
0.03441574670214975
