# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; IPS43
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=10, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.007144092026730723
0.007833926744744351
0.008751034658727192
-0.00416472320535922
-0.0047304457481837465
0.0009630120017410084
0.016123202929440313
0.008198537070512494
0.006407473714163661
0.003382238933470799
0.011999028847570457
-0.0035668344657333456
-0.001543023631442447
0.0039894758642935926
0.01114211849323632
0.013355377315271127
0.010813616078472303
0.0024874300564351514
0.013652243845636288
0.013294701935703354
0.009031104889176201
0.012064817686921577
-0.007155193684593447
0.0025404535248160663
-0.00796581537525045
0.001020670385421103
0.003528843412766706
0.0022772034369247145
0.004291746765978122
-0.009395066914576936
-0.003438875144395724
0.0058232625553088155
0.0050108264270769375
-0.0003234911119164661
0.0002950976983369996
0.002358969616429334
-0.002756911747722659
0.015264101361206806
0.014113734581839303
-5.7471656095070545e-05
0.011255289030328405
0.014288647870787917
0.01343738218214056
0.009393100064444024
0.009396055870669415
0.009094191962259038
0.010595574741656417
0.006074116333672665
0.0023962477598145062
0.00298078632667076
0.0013737602098372141
0.021590599485730874
0.010270343342323287
0.020749695815548422
0.016008490591548366
0.012974935659098106
0.02031982319588754
0.018241783446284146
0.016465232305412622
0.016831143991464157
0.008298348819679842
0.00937405167697722
0.01996093404179814
0.013852071738504671
0.02244229158172092
0.02284599236527559
0.009426373624981058
0.00710094400986222
0.0075680409963320506
0.0009275691469729013
-0.006869986351448431
-0.008542098754827344
-0.01988922578348847
-0.019982938512983
0.020278977453288126
0.007590467401646563
0.00042694912462686615
-0.0009640919552540849
-0.006935716604580289
0.010877152684988671
0.0066405847070913375
0.015849418660208846
0.004234828336423566
0.005287920769284762
0.0005332765273700132
0.001955784245178795
0.004315814797441971
0.008091059808898547
0.01576435125205635
0.012792066003520872
0.015405095971267331
0.0010785386497816707
0.0019820553598591173
-0.0004138117983252332
0.016291892488976882
-0.0031433148256921656
0.002533497314954932
-0.004424202604913189
-0.009631339934575364
-0.001135955645724743
