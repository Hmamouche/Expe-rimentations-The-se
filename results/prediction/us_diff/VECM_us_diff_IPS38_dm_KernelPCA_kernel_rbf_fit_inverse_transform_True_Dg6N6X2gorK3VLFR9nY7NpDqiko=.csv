# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; IPS38
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=3, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.015173590599334765
0.006161256690435916
0.01869421527298163
0.006896729656814161
-0.01117602313983463
-0.0029760329229264375
0.017989845527942923
0.0027968036204885777
-0.005625660666878416
0.006249834821898406
0.012351976202100948
0.010876214182878631
-0.0017265847295838425
-0.004567527519495268
0.015922480595856103
0.015085088110833167
0.021969810969409132
0.013915865630295452
0.007916437072529186
0.014331215682922803
0.015797740788504478
0.015030039937284433
0.005093995999040665
-0.007762426970798746
-0.006934676983669394
0.004986257270486513
0.010994464450637368
-0.006368048623121438
-0.009866687225982388
-0.012821847288126539
-0.004494189783319901
0.012589306254667487
0.025002169487886722
0.0012339179475776454
0.0004951099652295626
0.0018925408724003705
2.301917934531897e-05
0.005448356452539551
0.007119064736446409
-0.0029506826623303013
0.006506979517161978
0.015791199212869454
0.009344044419701436
0.012773577524516976
0.0008969805438485178
0.013253021978706519
0.0015681506806903974
-0.0045725203858561015
0.004725030866416512
-0.003832473777305996
-0.0065756757049729945
0.01446979704273226
-0.0021172150672394783
0.0100364341575188
0.008675946979740392
0.010459466343980107
0.017512794625647123
0.013081491850128761
0.010258797730502419
-0.005613004979195178
-2.5464839922238747e-05
0.0012367320922965289
0.013426968511211243
0.0029359201493381823
0.0044786877335914336
0.014357347615556227
0.003416925746252225
-0.002623879571432828
-0.021353421724592724
-0.008167132915822268
-0.025440576364033955
-0.011987987735555247
-0.017632218033529094
-0.016869531746661524
0.015333260171587038
0.0028171275501719176
0.001752601602958519
-0.007146826331446766
-0.010500481566267194
0.003046131159427354
0.0097825166604334
0.017287713956346974
-0.006975245905973928
-0.0020980022648156497
0.004213829504355325
0.01555156318856476
0.012715680039470097
-0.004006158293770566
-0.011094544663257053
-0.004148782791136335
0.03299144684641778
-0.001820570334188757
-0.013834117293225517
-0.015363974481034834
0.024790629418519568
0.01105807587533107
0.0008914022873856581
-0.0009520987912881123
-0.007917053270807316
-0.008190418047799923
