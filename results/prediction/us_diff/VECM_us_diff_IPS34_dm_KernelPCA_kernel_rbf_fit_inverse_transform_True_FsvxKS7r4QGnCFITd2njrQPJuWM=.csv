# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; IPS34
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=2, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.01917556569812192
0.011871236446570668
0.007886263117909324
0.008655454148976748
-0.0027641158953564783
0.00016050854336121557
0.004005840612452207
0.0022896181551414494
0.004355728175546734
0.003449207672079264
0.0010602649803780595
0.0031375613425213816
-0.0012295280420223952
-0.0034048486413025027
0.0060087223560070634
0.006129204201953287
0.012686698864413934
0.004690113249124802
0.00226244379736675
0.008276902626022346
0.005101489420407576
0.011585957865594312
0.004656562646915668
-0.004037587048479098
-0.0060866059180304955
-0.002738109700953447
0.0022609586981309597
0.0006043765530464535
-0.003555373367786426
-0.00848785789036354
-0.009554543301377925
0.003137789137257312
0.007113656442183681
-0.0015136183408617253
0.004102993909648797
0.002613863156848063
0.0022574600761419285
0.006369905607551671
0.004912409200103435
0.0031117068789281816
0.007042941853059884
0.00966221541970959
0.015581455371863936
0.017872122984862897
0.011012169326477724
0.01378404617250345
0.005423370492302443
0.0013448081871477724
0.008200663754121967
0.0078070329528756605
0.015108185979431973
0.02223489931765017
0.018473552595059742
0.021470966045162135
0.01435750875025627
0.01749656835098663
0.022270662601601075
0.021773454081463264
0.022140210476962387
0.019761071995109934
0.014671167922817217
0.015321384361507893
0.0201607963737764
0.02168359823345728
0.02781998457590197
0.028152103206467802
0.022670978413229303
0.02081811942022807
0.017588377378494894
0.00826713071691605
-0.0049005952859001315
-0.004640410158498226
-0.01332799876577536
-0.020114482301052266
0.0019359816517295282
0.008111006909912073
0.01215362481828687
-0.0007632055218819624
0.005193413815877256
0.0031899922765525066
0.01497502260202836
0.020976337794040775
0.01525415551716786
0.011285324444629732
0.006840541279857563
0.010381642631020939
0.013714291770900274
0.0065473178698202805
0.01569286515869779
0.02068303936691398
0.015309969135851071
0.009594821709326235
0.001768006825458739
-0.005020545777457097
0.005519559228004668
0.014050343008547028
0.010177128890509948
0.00785803503201707
-0.0023065242367120865
-0.0022944941283242278
