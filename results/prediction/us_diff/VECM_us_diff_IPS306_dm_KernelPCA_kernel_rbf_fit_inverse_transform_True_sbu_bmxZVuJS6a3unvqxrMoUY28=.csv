# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; IPS306
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=1, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.02779996155969982
0.04702270735745472
-0.0037842287543115756
0.02005766563629998
0.006895695617799341
-0.020452303139023843
0.007851716803235412
-0.010789785912935865
-0.005609023032330385
0.013022554917672634
-0.0061730386530434245
-0.008396386883215864
0.0006368756916872298
0.007608193996325314
0.007788991716159721
0.015466105872189823
0.017710554823519135
0.019152629975504994
0.008407061111817564
0.022636907931850962
0.00968177211795964
-0.01055720842997789
0.004618434924369455
-0.009214235081638775
-0.013928490575975309
0.003238229577420007
0.002493961237122427
-0.0051689316934275115
-0.02034756155348126
0.0013758171914469645
-0.014827966322693056
0.007522862434754213
0.02566209154165708
-0.010201412813329255
-0.003365591012059007
0.019593898923546422
-0.003116476026639499
-0.009124873249929137
0.022098554631897895
0.0006880165095574107
-0.007300332322754151
0.014222554372797683
0.028891104589561668
0.007260785351509555
0.00977896607965789
0.010819655171033954
0.006781759090195377
-0.003939129592221571
0.001758247348118103
0.0027904213970842092
-0.011519955559299844
0.018624182336016253
0.01243937218117257
-0.004082031279220171
0.01849979671131481
0.011788728479950463
0.014684256300729384
0.007088046429435576
-0.005132797874823191
-0.0102270483553911
-0.008764585748762531
-0.00241182622982437
0.005991897631856546
0.02790977258814858
0.014561645842378372
0.013737490865133333
0.012526219937647458
-0.00929170971214839
-0.0024996219677829324
0.0053364368204748425
-0.013642873996988065
-0.009396995343899338
0.0045049699682980495
-0.010715597394577
0.01262645019546022
0.02580577987615654
-0.010244227337074557
-0.0037869317321324635
0.006320473532458391
-0.003876257193603804
0.00020167848965325311
0.017792119922423414
0.021513536221148623
0.014117298162447304
0.0176317911946517
0.018206602975353727
0.02757371032850508
0.019427483867222893
0.011633458191665037
-0.00468432105197346
-0.011857095620084707
0.007668680781267921
0.005236857572289992
0.01002242354487409
-0.005834432664577609
0.004137257185137833
-0.008929494076227153
-0.007696726519144945
0.004274607625770452
0.005308775051535993
