# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP252
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=8, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.002112816456278889
0.007280757108941495
0.012123262392165157
0.004755977084515638
0.0024779126696960465
0.0046488828247075705
0.00812549070561438
0.0070382762764318735
0.005686203942897927
0.008282920992396872
0.007396982123439137
0.0034123923497542796
0.00098376041502651
0.005156526709073599
0.004640685684840728
0.0037330651220325883
0.008291572269629607
0.006315481224143474
0.003688471313000102
0.010480510389476783
0.007611950323766771
0.008902013388960527
0.0019063394258493833
0.00014307490576698158
0.002782942050613264
0.005036153128732198
0.00203376218326495
0.0025235943105865
-0.0003535885133758484
-0.000892991656095156
0.008104763361478633
0.0022574571761361435
0.00542403663633007
0.0025974823576119534
-0.00012875171628331942
0.003925943936114279
0.00421655043845554
0.008044265199040241
0.008191556954671782
0.0024090231603400313
0.007540645087108921
0.00882184701337487
0.009168837632673229
0.004398480377825616
0.005987363208356851
0.007258839882915434
0.007511464755971798
0.005968917128196748
0.006509833838298615
0.006198953666438237
0.0024411458193122444
0.0037667216906816636
0.006396029196572953
0.007556559469535338
0.00672159339641196
0.010913647189731038
0.007650556641630108
0.007469624031361766
0.012414188257833293
0.008335882810098276
0.010061501622115235
0.012224992285717181
0.010981273523133502
0.008796113969330747
0.01014687520718399
0.014352326889225633
0.010932250007401566
0.013703142596138654
0.00981696384367793
0.007938251037019955
0.010700225199870732
0.007419828590362872
0.0031772879996200204
0.004411960828937604
0.009743762786135306
0.010762589193870117
0.003706588430030084
0.007093198338646431
0.0010104997957389504
0.008949893186732023
0.011325101260777293
0.009106384849538662
0.01229860763993818
0.005176175316899349
0.009638950692320396
0.009520767878768844
0.008588258629254025
0.009720553173361188
0.005879460693586937
0.007893181467183642
0.011479693852157163
0.004690737633338943
0.006918571020351103
0.012811133900202384
0.007838907671540368
0.00881758877508123
0.012537618293624177
0.0012673237887431184
0.0030128574896361527
0.004843916159740769
