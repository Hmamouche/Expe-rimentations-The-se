# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; EXRUK
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=1, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.027168890513601683
-0.006444211383011907
0.03192894096480342
0.011525087730047193
-0.011627023695653025
-0.028249210107126044
-0.04541186142074878
-0.003121554615563642
-0.004981742764610449
0.001818437516750624
0.023572076557616117
0.04387976619111739
0.014132843120118622
-0.006055915999472623
0.034729688871359084
0.02289289030372162
-0.007618602340403088
0.0645490360438217
0.04159411045843748
0.03164756874457867
-0.005535158713416496
0.02195933843279447
-0.006941602616000727
-0.04701306286269244
-0.0022822163943912186
-0.024444992509972965
-0.014983646480996269
-0.012195208984636899
0.043728640142100365
0.04858534722426
0.017205792775404297
-0.030552550498838045
-0.015261349133867449
-0.0042805812940932275
-0.04076161555486181
0.024419690914861576
0.04734272690261112
-0.07513280218102947
-0.01825087975767689
-0.00856194223286188
-0.0563444921023737
-0.018109475867448415
-0.0007137517278771243
0.002786338191611398
0.019944785241111002
0.0202693724396105
0.017562156503560997
0.012413476601172625
0.0009039402467754024
-0.0007902866367688957
-0.02663605937561917
-0.010963768313418583
0.0036329040261242423
0.012212298829614693
0.011002944748334426
0.02054492867191599
0.010694447424747969
0.016969494088770617
-0.0009648652759429461
0.005276704571169837
0.002733625240723846
0.0037339855747812447
-0.01375271842762097
-0.006318483298702376
-0.0069842940057892825
0.0059929762170906325
-0.0031868987219322398
-0.01730165899531714
-0.015246727375495104
-0.017791576185913528
-0.023257293802558067
-0.03461654215778487
-0.0082277221473236
-0.01719924429877522
-0.01401808813468738
0.017104624122557033
0.011352220148005032
0.01398034034732564
0.03296314597408707
0.01668474995422363
0.0059462520813685655
0.03592915622344012
0.044500387852566395
0.008352494261075972
0.03829571702898604
0.03552702080421412
0.014289347945269228
-0.005239291201450137
-0.014315044570309993
-0.004777241598656841
-0.013545586884863497
0.00445827145931421
0.008638162374821718
0.018985626152971082
0.020218817479811538
0.02061872432250509
0.017569562732689097
0.008640787831953958
-0.005554696757708416
-0.0015866187728173415
