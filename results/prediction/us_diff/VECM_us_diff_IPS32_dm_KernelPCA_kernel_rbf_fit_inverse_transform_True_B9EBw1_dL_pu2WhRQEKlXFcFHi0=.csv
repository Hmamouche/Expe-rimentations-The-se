# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; IPS32
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=10, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.008884320839337328
0.013167236332831758
0.0064827149978219185
-0.00891578263126389
-0.012954376999260896
-0.0004688065354676893
0.012512429694182071
0.0027180053009185487
0.008631400883802196
0.0024397309326682124
0.018570620107106597
0.0015311140608727366
-0.009869504900595114
-0.0030854444684218483
0.0056065674469141956
0.01065821535131565
0.016938143926595955
0.006845307913261269
0.012521657551509684
0.013126522995364447
0.005314133116339252
0.018377177751424244
-0.005874338013118071
-0.007279355059507674
-0.010151212639405554
-0.0024181555525182767
0.003861313809157579
0.004845516642361252
5.474737538736785e-05
-0.013643476442968297
-0.004170715992738565
0.0013375854169783339
0.0078672214821101
0.003215835092417953
0.007247777832007577
0.010783813679401497
-0.00278492969971953
0.016416213995556574
0.00626263691339711
-0.005746872568285745
0.011089790110132789
0.014896879417252911
0.018936690982301017
0.01400918769809621
0.0134178314476269
0.011208145242281517
0.010212414340298782
0.0017577257300442533
-0.0004087848475695867
0.002227312529996489
0.0025614463908557846
0.023439255532028025
0.013496185435005793
0.02370492882867295
0.018837601561169943
0.01597216698617981
0.022330010221577174
0.017457189571455308
0.016958161111849467
0.01439628769192798
0.0039192001245421226
0.005521864170663106
0.02245117286370868
0.014010117975660395
0.02486527614379272
0.026442073402577138
0.01616282760248723
0.01141998309521773
0.006570046618669401
0.00048011220191472624
-0.008477882757045724
-0.01033563773646683
-0.018375430592038243
-0.025779495440831315
0.022172323301251948
0.014969234659486597
0.002790428731776068
0.004004622886891033
-0.008105871695076147
0.01187901937487046
0.0067675282553815545
0.014999590045524334
0.008738956279515679
0.0031085691158521324
-0.0026262583677097114
0.0008393891557211338
0.002816862584478807
0.008077590742575727
0.009013804797738802
0.0006302966139584937
0.02296779794505845
-0.00015137694294806614
-0.0032813040923473404
0.005051068422562778
0.016608814347326604
-0.0008412743613044568
0.00686338511519764
0.0007299831034919832
-0.006485682286553517
0.0029158133633771957
