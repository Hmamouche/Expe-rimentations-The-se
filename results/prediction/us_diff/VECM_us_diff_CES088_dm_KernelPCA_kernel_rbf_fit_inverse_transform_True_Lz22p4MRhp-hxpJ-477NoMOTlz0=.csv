# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CES088
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=11, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.009015472542942589
0.00900713101811225
0.008436779520582503
0.006304472940106018
0.00942740010792718
0.010600260088845848
0.012698271215483625
0.012913461671682324
0.012395536628671086
0.01457065285097622
0.013062725060056783
0.01335120341792145
0.014682407186243836
0.010777926959291806
0.010626020332725177
0.011353920929893926
0.00668612190052572
0.002553757241017131
0.006514781267250896
0.002357355824739034
0.002667734064885828
0.0027396958095291584
-0.0004597465207032145
0.002834593389901427
0.0025033926422768516
0.0034738517624757857
0.002022144350326506
0.00013614534516063104
0.0013585161255381228
-0.001754738283835762
0.000708702117411988
-0.005381115817297517
-0.0022586484480350017
-0.005806740635523231
-0.005573663000261475
0.0036086410595329577
0.0027607021347249732
0.007045298465674097
0.007383937042092351
0.009950319094535847
0.012271328226939306
0.01292480134106385
0.0102974038228629
0.002503040244892668
-0.0015141500792611358
-0.00878545921411559
-0.005817991461688879
0.00039582426055707014
0.005461591581696392
0.006278069416837371
0.006445352621088522
0.006963931063947996
0.007570561488790594
0.0071936863894079715
0.00712189544965982
0.009887453910517928
0.012758850778608992
0.012637781837503014
0.011812992826505239
0.013668173068435782
0.012666966075973295
0.009874264584762394
0.006028546407736903
0.004870093803711794
0.004466938488259534
-0.0011404299169162357
0.00010346964436933276
-0.0016486466706772888
0.00420473476051078
0.01013566939024448
0.009376143416868502
0.0025661748754802986
-0.002179468628939093
0.0031300396132464135
0.0003629575261892993
-0.001107661994462278
0.002142784994771668
0.009941894272754765
0.008615748862744637
0.007188658310874601
0.003321869702317756
-0.002887522460311538
-0.0005011025354638612
0.00756933302949192
0.0021148327021771945
0.005068380603869568
0.004187202480066955
0.003353223799452295
0.010576154089976666
0.011699733023607417
0.009203470088976679
0.005005239587257706
-0.0008429401583537654
0.004430178598901038
0.0008432071999942509
-0.004299081747799931
-0.0056023073222188045
-0.007331958782381835
-0.0024633389869445203
-0.007027736426809391
