# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; HSNE
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=14, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.5600456795888431
0.05959778517225589
0.006722300238807016
-0.10720152081730064
0.21506503452525005
-0.015249816818521278
-0.051929535815182656
0.14256230964881556
-0.01739122347004895
-0.0810268247464952
0.3429868497676841
0.09994464669104891
-0.10138032453422285
0.07256795518393844
0.10608855871323593
-0.021617433714648665
0.08083885004444721
-0.04783044999424581
-0.22219791953183854
-0.03584979101973194
0.28068325861578236
-0.08042748736532176
0.012915489565198592
-0.0040049490670014416
-0.09885931765828944
-0.12899971500129362
-0.045674377209385136
-0.05858646011109906
-0.11289228188884412
-0.1774182218624272
0.09212244002439404
0.0016360112714378927
0.11965000962642995
-0.07735859418578073
-0.044839627606575616
0.06712334942960646
0.0738072020103798
-0.052990279665400215
-0.009157432619545077
-0.0692832376190689
-0.0803219189395003
0.09957437775215344
0.02830254419330184
-0.0030707745351159846
0.01590166508921844
-0.03455641729593263
0.039144393001453545
0.06359999145067971
-0.08202707523360557
0.034254400525782394
-0.10644091582287543
0.014151891469215722
0.03598886757947658
0.006341541000934906
0.011168057848878627
0.043273822338212864
0.03344132937304612
0.04011938688126501
-0.060264630125629326
-0.02668039238123456
0.07054585180253603
-0.034425088433387555
-0.01647055649947189
-0.006802006276910896
0.015823145597478272
-0.013731413218239147
-0.011568890387518353
0.06418940032723269
-0.04826183285551459
-0.06474310636489136
0.04684944970772855
-0.0816065364448682
0.057114386069173975
-0.0293553598094096
0.008080420835917403
0.14328557838061018
-0.1081052107178399
-0.061361538342124655
-0.16017456134666314
0.14561272570987455
0.04223195095803772
0.03189942694640409
0.03460166643581273
-0.013677090970361343
-0.043914316306656244
-0.01629294286930017
0.08527828828218831
0.035978832479102066
0.020260522408523746
0.009340833028522653
-0.015248617091278985
-0.05279870602522172
0.0525029688375361
-0.03393642760440232
-0.04507981923273906
-0.008877233883093742
0.024480853964047814
-0.037727556398223616
-0.05292428574820749
-0.0735155892671199
