# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; IPS32
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=12, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0023049545838369507
0.02057059984856751
-0.009903465834575808
-0.02091177086459984
-0.0072202566399438475
0.002422317875392192
0.012985997154939378
0.003316639262936089
0.008603511173826742
0.002838811134259103
0.0148666807489899
-0.0061800294101242124
-0.008368942376450025
-0.004483981691466064
0.0030830530288520415
0.015180442529979484
0.014703688866029196
0.0027216479020183942
0.00946138934915677
0.01412409269153806
0.00553824667817209
0.018121882200193225
-0.005199966903043011
-0.008358127809762406
-0.007360989617680563
-0.003626912572073791
0.007750173378703177
0.007390609750805167
-0.0013112996202824904
-0.006256624852780018
-0.006892799325167762
0.001343448132057652
0.011144907359301646
-0.003195493020038874
0.0030207254516811366
0.00468413650453796
0.0017011638147625763
0.021340594735828326
0.013896881739740644
0.0072952688906130995
0.013719270006850127
0.004341524682482728
0.01999662964957686
0.010991144576285876
0.013676685763457704
0.012652317234208179
0.009771631007246918
0.005339649874786246
0.002117311670853499
-0.0011361735647515076
0.004310588545766371
0.02461170471439672
0.022477566526501368
0.01684224397725996
0.01544911060111973
0.013776543429671993
0.019848186290506675
0.019529661888655795
0.01651553067925648
0.015763350411363033
0.0066099292321198
0.0038151021981517653
0.022257429750826927
0.016481158520202974
0.025233203698928463
0.023895549147355394
0.012722818842763143
0.013404554857395062
0.0029852416063615205
0.004710191872090497
-0.009542684073433637
-0.008817304008959472
-0.019515358126078845
-0.028596262515227896
0.020062759850891863
0.015546083772946868
0.008242126184716798
0.0001930899639337345
-0.008634866491659652
0.01631187523024181
0.007509714051809921
0.015085269310819284
0.005624109640719398
-0.0008377054345214397
-0.0014535111326252788
0.0024602452132314635
0.004885616907329641
0.006824152153027973
0.006374165475715325
7.910474928999895e-05
0.020169403744179606
0.0029109766765794097
-0.0025961010858089042
0.006621906204055158
0.014634628283649958
-0.00016027310328820368
0.0074933543755844965
-0.0005071362844728958
-0.005844529066525404
0.0005735016080027086
