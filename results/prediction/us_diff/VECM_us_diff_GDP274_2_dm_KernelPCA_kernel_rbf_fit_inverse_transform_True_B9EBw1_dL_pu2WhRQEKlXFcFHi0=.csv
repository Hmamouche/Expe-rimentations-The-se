# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP274_2
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=10, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.005216611559665914
-0.0005077784072819915
-0.001213720841172941
0.0033328725752324166
-0.008133669433955928
-0.01304600395191381
-0.0004943558918174204
0.0021262099413636814
-0.02273351797643216
-0.004661978929493348
0.004256191781818099
-0.006880068109938768
8.242517385169358e-05
-0.006229263592279679
0.00687527637588368
0.008543719435527296
-0.011392564903989795
0.0017993263738392416
0.0013113197807012615
0.0027936694068201183
0.0021634017815776235
0.00042086786230370295
0.0030196086032233107
-0.008251510263258339
0.0009615167373757769
0.004966702450688925
-0.004882407205617332
-0.005138379025507935
-0.004285907847195156
-0.0027808708067332457
0.006316535498670592
-0.013804704117990476
-0.006045054828835819
-0.007439338071802076
-0.0045229423671069476
-0.004505847874373659
-0.011735318069054701
-0.007482173525604714
-0.012909118224435367
-0.011715113710172432
-0.007063979405899172
-0.011728307975111044
-0.00630705098294253
0.002982028796088525
0.0025414306508071724
-0.013755888855063137
-0.013028607838264048
-0.009024309318955998
-0.012604298286268908
-0.019529282152980252
-0.0143916146249219
-0.02755501528951405
-0.013582281465722025
-0.023954327766322076
-0.026488090225872597
-0.024092132569954367
-0.02288177608063053
-0.019271093329443396
-0.01928229240482003
-0.018504064071391452
-0.0241009731306659
-0.02782762783456213
-0.02028284826280618
-0.019717449237978094
-0.019446431952752738
-0.02191768014157766
-0.014615245829613144
-0.005475730922782468
-0.01566383402099791
-0.01676123779618479
-0.018312329977898483
-0.021035132435300363
-0.016726042142315267
-0.016426856998389985
-0.01816296885058531
-0.01713585010127593
-0.007297129897836286
-0.023731601770122856
-0.01966942849486899
-0.014728764165493102
-0.021863311689107143
-0.013628345283292695
-0.0031992770743945846
-0.014726602616201786
-0.011621100906203177
-0.007992700756670312
-0.006764056258277907
-0.006113607783577369
-0.016682539403934053
-0.011800533014078643
-0.007596508539597412
-0.010040510425727671
-0.007785077565592723
-0.009854281018274994
-0.01493396583104827
-0.00648144772864582
-0.006658880425148693
-0.016324263860223093
-0.007721250402059045
-0.0062310598616346835
