# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; IPS299
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=4, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.011805452039315975
0.0022356448395750537
0.017020092781631396
0.00999321366129054
0.00452233715973238
0.004566080707003205
0.010837147194520457
0.00907527138871999
0.004893573610162671
0.0026184311067166894
0.004242015340342579
0.0021550129036207377
0.0005201049856991545
-0.0014645074156709027
0.008925580237715666
0.009323008093513413
0.01128485132054615
0.010895299204513542
0.010366415305490503
0.016680588063632863
0.01323585083868468
0.009858110623135892
0.00018721941697362498
-0.0006140332557299567
-0.0029307234505915516
-2.503605299520738e-05
0.0018990903529717813
0.003538986259096982
0.002595643867517227
-0.0055710079385467605
-0.0020812016867321047
-0.0019835786773240043
0.0031641298035499257
0.0034309662263417437
0.004557355251071736
0.00856646788319741
-0.004833571731575041
0.007067771027648214
0.012287252604144164
0.005811426638896925
0.007294645774298675
0.008516527588488719
0.008865269552416788
0.010678238159909524
0.010627643617322696
0.013872007976947579
0.00208404313865267
0.0035084022186922985
0.010669237546346787
0.006643554213405175
0.010077482086686311
0.01425703853311669
0.009246137471141619
0.01709781613655362
0.014216125148931526
0.015860629108944372
0.022074889216941028
0.016923297886426214
0.017390311080553448
0.02060945301830763
0.013816644834533192
0.010722155786686897
0.011196757090039313
0.010320875561461433
0.01102671521777162
0.014206340039401999
0.004096611280226505
0.007165035418312169
0.002860839039359774
0.005074869463168646
-0.0004895095800545974
0.000921149586076329
-0.006063682756922294
-0.014090915976668101
-0.0014736608957733538
-0.004825025728755668
-0.0038180428494782015
-0.003778405484914303
0.0004831015194777335
0.0010463828548117533
0.013266438752259259
0.01364998536709314
0.012130917747980127
0.004606129827079869
0.0037808499741243196
0.0042031614676179925
0.0026680861144269966
0.005391665812053738
0.014497912774815835
0.013837680411480056
0.010870065503666895
0.005781710160915134
0.005180826636637334
0.00519385658427398
0.008445948489859703
0.009218821809752625
0.004731301105007264
-0.0038599049978842374
-0.00032317494774020274
-0.0034978324411992345
