# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; PCEPILFE
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=14, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.00885538603126838
0.007417263629291359
0.004342411853400942
0.0085318263824688
0.0071952521165482
0.00509165253294603
0.010557398718965098
0.007111178821627427
0.00462857743416701
0.004763571275474268
0.006018473329719703
0.004836856906402737
0.006458478210261864
0.007713867311691565
0.007066104575484553
0.005333181493765063
0.008173733023022215
0.007106075601826989
0.010252671661461647
0.006838644264921099
0.007963161962971203
0.008297989651828878
0.008120254072543012
0.006764479219573211
0.004588575730158038
0.008868974792967454
0.008198129847981551
0.010593338851686496
0.008692725037328757
0.009870964756720517
0.005954580035937697
0.0056211660785797455
0.010991311519094705
0.008945194470313379
0.008725224678449701
0.006313448918703777
0.00713177518367991
0.0063514053482405415
0.008736806740213954
0.004729764019042693
0.006485594037221351
0.0039894051689626595
0.006464685484550564
0.005748465172752685
0.007468179608479469
0.00432328945141341
0.005324213002451716
0.002426456243369952
0.0037467839495059054
0.0060314855354630294
0.0035491200386281734
0.006539587163356863
0.004691766322212178
0.004514359900713708
0.004438850651219366
0.004687780745587256
0.0032666969088825134
0.002873440513854218
0.0028003843349161646
0.0019322697490169708
0.003557649281849225
0.0043447477551834925
0.004881625413642159
0.003951525228883565
0.004082427234918124
0.006078222357920951
0.003756429044410122
0.004281505415824281
0.0028723751755287447
0.0041782279628170904
0.004582193598071566
0.0032438730361130205
0.005426776106522025
0.0053679048254101375
0.007661343166020478
0.004750588682562558
0.0032399127062400336
0.00506161909127607
0.002818243716588334
0.0026224012893227805
0.0025721159890701862
0.004936746102924779
0.006549227572154587
0.00584828161998576
0.004941822531407465
0.006118609423313188
0.006388065102053378
0.004970158771320766
0.005240369428017521
0.008452030804847853
0.006221643124109195
0.007172300098633776
0.007206402635307435
0.005330217747332514
0.007175191236065325
0.005859317824010332
0.00693006525841124
0.005315146535987791
0.006779278924765412
0.006987626567186522
