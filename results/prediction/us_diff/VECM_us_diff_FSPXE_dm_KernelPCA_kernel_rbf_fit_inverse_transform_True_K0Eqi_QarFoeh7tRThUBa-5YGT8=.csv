# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; FSPXE
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=6, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.014311515675256646
-0.05672058637594234
-0.046126257036176156
-0.038341292546465434
-0.005098462421633743
-0.0005505585324070347
0.03445100732834287
0.023930484428571607
0.03121222487187968
0.031186673292595786
0.05003381528449652
0.029363626860307617
0.00983699744459981
0.011997061542728962
0.06380741531348334
0.0054992199451808655
0.010586933699519628
-0.03495347853010867
-0.04532840205863674
0.027670742465925068
-0.06228227530938178
-0.03839993892642303
-0.004292900722870307
-0.009123036114283127
0.004361021108693745
0.035814736350345495
0.018853976126547156
0.023354048441122904
0.010539773537627308
0.01650108066941798
0.06379815466816582
0.006422923610406606
0.030783837037449434
0.014416328646375287
0.03520537452486036
0.009868117192706898
0.01805390906632609
0.036575195100049626
-0.009987074411354711
0.004252214931046344
0.004652332158421514
-0.003158291973667202
-0.047058699456678996
-0.05132392321053306
-0.031042423484100662
-0.054417702852785375
-0.04072966650412634
0.009482177345540986
0.005923338037642123
0.012803519494463022
0.033167906944106915
0.011462702829042964
-0.01444879200203889
0.01263993527193603
0.008256977230441026
-0.01666203809972448
0.025988249259535332
0.011988260460305383
0.026037387273411112
0.06334383457126946
0.01887266431123556
0.06329863018258547
0.07088056724722597
0.02821365575029265
0.012378905979547404
0.002357474173233772
-0.022890452134324703
-0.04284241424687266
-0.013345374551682547
-0.03377152676473337
0.0022469960903100505
0.0026946971345366607
-0.012858212922890758
0.10224713553467851
-0.016235730583261103
-0.08378039477936244
0.3825669341122045
0.22224535817726226
-0.026737413049180335
-0.07686441433210184
-0.021876055932636786
-0.053191385836507586
-0.031734150790144716
-0.06779300132738897
-0.09583647796838365
-0.06803110064531923
-0.03740318413970547
-0.010049872985972652
-0.004760579328035988
-0.013838043403177605
-0.016565734217762078
-0.05495873933007501
-0.002656480897315597
0.0066103299388818315
-0.0024619570551340023
0.009848421395501338
-0.0009411348217070077
-0.03773369384154949
0.03737545837267081
0.026770321052729543
