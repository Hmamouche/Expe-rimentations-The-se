# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; PW561R
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=3, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.03386168416112714
-0.051574617085398226
-0.01580514986680509
-0.006735752998710013
-0.008636432375200075
-0.004551044900916165
-0.013952109655497997
-0.009010423881665942
-0.01802786484521145
-0.004263069392847522
-0.05387031496879336
-0.11426401952744357
-0.004847199836862302
-0.05145860242890089
-0.04528128908694207
-0.004960690991763654
0.00036681540964509166
0.012262696501943808
-0.02674039359109222
0.020148016716774214
-0.008322743378888066
-0.042872233351775285
0.03168972934863932
0.010161737540481438
-0.022776615231286754
0.024636092201395732
0.028258728273204768
-0.05013249610917818
0.03916155599342973
0.07204284146363227
-0.061297052424153946
0.045197047735221985
-0.016138752326635593
0.009246239644921904
-0.06368319083146265
0.030832673680152013
-0.0184584058276503
0.0005146874131717019
0.004709193555436274
-0.0011389427521765402
-0.02783982627083537
-0.006641389442364748
-0.02968392722529249
0.020597984318819165
-0.01577510786620224
0.0021544430203396586
0.014261856291260148
-0.00446358914888109
-0.011621774496424202
0.017185782102056624
0.00020767194254127006
0.013096377366941778
0.007639719066816378
0.02187115732250695
-0.006801261237723679
-0.0003090550310984909
-0.0074242117435617105
-0.011602695371446044
-0.04026934910254471
-0.006734482060049216
-0.026994229960331316
-0.01909959812517999
-0.006258379992446559
0.026595949213382705
0.010716428693615165
0.03314226333140648
0.050392952674272934
0.008753573621792078
0.04650357598809873
0.00227329446012066
-0.011875117706833863
0.004507746170199812
-0.01514339039807585
-0.04478357927454514
0.01252588174740635
-0.0084547784194799
0.0032309642025634697
-0.0006023468308286586
0.048187606167178175
-0.029366861408309318
0.03548288838870111
-0.007547602235763256
0.021695543869833987
0.008693633510746764
0.02533700997485233
0.028304033903965235
0.029645645383406694
0.03385604133692243
0.055070964914007196
0.01059363290656814
0.04871470316273844
0.03513879578374468
0.011726105036495252
-0.027025428930175822
0.010503760174725672
-0.023836369098837615
0.017608315503229558
0.07322244161692361
0.08304146309248439
0.17277416889865063
