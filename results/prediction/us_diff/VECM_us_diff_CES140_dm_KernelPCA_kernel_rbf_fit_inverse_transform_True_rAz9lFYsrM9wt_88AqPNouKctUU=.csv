# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CES140
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=5, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0113202874285454
-0.0015051574610511138
0.0004887807305883013
0.001010859641159289
0.013048432530355264
0.003688086837911328
0.0007913002588322103
0.004550735244125433
0.012047730958185367
0.005772304995073162
0.005055538898230769
0.0008032090461320013
0.005607594701054981
0.009160546953142787
0.005681679338178409
0.006993496657665795
0.002521185992682465
0.006865995107318784
0.00627782711602903
0.007839055269635735
0.004458112587017491
0.00846202136632789
0.007102786467848199
0.008293971869711914
0.00540644676314149
0.005183664661356426
0.008658711486674912
0.015332684388150898
0.008588210756073394
0.005018756791344882
0.0031957765784364125
0.005661711758747437
0.000618323289052368
0.0006836857007319242
0.004916757529706438
0.003885682175874457
0.006837833948263887
0.0026084749858541014
0.0038415265507622657
0.0030138517475755966
0.004209601605073035
0.003336007864866232
0.004754734150213483
0.005471795879051118
0.006314558979214135
0.003785442627771426
0.003111459799843947
0.0031711417347570266
0.001309469067828418
0.002277063052088489
0.00278402841495631
0.002264756423955594
0.0002047695750603503
0.0009197459019597169
0.0015311616060378365
0.0021432230469485064
0.0028072083176320503
0.0034139072600448245
0.002807604808933974
0.005700851748087386
0.005533923042217644
0.0046549844337760975
0.006071490154321861
0.006619646174771585
0.008055591875880348
0.0067175297391983985
0.009681934407833936
0.014705778880466126
0.005099480030703314
0.00485169466144227
0.00031022988864988325
0.010479899502461558
0.0056262628513051895
0.00567487808431993
0.009507777305619325
0.0067629945382593065
0.004070336222555603
0.004273273044920204
0.005324279581416213
0.003791799806808265
-0.0004203751490167824
-0.0008148123944104563
-0.0011217217968588823
0.0016527590471966623
0.00010910603753909779
0.0030987048261151024
0.0026520445186077454
0.0023209254606044198
0.004818688903926225
0.0007225227646735874
0.0032947930333847002
5.1744126109248855e-05
0.006927487069132749
0.00210415631911323
0.0033177681730144635
0.005883933190022736
0.0022882995319884252
0.005298281172701094
0.005030722429318881
0.005973977279377454
