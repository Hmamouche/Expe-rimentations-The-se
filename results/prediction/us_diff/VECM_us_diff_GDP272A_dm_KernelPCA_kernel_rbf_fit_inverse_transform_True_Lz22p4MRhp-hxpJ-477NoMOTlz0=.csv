# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP272A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=11, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.004046251782550811
0.006221047750611035
0.00610312589479966
0.0066512436513154975
0.006558587712846045
0.0034805140367568715
0.00915746063061375
0.004252249255246358
0.0022289883174421246
0.005182286844939008
0.00211368282513897
0.0015748774044081312
0.006235000857481932
0.005026152823571189
0.004726841916161465
0.004258958320851472
0.006790139082022188
0.005289576391228724
0.0049711844400699475
0.006862710796830935
0.006969897136584436
0.007706418399573212
0.007365282218348301
0.007719328080078544
0.00537454598156239
0.006199109927118187
0.007897980754846025
0.009348825155873224
0.006805260494836724
0.007677072081101326
0.008687779040297643
0.004368184658884617
0.007489858529494339
0.003990051549502676
0.005446073934984817
0.005550499837335278
0.0024099535241835536
0.00424705920264111
0.007985927511384631
0.0034403638579481553
0.005846587957898168
0.0041991463021747374
0.003975368918180473
0.004801544849348896
0.005881923092858782
0.0048755276865641625
0.005076801372402793
0.003624171260519317
0.003993375156400364
0.0055027051132012835
0.0027766699756110714
0.004153110053843668
0.0046014878590712035
0.004486903375031078
0.003835391421470661
0.0036892335366940743
0.0030441778369478655
0.0037191053133545024
0.0010881594258716815
0.0022203377486887674
0.0024246066329007545
0.003571977617982048
0.0030488516605098595
0.003395780258793996
0.00374789936698575
0.005489966355928112
0.005951988237387022
0.00499500984935995
0.0042328511571158925
0.006255364678694758
0.005685482376153813
0.006918486914322498
0.004678842366829861
0.004945338161239619
0.006921710807958995
0.0017230865544406817
0.003762662545097893
0.006195717594767489
0.005953124891349657
0.0036223199051696525
0.005589419874283855
0.007774777179863133
0.005368993303484419
0.009812610333000836
0.007764272496705093
0.00898963289591681
0.009780556990711863
0.006572631037145392
0.009656663881544958
0.010048327485264562
0.008783917366488902
0.010765435392692075
0.007178926224174527
0.00799730325010526
0.009528806957198824
0.0057770579246899595
0.008021707885894675
0.008411867703119105
0.005212578489009429
0.0037053354461146796
