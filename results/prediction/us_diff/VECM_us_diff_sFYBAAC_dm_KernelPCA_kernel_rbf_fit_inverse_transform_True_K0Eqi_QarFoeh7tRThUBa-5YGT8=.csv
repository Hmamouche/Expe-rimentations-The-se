# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; sFYBAAC
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=6, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.02265756531562954
0.004814973128977131
-0.011282606791819782
0.039127056636504134
0.014113641139228559
-0.049044433861995654
-0.09653153759706395
0.03418313009670909
0.05336162343949914
-0.03706137162684166
0.0540332789410605
-0.04021571081309387
0.09010756132000104
0.0723599275956181
0.0172961634540412
0.004606570552870727
-0.018936925944599003
0.03143826114993308
-0.06542627253200163
-0.002278530416224984
-0.035608302761279235
-0.07981360630137985
-0.05327031277172823
-0.014202377759396787
-0.01337826539948346
0.02192712481610134
0.008927675408089532
0.010063733307154798
0.06901867755854264
0.046703236646312936
0.006003100043386004
-0.003012045697172675
-0.07628125873351453
-0.10724900109065472
0.02274928962016343
0.021277665702620706
0.04639619927764083
0.010123840242224375
0.014602345336616421
-0.00593802174745014
-0.03729083229098903
-0.01582027711097782
0.01456831445005745
0.042156349145918
-0.034046934462787275
0.008399161570686427
-0.03939272821758275
-0.05177368486856597
-0.011941367258861786
0.0034426910312721328
0.004153215349535513
0.03322260322311252
0.0033649878762375927
-0.01301779456696509
0.004762681040793582
-0.03319327606684179
-0.007797552873459219
-0.00461362195969349
-0.007677318630325176
0.045419606421254234
0.019870533042128463
0.06636378472440063
-0.00048616433223588884
0.04982493630540398
0.03247015517727056
-0.0035418824859900786
-0.03131145975474583
0.04463999270604359
0.002374812579017973
-0.013085072830901271
0.0379961796459479
-0.009130471614261863
0.07136533941519843
0.028546939424960033
-0.02651675918506979
0.015324189796592197
0.005660957943657591
0.022508014310366017
0.05423236843356012
-0.06655340339503661
-0.007909012138954999
-0.05973456426105674
-0.07145172478536398
0.019669019564377825
-0.0034074402375488325
-0.012469656928463243
-0.04216140877021254
-0.025086291850675436
0.0072849989115807146
-0.01507911089784278
-0.01906577345169011
0.030938607749337734
-0.008325269192340497
-0.02430385876937656
-0.00027662780784747446
-0.029976241510055
-0.007219348445485829
0.1045225148503528
0.06709948157471106
0.03635672174031232
