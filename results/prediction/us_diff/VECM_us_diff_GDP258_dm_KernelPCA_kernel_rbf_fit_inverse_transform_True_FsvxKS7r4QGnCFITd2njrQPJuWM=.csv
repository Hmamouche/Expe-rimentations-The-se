# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP258
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=2, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.014517952578034302
0.014092764343364343
0.012509442014514762
0.011526280797641446
0.011223827545844601
0.011300858498110378
0.009441040457070848
0.00678964029141996
-0.00012291177122321318
0.002788075651195798
0.00557136763670713
-0.006199630470080133
-0.009402471052467042
-0.005928266340313294
-0.0016690657160730966
0.0011841953520908234
0.009316994551439394
0.005000678221656634
0.0036354652402826836
0.004385633387089135
0.004150559897001515
0.008279698559751135
0.0033835342563401406
0.0011948023942929373
0.006407283727075564
0.006692187722063757
0.006021630171984418
0.0001307968942275454
-0.00827778161293557
-0.005697202950663499
-0.010130515888899133
-0.0026203817500758952
-0.002745872134763058
-0.006308750220223561
-0.0022822335385223646
0.003253476447867236
0.008020046334932068
0.012104269003574057
0.014202916451553712
0.006497521435451803
0.009749894756470381
0.014391937207445908
0.01821674655158689
0.010544088696583048
0.010980929085394787
0.012537038195421683
0.016338936807003334
0.010790226885704225
0.010581398506658785
0.008279937299148202
0.008689639672348882
0.01570347762007964
0.018628650146956378
0.019256567770002002
0.01855513080932295
0.02041605428075806
0.02266164348168992
0.02292175364987554
0.015185668370501315
0.02230302954319452
0.015217285881296571
0.0152169105641496
0.021453435910186572
0.02016629717495201
0.023586054080941717
0.02170446095768142
0.015450374953629152
0.017765974242222853
0.017604156238483246
0.013607090715029602
0.005842623277347211
-0.011242713422608696
-0.02135828629907352
-0.029519646153428395
-0.022364855505474956
-0.021307554240521824
-0.019253108405355226
-0.011284332675879829
-0.007089387525257889
0.003093941150192228
0.017831514841541544
0.022146357815607944
0.005189631752474814
0.009100718444376769
0.014774849372858105
0.01914266970613687
0.01682240661285794
0.013941725383880305
0.015418200545544068
0.013522371597013728
0.021032588052635387
0.01683101862313302
0.01561791828332507
0.008480677840436482
0.00773074289047981
0.01505208521889103
0.013768902181803891
0.007718396837483315
0.008122367004853321
0.010222452213996031
