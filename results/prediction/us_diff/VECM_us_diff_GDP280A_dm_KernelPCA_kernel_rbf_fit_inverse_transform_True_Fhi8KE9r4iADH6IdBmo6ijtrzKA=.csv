# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP280A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=12, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0004305353279978546
0.0005495073610229384
0.0023016289175194172
0.0011311812900222425
0.004338224590197191
0.003908678901511243
0.002073481984652638
-0.00022343037058458748
-0.00028806297169239273
0.001030958163101669
0.003098471224452268
0.0025469536941923722
0.00262412137465734
0.0021961592390309917
6.118353405169916e-05
0.0022019948982954147
0.002319841607433662
0.007690285929185307
0.006302602123070607
0.0056879890831811625
0.004955112696066456
0.008770582649894172
0.0037280685458896436
0.004830478480736616
0.0032950326333120554
0.003791186738484764
0.001728613705631678
0.0058393978156166424
0.0021859468914493994
0.002033380680303444
0.003966448407264754
0.0014738195903193853
0.0014009489970713144
-0.004447583062813703
-0.0007600946512952512
0.0016133553291952747
0.0019343602267427222
0.003193660663981848
0.00535899212943022
0.0040197866562624125
0.00743774531685789
0.004441517528328159
0.0036222666601390834
0.0031151292574531147
0.008287759108881026
0.008113794555725355
0.00821940530543796
0.0027649674227304996
0.006711749058542863
0.003995480832603246
-0.0021971452437107184
0.0011563799166668537
0.008943412247541685
0.004019181780793168
0.008230984905291342
0.005881254846929637
0.005546392908943126
0.006421219238403409
0.008665932967197322
0.006513188515414125
0.005390119001762501
0.004210386422124533
0.002421167478415781
0.005263507782969922
0.005228716822400965
0.007425323992382214
0.006952791858781458
0.00598604284127408
0.005984033176824926
0.007671495302195817
0.008344483251329525
0.009130256889529132
0.010000860112733087
0.0026808883786323067
0.0065895221751383235
0.009797393506934536
0.009600111576357592
0.011037730776622639
0.006922430596723725
0.0015990464228408097
0.004372727198985778
0.00618404700616897
0.012572686511441637
0.013367889452485375
0.020138687122161665
0.023232503761726263
0.022670148699412165
0.02171547923218349
0.028639966965698198
0.03637237476038991
0.03216923717655916
0.03248243289767229
0.012044898290584067
0.01685722867158284
0.011277188961126262
0.004904350800204402
0.0025931010971294082
0.0059373819083022574
0.007877318060575886
0.00873498431574411
