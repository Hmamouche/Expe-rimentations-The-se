# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; PMP
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=14, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.17307317739255246
0.1804629230740497
-0.2711133473629277
-0.4646470995312661
-0.07188600728238871
-0.18869009925311517
0.029257109587422184
0.3236282674835333
0.010541608454268839
0.3494491948814551
0.2514258257311669
0.016627273139802497
-0.01844692468919641
0.021922428556207685
-0.03186518212814443
0.04021804872403306
-0.10910916056582182
-0.23468015351201263
0.09241069596524383
0.05261019121214338
0.0904123338527548
0.05302110180589814
0.052426187756824144
-0.14484641706516752
0.04726599910163414
-0.032896001865458664
0.08829919010388847
0.03060149300796158
-0.10312876865988739
0.14277524466704877
0.13624289491615119
0.13895588388289798
-0.04836429668824234
0.1027979728064765
0.07648562474862328
0.017834219187636845
-0.12568655485499236
0.13992318101469187
-0.14309986412468317
-0.0838556816696517
0.06275699264493885
-0.018284226773300386
0.06962640566586778
-0.07706400445211552
0.035826413553941956
-0.15909730881055043
-0.09394601412092549
0.11454151701500986
0.0563282552914293
0.09474783382529267
-0.10973280383705473
0.008614709535322312
0.012772942553524465
0.005222408274525581
0.04056101104456386
0.02886064487728275
0.06903968616990377
-0.06254969150644396
0.028603325190730663
-0.04749227292437632
-0.0014560183909593646
-0.14707083321824005
0.16570816739771846
-0.08208407987260752
0.10618727205607886
0.11052592333924557
-0.029983228839863284
-0.07726457845960595
-0.009428368136147312
-0.0638062206163699
0.05005301960510209
0.18037721695362186
-0.0066109897978007676
0.2142250381069549
0.08120818228990614
0.08704333899685754
-0.17132805466209008
-0.09156534521592767
-0.09328072154829016
0.17269216627339323
0.09269186575968606
-0.05473523090167261
-0.03515632517705826
-0.09422422590684887
-0.05867056924188245
0.02611634390063229
-0.07826623402119721
0.04683439208136396
-0.06315420766095303
-0.10114671557490112
0.0954562063900585
-0.036693233418829525
-0.09106759403660798
0.06282664389206083
-0.029597569120599014
-0.027624677854570564
0.10430172500118509
-0.13659864048808568
-0.12589393323768108
0.09465903606374741
