# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; LBOUT
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=14, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.011628893230921748
-0.01907195987066175
0.005570387920580137
0.004452513919513795
0.0011126770170428201
-0.007915652697694342
0.0053553623377248045
-0.005184502723287629
0.010541022416397351
0.0189954616912809
0.013414497713952398
0.006476641405108094
0.008458767262225601
-0.006016397157977585
0.011539531746705299
0.0031284220138046584
-0.0035561709537026073
0.003303113034923054
-0.002351406527170039
0.012859946980603821
-0.0037186272063194194
0.007257245865226786
0.006919409567965615
-0.00373346109845658
-0.00048371449384616676
0.008622482497326708
0.005806897629860058
0.0075809438869281634
0.003462968092713584
0.0020219390612857798
0.007579523238090278
0.010775037479848072
0.0040685110929354375
0.005069104942946815
0.012311272416274947
0.0094153102764561
-0.006761613964700855
0.01594702502854087
0.015550641235387868
-0.008350004650675263
0.007116386765287521
0.00744342369720029
0.00862412442702103
-0.00462217690851232
-0.004694603928912255
0.001828638384554252
-0.0013027375066702995
-0.005009014793533506
0.006327164119579648
0.011486029368063403
0.005954856651422471
0.0117270967596651
0.002193761797125094
-0.004418373962342959
0.006453603667886212
0.0028829388537018707
0.006848001042078518
0.003735116701414253
0.010933409076377552
0.008196682452817104
0.012304456220335935
0.01227889275668352
0.0070155029898854955
0.0031177526639656434
0.002104943541139751
0.009673503826378813
0.009790691170863381
0.002869843016007601
0.010283643895575338
0.008619383699813774
0.00833283315488131
0.01595758556569325
0.011380533883995165
0.00535352868481934
0.021225105884680816
0.01396621933757616
0.0035306005742615117
0.0025982264822615258
0.012358112930318271
0.013421239771480412
0.009511760150598608
0.018164165065607724
0.01957326148464246
0.001749900470874065
0.004875501360549922
0.013173827206352006
0.013473917726476891
0.006368981314646884
0.0065464362004494184
0.005908342558109719
0.0013073169866538547
-0.0004031864174300478
0.001718920177790835
-0.006203643012747972
-0.00200326008988973
0.004580971314478694
0.005229760318187337
-0.005155966895979566
0.007608614083843081
0.022480270565129058
