# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; Sfygm6
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=5, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.15868001415806515
0.1556172430254712
-0.04590725292288063
0.15695923520865696
-0.07447211189884896
-0.014100798376958726
-0.0840993491157821
-0.05382767606126503
-0.1223578721292069
0.008540043743527875
-0.08780189952397349
-0.024406675003435532
0.0202106391798883
0.043651876469070365
0.004537225706591454
0.13101424451647598
0.11895505990521431
0.0034871690189149083
-0.06503726857253932
0.0774945527305049
0.021989681985962947
0.013911078732226176
0.015604030875678472
-0.03459197074138994
-0.11136100323391548
-0.0924710354113619
-0.014626950133046948
0.030278925264143264
0.07474801894181052
-0.04858046407532775
-0.030357372045436138
0.05382665206941413
-0.003958311813285723
0.03450030748265382
-0.006583402676432877
-0.003851877983871429
-0.08202083782932082
0.020807920094567667
0.07936154576678589
-0.03611482540510304
0.05985507028469486
-0.022432269398429665
0.034298006364075914
0.11987556859970526
0.03808344305332082
0.007725625697105207
0.01957483767073028
-0.05323271869672348
-0.04592499319238909
-0.08251889091802302
-0.049113501413599076
0.06873152561793262
0.03696056108415993
-0.07339591247374122
0.047701615482703
0.0014139484380608358
-0.03214182822161218
-0.01866261685495667
0.011881718969973535
-0.008246749312329719
0.0006271417489443036
-0.05041216937694091
0.015569012636993059
0.07597859339773805
-0.013321780229713361
0.05506932863318613
-0.014511340347455652
-0.04808364715428965
-0.008581887403351128
0.020382418118508466
0.03148360166195198
0.0039442310698078985
-0.015616739412274431
-0.010854818734019328
0.013993633671184377
0.019191042528152177
-0.18028770953599227
0.034907262920186186
-0.040671027175675625
0.02130301056308176
0.13839350536237624
0.0006133652842489831
-0.023136562962731384
0.010068448592588358
-0.048323621812917765
-0.010852638954254177
0.0490449476908654
0.061973255703293935
0.0008218875189334538
-0.013681020945826426
0.016503716497105705
0.027585810306436045
-0.04326624872218379
-0.03442972059242134
-0.02809258539787137
0.008720340626241633
-0.026799465071614716
-0.04413261400868441
-0.005926797981920312
0.041757957227059994
