# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP260
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=3, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.010979348127713813
0.008883592701812874
0.015362097533628622
0.0076886634962025505
0.005403363548822981
0.009433283719757844
0.008744022406415718
0.004685191752447106
0.001894672393299184
-0.0022198685790338502
0.0060750706779969035
-0.0008934220178304457
0.002097196651914393
-0.004340431553765558
0.0022129082831886145
-0.0034551329867214906
0.006436954278681152
0.004335233797362554
-4.067277534686414e-05
0.008724721186850179
0.004480708439322479
0.011989618322438014
0.0035071508669932963
0.0012278386256416149
0.0047978495498806365
0.007387724792693081
0.003509052242274835
-0.000385432279088349
-0.009490341273723437
-0.002962877704216738
-0.005073810972099762
-0.0012239840548290077
0.0024920919789073234
0.001207091460562091
0.0025226178048062434
0.001443923673730953
0.006609638055511335
0.010881580984316006
0.014959354679628202
0.00826308095191379
0.01241291466027579
0.012201880019577987
0.01925050198151822
0.014279777887345203
0.009848948831666766
0.011135028933800892
0.012818016581902443
0.013651809074582705
0.015029312611507561
0.010311505130499141
0.005760864605157736
0.010485861062222842
0.016925720644218132
0.019111847265432566
0.017580146170496046
0.02061752660399593
0.019778664728773217
0.022972622310963448
0.018365332199452036
0.02616420751622605
0.013489287521982987
0.01714758445979818
0.023402914946213632
0.02173079513077933
0.027668515741285524
0.03012763912084238
0.021839707976984923
0.02081381748660722
0.019394325400239686
0.017621629734174256
0.01013088746943958
-0.012763747468275525
-0.025162835517968964
-0.02805765641186725
-0.019127663750479994
-0.009520996264842306
-0.008949625313906662
-0.004404974245193807
-0.002122486302736152
0.0014339885984987618
0.015138681939995657
0.02457460514994433
0.011521103251331466
0.013269457532176135
0.011957075376997814
0.02261345369028457
0.020582182657335347
0.02110612063849549
0.021712364805157647
0.016385815211440332
0.026365034157555277
0.01652246612167118
0.015082146633724971
0.007346154250643952
0.0018856101198093174
0.0061719561883477195
0.0030853728570375445
0.0027803769358473
0.0026109679937893738
-0.00027940272996515103
