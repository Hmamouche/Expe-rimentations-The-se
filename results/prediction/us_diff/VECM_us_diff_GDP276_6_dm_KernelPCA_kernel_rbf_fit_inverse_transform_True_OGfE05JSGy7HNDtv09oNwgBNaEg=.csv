# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP276_6
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=7, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.009031885841144336
0.007461248783566088
0.007685628669326301
0.007969506098692757
0.006501667731271804
0.004624297670040925
0.005119689190479222
0.0052360169660366895
0.003750961860837028
0.004523204001550828
0.0033061353933729015
0.004407970128397952
0.0037891635351922598
0.004145628034484722
0.002229941233181959
0.006275352407668149
0.006822878695694468
0.006842262285123545
0.008242804787085738
0.00899698553661487
0.010488656634778968
0.010952189168454711
0.011622078271856455
0.009612238387544575
0.01029322404766035
0.00968715118117767
0.010271648733558849
0.010182758298423392
0.010294641213793827
0.009292264128441323
0.00800859121868249
0.009348088341491301
0.00816219054284948
0.007996817217793209
0.007192575512188915
0.008644027675013048
0.008229628136393418
0.00840468157948073
0.008670471625255735
0.0068089342962032
0.007177866759945207
0.006175130561964066
0.007985537124602123
0.007237664393548124
0.006978192394103188
0.007613270049864203
0.007349645843840514
0.005602457582643831
0.00500802607637787
0.005010156468556795
0.0036374758775372077
0.006020707574439957
0.0046150459348889665
0.005253658285916426
0.004422411743571967
0.005003250988845553
0.0044983891408729906
0.003685413810163551
0.004499665021374768
0.0055509410372466365
0.004895030185334965
0.004700865232730972
0.0042705703859549915
0.004513589518969425
0.005225780526064943
0.005873008102895889
0.005235709792036183
0.0061213870194040555
0.0065817010998947345
0.006489829504479141
0.00903089656627114
0.0077796938203283685
0.007672424949592509
0.005086920502330639
0.004088850779764725
0.004943262866254033
0.005427222307771247
0.0065542324810175905
0.008300831595080905
0.009858534742646528
0.010272418759126814
0.010935317257672947
0.010337110951113651
0.009447772002411042
0.00863683764431864
0.006633467267501813
0.009637626848647418
0.007622407657609404
0.008150048399001214
0.008400675470029243
0.005688088722358573
0.007516748637641568
0.00726191861730834
0.008355039781975252
0.011555857114012661
0.00838509810769933
0.010326341410130613
0.0048338878472245035
0.0057859860223438975
0.005534666136727778
