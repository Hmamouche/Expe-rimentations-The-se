# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; FSDXP
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=5, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.022093409253497204
0.13062706791161519
0.04996987756828174
0.11956628204727712
-0.029233833720174268
-0.025430161069031693
-0.07452847943771236
-0.04872043561861155
-0.0716677811582394
-0.051484357979719966
-0.06089125814902517
-0.03678784407949947
-0.0219580940516774
-0.02146307727559751
-0.04090755653624179
-0.013924635563642087
0.04191321703104168
0.04497884879716456
0.02884060511101939
0.012950636022538157
0.030041041521999802
0.03820907644285546
-5.142476670010358e-05
-0.01788777766517291
-0.05489877483832268
-0.027247664482668348
-0.01442816600143462
-0.003538981228106723
-0.0061271400610506035
-0.026189004364754825
-0.06991193150939229
0.019623191298296733
0.012259410293734924
-0.031766371799692945
-0.013221227973120135
0.03120117005153126
-0.013859695902017344
-0.007127214922093322
0.013028336605199944
-0.07859714565675159
-0.005946741129897464
-0.024079304712077712
0.059243144777990336
0.07040454492707571
0.018041376453845362
0.029495040169899636
0.003281961916949649
-0.0573261193505348
-0.042806101971004554
-0.03971211807504181
-0.0440094994042005
-0.0029412384542085515
0.006374365170603996
0.002739281857350168
-0.010477952824642915
0.01774504506574091
0.0006728257004798336
-0.011727895317861323
-0.011476330184341152
-0.02927235023645413
-0.01945167439805242
-0.052286959011517975
-0.02691698609924977
0.03367800495438339
-0.01216130700126105
0.02519350416490003
0.0004303739926320828
0.00926392394758404
-0.0352867467550647
-0.02887987703178915
-0.054180023733503835
-0.0301925960595093
0.04220267738177624
-0.04786867650975846
0.01631427217922878
0.02203007749867327
0.012701784067179893
0.00644853105300746
0.033645189464983113
-0.0028516892698969946
0.042065450437151854
0.01330085055165123
0.040699365739295036
0.02788950881954521
0.025908289058025856
-0.025346482609246396
-0.00962576344646597
-0.014597636839778322
-0.014451084004111363
0.00412731861713527
0.008392620566061182
0.024514797287596424
-0.008838634173332012
0.01453175034731416
-0.014441367036956854
-0.004293507841376372
0.011500264446145384
0.0044233974119955
-0.024892200042462044
-0.006569200259778825
