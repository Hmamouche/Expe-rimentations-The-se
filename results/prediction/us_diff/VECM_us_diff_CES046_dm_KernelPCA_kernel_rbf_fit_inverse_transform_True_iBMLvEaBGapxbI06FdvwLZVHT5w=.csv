# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CES046
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=15, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0048936854902579124
0.01333707395219694
0.004195036367100748
0.005825778541316096
0.007100233694171671
0.008702178567902539
0.009035160744707242
0.009291379695944246
0.012977776604643092
0.005928979577174679
0.007126093677993522
0.005031231826196139
0.008074189478547586
0.006885610274208989
0.008541921282215398
0.007956527849999393
0.006196490251593805
0.008095581235085894
0.009662499936940148
0.009955716734537559
0.008227165694352149
0.01225585684620475
0.007967006066649358
0.0072923781000343284
0.004746576229575304
0.004710810305132016
0.008474423246529592
0.00563761140879788
7.479205487771051e-05
-0.0041284876829024535
0.004329417463630249
0.0026388744142566136
0.004366307634977404
-0.0005723579608243119
0.0006768393945675022
0.003927371736442868
0.002414039006565575
0.006217333111427497
0.006737611202373746
0.0071852755487453596
0.008848789982284787
0.008133505997904139
0.008441642470212578
0.008963124662232754
0.00954711232490228
0.008544031174707688
0.008901605444712971
0.006657669003578003
0.00632178694005698
0.005566496027181933
0.005745294383391041
0.008502691383264071
0.0071889486005756965
0.007445194126854238
0.008777011831788797
0.007650373318659054
0.008758689994016126
0.007708010779654964
0.007742722394103206
0.007710361627222489
0.00883899471484876
0.007828959203170298
0.010003730604489464
0.008368275299496658
0.009717253738976039
0.008980311600484295
0.008291614745274522
0.008527004282549797
0.005578906535677839
0.0029776716394409363
0.0027859363734427708
0.0009826165310012102
-0.001981898297795669
-0.00403155339624364
0.002323907023268395
0.0013630139265867131
-0.000565553723131883
0.0013962730336284318
0.0033615724422381716
-0.001531070878440757
0.003362750693059824
0.004339915728126028
0.004415929478377405
0.004464273409016824
0.0041125591532349915
0.006472876148048704
0.004708316305271354
0.006402632545101289
0.008975493017267187
0.006299194449627861
0.0049542086013805746
0.0067166123307733664
0.0037485147722462766
0.008028626202568086
0.008297581361361201
0.005280525568704619
0.0021530584417766008
0.0009425002482337623
0.004778081944435868
-0.003654096710288004
