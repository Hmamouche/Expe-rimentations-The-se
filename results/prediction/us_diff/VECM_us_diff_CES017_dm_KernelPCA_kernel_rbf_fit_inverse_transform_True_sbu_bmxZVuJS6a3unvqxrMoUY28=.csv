# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CES017
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=1, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.08018074921867058
0.05541795372030578
0.041318713616335864
0.033395198789309286
-0.011326852506506519
0.0003538863986523801
-0.006431599710543466
-0.0031645519539610528
0.0044892606840653965
0.008508202452194248
-0.0025685222383021525
-0.012441133412881352
-0.022861082476233342
-0.01848332424042457
0.016785213131437573
0.014123844360068116
0.029219068456142923
0.007813130798317976
-0.011171332570389094
0.017814288755800732
0.005872576493540333
0.024213365873657706
0.0010280583717956744
-0.027733245652817533
-0.036534694500984885
-0.021924147244498052
0.003340267168009188
-0.007535297557207766
-0.03236966223247484
-0.06404895645528165
-0.06731579246197356
-0.012263312162967782
0.012811431073473796
-0.016535179048334084
-0.0016753572151152565
-0.018271862199024314
-0.016842800416102092
-0.005372289170959893
-0.0010122103036767534
-0.009377226374564066
0.00383120182064869
0.021751119744568306
0.030276517074900665
0.04772121193598132
0.022288494156435208
0.038116955223534844
-0.006575707227004629
-0.02895560974054228
-0.005709661724900177
-0.016364127061790426
0.012107664860213158
0.03613269702424058
0.016823313119053742
0.02860034969052243
0.011565906293278763
0.01877647016547437
0.023473112805137815
0.020509208464077566
0.009068475285972334
0.0010295305611525349
-0.00849888571249836
-0.006915937021023915
0.01663035973978116
0.007568662277911162
0.017143479405938994
0.01536591056919875
0.0024475661050182146
-0.014900788952902177
-0.020686102602701956
-0.029742045852150473
-0.04369066166555912
-0.034457951123617374
-0.049407390434583566
-0.06806221469259356
-0.012404861107316792
-0.036183527304582117
-0.03271639259826885
-0.04761413711932552
-0.0460590656331226
-0.028074761783659904
-0.005836002007403975
0.019193797826727577
0.010470838053360876
0.005430034605772265
-0.00855559514978943
-0.005267267962037344
0.0028050648485812655
-0.01136940744299229
0.012002391564477787
0.008313858959970222
0.01321291246314841
-0.006646862828832394
-0.015276465726480495
-0.02390066733763933
-0.01275187424083573
0.00014766692477443397
-0.028301738377366027
-0.024523279297751017
-0.0403469127587851
-0.028431464403191994
