# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP252
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=15, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.0033255766666304134
0.01006385572025842
0.007485443105042353
-0.0010200527895382425
-0.000884980957792659
0.0022115535751439687
0.004493708593630828
0.004406931919364558
0.010847627273167
0.010477586401648947
0.01458517527130358
0.012457614907604246
0.006056766530327927
0.0007649557272394916
0.0029997858919381163
0.0036006201597038896
0.00551540662290669
0.012115082847578585
0.006873066176865367
0.0072184267752576055
0.004518279950601521
0.015341200987281686
0.0001004141828569035
0.0015625996494329575
0.0047429292715580815
0.006219395506523201
-0.0004469540451629742
0.0049049011017276095
-0.0008979075176649605
-0.002920918568128971
0.009254920569215142
0.013119017936193507
0.006007492969487936
-0.0027947611615394253
0.0023720781773264085
0.005246220446465303
0.0002712103921632519
0.008478921404249036
0.00999943466436858
-0.0030617027719195564
0.008504353372097517
0.00805859598306627
0.01113122043269306
0.0016648899228412875
0.006301134231901812
0.0060988203343108624
0.0035166323101813654
0.007514760128708282
0.006877083709566234
0.009168346379120782
0.002619606548735165
0.004915731710841272
0.007171165756060936
0.0032405188352013347
0.00765980799284448
0.01017161042295403
0.008869851666581
0.007921933575276579
0.013345874648811564
0.008811411515241143
0.0114268744849475
0.011280789202216918
0.011457572719829246
0.007900826700415954
0.005974780220459844
0.0132806363214555
0.010747407934425721
0.015591697812003123
0.010022200407956004
0.008892987501266294
0.008086188111266926
0.008463276835042496
0.002505548180063339
0.004555406257647889
0.010545444794258747
0.012473488016706736
0.0027489014129926945
0.007797170479466251
0.0019267766034853323
0.008523273270735203
0.009153044034873154
0.0078378198910856
0.013149315100221468
0.005571443388678419
0.009653413887776633
0.010713639424208637
0.0070165615090361415
0.007828926998315125
0.007975884297755356
0.007097677100353201
0.011646103162941141
0.002346101581634459
0.009371090286972455
0.011927927137073618
0.00895245447099101
0.0070734586652697875
0.014145288920246864
0.0021164906127641575
-0.0012674470903280386
0.007453352068658299
