# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; FYBAAC
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=5, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.0531355195003415
0.017183767906131023
0.06346040683323101
0.06783282717632787
0.003523324409681297
-0.055976201695498884
-8.171243058071112e-05
-0.06635315925845882
-0.036518734926760985
-0.060553964457225606
-0.06758470495993182
-0.03319824377146333
-0.049834459924573374
-0.013835757604132342
-0.04489249197722035
0.020504898782139284
0.03074320214297451
0.0438775229307805
0.02627825003563436
-0.0031383342142584894
0.0096759022039487
0.007376628246031525
0.0109832258309332
-0.03724495770466939
-0.02649682394110319
-0.023121859571171178
-0.00960584500096328
0.013641349858507755
-0.02445854196840004
-0.018794604529313606
-0.006989979417772258
-0.00021875538667675241
-0.006706769486411818
-0.006876679997481336
-0.012992483837020067
-0.01708711257018692
-0.03212415964393131
0.014608355144496907
-0.03022975590322704
-0.033865401401450876
-0.03170739842775061
-0.018202725513654254
0.02118722168670832
0.05263397659862342
0.024342865171016005
0.047608933071468934
-0.011688442032718554
-0.030807703676447837
-0.0231264801412118
-0.029102743065503985
0.0011357603274883528
0.004183473976270177
0.014403788411499849
0.012458785957650473
-0.0015756787591865223
0.012414895554543608
0.012393812358381166
-0.008821535229583195
-0.01154818781237084
-0.020607900232685057
-0.01767178968183377
-0.025137993574332336
0.02474763744352986
0.017477888036109668
0.01373119285665009
0.03798163242406332
0.021856067147503655
0.01157244973702191
-0.019565751754116057
-0.004807049682765376
-0.048059155795560735
0.011459906385651582
-0.009322656328322671
-0.0270778499832995
0.0105208989105686
-0.016140101858946525
-0.028651777826392215
-0.013028954248902897
-0.045236972205990454
-0.014187291127078823
0.011875557891648857
-0.0030658852312087518
0.02782176719939995
0.0043549837028893056
-0.03817309449725853
-0.0023292956800241623
-0.02328923847692997
-0.02739378340425523
-0.011080869478971613
0.01248618630457091
0.016011818447122114
0.023193244891404848
0.005512712726368728
0.004230269298418798
0.004511916966215008
0.008047853026469381
0.022010324564525435
-0.012953065559820169
-0.015568879200439794
-0.003367508812369643
