# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP276_4
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=5, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.011167302747536398
0.004965664119385057
0.01722161313543745
0.009763844474848129
0.007922393145334376
0.010462427644311162
0.006050932393143763
0.0058435960803319125
0.010762432073236513
0.012911044850147659
0.00907204792079974
0.009590051233904804
0.00553570339204773
0.004246273272392854
-0.0004090479051196863
0.002070298944435253
0.0030810236435233574
0.0033980369376745033
0.0016930063854882914
0.00030616209446885853
0.007794973324046189
0.003620854829619891
0.008623593769158494
0.0035526157249300356
0.0030411160266801463
0.002825029355777846
0.003739359726408919
0.00623577333796275
0.0047967804301677665
0.005510752582976279
0.007388791455111533
0.00465235469061219
0.01571704447644818
0.012475122463403703
0.0034447163299440244
0.0036599075892089156
0.004023593172462548
0.0036343900693436198
0.00781882440372895
0.005039295216553819
0.007101035617815237
0.006063368742236186
0.005046482195714614
0.007696405231454013
0.00772081178008719
0.0037529395411553305
0.007432156832587893
0.003668412025526614
0.0015630742034276823
0.004129245164480301
0.0014575643238023306
0.006295904842735844
0.007651804894222312
0.004457094519273318
0.005227691359334772
0.0027990557045835833
0.001944942875269479
0.0001310478086626154
0.00045941673866543723
0.0006438120684646731
0.0023950195788307416
0.0025836226289334494
0.00198511581779884
-0.001822855525873219
0.0002688028424588044
0.0030891115979780662
1.758908135662731e-06
-0.002733841552773986
-0.0011742876968896196
-0.0012863872397916262
0.001608739459164187
0.0001268653928874502
0.0029742567090517793
0.004931846306454185
0.005366671319422462
0.0055752557629888885
0.007880963329566098
0.007689769679556851
0.004509446715704613
0.005553975386502521
-0.00031511415717260416
0.005566660206814065
0.001131273811721492
0.0014329774247268715
0.0030939700783172834
0.0025870514330905
0.002648526020161852
0.007274780684491246
0.004350349726803559
0.007485168537477278
0.008425868141556237
0.005454111266780936
0.008193190827340331
0.007481437637390657
0.009450144244054362
0.009208611480616025
0.009900103762821614
0.006989963772062098
0.008540162508175214
0.009725207948609208
