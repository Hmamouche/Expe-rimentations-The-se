# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; IPS13
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=7, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.022754092025722907
-0.009945593000926619
0.022907592794398475
-0.002021181935786015
-0.0013893223044496314
-0.0011343058662240113
0.014738653503621302
0.010805446320033253
0.009374600551974232
-0.007616373173883515
0.011800042120070195
-0.005129462185159556
-0.0005686283108833844
0.006351783321080546
0.0192291136399832
0.01727404965540286
0.012262942858488349
-0.002715372520083753
-0.01118360920263111
0.019048727718451154
0.01799150661028582
0.035651946817420135
-0.0014499454885443202
0.0009950535182070078
0.0035415024282303862
0.003978910315411502
-0.007271716704471216
-0.006477053936980717
-0.02119978378038998
-0.028774920486705463
0.005463766115282841
-0.002363127957852781
0.00810082622324259
0.0063147507181749996
-0.0033680650035419844
0.006501714003678434
0.0012465979874006928
0.02664670452969817
0.02206303803668847
0.013328142783686853
0.023326275412490775
0.02016532884791635
0.02648922583902406
0.012284398204261287
0.008295060578580314
0.015703535340666472
0.011357398226830476
0.008061200366204037
0.022831722968288774
0.010265703682252127
0.004669514247526329
0.0055246678781151835
0.0035339980309024403
0.012917255119674023
0.020903130182634455
0.021104392450356238
0.01351876599597553
0.008030427238254381
0.020460651595421674
0.023429094926777673
0.015650011550600036
0.0055812824892718955
0.00870003114356421
0.015505727259968013
0.03299541222374042
0.02862090075352964
0.013092235158420451
0.011527390045457244
0.0029020175814379002
0.0016110466422840312
-0.009071780544389167
0.0022243185904687423
-0.020603411916633063
-0.0220231819876151
0.026116439782193024
0.00762975419546491
0.001645653192350326
0.006494046084189693
0.0046125505614811515
0.0327452056735376
0.029875817868114034
0.016792431481280807
0.01218926927694756
0.0018782840207039343
-0.005076509555102459
-0.009179463862965715
-0.00877259395713666
-0.0071025812976157066
0.005944793685299456
-0.004980477160600861
0.010293715629486083
-0.013914286484670692
-0.012136435701426303
-0.00183587625059199
-0.005352073785464574
-0.003727661978611365
0.00024113012980490857
-0.016377143924979676
-0.01185127689667147
-0.007539956463373929
