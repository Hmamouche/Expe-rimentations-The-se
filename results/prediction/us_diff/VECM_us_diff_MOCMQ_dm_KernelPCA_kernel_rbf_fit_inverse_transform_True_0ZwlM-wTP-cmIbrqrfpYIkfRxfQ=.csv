# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; MOCMQ
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=13, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.09417895948044339
-0.03201838102953307
0.06791039541410976
-0.03847852715306604
-0.019724866687705844
0.020113652963266032
0.03421432308582337
0.02443230326488163
-0.017171445403653694
0.050291358261851896
0.06408892001066493
-0.02107624078966589
-0.0357086806367896
-0.030657992568959656
-0.01642288065003657
0.02111003019794459
0.03451453270439661
0.0023144022635157545
0.011612677736905452
0.002241307659140838
0.03594342931794445
0.05133980936138307
-0.04095581014255413
0.003257700312446425
-0.014675458491055206
0.02332685099521977
-0.001810464356161428
-0.02071722062999073
-0.04033659250604615
0.004046293297605614
-0.03694416423334528
0.0270882509207786
0.03218357824326303
0.008505918444049678
0.005669645807809071
-0.011513136937042865
-0.00711699349729825
0.05078644974698489
0.00953828479244301
0.012589869721054879
0.05438331499884086
0.006433161741117321
0.02990704748495085
-0.025707787134703407
0.020497099789117044
0.014996597668488383
0.001932001112397028
0.020188774579729292
0.004737113107664205
-0.00818280653588487
0.0010929861494331122
-0.0006453507179400809
0.0029892864584470605
0.020668583465852403
0.028621606925378306
0.023585215542501935
0.02554983358651814
-0.0005166271701963782
0.018604771950756188
0.0053390329105466
0.004996448597728067
-0.022944465154144247
-0.004590457095322779
0.01375266847610759
0.028670161908331982
0.026029902972307714
-0.0028611652336478503
-0.002332279802849302
-0.025373828265586474
0.013136915802256982
-0.016289025180358473
0.0004267593532821894
-0.02808107565605035
-0.03850618116220026
0.008979183179960631
0.009561414630530216
-0.0009410297647879651
-0.006385591171971943
-0.024694806412644932
0.030758015388809533
0.007814151359828292
0.026478746979524043
0.04699932992513123
0.006462106054579192
-0.013713820920287131
-0.01718938790421205
-0.029723232606152398
0.004935013122212641
0.012925648142421782
0.0105257654462996
0.024097875282618433
-0.004330155203705644
-0.020899899477955126
0.01362184653396684
0.003907703900285251
-0.011355669667266876
-0.0042322424677552
-0.06004567006957326
-0.010186739466678307
-0.008533747078215838
