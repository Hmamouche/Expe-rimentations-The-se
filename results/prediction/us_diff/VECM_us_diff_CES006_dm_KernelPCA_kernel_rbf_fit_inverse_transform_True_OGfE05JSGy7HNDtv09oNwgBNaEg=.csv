# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CES006
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=7, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.0361238171897215
0.05250451249544633
-0.03312122467754888
-0.000384254480312117
0.011589599521724742
0.0027153910591615066
-0.01681224577570277
-0.03836902599148096
-0.003810727216361491
-0.042887609572495655
-0.050789776538544176
-0.054743671713725045
-0.05033140335305287
-0.03399954343008331
-0.06560446355389576
-0.03849740091732541
0.00568417451691626
0.019240734220046463
-0.033566177875420544
0.02825035061071335
-0.017512210067647457
0.05018822739824913
-0.020226103642715668
0.0027979568353456684
-0.01620338663504624
-0.01380114010853655
-0.010000286449441766
0.009972690377637122
-0.018438363951206294
-0.025967077099338324
0.011047819738980747
-0.048261223634702005
0.02088354452584426
-0.000530192895918026
-0.029394430957952668
-0.025040156647918654
-0.05233146087613811
0.051333649601205567
0.020823786539502585
-0.020527683607379596
0.03072655037242634
-0.044779298735492086
-0.017114527683996707
0.04682857900908098
-0.010703493132738698
-0.008454835168085055
-0.0028071199975152096
-0.022518115612171215
0.019287902730007616
-0.015451588107185357
-0.02974346805887758
0.016018397727198604
-0.024394729022237903
-0.026067383118593274
0.03919656750976201
0.031618893589799135
0.004700133386192428
0.001439005810033055
-0.0009668579799053702
0.01475292072926182
-0.02187922202483467
-0.025272941528517424
-0.023135926177306875
-0.01425702984498085
-0.015261635799888143
0.025441204937359505
-0.027960507833491768
0.006580790544553952
0.003507901999972385
0.007846043125248869
-0.02045598859483895
-0.00013088082852730524
-0.020967345899964206
-0.04030328286062104
0.04539483656390507
-0.003361100773698361
-0.050517658235690585
0.012287512815686907
-0.007904322657675922
-0.011153283859076575
0.010289405496676212
0.005810968110129433
0.028373817103006613
0.023785527709328916
0.020181354188762952
-0.02338167747703636
0.02657882216423167
0.01235928221601439
0.01134975756269508
0.02517183967826852
0.016338318757963946
0.0351694376345127
0.036058836413722234
0.04339998700602979
-0.018779885881452706
0.03699228813662475
0.0050584796658299696
-0.010450125731052928
-0.001001180771636012
0.0011875583087143995
