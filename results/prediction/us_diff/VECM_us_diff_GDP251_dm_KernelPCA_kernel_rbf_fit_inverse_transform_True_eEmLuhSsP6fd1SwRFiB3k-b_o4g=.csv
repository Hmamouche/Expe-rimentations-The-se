# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP251
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=4, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0045143121749311975
0.0015888876797964194
0.010204562194720585
0.007225575258417665
0.005619548363385907
0.006796614855145792
0.013234956906796356
0.005849733616129502
0.0070764460360260885
0.008963149625988326
0.00975250498152284
0.006146739252622015
0.0019885947349442845
0.0022089343481498844
0.008142134262763424
0.0041132525509409625
0.0037013683599837295
0.005738460557302937
0.007168397277151919
0.009826114261141872
0.007959477808672948
0.008510330909920743
0.005900483425697756
0.003611943228145573
0.005306873009260811
0.007256935515483988
0.0064415497078564666
0.0037415562658824095
0.0010356143275246665
-1.6280202419809077e-05
-0.0011728946101898106
0.0019616942087362127
0.004976395319835792
0.0010500689232996745
0.004159040254442356
0.005511036222533128
0.003137173283033597
0.008621136349905344
0.009349143296622531
0.003652870890265387
0.005718863361106527
0.0071005094252403434
0.006946358053613854
0.0066034082950059214
0.007640236500000635
0.01036494728692291
0.005127789817601249
0.0035471583413142055
0.006310325663300228
0.0054956957568781314
0.0042261849533322
0.008607413284141373
0.009311088798591369
0.010375396002237787
0.010431334042948243
0.00944839729749425
0.01377606382219189
0.010583277289826309
0.01055226823131203
0.008207224667243228
0.0059837425391364345
0.01064774948490014
0.01300028521252128
0.010659536929042106
0.010019008335270222
0.012790219164607104
0.011874419373965758
0.009029938991547144
0.011068434334353602
0.004835044060866649
0.0058107390536850986
0.002201077099249764
0.003416056933159798
-0.0031450923112396898
0.0065116506631629646
0.005646326831576069
0.004935342174521995
0.0031503323734435604
0.003150605389058896
0.0035990421270477076
0.009142113167546873
0.015250157199823533
0.011524984314003756
0.008848048076495117
0.00716668010613776
0.008367979390474194
0.008921459639356678
0.007997914495540595
0.009393361843090387
0.009171991907392464
0.009120819713895702
0.006762745901874817
0.004799221977136948
0.007343119456504256
0.006940444837070339
0.005674733599739418
0.0064930192120732895
0.004850469892718895
0.005715998482942824
0.00821488753911415
