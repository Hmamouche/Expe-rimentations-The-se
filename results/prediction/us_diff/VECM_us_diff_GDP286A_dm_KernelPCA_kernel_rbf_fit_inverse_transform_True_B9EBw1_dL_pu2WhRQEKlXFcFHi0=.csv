# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP286A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=10, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.006130430360458197
0.0042279524881449464
0.008539784807829558
0.008797941179006896
0.005173790923112261
0.005377987721754416
0.00518844822763366
0.001433644207916542
0.004063199985023376
0.005961149932440334
0.0021879736003110883
-0.0003899692615986875
0.003188168908159455
0.003943244508406743
0.004730493099070721
0.007345311377866803
0.004111903879403202
0.004666782513764454
0.0027422222213855244
0.0031298787598483444
0.0021532666177696115
0.0043441929438232775
0.004266295537692028
0.004179985609082856
0.0033901949522010567
0.0057249179765749125
0.005178896433776189
0.004523345100137858
0.008384251463376062
0.007874092160430186
0.0032366336102521978
0.0075090218888628196
0.0076283295287511285
0.001750128865377798
0.0028561336252445405
0.005581276460555659
0.0027852299403626378
0.0031613743233569244
0.005098744476678338
0.002503823056502672
0.004788605934965226
0.004146587089246712
0.0038048259860680588
0.00645300642967184
0.007286682293388088
0.002918485686565898
0.004818392833032325
0.004151407176714236
0.005074461321324938
0.004870937635785582
0.0038170226857228346
0.003251292416596153
0.004268243087983419
0.005019313008257914
0.0013200817212549662
0.004422611799925407
0.00387298210007958
0.004095937514151666
0.00013290595244076753
0.0040375095476395065
0.0020995296211294688
0.004229893812034165
0.0021984459429551413
0.0035408874147618116
0.00738988105263898
0.009343427397258713
0.008120344383898817
0.005971154988495124
0.00753455535630323
0.00842899096479953
0.0050829795845978385
0.007460286117280765
0.004957910538755466
0.0029389416857922416
0.006359937188807795
0.004511171467861885
0.005864634637463104
0.009502145263693335
0.007203462654372183
0.006738453864117898
0.010351322922746037
0.014106024672531773
0.0009262194664590483
0.009880139855566579
0.012003193406961134
0.012683666658479285
0.011104942025553042
0.012507157438309288
0.014296589689417374
0.014910471833355641
0.010776506837615333
0.01597032366866287
0.009493790885701769
0.010557401067788592
0.011182907858834126
0.008549019696006377
0.012984618201970777
0.014503068122142453
0.011526499845717644
0.012601255548894685
