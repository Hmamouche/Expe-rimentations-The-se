# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CCINRV
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=13, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.002327972268088876
0.008223828482143166
0.006412536496070345
0.008638399694257936
0.008545101205531026
0.004700406468211983
0.010616874131638516
0.011671558696430141
0.010006634839151141
0.012597483059778317
0.00789116744166973
0.0069390302536870355
0.005839652915234968
0.004460936365865561
0.003280999920965031
0.001005397946934474
0.0024756972533692793
0.0060342906911550215
0.006743430416547251
0.004348082370973691
0.0011587496671570923
0.0031645656277825905
0.009160302019228631
0.0036791052166392857
0.005915614731680095
0.0035398166869520476
0.002866754292038239
-0.0025291679113746716
-0.0013614025615869046
-0.005763557605367363
-0.0016086307446873827
-0.0018173461200896844
-0.0025892504120369835
-0.009882114261014001
-0.004412792032424467
-0.004802689548653998
-0.0013785154270232632
-0.0015709492810771191
0.0025105233242141587
0.0018478199996755389
0.0019620885432604512
0.00647280362239995
0.008886427704418337
0.009344704461034343
0.010731023782904426
0.015927223364203383
0.0132643200275937
0.015400801645033642
0.008753452796147148
0.011405698183111889
0.009076020442507
0.008521800151098836
0.00836825436246607
0.008005968113730697
0.004377813475758699
0.007427618909944656
0.0058793934414964055
0.006537222512154034
0.0037263683412453626
0.009546031585468935
0.010082626410561183
0.010935339223666697
0.012780068079054251
0.010382841021098998
0.011223216656978589
0.015491034225648534
0.01238965876418827
0.011103108746765497
0.020226733023991857
0.020935283746809547
0.01923610075947596
0.018838821013021294
0.011138950810677414
0.021272053108139104
0.01749973587673061
0.017260466085403273
0.015572894874236323
0.014184703950450982
0.014900229942028624
0.014039412901178914
0.013613831792729663
0.014437036719174354
0.014180882165760267
0.012379494025136212
0.01186152443030927
0.016130282662631196
0.014110611052080247
0.014693301123467084
0.013889674461881182
0.007513255680016318
0.007690709992775697
0.007372492571379976
0.00636339032073315
0.009868904899552536
0.0081285469044005
0.008473374714634215
0.011263210277078712
0.009911960084968986
0.004429131140845051
0.010530043452099503
