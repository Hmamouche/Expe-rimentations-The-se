# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP252
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=12, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0038136012062105398
0.0069691465800278615
0.013091288654627154
-0.0003156261721088422
-0.0018294860943584863
0.004666360131475369
0.006925500409035319
0.006880320499789324
0.011098978125152616
0.00479905842421364
0.00805461451638449
0.008196346820642254
0.005633257522349563
0.0033023678626411023
0.003270529984441571
0.005136340087781424
0.0020409776230397563
0.007567038530686388
0.008015594754268215
0.00614752003076737
0.0071992282204310825
0.01664113697813679
0.0021893823893696937
-2.0480940373905393e-05
0.005446870444676348
0.004889044319448864
-0.0005889464964773408
0.005523322147491867
-0.000332107287736334
-0.003512759893193896
0.007600749719983002
0.005548300638472028
0.004392282077196757
0.000128302580138236
0.002901440214719675
0.003466235638256464
0.0047581450941041594
0.007660041130936975
0.005830899322815582
-0.0011276697802589176
0.007924243979362741
0.007442931951576662
0.011702483193216848
0.001904933813041118
0.008254693726126736
0.008145678499248804
0.006510016774125539
0.007114396456005412
0.008137361832476556
0.005515727892057621
0.002329623922215956
0.0023112998238530784
0.00805671957971668
0.00544044519390577
0.008395025522379192
0.011578558930835658
0.008690017899184322
0.006783159496940394
0.01280502107195063
0.007686202288352773
0.01081736248948242
0.01244237734820826
0.009958782046414679
0.008264425036315075
0.010031794678731863
0.01519442967147476
0.011479212627965337
0.013867526741812299
0.009939407726181525
0.008128959637756953
0.00825078667096871
0.008294252062844737
0.0008098332062382346
0.004461420574082799
0.009789049146067966
0.01175570265243754
0.003119671603762732
0.007881744577999861
0.001164302893438384
0.007507277586559905
0.010010693596951899
0.010016427250475997
0.01544057039690905
0.005074847027488297
0.010271376155519945
0.010094963660449324
0.008976520630668837
0.008922053902852545
0.00684419225084817
0.008892664347659278
0.010904693034239911
0.004697261762697346
0.005755158468899891
0.0136508133574325
0.007595186952541445
0.009562662694308076
0.0140729167643717
0.0013591091716850274
0.001961045978818466
0.0022264393000574058
