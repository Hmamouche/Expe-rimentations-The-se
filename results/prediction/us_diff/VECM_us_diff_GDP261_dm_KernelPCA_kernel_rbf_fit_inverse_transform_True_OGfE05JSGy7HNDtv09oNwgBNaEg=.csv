# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP261
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=7, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.016235069766862023
0.004692827199862163
0.03420891685984327
-0.017030909897156745
-0.013432365395718094
0.0036903273408631088
0.03466158172938684
0.03250064260788828
0.0036980704280207277
0.005315884337598011
0.019924230522674117
0.025198734243658417
-0.00658320942182574
-0.0012304809747169794
0.018403549391187806
-0.007527207049618526
0.0011852526456010669
-0.022270401660664175
0.0007963236064263048
0.012923754491428555
0.03066272849348793
0.034961975464683645
-0.02321406883480273
-0.016753588536149763
-0.009443105417180898
0.010798592676239425
-0.007542213674460433
-0.02595648226761954
-0.05464815709908962
-0.05562385327185274
0.0051845480489689285
0.0013248909684662738
0.021938023804288276
0.013323869573196683
0.011020243646709223
0.0037355661924935958
0.00846405272351414
0.01862296684840823
0.012858885285943592
0.00039331823386403245
0.0294671872814593
0.03877273547253706
0.020641503297095916
-0.0031473503032649792
0.011465680911039411
-0.0038231825840855864
-0.006842616105844407
-0.0032393447310492406
0.02168117012313483
0.013977208673218427
0.010488402720944551
0.0010905259365701515
0.00662033689344642
0.004568852355027133
0.007383229214310487
0.01631584611955555
0.01588833362887828
0.0043176810730700885
0.01730629460438385
0.004525524852336871
0.019336430939681203
0.025666241856943797
0.016779776048406705
-0.01004069396337939
0.004199829239974583
0.013479471672686084
0.0050616638287601665
0.0015305256500911645
-0.0028555126444573696
-0.0006584506244051885
0.01909123554531158
0.012958244885781456
-0.008679500240952282
-0.004650017653153003
0.036473471642630186
0.008642831420474742
-0.007379063391881015
0.01636933400604819
0.0005158679170869361
0.035480517131493465
0.029356690215876818
0.05143359015523502
0.0222622203930697
-0.009315221411321871
0.024396996207265292
0.025695046858075596
0.02601205328657255
0.01833002165381295
0.01792420701746668
0.004608305872060967
0.019150808033018826
-0.04655367345569028
-0.049491516624404076
-0.045420828269886186
-0.050584699381578696
-0.03593770300654406
-0.05414561656064811
-0.08996326275275426
-0.062455391228655954
-0.04829905748014146
