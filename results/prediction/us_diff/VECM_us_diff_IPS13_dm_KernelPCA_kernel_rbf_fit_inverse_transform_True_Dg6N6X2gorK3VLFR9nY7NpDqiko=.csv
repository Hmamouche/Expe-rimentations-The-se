# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; IPS13
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=3, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.006067448625563741
-0.010564353367635615
0.015056615879273379
0.008372413376634961
-0.0005346696216575637
0.006847970794417404
0.00812668643019848
0.014891597765565954
0.00083225358924012
-0.003413913165042375
0.008765461274501684
0.00665770819191778
0.004362239145988043
-0.0023252385223686157
0.0108548291594772
0.012606514669307536
0.01129612754343817
0.0006008337895949433
-0.00474321878461206
0.018155384192324184
0.012853645986600423
0.015541571957149678
0.0026176471118605953
-0.0004073087118855116
0.00848732210104789
-0.001810455566530766
-0.0049416623758462685
-0.0056155136406880884
-0.013069111456523824
-0.015070378877528597
-0.006930410064096875
-0.0015869741855801082
-0.0011891385642221943
0.00666281135337054
0.014014725153485539
0.010685659278487487
-0.00021357240907703872
0.006407969997638959
0.019125135994777744
0.010917432895415507
0.01030835507837886
0.020429194369967603
0.019659247834530033
0.014770821347406855
0.017200920378978447
0.017259802097609522
0.006916474915323826
0.006621618072705218
0.013033396787558807
0.007952313850678131
0.004587033524929328
0.009747761903426695
0.0034854274378584467
0.01769491337821132
0.020695387591406225
0.012431201760456378
0.014169375408544821
0.00989743984899988
0.01296681983928773
0.019096933841188445
0.018183012575199622
0.012133343803046518
0.0017967216981305367
0.022713157088925854
0.033289783487535925
0.019205714863393817
0.010154943269464813
0.00972072089892084
0.0058592051891065864
0.003038587720706115
-0.006295793955980955
-0.008414621339842287
-0.01835624951229651
-0.008157271091594276
0.017344951778170567
0.0030072724510888616
0.008950879286244162
0.001638936471338573
0.005336339741643747
0.014446736292516736
0.028832771362650694
0.02236566833649546
0.01478281524514601
0.005440900704248329
-0.0032659169874055486
-0.009058861237332634
-0.01158802443831447
-0.00863132145689832
0.012731984421024944
0.0016594807510967604
0.005805553686954557
-0.004718898423817052
-0.011190206761893548
-0.009701182981051416
-0.007220068602266599
0.0032639433683033544
-0.0009265937259711032
0.00025134204611801565
-0.005036327545805739
-0.010158040103938388
