# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; MZMSL
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=15, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.01370223572723021
0.009369642258124842
0.0006826962834230346
0.0012746662358435067
0.00653574670220006
-0.0017045590637218798
0.005615470420527641
0.004274206462307904
0.0065386609988240686
0.005767415518297755
0.008299053483242301
0.01075962466476984
0.009909136123599893
0.004404769885219503
0.00025742319980739904
0.0013835093292309118
0.004354358131913117
-0.0004044890977438569
0.005146187286360446
0.001565318351613746
0.003452089190946108
0.0018518876553102093
-0.0006274492166157724
0.0017163152452796856
0.004332572917023847
0.0009520944485619502
0.002637593495487492
0.00436931446185764
0.0026516053795735467
0.005826771502884137
0.008595395621306302
0.005332182047695347
0.007997411476274936
0.008342707175847779
0.008214902402561813
0.007314097377515833
0.011993095518356683
0.003816302289212648
0.0047391394507847705
0.006248715114036866
0.00319637520495336
0.004303611104001389
0.003547529282503538
-0.00020416286640342223
0.00010347949191498007
-0.0019086575616666264
-0.003748469872266624
0.002109340273306576
0.005435382653416444
0.003932836846179013
0.005002691455488668
0.002390705190261702
0.0058919298021934356
0.004166929519165637
0.004953537003811875
0.007366895166023509
0.008716377109107444
0.007521797468850727
0.012318228021451208
0.010146656787504616
0.014012858012065633
0.018007478516716666
0.01006924533070836
0.012577705276329917
0.008410119863868463
0.009902074889193736
0.007197226705026639
0.015058075439838413
0.01057174117301113
0.011550026399417379
0.026164473320279182
0.019122352981207052
0.021028989394152597
0.030994189613354636
0.013822043105812469
0.017832176845688358
0.011542066767373248
0.022091164555204837
0.013648067435867682
0.010556816161679998
0.012363498151888579
-0.001256866212364146
0.006732746300989854
0.011901158927373482
0.006584901806787957
0.006909440840840268
-0.001524962973756287
0.006832877344920783
0.0058708150208542885
0.011781238942084823
0.007880090157805456
0.00027742995106727055
0.010004621653474953
0.011381557537123494
0.011265009253620978
0.01784769026822496
0.030047719389841798
0.030781168034304064
0.04022730757487605
0.029461019179871185
