# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; LHELX
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=6, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.07951790018613042
0.006047097432899908
0.05372026841968933
-0.0016320147700966715
-0.009174515916212595
0.045005374292160075
0.030256097206765812
0.011116324565319684
-0.015125639528430913
0.003436930153347811
0.0006261985847714913
0.018937010781998432
-0.016240238790538625
-0.018223282966055458
0.0016644381980246569
0.02308080449942032
0.053545150803887775
0.019952055476350313
0.018461877375984637
0.005148050804888787
0.011892889737382166
0.025317141243536418
0.0025768993869006145
-0.021685417262575966
-0.01231832353714395
-0.012142931502016426
-0.0194482003565723
-0.025184339813592412
-0.07872723939593143
-0.11264967549977149
-0.03871036872197241
0.009933659721401174
0.008276626676705156
0.02057551246635513
-0.001649954521418349
-0.02247072813480066
-0.02215109456545708
0.020730088047543074
-0.011196702154905366
-0.016043932194129286
0.01753149410081435
0.03709886773468768
0.04286455242645151
0.01117165425440516
0.015650459442267665
0.025879947176756315
0.0064899967121119385
-0.016718688413055332
0.014976099152036593
0.009602731250272058
0.002131141118319529
0.0031364634786800478
0.00628652413275632
0.01144464032429573
0.015393158806058353
0.010353152040158152
0.02727302428126134
0.025216331711886305
0.027796804226853322
0.006145399916882733
-0.023625471139371707
-0.0008750223132304319
0.035525797357032006
-0.02208336157033421
-0.00029694861345648136
0.002811573165203029
0.0102274724063303
-0.0101247041172703
-0.033807428011898434
-0.017069561736846133
-0.060932815557748224
-0.042152782673723195
-0.05791017739980463
-0.0712667134830799
0.0009326753725963002
-0.029900107674545297
-0.016325613015277764
-0.01597578817162237
-0.043494528857033185
-0.004664926026573467
0.029026852506150135
0.013606249842587221
0.012744937924229482
-0.026014070846673933
-0.009117359223713477
-0.01260123521042738
0.0070329345220702475
0.004262922634830512
-0.002428380879405663
-0.007184920663651827
0.02594605893124064
-0.038876327529134426
-0.024656736701275994
0.015876151305771094
0.00545930465369587
0.0023681697748227162
-0.0036347437165391207
-0.04233860258430408
-0.007212088275190338
-0.024951906127258446
