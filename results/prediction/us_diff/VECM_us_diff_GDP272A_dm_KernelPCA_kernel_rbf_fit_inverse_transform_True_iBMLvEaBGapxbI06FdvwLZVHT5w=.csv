# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP272A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=15, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0053077086903151474
0.006787033681725826
0.007077145701126148
0.007442439505285897
0.005092816620338886
0.004965148646959958
0.010398186826255982
0.004645089951427197
0.0011391144134555078
0.0083847033123127
0.0006773902826947573
0.002075943083936023
0.0032500650824504583
0.004485095903267823
0.0054797305108349745
0.0035912952294336305
0.008385895457566161
0.007777060065415188
0.008574863453059852
0.005478026485884019
0.005222554073971732
0.007425658380164077
0.006213076064339277
0.005369993228001253
0.003920434266856459
0.008177052076813952
0.008173680415765952
0.008006216617952491
0.00802386181246833
0.007468656635848992
0.005386134566791049
0.003899266268206743
0.007666163108448133
0.007070334160910158
0.0051371758783119
0.0054881917658488235
0.0017243959126672383
0.005571032153191886
0.006834865888655314
0.0038257654817176953
0.006015138199628054
0.003640502303089047
0.004933206783311243
0.005606147072700139
0.006668700230226168
0.0044585397614243455
0.00463378034334068
0.0028544286937294363
0.0023306650669420136
0.004032841112604138
0.0032720618275191853
0.005599677294228872
0.004283594647822459
0.005706881645538859
0.004237074794209571
0.0032239766069453177
0.003236804567602103
0.0038235181259569104
0.0008135595851001217
0.0008051318146321876
0.0028801047999961736
0.0039479047282312
0.003824212003168072
0.0035323195947054072
0.004826439093642433
0.005849613513001359
0.005410264868530073
0.004402020100168113
0.004429454136930467
0.006840002880006511
0.004692237172638848
0.006299753377213233
0.004001590007510036
0.005141108623851826
0.006726550583663506
0.000920900718488658
0.005396186561277102
0.007406792001116989
0.005298527946905937
0.0033787519103158268
0.003479998529929548
0.007218566842152422
0.006906224046889945
0.010866860619768843
0.0066518318753562185
0.009195683940153762
0.009765942965801216
0.0061367078828855875
0.009057110261693176
0.012059829305275944
0.007883777427826883
0.011612241642151952
0.006650156199566217
0.008050340991636495
0.009087099193414053
0.006185163413548044
0.010178771431468097
0.007892573230968456
0.007133155730386302
0.002775427883626256
