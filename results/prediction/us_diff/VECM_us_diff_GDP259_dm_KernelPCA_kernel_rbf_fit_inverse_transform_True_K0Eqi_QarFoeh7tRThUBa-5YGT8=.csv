# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP259
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=6, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.028346308312346476
0.015420525477625648
0.01832727435081358
0.0350895038926048
0.03190853234249832
-0.008652422911856803
0.05295646723448581
0.01101844969188159
-0.004037633158525168
0.0007501752316135361
0.009311687703461365
-0.053164128620063505
-0.057117979331929206
-0.03317126860797573
-0.046022632157105434
0.0162350974178734
-0.008834008787523205
0.04407081377212015
-0.009904018462297796
0.0013865739073070545
0.0105092585799199
-0.0006518780104398563
0.012462969787750373
-0.012482071498952935
-0.001142448050999511
-0.00404210982596517
0.020745016113039545
0.0020532336650740095
-0.03055878312628597
-0.04390978288713878
-0.010302993954961091
-0.0436611375568321
0.0076016428808034515
-0.019717901677462
-0.059766481241705915
-0.028999031943518695
-0.012829506142592102
0.03272848806562187
0.008558668092920895
0.0135240365675173
0.0019384674550556808
0.00611099495733658
-0.018665683200824273
0.02688342783818971
0.017817504218030026
0.00828840200325923
0.007446506725471904
-0.002706161190041928
0.016195954483473073
0.0131651753794568
0.005442468464396742
0.012550958429619577
0.016881540501788212
0.024272396853290468
0.03169773233935691
0.036003579270434224
0.027988661158124404
0.013924812475017364
0.01605517125635437
0.022304178024049392
-0.0005206005428002622
0.0035231421316338817
0.010192564049701936
-0.013844810237876275
0.005960616341083724
0.013772410645769093
0.01085702891355917
0.012550283822409403
0.021942988047687878
0.015894563790893018
-0.0026604642884524516
-0.0016916884143328573
-0.03082586982665155
-0.05571710074833862
-0.02568913751820973
-0.05634457723274054
-0.07009509407561716
-0.038909755178782125
-0.03667464584177513
0.010720008325030174
-0.0076765800855845175
0.03518805719536364
0.018935024745925445
0.007804821603134709
0.011243536041690762
0.007260240139713195
0.008441281052895357
0.005849250308274078
-0.002361879433626469
8.908977601655797e-05
0.012543131489238751
0.0027041727133417168
0.042358902920401766
0.01687422173640076
0.017316260450919732
0.042117019658219075
0.043258934777735236
0.010254590933583267
0.01570263306586409
0.03358329405437946
