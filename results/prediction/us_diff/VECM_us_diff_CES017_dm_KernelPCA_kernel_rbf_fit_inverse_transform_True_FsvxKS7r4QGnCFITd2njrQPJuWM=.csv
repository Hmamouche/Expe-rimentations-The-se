# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CES017
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=2, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.07772338832852584
0.04331333839026316
0.0296141432903151
0.01706764356234505
-0.008515692596955707
5.4478314730316627e-05
0.0019270063941441385
0.002665466785672115
-0.0031922936681618645
0.00034411227888079664
-0.00590398724873953
-0.01485744252593503
-0.02552346767143527
-0.021697005549694573
0.014118045956159673
0.01005152222715254
0.029805996442831995
0.0021493101737770433
-0.009098576837185538
0.01646132172954728
0.0054782246208049945
0.029664530361895456
-1.0355969808414868e-05
-0.024496083968761597
-0.0279829187832167
-0.014246217255405525
0.008620960975960065
-0.0022649101757337914
-0.03391139413593255
-0.06470361727395546
-0.0617069586450946
-0.004983421173556212
0.014840524332041085
-0.024068188181693484
-0.01647237696474363
-0.025107487147102998
-0.019602763128793044
-0.009769677726802506
0.00014135489269171114
-0.011808413962902064
0.003234712385487117
0.019103645793146728
0.03231675963222822
0.0423653228253444
0.01107148046078116
0.03317827428213595
-0.009062982079588536
-0.02327969668852132
0.0006281970032032641
-0.003963441591715376
0.01947934687351084
0.03534127509524923
0.016237852795906168
0.024709192486283404
0.0032651587184702904
0.016971563989718243
0.02347350607356613
0.018958235522596945
0.010465215011797936
0.0027591321344047704
-0.011666162651620213
-0.005544362330057828
0.01586121843096546
0.002949733602666903
0.015961961282356614
0.006998525082078193
-0.0017630184770508705
-0.012062464424182203
-0.01809658389554573
-0.024799055160059303
-0.035861301346237974
-0.034801070845033574
-0.054445795932956204
-0.07507649887048105
-0.021115048690543755
-0.04444413295551354
-0.029513552554420147
-0.05809317927999934
-0.04466786045046856
-0.030181272863941108
-0.006858705642750692
0.01843128032034016
0.007407779449955112
0.0012144038890599706
-0.008032336762480968
-0.007957688661430252
0.0032004540829409576
-0.00868390085324732
0.011573409203285945
0.008734901340845935
0.014262200082516788
-0.004501022471941541
-0.016437733406693227
-0.022566080167255382
-0.009023212761736604
-0.00012631011417901447
-0.02460435906101239
-0.021455982943165985
-0.0417987885054075
-0.025499816194730095
