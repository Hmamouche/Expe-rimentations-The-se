# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; IPS32
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=4, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.022685260788000296
0.0026234472779583734
0.007440311265115431
0.01083088614930053
-0.00552676568435872
0.0037397699480276477
0.00835383285615779
0.0008025161032072154
-0.00041728070975077585
0.0024693219677180914
0.006505707086184428
0.003155107997208465
-0.009779468521616846
-0.008532880370567148
0.008429316902445689
0.006108201413422962
0.014457787700506309
0.010131883442024947
0.008168527437258918
0.014046368389884474
0.00887365634774321
0.016173054547838638
0.002301655000623102
-0.006626576617825086
-0.007428031730200339
-0.0009122375339364714
0.0041941614493519325
0.0013988470194933587
-0.005052634711414352
-0.009570953350562825
-0.008075701947976946
0.007429100122747423
0.014994149993395899
-0.0008792679077191587
0.006685665184213898
0.004670470295105669
-0.001264374233008936
0.00792888828227259
0.007551250994211099
-0.00031339272908026254
0.009125417659616556
0.01194511507166559
0.016281517190663418
0.013910717189192536
0.011276463587237655
0.018132381045683505
0.0031641502554820996
0.002047178936511481
0.010475232458962242
0.0063980582648105865
0.011769134622255296
0.018031611404450556
0.013358776568070005
0.021586968377962177
0.013463678150616906
0.018193672942341255
0.022587451364911727
0.019333205012286095
0.01784011612233244
0.01373264509154096
0.007754388080382085
0.009647229401772907
0.018564461994007096
0.013180470447898099
0.020620486460561065
0.024813824921767043
0.018027902121164834
0.0125104266017385
0.010034586178924004
0.0012363426022688221
-0.007201921263031393
-0.008095408401355976
-0.01274708102379843
-0.022498363866063957
0.006766277222936714
0.004298442803248739
0.005433156926142303
-0.0025177856638424387
0.00042288709048567564
0.0035658765533778565
0.012722652847321233
0.019433069514330926
0.011845999852655192
0.0018864535429408613
0.002199562364808116
0.006766349700969289
0.009065584117761998
0.0035423940266095582
0.005351286220270722
0.0036575370907236324
0.01478357704456435
0.0027042787451562996
-0.0017588464243219778
0.003996387395776595
0.010736174578048138
0.012224613406818335
0.004915251395344269
0.003086176557662716
-0.0017852449526059174
-0.000766067111635024
