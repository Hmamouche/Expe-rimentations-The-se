# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP275_4
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=7, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.01059087382873551
0.006836842236466306
0.009201639262839003
0.005138659940645886
0.006980045340493006
0.0020443905631798128
0.008019914990031893
0.0078115722236520874
0.005237779654473241
0.007643670331621587
0.008380181745967712
0.005902246825231369
0.006570427002908719
0.0057452394968635495
0.007489824113969961
0.010526957036454983
0.005982417155088636
0.005134626715916211
0.010213838579205717
0.008750805486653225
0.007254202617942056
0.009707542053708221
0.013406158863310152
0.009973523700172626
0.008443666944391118
0.008589915426061403
0.010993970139784504
0.014202014300108423
0.007434915948555285
0.008846413304405453
0.012341161677844277
0.011721861439330298
0.004631717910736833
0.012112995232794032
0.009475013683572606
0.0096142920545867
0.006375993495712489
0.0024945776314183
0.00763383365240366
0.006325505774914026
-0.004651765346480801
2.7776585728773182e-05
0.002660420756913651
0.0014431063871004728
0.005316314873200154
0.00233869738507827
0.001993987903597635
0.003655310963256755
0.005024332519082672
0.0044119009569690846
0.003247845397542864
0.004110960139216977
0.0018556541436655066
0.001920661939814825
0.0011271352822923852
0.005727256450198283
-0.0004578361978652988
0.0015475634352012388
0.007387610356230715
0.004208408954492761
0.004986030236396287
0.010096087607946358
0.018756906338863604
0.007312445549345075
0.009912684188767344
0.013601537887076413
0.0034770894712257134
0.01098043497686964
0.0064355093681578
0.005288605234382111
0.009828296026319098
0.009864961428941126
0.008460426489175924
0.006753571840313159
0.0028748982526092316
0.00982462413472525
0.005647421226845072
0.0014875153884362836
0.0014544771898047624
-0.0007153684693926389
0.003117666113035334
-0.00347641046481226
0.0037134900274106352
0.0041662142375647245
0.0003097220299316645
0.0042105225880134595
0.0042760240544263885
0.0032366766327968166
0.004796368830983696
0.0061940167177387305
0.005895214086953307
0.006081924210723831
0.005399763388211822
0.003208288064889658
0.003014549171791361
0.00409287536880687
0.004017097680791237
0.004977536782713511
0.0053510576431545845
0.004902123482671464
