# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP276_7
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=10, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0035447262547971
0.0053234317803550115
0.006525709144449349
0.00786308601751347
0.005786607356399271
0.006962813107185431
0.003028452823330654
0.007347386572037556
0.0028004556964115186
0.0036488185022984523
0.009147213228250482
0.005547697610553515
0.004715266383228455
0.005342617181836414
0.006662117364840387
0.005425523809497971
0.006452706195984566
0.007167097730928387
0.0026435106072461786
0.006839277451834316
0.004857383881743977
0.006493278706906822
0.010803332421357241
0.006729354685052263
0.005256928055299151
0.0076405820631879045
0.008301579180148582
0.008989097187855882
0.010052293823803155
0.006956512776898121
0.00870402778136948
0.009724223554583841
0.010044569333742197
0.00663279708946894
0.003885250367119863
0.008084218325375989
0.00860446405393946
0.004020193658254904
0.004107655397173802
0.005794015901240257
0.006880447749453351
0.005740673377215915
0.004332066732522535
0.003593078435803839
0.003482731741578851
0.004962721658378896
0.005641835464746589
0.0034690181115342947
0.005306997613442745
0.005476816851359697
0.005904472517437936
0.006171855627392443
0.006910610613304894
0.005642405204084076
0.00664402473589574
0.006995160636068823
0.006692021340346032
0.005749368896626023
0.006273037580348142
0.00584098667773623
0.005736383227692438
0.004929269185150531
0.006220440850904454
0.007759969994183026
0.00569358172129274
0.007835232105886191
0.008933099942715905
0.009768944599118744
0.008268358916468002
0.009414568115007812
0.008402306233581847
0.008243644078653618
0.010301416598364874
0.0036514310016718017
0.0062885482968690135
0.008970100513646363
0.00795084878126133
0.007999230744818672
0.0070480953514670906
0.006466442259338601
0.006257855975977704
0.0057592209141623316
0.006258039901179911
0.00746909268221777
0.007966370259129094
0.00708542106055874
0.008115005082702851
0.007020627262252224
0.006780460777801197
0.010020883879508927
0.00795618409954038
0.006519798741410725
0.011132628322893438
0.005608345255775258
0.0010725155548462733
0.004221278875722278
0.005136744279019703
0.00744965494028706
0.008242453446294448
0.011564544192955177
