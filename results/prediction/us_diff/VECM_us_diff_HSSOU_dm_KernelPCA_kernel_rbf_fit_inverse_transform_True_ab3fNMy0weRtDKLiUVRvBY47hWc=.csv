# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; HSSOU
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=9, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.08719821677329323
-0.006312566114642391
-0.06414885117525705
-0.17938775889184286
-0.08528404059901647
0.09466578142576479
-0.03882192877305348
0.04396448832087428
-0.003334309445816787
0.025880064910219745
0.007123179411236306
0.05379229204332546
-0.1113724196658307
0.013602067844699292
-0.11029479570010421
-0.15241569636784857
0.1318496998764919
-0.019261041549825036
0.013183171383179981
-0.12624743983916065
-0.061908291262451856
0.02448385378113273
-0.07651374106998723
0.0006310304164388186
-0.006228540745710434
0.059457411380387834
0.016341265887276434
-0.03601428971320279
0.035918863893741854
0.004881436016557696
-0.007114979079161466
0.06609502842508709
0.020474381329014312
-0.02354455653440521
-0.03933590474566779
0.047972153579328145
0.013154821045553454
-0.04343144987436905
0.07989326125288304
-0.1027293299709173
0.026766741661759283
0.08510130001182137
0.01118147982277434
-0.022195850778199383
0.1065161197620236
-0.11552137523175844
-0.029560068993265402
0.02017216767298858
0.007531459704719752
0.04085614093701762
0.02203648840014808
0.041307373109669504
0.03980430845299854
-0.01789455753820052
0.036696624294599356
-0.022835242890101803
0.03619314981892891
0.0006720713559393646
-0.010851167922412093
0.002504361213326408
0.06046794291825721
0.03494976572465554
0.06238425784422758
-0.010629604944827366
-0.005085998086637556
-0.025566297389481143
-0.07896843539841428
0.005737328529112294
-0.02820869418512774
0.0340007476521989
0.022174980933325532
-0.015153983020276166
0.05895374973702182
-0.015027510704500355
0.12088893005843533
0.0985275836792904
-0.07544526575968621
0.0050341835220211704
-0.07953227531012333
-0.04651037432086956
0.0848869618461437
0.06483084791492733
-0.006918770980052079
-0.020835350292033206
0.028421310254541927
-0.045370172725005015
-0.013076369769186042
0.025099913466758664
0.045862345752452474
-0.017861534017650553
0.0305551084934079
-0.0001336933508825737
-0.03698864640067693
-0.052558334811208404
0.015032782508750345
-0.04070822324433632
-0.10834756566310137
-0.1419994774790277
-0.02994184167394562
-0.0646070071989433
