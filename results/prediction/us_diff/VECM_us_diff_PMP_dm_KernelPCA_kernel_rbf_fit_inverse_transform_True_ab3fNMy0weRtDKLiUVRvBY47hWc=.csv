# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; PMP
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=9, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.21916176032386847
-0.1548089403055207
0.11497186645890253
-0.2520697135110777
-0.08851652939969534
-0.03952255422606121
0.02521720884164559
0.14019537682045424
0.051873049387890294
0.005306669806743491
0.14743447682262814
0.0006510484089705115
-0.09017965023548137
0.01725417835509909
-0.014140575828442678
0.015206712700043961
-0.04471772925553032
-0.10164770018100872
0.14380747799238197
-0.034649945586498476
0.08062255284308642
0.07337561991235514
-0.14772280484283148
-0.08240890125647873
-0.026630399118816348
0.024000127357460082
0.0010203410959657919
-0.015842709072204843
0.03928932036218031
0.03398477347999049
0.10881071848592153
0.08716511316908962
0.0022409961888367053
0.018362029475540498
0.05647183701990184
0.05207949951764109
-0.02958333498742952
0.05513594247413123
-0.09641697416420317
-0.11181152830412416
-0.038647547665425636
0.07854503008040678
0.08195642157415453
-0.04410579961316755
0.049191016046626804
-0.057325993619650475
-0.1293866074189972
0.11799059018660303
0.0019119789619572725
-0.03573769713307014
-0.04620737456855821
-0.013054322676416041
-0.0478268005200585
0.05836706873498354
0.0437794060661437
0.08320267775321047
0.06130021395722134
-0.025668498893757562
0.0037898235450132024
-0.05242406537633408
-0.05713580496549692
-0.09989374114479584
0.08189402047018009
-0.013830185707345549
0.12463726905359504
0.07446357072999826
0.013031739989056781
-0.1143001258545926
-0.01336549447402395
-0.08275539374739081
0.003772415714899533
0.0932572513790895
-0.01222599083820966
0.04904354065223513
0.1744342827384618
0.04698352363552395
-0.08129144557804235
0.013323199785794757
-0.1408585117647604
0.08259376537579835
0.05789609160672567
-0.052265785531767445
0.0028870803435315714
-0.00041868700684817226
-0.015132421831981244
0.024414805933070827
-0.13778119443772288
-0.061571428191817434
0.003935404799094432
-0.09845810662781396
0.14179600789458
-0.0697708135471832
-0.06304667249838482
0.019348299101404037
0.02839321826629907
0.00877567950698735
0.06242721277437539
-0.039191393684260604
-0.1264060376494917
0.09846963911624274
