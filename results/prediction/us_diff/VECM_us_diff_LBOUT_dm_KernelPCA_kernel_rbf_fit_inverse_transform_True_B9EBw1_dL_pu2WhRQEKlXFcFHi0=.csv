# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; LBOUT
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=10, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-4.18616752285491e-05
-0.016383956610821423
0.021620556628853344
0.0032926890692736204
-0.00019466585228920547
0.0034346775832187725
0.004479927260099134
0.000517447716747276
0.008321787936277946
0.010576365758658458
0.01601168570872426
0.014014563053999009
0.005651788407398051
-0.006066352690289291
0.0098084697468187
-0.0005015253337221791
-0.003326255847999009
0.008240613783704609
-0.0003567451700654616
0.0064611024563672615
0.005510943762944465
0.014741673898590584
0.006248218305846504
-0.0035355657287576806
8.962508276802558e-05
0.002500417972113495
-4.3196626298175984e-05
0.009091776860357653
0.0033563645422160825
0.00029581353140398735
0.011402331300597035
0.005548496377092411
0.0026795140365941097
0.010364753991902897
0.006236285074010743
0.008384984170650195
0.0025662573469337406
0.010383123640379358
0.009967371130204229
-0.004754123995275659
0.00572456923703131
0.005517657272522233
0.005670256459922916
-0.0016987137981403838
-0.0022404806991861725
0.007346740389703376
-3.6444208921327347e-05
-0.0008709757362774344
0.005276024177112389
0.0063853566976445
0.0058606154174742735
0.006533548213523851
-0.0006762793890949925
-0.0012855592451484444
0.007020093004419364
0.008363160986136202
0.01010672026273264
0.006738315030884248
0.012319844337584363
0.004976977966110779
0.009957394200584103
0.010327856375272643
0.002742229037046656
0.0033947657324367186
0.0011354331592958468
0.012377638845436965
0.013919639213047737
0.005392831166050261
0.0131755132915888
0.009187358369552995
0.009991098609074862
0.011636602523090785
0.005677960027041614
0.008879982303441836
0.01799715586819997
0.016685968170579296
0.005997469278392505
0.006716296536515774
0.01114883881022534
0.011755078221860882
0.014087695106777768
0.012603396042823612
0.019258228878332583
0.0023521412858681775
0.007112963084848102
0.015474875382712621
0.009503365377974537
0.005200391510811175
0.006807748444586745
0.00455585549217854
0.003392654844810235
-0.0019009797646775532
0.004339408922741289
-0.00237944935608455
0.0004740002731934965
0.005242840631552355
0.00578213777489193
0.0007911246875998918
0.010399605159964015
0.02123681034100496
