# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP253
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=3, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0026910123661696306
-0.0001345571457937061
0.009658554513826021
0.007807710580496414
0.0023226743573599275
0.01018452534375652
0.01139770516916598
0.007853096412447547
0.004710999972849499
0.02125241828781975
0.007584375417525643
0.00616736433319313
-0.0023667075668764737
0.0014960834796955633
0.009827198093528597
0.01719485094225786
0.013886692261637468
-0.009932729729329752
-0.006669158779196635
0.016598973911119988
0.0054471065363752465
0.007058017352779042
0.005484775655140329
-0.0044824034880523245
-1.762002677753384e-05
0.008207381813921303
0.0005121546769488055
0.005341650781909741
-0.002440817179561917
-0.006200451739450794
-0.0016417511283990669
-0.004215083677627324
0.0010179612926003348
0.00015063030396886713
-0.004554346714033486
-0.0016536967034915142
0.0002564110533184211
0.0030814870311915927
0.005311383291798688
0.002585733205026055
0.007642400710302478
0.012105394953965044
0.01421065063505154
0.009433921244377013
0.005931972626792783
0.006182621982616348
0.01017673266720049
0.006652265772708582
0.004767298417711051
0.005681941294609932
0.004101620240014175
0.005763462344160614
0.010993148658859933
0.011300853249803913
0.00836734204022762
0.013973407831694347
0.007855654126819754
0.011402715304444904
0.01666930125176133
0.005222988676107816
0.00945636758508896
0.01269699641140453
0.024203123544555262
0.019660846311781128
0.01930068606602399
0.023868792919413462
0.007013967203707264
0.03125095727154006
0.014727571368110405
0.005991474170059923
0.009574365612673417
0.0026922119990625245
0.00827001591608097
-0.009446840790447887
0.021545877157478747
0.02869159702781945
0.013989127385448542
0.025335087074313933
0.0021589486695442004
-0.003094222311806969
0.0076765490032229275
0.02601298928029729
0.025489473760100568
0.014315280355449546
0.008398363998481316
0.005357946570852437
0.01462934441388652
0.009492393211283423
0.012562119707560986
0.024562679298721152
0.004498964161337774
-0.002439091609586939
0.005651175839305285
0.00664669850315908
0.015323931256253219
0.014235463157933451
0.019389869376040238
0.011302944733706011
0.011694352414270113
0.006452024090252688
