# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP253
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=9, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.007253979664281443
0.0009600710774061369
0.010305885365517051
0.003831811864678811
0.0023958087986371036
0.004488622090345054
0.011714563670226876
0.004615323455829718
-0.000948249923125909
0.027849606289081563
0.007897955077645753
-0.00205413237097893
-0.012131733503435504
0.003343031432523856
0.013661861310761522
0.02213894275825721
0.021024523676217217
-0.009001289700677003
-0.012068797907431695
0.015606445873543269
0.012736490294534993
0.021842024856260155
0.007566292884145522
-0.005439672626092006
-0.003018602229367769
0.012319601313899585
-0.004983567632336273
0.006659692033997879
-0.008471921380719331
-0.020055720322037084
0.003080350231518072
0.0027338692373655733
0.0095460923550323
0.0010173232781945343
-0.01795758696137984
-0.0035266615852424027
-0.00016033128507391217
0.009629420688303742
0.008730358606547604
-0.005846993706980377
0.013238417734554303
0.009791929375388453
0.013052089041202685
0.007027995596953992
0.005526330135686489
-0.00014255606802980646
0.0115801887565997
0.010771499093927526
0.008870558715215651
0.01030229755746526
0.0041493042586596435
0.003835973507575463
0.011414858095580231
0.014607053382862223
0.004771701072938999
0.015026977935101923
0.009624448701426397
0.008302989351081251
0.019746620717941192
0.010636045926764488
0.010361863780085152
0.015412653344411546
0.02460217914430111
0.013386547396710382
0.015450527764490844
0.0289985865306219
-0.0008970110358919904
0.02815404844047832
0.018490232919693452
0.0074392505893002645
0.013648004961740998
0.006013302043289911
0.007448179583424934
-0.012250867329329073
0.013944273154058797
0.026103713482381025
0.013497858211676036
0.03802574205896139
-0.0018651551700491495
-0.004014100279286392
0.009314656536716568
0.017486214413000096
0.03256208443438258
0.006060155630919923
0.004725449097623615
0.008331009546438665
0.012808446443668213
0.013003361508789219
0.011157587569760437
0.02188220972682059
0.008695694470816912
-0.009960172835578375
-0.0008838624824766704
0.019070594318667186
0.015790458389629152
0.006261345395797168
0.02557828537415721
0.005977407213361047
0.003024872571332762
0.007014699619244707
