# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP286A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=11, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.00743543849979305
0.003807098662854079
0.006085377136479568
0.00963959588347869
0.0035621412627121923
0.004030439074646609
0.0053867760512484875
0.0022507303959069273
0.004264889205855072
0.005339233273332958
0.0025652831252587008
-0.0006079134289568705
0.0036688969752823822
0.004829322109928245
0.00531519292184683
0.007690681454300432
0.004732679460122453
0.004655007124597708
0.0031918716813329412
0.0026933859471457884
0.002539607807919838
0.0048785045557825785
0.004144026721803884
0.0029952490486467756
0.0033447434790837153
0.006186914298516815
0.0041983931528851715
0.002858654639159015
0.008224526610396427
0.008578614971246725
0.0036839844140105545
0.008224852265995787
0.0071578678213964995
0.002378660110365625
0.00211930861480114
0.005354126473928781
0.0025006842420533656
0.003101727879681429
0.0057355248560991366
0.003901613441115081
0.006375301894720166
0.004298730037555563
0.002359373644971635
0.005934300938369428
0.0073027052836563125
0.003259809999066534
0.0050417159333687915
0.003894123499057805
0.005912362251079144
0.006052954281553896
0.003611849856482528
0.0038333345662641084
0.0038068647033153618
0.004288634953696278
-0.00011645357879946222
0.004100197103901969
0.004415250841253981
0.003941268978403279
-0.00019057580100601543
0.0037265793434229184
0.002966491793138526
0.005177230646416546
0.0017924365522471147
0.001893745106675928
0.007233569950528061
0.009717759200325008
0.008815246952921617
0.0067113937735718615
0.007391301732136761
0.008999936343958693
0.00539958541472026
0.0076826985083763705
0.00549519683640261
0.002659986198409945
0.005929252442087343
0.0043522682217854115
0.006015483627137497
0.00915196109560649
0.007590891825346105
0.007121947312644855
0.010086895426717516
0.013748676162806618
0.0011479456937705376
0.010117168864532197
0.01185493448357596
0.012605750318835186
0.010712700234142725
0.012685178303924982
0.0144835241769405
0.014927460041411914
0.011072146619130122
0.015804029903519434
0.00888415619191809
0.010490138791135119
0.01134186797373556
0.008212605658987814
0.013328754499279694
0.014469885108907912
0.011487797988363012
0.012730535179217234
