# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CES155
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=6, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.01475798745953021
0.05733537263735668
0.05625150727255763
0.009591740661797856
-0.10960251157779966
-0.005793420113966295
0.07889382151501302
0.0021328524357616483
0.0014157268185192202
0.006266551884722474
0.046908076889389715
0.030128874492472632
-0.03934087259295951
-0.022011081853827767
0.04305011119838399
0.03296763138409846
-0.022668576365094055
0.03875320493075468
-0.025397866037977314
0.06693110441305834
0.021009216842867485
0.024862606607585606
-0.005380596713697961
-0.026680404893545614
-0.010520419369330583
0.0011954158981962587
0.0026845995670551097
0.02371207329547662
-0.039573945320127896
-0.034892216930685484
0.012179095778751418
0.023994676370904813
0.11945511589116789
0.022509433712029077
0.013580514178212788
0.0013539995143319588
0.011073157752397863
0.029667982233489036
-0.0002989760795365174
-0.004619241419002908
0.06104896899557185
0.05698616424886134
0.0534532823601568
0.0387963824184653
-0.007039103942857315
0.029333776238064133
-0.03115017462426422
-0.021193477245763752
0.0057480005839532465
-0.011590749632207697
-0.007665800061848377
0.012824021162593702
0.016146082359115653
0.01805146608395486
0.03423681000721714
0.0427730093661612
0.020593633570251034
0.008133696881499132
0.009498840038824924
-0.00397528615102013
-0.06338545526650072
-0.044946543063375345
0.0018701820001776875
-0.007819620812959368
0.0015189738209495647
0.01849060660408229
-0.009442303306157331
-0.03110321704237349
-0.056253290300559235
-0.04234707812107126
-0.04962844157916954
-0.021435428551699172
-0.026819337278702608
-0.026610944198242496
0.03539102572150625
-0.01348317033414047
-0.004902239422100019
-0.0030605718558101994
-0.010135180985957611
0.02264150202510385
0.04104020583743964
0.04223060299320125
0.016683471346788055
0.006786558395369732
-0.007327772340298501
-0.02025458532816915
0.018753162986153905
-0.02276770283221536
-0.002628322141947066
-0.00569312139242426
0.02944216602111252
-0.00913385692091478
-0.040730505616670104
-0.012983740123758452
-0.02104714719580197
-0.0038856670518987464
-0.03957888190235883
-0.033971440381355224
-0.04647206093212508
-0.00035090955163688065
