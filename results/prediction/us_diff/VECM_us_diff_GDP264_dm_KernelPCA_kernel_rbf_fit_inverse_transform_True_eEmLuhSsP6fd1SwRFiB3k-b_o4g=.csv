# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP264
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=4, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.0032519314779027083
0.00846706819417315
0.012311705918705389
0.010816236005362254
0.006823141849407819
0.0030211033613970445
0.014080887950921274
0.0025717500255190446
0.004126565490600149
0.00751719204974704
0.00384101360490874
0.0032098158349709517
0.0019008169066442437
0.0062537446578430425
0.010113629890256897
0.007643943450961764
0.003963505111160641
0.003522708547826243
0.006101534984987335
0.005425694183472518
0.002506653872665621
-0.0014451494458261591
0.004010426307496561
-0.001206409590981952
0.0011961375402337053
0.0025791750146151853
0.0036558397851514635
0.0026335376288201123
0.004321324420958374
0.0013237805608949773
-0.0024353131419472688
-0.002104342872608104
0.002055938897683922
0.001624137887335033
0.0069315386400104016
0.007933011954955353
0.0028353290509861816
0.0037132739837827475
0.00759643088664611
0.004564592329225019
0.008076431364808451
0.012752946718140642
0.009708606725523245
0.011272595836044584
0.009989555776322247
0.014361731341399649
0.010297051596777764
0.006139808937942068
0.010285041950807362
0.006831160333556473
0.0038310841281183027
0.010225473776552795
0.009539344995943253
0.012133847817593517
0.01647247667205497
0.012829265241317793
0.01803912265903505
0.019864083365308663
0.018584496720966986
0.015442631102091488
0.014804923188848034
0.012429043340453224
0.018120268163836915
0.015652815419466677
0.016541996444907357
0.023632324638779942
0.022067558535296756
0.017880524291866835
0.019635036127445965
0.02233542617334688
0.01855875599342908
-0.0003415114469241705
-0.013244787041382183
-0.014767803591856726
0.007555374454037494
0.011753070031139842
0.002321230226956875
0.01177894601131167
0.0016269150713717755
0.001967261159465064
0.01592414992020088
0.026751620580986457
0.021612413149394768
0.023414709929896207
0.013699969835611735
0.0217827826222554
0.021334273830638836
0.0013361545972930859
0.007830719271564705
0.02340751050227445
0.023908553411533886
0.004557957084379339
0.010661279074731689
0.012036963170172721
0.015851163547410826
0.0039018110207794878
0.0021906564701914114
0.005564752407739934
-0.006415573488837394
-0.009423612718199083
