# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; IPS299
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=2, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.010587646181812245
0.009441551724726199
0.012951089544822018
0.008947368686821923
0.006470540178788957
0.005410469501948361
0.00597538281243757
0.00896575530078214
0.005452636182204972
0.0032637197517045233
0.003668779086183384
0.003798504568062038
0.0024396226442799413
-0.0016549198800904041
0.006483919978646185
0.01116106866944752
0.01286007957716099
0.008746259613915166
0.0069661720076218065
0.014895274137118513
0.012065609280772322
0.00937704002070975
0.0014357719649817006
-0.0010711159584964962
-0.0020169566993538776
-0.00038139380597381736
0.0031149786891219136
0.005016814584486324
0.0007229636184524388
-0.006272843676300733
-0.004575976985480789
0.0009674237870584597
0.0024614775105426937
0.001017336011202298
0.0044172696698100014
0.006511703492891592
-0.004855002636657041
0.005951307383197652
0.00959606714292573
0.005633291310043833
0.0071603572668751106
0.008974169578950763
0.011674942176100806
0.013925283152805579
0.009595455246695252
0.01248955575946766
0.0030687722077343948
0.00021110839783562967
0.00871511907227078
0.004581580511799275
0.009429629169880351
0.014472672990137107
0.008463160263181368
0.01373229273460334
0.011634521069631911
0.01302305964818319
0.017238183843972063
0.015248557277788715
0.014750225269378619
0.0194962996860965
0.012984148021094072
0.010823706296556542
0.010780966018634923
0.011400425555790105
0.011332838174031343
0.011173805165646531
0.0037627392691579244
0.007983648294626562
0.0007133270326633986
0.004366467766773187
1.314061718310001e-05
0.00212834813899195
-0.004825544621003778
-0.012044299219323889
-0.0025899793841763627
-0.006063453714649024
-0.002674063437029863
-0.004952480133031374
0.0020901167100226435
0.0010498050015582223
0.012983261903690584
0.01231331521353824
0.010210797952962305
0.00651840640943968
0.002308431907275473
0.0034788099244974354
0.006933810265566463
0.006334151505713971
0.014329320517939316
0.015247078029270156
0.009053883370570705
0.00773963837107101
0.003013412889800517
0.002702117021078936
0.005786635929328372
0.008382070507855896
0.0038081728448320865
-0.0013823785007322452
-0.0015037811944507617
-0.003037157489498808
