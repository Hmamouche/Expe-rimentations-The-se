# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; LHU5
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=14, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.07138678406833239
0.09855228416696196
-0.15168578502966906
0.15711344415503267
0.06681544802444009
-0.12196697653515196
0.022408621103775506
0.05598896007815138
-0.15677553728657573
0.017015533175644068
-0.05550704247520669
0.07846758447289182
-0.02023281366422426
0.04249177579665274
-0.03943460489422344
-0.023616543703275192
0.05196480028655651
0.06520623138522971
-0.04700269403575727
0.053464691064034106
-0.07996531532486206
-0.08533755398698142
-0.026162209205717525
0.06354303652682675
-0.07689381669619666
0.0344558998768019
0.023770726328031486
0.036635498123529356
-0.03878409620357642
0.060020703048896853
0.025266231147617873
-0.06957466689406976
0.007080889233284458
-0.052521457102250445
0.023031159270891402
0.04072855190457003
0.02059518130281042
-0.00483594447726635
0.06372956960549786
-0.06575528406168751
-0.014327845778848124
0.0020756233755367184
-0.058426066971043036
0.07119145131412022
-0.07904790396828817
-0.01663741974256731
-0.0454966044992223
-0.07045951347378397
0.004031437980942458
-0.09892019875537728
0.023385325346085378
-0.01664316069539747
-0.008188606437565193
-0.009391564257781416
-0.021695164095052268
0.04650382390952337
-0.05861419256774448
0.03216054789662833
-0.021869441039897644
0.008274005916770584
0.027807520523882717
0.021371148751060713
-0.023849834471435526
0.04151044413941471
-0.056796338751554924
0.0304920671750702
0.01688822405559031
0.039714617727351534
-0.005225452501049286
0.01025035031505952
-0.005402768611582705
-0.043063288717965637
0.026434062861413858
-0.036870859679494467
-0.042852542471881826
0.026502901459786746
0.0611119357808413
0.03981175292685401
0.01767884359137502
-0.045360247680708565
-0.06212427837787808
-0.024094490334999316
-0.06551754253984525
0.10508428336227774
-0.027926887526680745
0.016877202577039202
-0.008223899612366121
-0.010857906333468165
-0.030964170179699935
0.06043816593580093
-0.026832620503459303
0.032766014962416844
-0.014643314811116585
0.016806711363847853
-0.027110492552975925
-0.01861620921431459
-0.017072843032156684
0.04438435566012554
0.044088548694661
0.025219797155040018
