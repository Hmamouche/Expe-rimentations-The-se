# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; PMNO
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=8, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.13860741841918345
-0.13890438323334317
0.07147243095688403
-0.22031076661856513
-0.05752426248912497
0.02338466208271761
0.14452985339559082
0.0710502627901357
-0.03844407946094655
0.07892842565187347
0.12548035955000345
0.036802417440132025
-0.06107486080010393
-0.01632194034514243
0.04446205916083962
0.04110868405807092
-0.018220893816029628
-0.1447535161134382
0.0665389975895653
-0.04170594944240316
0.050850384904014195
0.13115395052186038
-0.18635999016069857
-0.030986415236415994
-0.017096529446301183
0.007207017002065209
-0.004917986250059361
-0.029490156692685985
0.03530615044786441
0.016273099444366855
0.17680381942519183
0.09824744642576222
0.038143033941231044
-0.03863853332751985
-0.044805595798380074
0.05050485836902593
0.012977237178072275
0.09429785243701022
-0.07095455699371139
-0.06674431135136319
0.016795936824999712
0.050648482406285604
0.12197355157658596
-0.08600081806291175
0.035213729615493704
0.0696591900847254
-0.020032569141708614
0.12774104135699554
-0.0035432384587866447
-0.09307697196286055
-0.08301011434913444
-0.060782336859263014
0.019723495432117353
0.05745928217137485
0.026810017606368267
0.06755790105664114
0.10131155683771645
-0.0590196986412881
0.011007604985498158
-0.018477319857815894
-0.10328420887087836
-6.640439423259356e-05
0.04681662053190986
-0.06097326714362094
0.07173364970419446
0.026460295307556256
0.017919902290163166
-0.09540338737863278
-0.046227702712434926
-0.03204386791336725
-0.04271505414210176
0.08729727235891971
0.03817254429202487
0.1038726814286283
0.1478634560262206
0.0632984996641419
0.02579081777550959
-0.11347816614985344
-0.17681727146832726
0.10252157300640555
0.028355948756414288
-0.007869052909019715
-0.018170068975795522
-0.002579492623296155
-0.04647744120903945
-0.05409042716657107
-0.048853285959295764
-0.05780933824796673
-0.02507180670122358
-0.06744112562360316
0.11421906391952326
-0.12331028956746129
-0.06767057956371929
0.09491036164174495
0.020466250627073437
-0.037981060456720867
0.09138872855364127
-0.07241242561095436
-0.13494767617802395
0.06157700607514733
