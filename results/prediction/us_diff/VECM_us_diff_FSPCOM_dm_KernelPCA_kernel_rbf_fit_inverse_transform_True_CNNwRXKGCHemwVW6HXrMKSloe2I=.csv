# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; FSPCOM
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=8, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0035204281058737316
-0.0060602944381653815
-0.00016438781455997004
-0.007829636978795238
0.0023026529299643526
0.002477548139525004
0.00842047651283247
0.008906321535889005
0.005924858970941053
0.004906456157171976
0.011080135882389857
0.011737825179910519
0.005630764842848317
0.005487248885649061
0.012919746682029581
-0.0023738067082027378
0.006912488097883958
0.014437223581104022
-0.006018599756178929
0.03863031179566777
-0.006209637634565982
-0.02638024020380538
0.0019383041329132694
0.008650451390131798
0.014506051741797166
0.012690368041079113
0.006521453401556705
0.007902868174227739
0.002600818750003653
0.001701731890703002
0.012223515247881182
-0.008416095452122165
0.006722098378666977
0.004724243217430235
0.013799795774706317
0.00022356492588638654
0.0009905979947240123
0.012938526505003461
0.007148893064448828
0.016445203314498457
0.009860349081057611
0.0048385442613699875
-0.009535204148110467
-0.009586949277716705
0.0058821888039076505
0.001474704898329186
0.0013710581014790171
0.01861797045482124
0.02977254590526958
0.02192573423651205
0.019605522922007054
0.008044448960358587
0.004307252685940264
0.019976176298440406
0.02492164941200693
0.029625269041486792
0.04216340539063952
0.04391128941920291
0.0528994954423864
0.03487299443406174
0.05801135597154573
0.03665892939503086
0.004812245901975256
0.030035347813498637
0.0380441160186814
0.04891450620869989
0.04616971318856979
0.036591524522544744
0.030224355761306075
-0.006512379752167579
0.0049931810373327655
-0.03739578542095485
-0.05139626221137218
-0.025550240486117436
-0.04285355087469178
-0.026966621309262386
-0.07205795013416912
-0.012118818054203416
-0.07251401159447596
0.011151461188276294
-0.02405304817924967
0.03269904055094015
0.03153443368833631
0.01410450411466051
0.022830936972026296
0.03648370525463599
0.03491488891877329
0.011045228950341095
0.009448768288954579
0.007504566213502038
0.03638531697698671
-0.0027992189065133228
0.01263471840074922
0.04430588703227607
0.01429688445510817
0.04927092399522648
0.01871821183855622
0.030765613351486205
-0.051734918896810554
-0.006961263553645812
