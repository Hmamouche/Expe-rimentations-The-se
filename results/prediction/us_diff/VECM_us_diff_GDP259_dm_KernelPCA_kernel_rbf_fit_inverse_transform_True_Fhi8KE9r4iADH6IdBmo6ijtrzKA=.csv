# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP259
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=12, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.05619548557789616
0.025218468526461372
0.05117302409992355
0.001256805684052724
0.012225321997115618
-0.01762754719056905
0.0466026039006513
0.0060570436091785815
-0.021214546366509667
0.02222803432957872
0.04501566447220166
-0.06335511854715578
-0.08255246639529414
-0.030199467429396942
-0.07046018774006786
0.03571419502235273
0.005514257740224182
0.03819750561013201
0.006587689435421033
0.014300068990194214
0.0014347403605656506
0.017932464159849455
0.0008786135032401599
-0.0009470012887476077
-0.03793210726562201
0.01629097811661441
0.044471407231425085
-0.02766196804202438
0.010812794962199938
-0.07369947969524569
-0.04245483615053243
-0.03199895369871506
0.009497625883271011
-0.016160719832440287
-0.04903701245127245
-0.02078075744462557
-0.016959755752224588
0.0314126832885944
0.03274707955778029
-0.00757195489114899
0.01749801957576352
0.0007695208070786323
-0.004202830327585014
0.017502209496958465
0.03138945258520339
0.01685798460168177
0.021746288261527295
-0.022054378033766944
0.017558698790606383
-0.0024128535052382067
0.005285812433754367
0.037517178269646206
0.02152525176370573
0.013555229120781942
0.036032547768566084
-0.00448445643717049
0.029894854483449383
0.011688948919566327
0.00539710504127529
0.03923004774415175
0.005951934364930735
0.018835950986214482
0.01475643203233321
-0.0018937392980083179
-0.0012374181446175034
-0.0009203532945791758
-0.006559485904551959
0.022970165509051
0.008173066684043023
0.03636424903599996
0.0005904722370345603
-0.015387252877553085
-0.04086466163171773
-0.06204196950250762
-0.00026964474637548516
-0.02857499702161018
-0.07049868207355187
-0.054649907360765665
-0.04401170818926779
0.021963563928816942
-0.007837488830595127
0.025819507358325205
0.0279270725562205
0.01761012741785894
0.011103815901837712
0.0067012016396630885
0.016582748225968454
0.001451900080278925
-0.00707093243971766
0.0032749853499652176
0.0004029960338555053
0.009602095405719198
0.04607702528268848
0.00931780072969347
0.019450875467535746
0.04129689444993324
0.03120025987480492
0.011622505532092315
0.024648740932072505
0.04427178256663441
