# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP276_5
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=1, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.0035902587523150625
0.021824617264772198
-0.010323240975800582
-0.014664210252104959
0.01804071896356303
0.008347327353592752
0.011562355427282171
0.009974047961972474
0.0013981199724819272
0.006779295518579648
-0.004122750261387952
-0.0011615229148650213
0.0020685225005867424
0.0038994951360225025
0.006982714453439136
0.006040754342140862
0.0037103019589620574
0.005996347904795526
0.006078718920823148
0.006442868283614393
0.008381447062124809
0.00775269752503521
0.00792155430991929
0.011175579290247518
0.01045738886154693
0.009276255050321558
0.005902399154907903
0.004457180981758051
0.005914595077893429
0.007635519934260106
0.010653977860792486
0.008518122858982853
0.004683194547856533
0.0037825536178471633
0.001816143403301846
0.010282398998431221
0.00893578033911058
0.0009500446799833102
0.007175777611645659
0.01040415655466331
0.009292645973667737
0.011095554364950794
0.00746937047741924
0.0033795130465170673
0.0032866480373099174
0.0024535572699476505
0.0022346819312274767
0.0022058493220732875
0.006754511641185416
0.011799709177475705
0.008195492822731052
0.0029729886559830307
0.0025901275770048105
0.0008815869869541982
0.005294639865517135
0.005874738758069294
0.0036977550715110246
0.0018916509398748524
0.0030837359756586977
0.005944161059719412
0.005474045334746025
0.005759749343272587
0.00436855971733978
0.0038358833500997894
0.0038689564496235365
0.0035484534221580603
0.004903391600398413
0.004239804151425702
0.005427782496392867
0.007992955373453486
0.008232637751636376
0.007384681527381651
0.006386909992273233
0.0029109040451398703
0.0009631022696064369
0.0019946717527522992
0.0005611219490132735
0.00012307121835768175
0.00677283672222131
0.006445767098947103
0.005714802828288545
0.00819454446330547
0.0070516864141407475
0.004147357443823135
0.0038810531234723016
0.0056639014107766755
0.005760821318334173
0.007456031516052185
0.009933689030248785
0.011641295028444494
0.011647550708622258
0.008305101932675873
0.009014112340619149
0.008772632264402192
0.006087957902401475
0.00600673381027443
0.005209249417837771
0.00682246704678144
0.010418517515083546
0.012603345008032315
