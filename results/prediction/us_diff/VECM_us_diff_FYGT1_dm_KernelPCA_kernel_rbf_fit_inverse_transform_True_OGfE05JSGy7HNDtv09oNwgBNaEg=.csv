# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; FYGT1
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=7, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.16314142809197515
-0.008407394024390197
0.09663499324986763
0.01166145236524107
-0.019285737922148237
-0.06723260035582601
0.07173528621166854
-0.07210252587909677
-0.04803398986507343
-0.04172037424876578
-0.030345613806619192
-0.03201117486036216
-0.08736257247976652
-0.022257743954310225
-0.02906045554283682
0.035247742192863356
0.0343215327154698
-0.02067682151947081
0.05756365257914525
-0.036330866033133354
0.037144165347837516
0.041388279800494435
0.03566397602106661
-0.020618389445243857
-0.027670883708122714
0.013651118601806032
0.005219466594461798
0.02428305949345769
-0.08763251498024896
-0.03193621853402723
-0.04540490544154093
-0.07576074318225325
0.011840932970559315
0.022591838860143452
-0.004051479685334683
-0.03036134868157158
-0.0819025361419484
-0.022882989648220615
-0.008406035579519754
-0.05351405905967554
0.07152496208846726
0.022297500447289897
0.024758173097830388
0.022886256293082937
-0.029223403078774808
0.07911542098570816
0.022437835334472973
-0.011682213087839037
0.011929708416828763
-0.012938628089284837
-0.02330060220278689
0.021608132203982354
0.007188767992025903
-0.003406367458696812
0.007516386754890592
0.017611574280279936
-0.006540736239785558
0.006799050434468211
-0.014146880783953104
-0.03863318101083381
-0.022153838060143562
-0.03516256948843029
0.048911072962452
-0.019311955018218852
0.02678933161966789
0.0426358653885986
0.01668417775468444
-0.01333931952413201
-0.021352434041983757
-0.010371691952112842
-0.011657079619983746
-0.003510039997071307
-0.04826919220898816
-0.13893356491093992
0.03928289456932168
-0.027791443741646275
-0.007395640389917392
-0.04096818858580999
-0.05743341051857016
0.040903939228050204
0.004038029269784693
0.026099084605464118
0.007880973058675736
0.012234840473154682
-0.04236815457408719
-0.01312765807844707
0.024101696060882333
0.018747691956146954
0.032273244177458305
0.029227928341980625
0.04274411918650727
-0.0058351693911567045
0.009824932857472898
0.005168771367818481
0.027438753909919962
0.029392001472249872
0.015361357880620917
-0.06682138763302777
-0.07816637275299584
-0.0049233456305480885
