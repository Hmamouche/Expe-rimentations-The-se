# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP264
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=15, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.0016376673593306514
0.02296478752768756
0.001384216325508791
-0.005733400716866965
0.010264744468312968
0.009698653225720104
0.011522934311221613
0.007693946727542797
-0.001750349612725811
-0.015431619578673846
0.002117887588463662
0.006575125684027531
0.0031145363975230936
0.0064911941118858466
0.010983647646944265
0.011639679785117537
0.008156692284021907
0.004600306035742645
0.002763245251651408
-0.0018444332488776602
0.004562821108143244
0.008000268275111525
-0.0053369773009933515
-0.005383666425418763
0.006215801015751941
0.002139487145927202
-0.004994736696413517
0.0018529558883776751
-0.00015894895635851052
-0.0011814203646311372
0.011523992450984167
0.0172700734476111
0.010552085115165335
-0.02140497442144295
0.0008417541453836085
0.007216695072220439
-0.0024037675852636186
0.01370063049581146
0.010229647284953168
-0.0016438410047985485
0.008950672644303288
0.0146891962122745
0.00876796287089253
0.011329630785252552
0.00010264584722284543
0.011342253862572883
0.013338635357757412
0.006875552285540049
0.017230477701848733
0.007759035415775491
0.00117100460200865
0.012727478971781208
0.006793444853676073
0.008311465217245672
0.01777518307250539
0.010419476447502683
0.014088980047206389
0.01970174839945653
0.01984600251193307
0.014348202548302718
0.01651851229572836
0.007255544246395019
0.019013551679540313
0.018177038770105534
0.01862880611653496
0.018800696056625602
0.016744293534253312
0.018995476080874735
0.01836402965566545
0.02176502281934466
0.020004199824275357
0.00627579006351714
-0.013489265864157895
-0.017186721121385657
0.021321452020824166
0.015212620235705902
-0.0021077039487456626
0.00926780937172769
-0.008985204888301348
0.014633265010759297
0.021154280160239965
0.018871969285715995
0.0183074300049302
0.017016773033967578
0.013151722220049091
0.016861481076701997
0.030355239580225193
0.00825253364059465
0.0030428679380397113
0.018627332131781527
0.03086780806739991
0.013506413281959275
0.007404153359588435
0.017397113930113152
0.015020808243382111
0.0006324942487928942
0.004279293952260144
-0.005480774665752487
-0.003487848031672372
-0.008395182248322643
