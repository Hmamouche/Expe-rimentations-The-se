# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CPIAUCSL
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=6, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0014462846991342686
0.005845364152259474
0.007709313693293756
0.008174354985517706
0.006656690262976335
0.00343925341175773
0.005099045062080707
0.004373059650070865
0.004608849274684862
0.005289768094959924
0.0028486022015403608
-0.00160085768918361
0.0028764163558560115
-0.00025718894978924914
0.00803555811459481
0.0047217557766799185
0.007129710357611562
0.006314619915841608
0.005488728054226606
0.0076722838541808695
0.006988411529266276
0.007928610168623822
0.007874294363612632
0.009357094888659372
0.005928897342483979
0.00743150661343353
0.007808180312631905
0.007349991708923859
0.011319017137190438
0.009179748684995503
0.008977238776657487
0.0054924143658798205
0.0063478336418581905
0.006652509958994959
0.004907899300273367
0.004888838336520221
0.005783870362331076
0.00792448974889171
0.005732071780114415
0.005030899572672498
0.003046786946227766
0.004796673945356523
0.004775328918518721
0.008145560362141832
0.005629181562232276
0.005544926633396568
0.006502087025266932
0.004917819732308043
0.005423886909027997
0.0038455019040206095
0.005143893583504909
0.007517747759498663
0.005242478368272731
0.007505328940755079
0.005986517388555142
0.004588299734872677
0.0036046295772070584
0.0036616739828638886
0.0034844099476498487
0.0029341846819761993
0.0028199844231341304
0.003445929645973972
0.00442045571121882
0.005933972326579951
0.005639949443833462
0.00766983649367785
0.007321523679446384
0.006928301844837166
0.009502040249518371
0.006300298336219027
0.0071938176401064105
0.004892501131867527
0.005712465303362765
0.0012405812208015519
0.00410126428453916
0.003227421491397038
0.005354807951941705
0.006912740775987339
0.006741017257999478
0.0018955573400918635
0.008103711027245646
0.0013090070012573972
0.008701465647050863
0.007149478133759717
0.007417122798558257
0.008537675321511494
0.0076346766430780725
0.007949671858539427
0.009000562243341602
0.010782283959155864
0.01069894470787279
0.008863248132706225
0.009149110872069821
0.00360565217648646
0.006608345179717819
0.003533029034855012
0.00866163434566624
0.010982865327724047
0.00881362748163335
0.014091757499041532
