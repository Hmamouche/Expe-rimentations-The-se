# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP276_8
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=13, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.009837698919666607
0.001821158346439368
0.0031120121922423314
0.005347251817598545
0.00490873806489356
0.0029577891034657227
0.013341780167231056
0.0032394507437057724
0.0060973143655470505
0.007121717748326777
0.009614771446182464
0.008407078958866276
0.012105264120618906
0.01181420948689273
0.0017883274172531636
0.003948887608601976
0.0026430308337907736
-0.000764747791948859
0.01240917334263829
0.003975993249115989
0.006687928889208305
0.00550102073624699
0.01137458263999937
0.00017209604728062955
0.0051376135909995185
0.0029548396684487763
0.0019227059901711142
0.013517881305907252
0.008744080592422146
0.008128471862970587
0.006496533598966355
0.002967181849051977
0.008985739547513923
0.004791917598726445
0.014414901542447803
0.0072560678850951636
0.01135869941349751
0.0029663154068578805
0.0022192767870263257
0.008840471878199922
0.0033185835610359277
0.003217180735585158
0.0025145735804235655
0.0057403313441255375
0.006024148787793845
0.004644201855776417
0.0029253405523294532
0.004700717802076657
0.010058412178661626
0.0061574291072796555
0.004919203452262679
0.008398757712728555
0.0061911537512895996
0.005902217000207846
0.008650334143849896
0.004969509546972912
0.006901311726643241
0.007435270422244106
0.0028538629563457122
0.0031378806619417245
0.0014949893521926216
0.005646698276861311
0.005040271710667453
0.005920707328355495
0.0035799130956460385
0.005489100211274384
0.004974223015213414
0.0020351811105736445
-0.00013565135245717118
0.003081770337056207
0.005262759524808688
0.000896598799810671
0.0011892517495114177
0.012030513243053138
0.008197691194628619
0.010682817293484047
0.003919670067602634
0.006411600812525763
0.005960598725284674
0.0049378787930213185
0.010289633417575128
0.011380170339014976
0.009105583964564573
0.009186884524429374
0.004439376841508655
0.008192110938719008
0.008660269005277357
0.01087804527390994
0.00794845286261834
0.011718629216675831
0.00791578610228651
0.011793996992697401
0.007390921590628058
0.009101482288351061
0.006013910786648718
0.013178707219400818
0.012448367252639246
0.011477538236140505
0.009085498054131684
0.009987739790053195
