# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; FSDJ
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=13, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.0026937024587043255
-0.012126454968887281
0.00013977006776501105
-0.007321072305650006
0.009419579564820871
-0.003048621587053776
0.0029466208258626635
-0.0005763879192824304
0.0018895672024217495
0.017642917401482956
0.01893152623808585
0.012666784557391224
-0.0019423736470102356
0.006238006277883061
0.01458711458846016
-0.0029241420693053586
0.0033907108530838144
0.00978649637983875
-0.005476014037704589
0.05053046938499005
0.012168371679656773
-0.0292430386129565
-0.003414007940315913
0.0012854964311833066
0.009661138224375686
0.012170069379386876
0.00741359110971109
0.004145254231589051
0.004989553098105587
0.000804696002604553
0.014463587563703768
-0.008916542328382534
0.0021761010552887633
0.00745191816158069
0.013858648733209133
0.00306727113605199
0.008398182288529833
0.008455544389511653
0.0019955304644192567
0.01002720069235589
0.011176466910175178
0.000782466143058286
0.0033098971360402685
-0.008072267584321429
0.01388554096351288
0.006066749693279664
-0.007186696446473205
0.010950521311407186
0.031308636800759716
0.02023275807057672
0.028271527436428457
0.009813478301952401
0.014351962085825018
0.020851032192151446
0.02801908439759763
0.018870265646962564
0.04258894685404351
0.04373068526405191
0.04776373260239876
0.024387784755162904
0.05519286341862258
0.03223593734301503
-0.01655010301170793
0.017046476367109244
-0.0022103620829311745
0.048464677345281114
0.04242698000192564
0.04723668408684913
0.012887768574023725
-0.004954325455904532
0.008242952138962164
0.0007919214457225848
-0.012871146533892406
-0.012169512814981267
0.0011003321561162075
-0.016574504480634612
-0.03440861356147746
0.009086366183073395
-0.06389205600699277
-0.02094902873455464
-0.03376826470841987
-0.0012467922562689028
0.021334419355172097
0.00927699473676708
0.015689488069426216
0.029405779804124062
0.044327391960752235
0.0028543123858635376
-0.0019711152718546194
0.001986395200761471
0.017973009538144295
0.001959502060754688
0.016687969051304655
0.04114081613715904
0.009802429783733014
0.03986386783876722
0.03562153653515933
0.02290924913314688
-0.008950567369390313
-0.0011031936006014736
