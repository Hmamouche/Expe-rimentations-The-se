# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; MOCMQ
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=12, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.05780119737995594
0.025302515522027058
0.03228529920803674
-0.04043783540498405
-0.020226997728430885
0.01395638708231337
0.0386340542689172
0.012944222428211766
-0.026289254578371207
0.025601548066362306
0.04800659330440893
-0.01654252629607221
-0.0227202956544938
-0.020353571900305983
-0.009244491157574274
0.023370447371164907
0.03418563317154111
-0.0038891743761396026
0.005708830900334142
0.008616857096422605
0.03369114480016244
0.03405233169714782
-0.04316030422987335
0.003769456941569903
-0.01640534948720175
0.028114135538025276
0.0005485769347498386
-0.0229591974701501
-0.04267202061886849
0.005314139776964545
-0.031462280061057196
0.0371134561170826
0.027874045241142602
0.00951198193477502
0.00573283124151827
-0.010038395657749045
-0.007437133741042894
0.05338447211954153
0.020802972937133
0.007473988489121787
0.06245571200136888
0.015931120047649305
0.026330744487792213
-0.03438194426760795
0.017260205323922678
0.0026581608164536526
-0.0024177150058219484
0.008028998999376015
0.004201910435597115
-0.009417008255971492
0.0005517049083557301
-0.0013672360008073455
0.011035824898562353
0.018632531513893883
0.020983369747264558
0.006826357385137958
0.019647191832406295
-0.00817652505614407
0.021929044987872286
0.017326471582801154
0.0089308203873101
-0.003843644918716053
0.007175683781367003
0.016277218690668883
0.030863140500627145
0.01992571083946112
-0.019962343717036042
-0.009347805853760879
-0.02145530223824783
0.012477043102579513
-0.011595333819054436
0.003950418070809727
-0.026708672616440422
-0.024417781266730342
0.022248992266023213
0.006342237452520723
-0.0005603089515655545
-0.006269482521389179
-0.038593987062300134
0.023174623114779982
0.008049067034254407
0.03007281536328415
0.04171973645378444
0.006447079105627099
-0.018194445048105683
-0.024619395477526278
-0.03077995936440288
0.007573250756836455
0.023231498738787867
0.010552972741670053
0.0257956269959737
-0.005628822215845739
-0.022654083394403318
0.011984961091851296
0.005980557032703941
-0.023016188877927116
-0.006893244101214507
-0.045264635974492894
-0.016226661354192297
0.002473804905983361
