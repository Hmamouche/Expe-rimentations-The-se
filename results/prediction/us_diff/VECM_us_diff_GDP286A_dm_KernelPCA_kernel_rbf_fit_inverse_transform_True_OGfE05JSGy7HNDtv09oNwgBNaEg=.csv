# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP286A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=7, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.006198390303351075
0.004509822227985617
0.009275754729749178
0.008978532361831904
0.0031357309002127184
0.003477473597228869
0.005237963575315137
0.0013440475073893325
0.005121311296373726
0.004693242291317518
0.003802478899025053
0.0008090213905220154
0.0027286137859059275
0.0021675479266418532
0.004399545172142794
0.006033496708391668
0.004910321158243189
0.0054711392091622915
0.0021856334329592385
0.0034341943317895878
0.0027509116473765135
0.004657605416200019
0.005213785739651859
0.0034931023699912617
0.0035363651648370846
0.004682616083408181
0.005009226979260984
0.005200412804822946
0.006270088422772652
0.00785632272336663
0.0058854108012974795
0.005727875685173037
0.00818390732574792
0.00242719565105485
0.003511853124427947
0.0047067502776517575
0.004263891001810401
0.0033055907831540696
0.0034518847484698596
0.0024754326666093715
0.00460612588055435
0.0044478838206546654
0.004725864482953927
0.006767465245061968
0.0055954893399639055
0.005047911269210361
0.0036311610471124107
0.0035524370070117075
0.004336978498894845
0.004898821173539841
0.004945084407474987
0.004417891390960801
0.006060675469659546
0.003389302531039594
0.0016641971441327412
0.0043248575325832515
0.004620719815294498
0.004242588328238988
0.0010084362349162847
0.0031323806463297984
0.003086731645805291
0.002873262699688649
0.0024578127660235083
0.004565293513780383
0.006466691577679683
0.009004856972329361
0.008293075152395912
0.006704281300235341
0.007579946385366677
0.008486994111649222
0.004985680737392224
0.006454588291256258
0.005159134813562905
0.003336224565823399
0.0054495126869334
0.005248868091256586
0.005912531728874526
0.0074203520660985015
0.006852011762873093
0.006993032581127005
0.012252085912990414
0.011419054733511043
0.0037477269952174573
0.010355165609017683
0.00974411274458461
0.013788162954080424
0.01118765583986977
0.011799663590858772
0.014277441860272185
0.014711976597150412
0.011836937533620983
0.015477270273099489
0.010028331739613108
0.011309567773736276
0.009919340971729253
0.008516217791224122
0.012034609301108019
0.014531277136156852
0.011916008915847981
0.012921852971732
