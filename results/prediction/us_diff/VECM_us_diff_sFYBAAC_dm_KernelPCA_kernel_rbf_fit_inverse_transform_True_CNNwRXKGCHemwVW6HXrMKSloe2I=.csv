# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; sFYBAAC
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=8, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.04236564508277056
-0.08648932560792363
-0.052669819127313056
0.07146042684088577
0.00766773588183968
-0.03577653588338432
-0.04603501816944364
0.009428237612419985
0.02524283918774911
-0.02557492205120521
0.03228551914411441
0.009909266215202236
0.07516693981175857
0.05000912727013052
0.054569703634570345
-0.014509079574437644
-0.008505859504827708
0.03643946708330813
-0.08742715332141006
0.006246387287886424
-0.019147948591878218
-0.11094681114183266
0.0026850390029600213
0.003479980000025056
-0.021347634136997466
-0.01847342528695713
0.002752598477349745
0.017604962648865928
0.04661687953642012
0.026872394882403693
0.10722330218500828
-0.011972731082026072
-0.09082533832696243
-0.1176250066107518
0.010632168614334404
0.02090598950478241
0.06699804662795984
-0.028160139272596953
-0.022948084189876414
0.015654162472917413
-0.04787162381250712
-0.031572890757020536
-0.00017504536152529449
0.02926096860348352
-0.04348038306068344
0.0004424159463038285
-0.012673621510610578
-0.05563446126086056
0.0011030004752353717
0.030195779180496946
0.022715289182724814
0.0006866392506607818
-0.018435729528803565
-0.01006736109741789
-0.03953869176446247
-0.01955628522873969
-0.01733905287517474
-0.003873159012588126
0.0158753965259785
0.02472156272394072
0.03194398966671844
0.0701424129856416
-0.022547873110270324
0.0387385030832308
0.007706968129191742
0.005612053257612411
-0.015257454708807697
0.0660357932850714
0.03280474194309207
-0.04763469046908469
0.09901945854877336
-0.005788208515843905
0.09001646259029687
0.05232812229355165
-0.0760390095841674
-0.0073637176056311066
-0.010515113476225302
0.005401149485721055
0.08959966740486197
-0.05140206670109834
0.0028872149797433307
-0.08501248427435217
-0.06692289640654404
0.009816866830771279
-0.01774513893910658
-0.0016660014127117886
-0.014140425642770134
-0.01143089181089258
0.008451351755895849
-0.03034183439257275
-0.02761203471853543
0.04303638918710948
-0.005263483810528968
-0.01986322483925577
-0.006948057811757346
-0.04035583574138499
-0.0146107559103254
0.11736197663742334
0.0912405679946578
0.041983485894993434
