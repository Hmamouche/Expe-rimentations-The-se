# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; FYGT5
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=4, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.07275080238513805
-0.038260326910452086
0.07249125419274215
0.06219019041100815
-0.004471859029054309
-0.043221385819642494
0.0481609379185593
-0.09537194317402634
-0.0669125186546101
-0.058828782767874704
-0.05308360908069261
-0.020752346969170683
-0.08386673223372813
-0.0635700032429874
-0.041470460040465056
0.031861005233853684
0.049369113506872175
0.032101891745996494
0.06291633211566672
-0.005172123597652938
0.03132026817770202
0.01325017933098335
0.029924884091312734
-0.02418474514666784
-0.03395367344025242
-0.013672178660349133
-0.014203097084656405
-0.015096145801090942
-0.03278352685780704
-0.029011930750271416
-0.011610380544336312
0.006743625706684554
0.02240091395817233
-0.03175539965505953
0.006694379983714957
-0.044753610050502816
-0.04331073134103438
0.011023267941851853
-0.04873926202977401
-0.027621774419728327
-0.017861927637080603
0.0003238481275453808
0.028886380302001337
0.04076588610567627
0.029230611263593876
0.0707966639310264
0.01216516759470073
-0.009057837234421991
-0.00854411099034134
-0.04834663923770838
-0.020664458134003534
-9.12903847611929e-05
-0.001498539937578305
0.035458779129208695
0.015156980073777433
0.017700661461463
0.019956287863507723
-0.001156787554214249
-0.0047412441561767
-0.034966597148029945
-0.03767166940353282
-0.05123061865653258
0.030926179560650184
-0.027531280953954722
0.029482656110881945
0.035870569234017
0.0493813242064865
-0.007468449831457514
-0.001182175535826828
-0.04197479191427714
-0.04990586795203504
-0.017316835656706848
-0.0462297293577659
-0.039134914309204225
0.025767035169550014
-0.0313384561575622
-0.02839703094741127
-0.03202841721850576
-0.06498477730857413
-0.013510273797598215
0.028425970240320324
0.03130474301240958
0.012510447675528898
0.0274164323649957
-0.03142245325791312
0.023715127190834788
0.002597184867613788
-0.01694161834949638
0.020681194183856992
0.0022603884522169704
0.04009304360513082
0.0026719546658795523
0.009549215405983654
-0.010677220620545762
0.03463121408672313
0.00508073488176043
-0.007350685624788156
-0.042333351095939165
-0.06556942820893419
-0.011730245393213016
