# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; LBOUT
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=8, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.00594227191434285
0.0009167647246049616
0.007491882637228115
0.009611660057325782
0.0021182557046757872
0.011435359864792036
0.0080010151960636
0.0024167391225536437
0.009138414553050688
0.017217782852605078
0.006427799432741804
0.007270830420731369
0.007928195297469125
9.751270637003984e-05
0.004025019508487538
-0.0021017603474667093
-0.0013554770223581218
0.0024124131651702897
-0.0010258791753190192
0.007972676216902386
0.0047085688088343534
0.011927471832176706
0.004672894639392692
0.0007771647382354401
0.0016035200254226724
0.005844783080332466
0.0026447828652666062
0.005682605235951169
0.005060567267493922
0.0034024042727715626
0.007076258313469556
0.006835600447452927
0.005875155606822394
0.007869936867565843
0.00039563989939288106
0.008526969036417677
0.005332312761567547
0.009587630484283797
0.011613256280718156
-0.0015971477231768493
0.009294453406933467
0.003620717092364339
0.001615110199471365
-0.0033589711254893182
-0.004916769795756359
0.0033019668811572027
0.003594948247681978
-0.0031760474617342307
0.0067663997704907565
0.011154577980591716
0.005542392102898229
0.009088194254293231
0.0017444057870764076
0.0005445717022651812
-0.000597978568897849
0.007355567118955991
0.007893875772923222
0.008623933924727857
0.010491203863063436
0.0069529904683140855
0.01137312607672482
0.01283197933524781
0.007780583097588693
0.0005700621486625992
-0.0005391831116744496
0.012329934884172836
0.007860128695984979
0.00677442430041954
0.012018217138802868
0.009392389429438954
0.014613835032060013
0.013749543159367114
0.009609484477608966
0.004234263390185865
0.012291133484432108
0.014310408447463539
0.00853829295467165
0.013135892389616405
0.006244796923814471
0.010316047190195634
0.016235164624871953
0.017832485629790985
0.01308658289251521
0.0053884863745002325
0.004340060272876977
0.01066040309924296
0.01413746917677881
0.010726245005061108
0.0036873211193051655
0.00676216836253734
0.002839996882698988
-0.00295940383171031
0.0038250501087793445
0.0018720290116087887
-0.0011870936692394518
0.0020130097539212306
0.008875172322979198
0.002473666489556339
0.009742596210977382
0.01626097340951601
