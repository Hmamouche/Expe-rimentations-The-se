# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; FSPIN
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=1, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0032612229192214956
-0.004042407766768562
-0.0027301090938201076
-0.0033987972530075
0.0017125303542687982
0.0020894706006977484
0.0037702505253137788
0.004965719453045931
0.0019532768300439146
0.004069131344338238
0.009816092783168685
0.011820641815284938
0.0007938175276455882
0.004284175316908997
0.0212740309823172
0.005776645641695319
0.012440090703998305
0.008958432909974006
0.0025954687650108863
0.04199855188710025
-0.00680596528259428
-0.02604787306241777
0.005684885032320973
0.007941494050439387
0.011544018241869418
0.010523340033544524
0.008108810127942928
0.013467778551477528
0.006468692851923791
-0.003562333294926954
0.008404010832906067
0.007890880767810433
0.0021213339117479484
0.007478825383207642
0.012706511874696482
0.0025788644118386697
0.0030121672927022726
0.005762313285554928
0.002925153597457468
0.002628647097769375
0.0022435698798382677
0.004577303389284026
0.002830250840507466
-0.003018473112085793
0.003175724563100937
-0.00013690233403400765
5.4027395594538575e-05
0.013649060864135011
0.01936480692248572
0.021583731410291355
0.027374966981304896
0.022473314285570756
0.013151640601784097
0.023589481732114517
0.022670221814965003
0.02469187219952764
0.04680973999935917
0.03615834801109086
0.043155146488688186
0.036501541825871286
0.0508781738292758
0.035433820655366495
0.025098233385091914
0.03904401945823437
0.06107458381850257
0.04886932537910518
0.05186185487298338
0.026901018776138944
0.036607428634991585
-0.0291624716323974
-0.047132647105861535
-0.060300786108775074
-0.06286939763256086
-0.027477259181532196
-0.025184416013242866
-0.03017487517474131
-0.07263219600923235
-0.02267066730624657
-0.06038699530401069
0.018161708023065687
-0.003981878183462503
0.033054515073683545
0.0380953541379062
0.015292313076594385
0.005234554983647512
0.024582604534542144
0.01790654059290745
0.012915216807227452
0.017589837136542125
0.0009352401518283628
0.030851004090291435
-0.0028998381423095787
0.015084602240427073
0.03376799596974861
0.02567909199075763
0.05050470716746133
0.01898557649453033
0.04116577668251692
-0.03422896430583193
0.010646907503916501
