# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; FM2
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=15, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.01192497721858385
0.008522237045794271
0.0034134373669140574
0.003574785849399237
0.007931393389268276
0.0053712359806546905
0.006475309730172359
0.006055900184577113
0.006797030792041663
0.006108825830399223
0.006871983429932241
0.008591295236431058
0.007282937336408319
0.005237261425379263
0.0030044458701575967
0.004918907872300462
0.006319148692736297
0.0038920093596845084
0.005602460763747098
0.0038647148915793633
0.006030153634724783
0.00671327471672681
0.003865954371883629
0.006117726555879487
0.00695866771660586
0.0043930291852389055
0.00409104926758264
0.003863719686901076
0.0038517483595809296
0.0045610093518817256
0.007988887489664332
0.005458225600889011
0.004784273353853337
0.003168284018009361
0.004232276980300708
0.00220088858162341
0.003960913885539229
0.0010560056104404294
-0.0011148334445810009
0.0019133255727066068
0.00018524430193321301
0.0019908827020784156
0.0017473031622461635
-9.349016892945663e-05
0.0011041477407839277
0.0005653904905174313
0.0016550123105204255
0.004018558922014955
0.006290445596064795
0.0034908144972208392
0.004767829857710832
0.0021274924871315867
0.006004602498243935
0.0049959307135625216
0.004540159836075567
0.0069585813595017644
0.007231334330737492
0.007485156398988382
0.0102497003365362
0.007533565029610152
0.010537455936195747
0.012214155349042492
0.008851563579657924
0.008473988314940926
0.007867973557443493
0.007910983619548544
0.00738047491970701
0.01368910371575656
0.0075113676785649305
0.008763189446188363
0.015240586817927245
0.011242237375902707
0.015047539523994007
0.012376140781367862
0.011612076160037376
0.010734313294419217
0.014690898011920524
0.014183135959147716
0.012746761097910057
0.013063790996720653
0.011685031556961179
0.004044939335140896
0.013875781601359815
0.010492234743471406
0.009431104499532003
0.012307986847213195
0.0027064057011295982
0.012494987148040093
0.008759638033426933
0.011555034582779952
0.01036918372726425
0.004809901269041847
0.01155861626015885
0.012808423947259283
0.009485696591448652
0.013658832861722738
0.013700560207910033
0.014018046337327474
0.02006478920110336
0.011877407168582526
