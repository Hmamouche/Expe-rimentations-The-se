# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP276_1
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=9, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.004918883399939033
0.004104050247400204
0.0066090764712968975
0.0076908561380208025
0.007023070771751278
0.008414321671144554
0.006261349912832299
0.008394747676569492
0.008262210445855074
0.0077249048492623405
0.008958376730767917
0.008107435679955055
0.005522400972685005
0.007556149115127406
0.007059962377026613
0.004788351152567751
0.005418402704991136
0.00822879769476828
0.007809505565449023
0.006535711748693216
0.006842468092985441
0.008368260202946039
0.004939428466058574
0.006330696809997219
0.007874305984052086
0.007335908183728835
0.006132764359320624
0.007354211965301104
0.011097693904790432
0.005773503734947952
0.008492046942623555
0.0049422692749443095
0.0028267462977362968
0.006544685266306814
0.004604336298762581
0.003709545229857406
0.004776024855777558
0.005056760038752044
0.0050311758026853285
0.006651301246848514
0.005145938613978335
0.004290151505005112
0.004852855364885637
0.006149775429561422
0.004378267699262082
0.00561743227919487
0.005973294394089283
0.005784084496136313
0.007632635891460167
0.007407714413999785
0.005280591739800803
0.005682684401996957
0.0058762336188483465
0.003978667969322569
0.00578746177683869
0.006977033479305407
0.005236763611017814
0.006910465010231798
0.006452905511235027
0.006645201911831952
0.007081743545544972
0.007790111039402232
0.004546306196619956
0.005563061735386858
0.006054444290502472
0.005778355110175886
0.006909996861053839
0.007644051047148768
0.007072879258255374
0.00870550280750474
0.00854000611032844
0.008142927075806255
0.009049452418546738
0.009008278503208523
0.010206291033135901
0.008377842139073804
0.007411153596562298
0.008793143294657347
0.006304415505490229
0.006603514852843183
0.005753085589503157
0.006053621788576892
0.004801040651371521
0.007126467737958032
0.006993180529317727
0.006343845684765582
0.007762343303073484
0.006869843963160551
0.0053327765521965645
0.007227364399543592
0.00780462853119832
0.010750181420585994
0.010886705779956152
0.013139618564766658
0.010551310294006796
0.009495845459666247
0.009131301143167571
0.007806166749053776
0.008175431783888963
0.0064304966319410906
