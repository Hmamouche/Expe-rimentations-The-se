# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; EXRJAN
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=14, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.014984376574461713
0.04753212667779833
0.08758374317064231
-0.008243248694013973
0.03019525383090672
0.03447135202958871
0.04054537943278147
-0.029193313787330276
0.006433640749492002
-0.10419872741513103
-0.10817987224043395
-0.042429039613377954
-0.06986433185026002
-0.026578405609725964
0.007490546007331333
-0.026644152054351115
0.004809603103493848
-0.005325572427961403
-0.05836558558179393
-0.005464906917429052
0.025350674990063368
-0.06230171443822153
0.0357303791303975
0.004436723618218825
0.043024225440772904
-0.00390949968583975
-0.026465126826542167
0.04843625633750265
-0.06693600036226272
0.005297025170651356
0.001090367038726026
-0.06801978852291099
-0.013814009427801397
0.005265006643845115
0.022094474189753657
-0.0050152862433874845
-0.04583246107968895
0.007968750112720685
-0.04563321652246594
-0.046290140820966705
0.040179134119152665
-0.05987179445104214
0.0031635209799009342
-0.02040841600115858
-0.011698097344633578
0.021694358196849596
-0.00012060527545725182
-0.029124940127837458
0.024292479287572437
0.007905658074147429
-0.012157150922071834
-0.008637938466130294
-0.0106792298597366
0.08629702735509827
-0.011613349726247037
0.0009162295457023836
0.0031360454277305407
0.041919740805332444
0.004424933735576552
0.015920772796756414
-0.023995008891943715
-0.042359286357377804
0.01912655516967032
-0.013952039800107646
-0.024050466765989355
0.011736225852078438
-0.02076877128727658
-0.03216093305736589
0.018612154424725233
-0.01081565847904486
0.013603510419266664
0.011489586332728067
-0.020210931310718244
0.018066759178674317
0.018085083682282507
-0.056109400650446076
-0.008778960636400471
0.0062836019078337906
-0.0645957195789777
0.025063760840807598
-0.022987613584527153
-0.010861759101608165
0.0037117282352512222
-0.0016674457962830777
0.007038045343554639
-0.00020201584544452672
0.004391164506047266
-0.019007417366783633
0.00474363592666186
0.041163069310034314
-0.0020054055166849553
0.038294714178358835
-0.01436046970173398
0.05076768322885705
-0.014855165718025757
-0.014402152987751202
0.021497815287409544
0.042865015774439366
-0.03930784964163328
0.005261685097920045
