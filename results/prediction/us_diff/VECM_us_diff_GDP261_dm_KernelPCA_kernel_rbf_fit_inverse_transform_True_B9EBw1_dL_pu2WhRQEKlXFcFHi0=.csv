# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP261
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=10, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.019820031803658173
-0.01393884257421188
0.045232213262435365
-0.04993304619047077
-0.018737587779106887
0.0015562809354129
0.05456185564875156
0.03380397292083286
-0.011895751136322574
0.0066368389427022174
0.02995063008483849
0.023396239865293152
-0.00531958960402922
0.020472476843877273
0.012116650735467607
-0.013205963720570627
0.01767101495219598
-0.025025490771588416
-0.005800704855572421
0.005477760249227005
0.030750913760209667
0.0376610103522891
-0.031110495110194446
-0.018889068525578197
-0.017539856245704095
0.004125743823443457
0.007563122616870979
-0.025445084144139186
-0.04819045726034481
-0.04882596228289624
0.012829367282831333
-0.003922566951972227
0.000656457709234312
0.012265791202633552
0.011960140882825522
0.025100217127753656
0.015884718448514284
0.025946188516865767
0.00010058705516436534
-0.009274270952707227
0.027809469087065046
0.0323885518516789
0.026167606381238235
-0.005115544596172433
0.018821641947950874
0.007219148795106815
-0.010073630643214511
-0.012556364948945076
0.005257052222099049
0.0019034760635193767
0.016790306126781552
0.004809751720485449
0.0052709814411041386
0.012197078844761493
0.01211811651020422
0.008673435254987467
0.01745032568559441
0.007062092569843139
0.012385798794129993
0.009573536214913856
0.015075799956087823
0.018515350351317315
0.018253059876273063
-0.0030024765455719067
0.009230566986920319
0.01685116429994005
0.014633081274955894
-0.0034342155541277238
-0.0077902263133165645
0.0033037526068444853
0.01217983889540094
0.00802159161053434
-0.027689964892928
-0.007427990291391853
0.05698860748632407
0.02738832228447625
-0.003481548471813769
0.011834485011703928
-0.0022187383773170618
0.012999145480915818
0.028198749463794286
0.054681229635022706
0.03402376501456142
-0.006572889898249428
0.022470737154694824
0.01742859924210675
0.02076738082280328
0.01852944162112491
0.020231540288604778
0.0021574228250254204
0.014553975793130128
-0.043601804854853404
-0.054796442803446935
-0.044531968134399295
-0.04685632859018772
-0.03376283755980611
-0.06293574478113821
-0.08791978197372977
-0.05241282059359702
-0.04539256632403965
