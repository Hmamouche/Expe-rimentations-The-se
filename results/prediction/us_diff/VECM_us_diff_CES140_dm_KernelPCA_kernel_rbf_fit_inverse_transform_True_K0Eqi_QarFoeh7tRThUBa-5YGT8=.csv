# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CES140
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=6, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.010017115895644815
-0.00010461216712027304
-0.0009981236811376542
0.0010406767180438765
0.013531223105093831
0.0018649320442718459
0.002130111349390502
0.003394438605728003
0.013280711876538488
0.005578551966206064
0.005821958950907138
6.871635107810119e-05
0.005695506945241791
0.009527290736712775
0.005662716938185703
0.007474874716862919
0.0022093087469794593
0.007003305844477052
0.006054630624434605
0.007793415672373811
0.0047303017240207905
0.008543163107538197
0.007332699121002416
0.008026078100888833
0.005052731338812553
0.0056604640164955936
0.008965626189203955
0.014676066615827306
0.008594730511953563
0.004111544143561016
0.0012882981010573476
0.007870150853193699
0.004823032896832417
-0.0012290611680434188
0.003067344016778176
0.0026620753307447674
0.006833753569169427
0.003428106452905968
0.004546986892465135
0.0042753317446083475
0.004567928231303614
0.0028545664670876067
0.0039404013679186865
0.005865042962642008
0.005425668813588575
0.0034308157243269563
0.002409490837505534
0.003909071656335826
0.002273576902274136
0.0025253000300582027
0.0035055154355394663
0.0025457886103413033
-0.0007029676898278295
7.122052223664421e-05
0.002322020096379704
0.0018606880610508659
0.002552969107179726
0.0036614437587800973
0.002382665949494241
0.005864313830627424
0.005888415307654819
0.004747176057971204
0.005414273807678434
0.006758042701457555
0.00783351726620127
0.00600439227778922
0.009491104638482467
0.014871719683341505
0.004955914301991203
0.0050091003864355605
0.0011857212056954722
0.010021274441227294
0.0052541634969676294
0.00541031421017179
0.009124274541775583
0.00768637958543737
0.004041624272404617
0.0036411639833357776
0.006274987615690213
0.003141985496641653
-0.0003131093299779706
-0.0002814381690638149
-0.0019526309239002856
0.0025399542973629547
-0.0009802455098346654
0.0032160777456129155
0.003045348353457114
0.0017175462585706136
0.005499733242380201
0.0008547087291719221
0.0025451693930763396
0.0003063292820628036
0.007186104425822119
0.0005994376412220719
0.004286504232446486
0.006513516451396091
0.0013412447316425574
0.005523223349645803
0.005078591216246414
0.006011259584567802
