# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; IPS25
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=2, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.014199839918459646
0.012155949169671337
0.012847022805918628
0.009697205201086408
0.007341507266583695
0.007107493124639171
0.007545067841839401
0.0029150028353880065
-0.0001370510010034738
0.0018210550407414712
7.891394692533248e-05
-0.00228913086857668
-0.0024306312652976267
-0.002242306306528904
0.006686244252772141
0.007977723880779521
0.012523391594991473
0.014424860689114472
0.009773815737865465
0.012856285686304769
0.006795941654613191
0.009412751189047266
0.004205622833160487
-0.0007854369262928185
-0.00016193609461428234
0.0018527405116554592
0.008136952632094293
0.008444255943093313
0.0031156316353318407
-0.007447143129983556
-0.010088893934519234
0.003638784642396562
0.0076180841839835626
-0.002286034650999599
0.0008880327783053311
0.00835586095826028
0.004063963030524381
0.006354921548563796
0.007866226940032653
0.003558706031939111
0.0025771453347874346
0.010573519080038835
0.01039005023354548
0.010083307968944698
0.009179280474517961
0.01391240155807635
0.008795648918485024
0.004830175535770967
0.012626715934001087
0.009985763611580207
0.011065649068838715
0.01937090879036014
0.018551993447691345
0.01919566402628897
0.02252479946262154
0.026662976170432583
0.02822872177636265
0.030057233340752502
0.025374069597829996
0.01927662190959157
0.015789629045647225
0.015535399688097655
0.014210909167971391
0.013214212567361388
0.014954425247966549
0.013291207467989449
0.016933052247531298
0.01929303909994781
0.014899147618095855
0.0076657365766265705
-0.004418049935073526
-0.029811743582260974
-0.035733736007492196
-0.03770133771339868
-0.005206866118245326
-0.0076987817257148945
-0.006081409310425922
-0.011702958541207365
-0.006220025684822271
-0.0023027121563089547
0.011039098540444145
0.017514972588382263
0.013908551888914149
0.007452467539103207
0.01284214854013979
0.008307569038720618
0.01783478141203932
0.015940430696379182
0.0050030807290006585
0.027317910821236108
0.030279731017082527
0.023109191647643978
0.015539806543494579
0.014121215013774254
-0.006358998347603935
0.004496660854300346
0.016960740075038484
0.011201609425614606
0.006608626079306966
-0.010637965848894959
