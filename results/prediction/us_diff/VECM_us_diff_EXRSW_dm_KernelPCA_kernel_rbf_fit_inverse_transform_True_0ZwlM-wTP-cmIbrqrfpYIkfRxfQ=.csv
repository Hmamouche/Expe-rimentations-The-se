# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; EXRSW
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=13, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.00016667447106914757
-0.0558759579745797
0.04583727829100325
0.011185226627508984
0.06541181373444387
-0.017590559281051986
0.0357134888365556
-0.03723859649991271
0.02851071563344112
-0.024283127976967918
-0.035420131628323706
-0.04333951967018969
-0.08347572115775899
0.01767120471238042
-0.044544834810017545
0.011741092312575092
-0.02541595187165701
-0.05399108553375064
0.029515905659698388
0.07896531983139693
0.009784971487976822
0.01202722217503718
0.029571634774951876
-0.002894214261580644
0.027543205825356822
-0.016188927393843297
-0.03535140553253151
0.030371494594130105
-0.04488830106322275
-0.010771426596192134
-0.016870717905113942
-0.02647130390826078
-0.019471637112027
-0.011199926520090001
0.019231747595426094
0.019733979369597934
-0.00900810119258234
0.006840821558304656
-0.031471470206711656
-0.009214971967575774
-0.011299761429872879
-0.0717844964424306
0.02119817218976762
0.022576460887383826
-0.011747030832260107
0.01874197241579591
-0.00017539832306532992
-0.023900947257741834
-0.0077269452711509435
-0.033869659003066425
0.018492354697655217
-0.046822488932742566
0.035075960991358436
0.05521292278014771
0.01569510290128814
0.004190249604908073
0.022391084847716215
0.019428720463409394
0.008428160965886666
0.004882881682824424
-0.034323014889506745
-0.04346376536219953
0.041236665667235946
-0.026318622996181887
-0.012808867218663197
0.039279162063325004
0.015914075749581397
0.019022798658530158
-0.012797750847682325
0.005931720373843775
-0.030180385562629516
-0.013250980249658838
0.013444661911715306
0.0006254429892246318
-0.007476934806778964
-0.013843919505695093
0.02383780298071956
-0.03843671499306256
-0.069009591773709
0.044637541151465066
-0.01736385855743125
-0.043631363763293574
0.022427427661407963
0.004998571533272161
0.004645062524116427
-0.0012315591196568436
-0.0020804415656992207
-0.0002517739376583974
-0.012220099473887795
0.0006971208057700521
0.022781411526338988
0.007270803620453324
-0.016535967354490786
0.07114669732429175
-0.030258587592930843
-0.04056706077779123
0.049479972244620786
-0.0023293796466830633
-0.03169571206494562
-0.03060356666058552
