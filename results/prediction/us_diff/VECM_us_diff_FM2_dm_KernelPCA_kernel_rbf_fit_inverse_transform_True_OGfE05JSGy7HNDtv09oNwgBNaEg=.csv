# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; FM2
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=7, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.010959071830213739
0.003658319830793437
0.007840288016636715
0.003727732363433458
0.005586322081495702
0.006274979149959285
0.006525166516727398
0.008336319528226693
0.005338697085003221
0.006424932072252832
0.005918378215674082
0.008209845423901206
0.006520508744696172
0.005634001093477248
0.004686981035906011
0.004834313218714541
0.006243588788348101
0.00394208425348847
0.006201773654623627
0.005535659069215796
0.0038673025728919058
0.0054670287397989865
0.003720817236783156
0.005332162960414735
0.006614073680044203
0.005863210786421484
0.003757185127659938
0.0035493309833432895
0.005508352396234621
0.0037050319221775575
0.006989769621941237
0.004238260214846779
0.004051479186390932
0.00440890411780084
0.003988695413601459
0.0012795826532952647
0.0013285263930730307
0.0012431638056514059
0.0009573891406066506
0.00183012674933232
0.0009867177622982482
0.0028596256778713964
0.00010416097046291343
0.0006475763531460887
0.0014151456673041714
-0.0007804796126064928
0.0022636277989551536
0.004295905544902112
0.00557884926731502
0.004238008730825399
0.004768301412593895
0.0033069759172734262
0.006073985439502481
0.005518382627976835
0.004909738930015098
0.006111064047933807
0.007752727255664877
0.006668098154260997
0.00953487865350459
0.008444811432696063
0.009784965488883222
0.012930760951612325
0.009348944807900834
0.008738940145434804
0.007943627577240429
0.008991080661978337
0.008818672257445915
0.010765039373757605
0.008474765154207241
0.009079963342304678
0.015665410947036763
0.01284896135944543
0.014083648448391613
0.013802119514473257
0.012346930858736439
0.009393235789092819
0.015049877215077112
0.013648431133370185
0.012276737886507863
0.013509559168782537
0.012805920632640286
0.005610823295128438
0.011382456649021664
0.007574908058379421
0.009214934457696023
0.012961197412118581
0.0032004836472171727
0.013111640976390218
0.007963999006781774
0.01042694238847973
0.010677561041376455
0.006316638814017513
0.012704071823752605
0.011388755340970304
0.010463322025567823
0.014101055323753907
0.013068365631046231
0.014120274239028988
0.018755223520457078
0.011472024689361565
