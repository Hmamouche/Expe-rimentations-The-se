# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP276_7
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=11, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0039246031417358475
0.0037296044841832847
0.0038318729126352253
0.00964753322259541
0.0071221765324637485
0.0069554930016682195
0.004958614563420348
0.0063547651661828835
0.0018575742581872423
0.0038389785823565985
0.008685157564663232
0.005850391966167016
0.003971907571016297
0.005468922740794246
0.00727166900559829
0.005087653705641488
0.005921679047323136
0.007417181001971661
0.0019427689539727848
0.007357032552572387
0.005901935753470479
0.0058611699222478175
0.010065545879919967
0.007360976578764701
0.005095826956410013
0.00752670997082577
0.009044307795318677
0.007648746907886054
0.010702063345650738
0.006685605640726625
0.007420676590588947
0.01116823711970551
0.010054130072320358
0.006672913951466666
0.004469596661453374
0.008111307560793658
0.008498891914844212
0.003606855282180824
0.004010321356827618
0.006316884080056349
0.007217457294414081
0.004983933896625506
0.00458241770127776
0.003667336515657045
0.00348219510613947
0.004391680405900378
0.005746331079847469
0.0032058228003266705
0.005401886690178741
0.005436502320160523
0.0063100817074762065
0.007130838516754289
0.006520017773535736
0.004648569405685473
0.007419843937854672
0.006759306731842077
0.006107557445711452
0.005766226953991478
0.006435774023569428
0.005810664865726213
0.006323447151314482
0.005057253653416109
0.005620569740337668
0.00806456563225855
0.005684205110866868
0.007223428788591274
0.009020169144350547
0.009523317437044493
0.00838316188995093
0.009663229604613167
0.008240655538355674
0.008632481375204342
0.009822158598880169
0.0033698154152644036
0.006685389483808839
0.009141230496040126
0.00788650195879248
0.008503326837656871
0.006741849317838325
0.005478632007791857
0.0069780958531145045
0.0062093788275582925
0.005699441748675459
0.007305247963186602
0.007704785461376642
0.007086729064560526
0.00842151200041694
0.007163393106773839
0.00699077365036459
0.01003829130472534
0.007961546868975699
0.005789127769610733
0.011566321516626371
0.0056911787619883915
0.0009408169961853841
0.004331927658534495
0.005006365150524259
0.007368294559299082
0.00819027949750051
0.011587072593602596
