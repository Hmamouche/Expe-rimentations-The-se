# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CES002
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=10, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.011219181975443061
0.014179541725952009
0.01454114007146345
0.003663044739939709
0.006814383530183283
0.006470539835047965
0.013250116026247153
0.008514128552793286
0.009704145966524271
0.0057498009784920385
0.008864156349223972
0.003386429500624181
0.005343318916694851
0.0042860316188892715
0.009045310539435837
0.01454699074413457
0.00963554037603782
0.007173009488284573
0.010312187359531773
0.012664279736196604
0.011573348159714668
0.014657583711288688
0.002691549460386745
0.004384240689299262
-0.0018993249067579608
0.007607293648209662
0.008035502300052434
0.0009863468380193834
-0.001583372749951089
-0.010201298654905539
-0.004540045841397708
-0.0010807529726832056
0.004450222995430337
-0.00087937636212176
-0.0016255062595612732
0.0012074048222355128
-0.00178707974033794
0.008462345924374259
0.007869833519452116
0.0029530179257065475
0.01106136943122989
0.011726193552673401
0.012782285282066127
0.01439842838912817
0.01311601834734862
0.012086527389239928
0.007712166899409213
0.007934347085370243
0.0050837447467028465
0.0033887786859232985
0.007168854782811925
0.013123776128683252
0.011765958796487393
0.014037948635635736
0.011141137491358775
0.008753122996633871
0.012463702682681415
0.008325590490338361
0.009981077695856443
0.010747813439575152
0.006107548292754781
0.010258428137789816
0.012144897259312235
0.008546167085403802
0.012295540687075347
0.01043938265206273
0.005816088456904456
0.0005138279103800718
0.005891232024379462
0.0034770732257462093
-0.001430290096214972
-0.005909088657971953
-0.013666863579699987
-0.01114089639503889
0.002815883128257554
-0.0022622586498191113
-0.0021419407533470837
-0.0029322417312538283
-0.004748745560650275
-0.0032084510575239077
0.005958994402614636
0.005454777316737235
0.004327671187889828
0.005257022905481883
0.003353959567698043
0.004818290918229811
0.005704650672228823
0.005665018126280859
0.014323430551077003
0.0057289571536795056
0.012418083207928622
0.006069914890731247
0.0015238439831927494
0.007678207784205904
0.008961462696963178
0.0037454900409189056
-0.002748238912797443
-0.001998570298052591
-0.004611799281804807
-0.007034042037681392
