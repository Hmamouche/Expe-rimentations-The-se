# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CES155
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=15, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.03529618730972511
0.08427507304428217
0.21576795945828475
-0.1891779063852007
-0.16826117571248447
-0.02409574563049378
0.0957380911246437
-0.022320012705761963
0.06310893953368922
0.037153937026394454
0.096430105993243
0.05688752534711573
-0.017020076425273742
-0.05839074271713158
0.014107351723729837
0.11687514668784968
0.044029294367332085
0.07875993571287235
-0.08066222325170708
-0.09283062342967557
-0.07117620547306572
0.06214419531886834
0.008234550915177163
-0.05191737335784648
0.013578594655398558
0.03706829317508431
-0.007273916086550975
0.026343168481816497
0.009504690415002324
0.002266201350702081
-0.11213830980670521
0.12136043917247108
0.14688852970631716
0.07290540967826292
-0.0015758450545298591
0.04700573722908752
-0.028208167184536163
0.12295415688358086
-0.027220472386040133
-0.03443256176935962
0.11634644524998652
-0.006843104220548877
0.07491849888033307
0.01928954916594685
0.015367847880690101
-0.01817300498467598
-0.03011378458922771
-0.01753593687364262
0.027165654936609704
-0.013229860162693185
0.001898167552528536
0.02669368282401473
0.04093279876230585
0.03408127085834133
0.026473240497554916
0.006409282598104547
0.0497056334485826
-0.014068102891619461
0.0038211149933121986
0.03588885789976344
-0.03608068570784353
0.00866150365815706
0.014531857903882185
-0.020212989936912035
0.04034748999052563
-0.034220237240406584
-0.015247839653711681
0.0008923949666248474
-0.05835686348247662
-0.02152508860718924
-0.06604979246208717
0.029004859860187707
-0.022172221398725357
0.008280945366794398
0.05687744424896593
0.023422094135991
-0.013549120631984796
-0.07586327022097315
-0.014996335652317568
0.03445898087867752
0.08390053332076333
0.009818330597251148
0.04783410159525957
-0.04401884349384598
-0.03484572154798402
-0.01026172052795106
-0.011257928336176849
-0.0029219030496162425
0.0279840380749608
0.016005620470754947
-0.0388453464915051
0.06903517821756376
-0.08992957950805944
-0.02513682211932989
0.020785791310009908
-0.022241384096257324
-0.028355230698148954
-0.10556418806567541
-0.04030583064456196
-0.023747162202621103
