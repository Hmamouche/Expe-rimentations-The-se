# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP275_1
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=4, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-5.8313860666904874e-05
0.006854979567271514
0.008349111136065722
0.0036264387400291812
0.008285339595768451
0.00027187577903488574
0.00559105477873505
0.00048464487085724916
0.002661222716251253
0.002653903938082595
0.002236107044444302
0.005096816619661989
0.008125344198859963
0.004401561248499648
0.006803640911506252
0.005364203997119615
0.006514191691083908
0.005217961916449065
0.004022379014219485
0.004695000896412285
0.00803750948236742
0.005788667724676226
0.010394121428495369
0.008396182012080275
0.008356113429935282
0.00817129249360932
0.01047655882225486
0.005965234352359368
0.010915953745137607
0.004338761541242164
0.008183352730322318
0.007189660871377869
0.005723771931405402
0.0029146222859587788
0.0020947886587670706
0.0018211924888685972
0.0029307474558838507
0.0032281891995669786
0.00278379476711013
0.0019045250726848404
0.002315806937060867
0.00355740207816547
0.002601290891833801
0.005139672753857068
0.00508238953263288
0.0036073053144334423
0.004553873825723599
0.004514385803149051
0.004226814029234631
0.0038553942567989136
0.004164066208354543
0.006412683662791827
0.006104841676309753
0.008796397289955021
0.005625274752012699
0.0048576210246889595
0.003806155357711886
0.003431611004184292
0.0037820695656612512
0.003778766798813153
0.003784259631888382
0.003877494880214808
0.004997852458359407
0.004234872798689572
0.004549935886392809
0.0052137100001664926
0.004213254628552964
0.005378339653304575
0.007038559938842338
0.004627228567697809
0.006355936790757057
0.005926579519995572
0.007900636974180874
0.006554008688946661
0.007380983008554045
0.002816021199407867
0.0027172590553363155
0.0036719018140522895
0.0037168320877582206
0.004348981247622592
0.005300119527568214
0.007387807191184119
0.00750213975288613
0.009899024251921433
0.007136836552873889
0.007722843506285373
0.003969016728608588
0.006446145650480449
0.004544982151544894
0.006829616651474266
0.0051605062293029
0.00679772707978651
0.007122334902291099
0.005447720364422863
0.009830980236261803
0.009709437899982602
0.01210638041379083
0.012204365659332526
0.012241411654284063
0.014575716333578572
