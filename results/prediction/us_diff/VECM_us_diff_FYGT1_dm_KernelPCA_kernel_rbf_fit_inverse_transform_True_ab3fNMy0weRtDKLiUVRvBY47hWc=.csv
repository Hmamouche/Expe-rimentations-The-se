# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; FYGT1
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=9, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.11302643328311301
-0.03562384974713784
0.20481490097810623
-0.031277886286024084
-0.05156777901835598
-0.11069175190799253
0.013370854547994124
-0.047045806213019445
-0.040174640303975946
-0.03581151946636781
-0.049096895307366606
-0.05512644877201272
-0.05249351557483382
0.027069064989157073
-0.03847599519857241
0.07416354555760238
-0.00683682219086516
-0.06334131015511946
0.10227245981959243
-0.0021981627284874267
0.049648204640300925
0.11010778068281649
0.040985545815899554
-0.03220667295213362
-0.062482186738331974
0.03557524617618034
-0.008632519075805832
0.018974427377426027
-0.06844803190621086
0.005668632029544226
-0.11869362032191806
-0.062411082291602776
0.03993637755009275
0.017754393449187184
0.018752605111338208
-0.022654621743882924
-0.13463664852673535
-0.0326976870016451
0.027390921953403674
-0.06882787492366942
0.08953495028422487
0.020477550212347394
0.023131713424936813
0.00535854489258108
-0.0032745934853854134
0.10879945501396479
-0.011070344797584987
0.02831164382617994
0.022766323751044815
-0.035798745266103445
-0.03976516201192566
-0.005064822775593577
0.009781036718968149
-0.007488346860864255
0.03073607251292689
0.009078010549555725
0.004848295636938359
0.014426623676846802
-0.04166443524775531
-0.02621961748187976
-0.03662159545937069
-0.07629953666925732
0.043593717672099276
-0.02921817673602565
0.021948756670906247
0.06406669539665454
0.0331120244691438
-0.01330243770177831
-0.026548904868061267
0.015923982359591735
-0.037273822901948014
0.003171859671358362
-0.07475203532422303
-0.12673214645042227
0.08429027042782004
-0.025463540471447048
-0.043863164611510255
-0.026334538370304122
-0.04245107033925405
0.04373953608057455
0.008830235615651869
0.041933631733073184
-0.013357540376875926
-0.011308032882364656
-0.005728343152300822
0.002111330119327159
0.020776384412004162
0.0056057431611409095
0.02779201396040267
0.037752999320524616
0.028500872950345764
0.020577675880910067
0.023126426172312028
-0.02168754519103382
0.03142045025341135
0.02973706494069825
-0.00256750372377631
-0.06634879475211393
-0.08945246845941827
0.00597624464671484
