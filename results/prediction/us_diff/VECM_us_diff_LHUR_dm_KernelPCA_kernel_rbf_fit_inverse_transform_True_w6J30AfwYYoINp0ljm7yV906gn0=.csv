# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; LHUR
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=14, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.05665444809384505
-0.23584921662026428
-0.09435425663271019
0.07762557136374103
0.07592029798740767
-0.05897655212812761
-0.08899035783606209
0.09738241268841766
-0.11415612710206334
-0.015867023817413974
-0.0679810225235669
0.008198525657790345
0.0006597042609910383
0.011786430947929381
-0.0051995249620651225
-0.06301488182269649
-0.06907926361160605
0.05947185658164161
-0.07227580968186365
-0.0021060286722990804
-0.027635585960001714
-0.14463913235232456
-0.01964968527926523
0.024564406633196027
-0.025707740882823682
0.044772256734186736
0.0194697447191456
-0.004125409951067341
0.079094314137094
0.08781005756622155
0.07373042455258459
0.027688929201555433
-0.03852619359066235
-0.022904344205554705
0.020110524228387373
0.047052768078330004
0.0341402970095936
-0.016204565765235414
0.022486698594707793
0.017182990606852903
-0.07188489576535677
0.01684791366755839
-0.06089489634285068
-0.02164311887707366
-0.008052577165701312
-0.034553852130627394
-0.05667696629800812
0.009560126496617714
-0.0269281083109952
0.00485194417853055
0.018157245996409423
0.011154221898493645
-0.05775763461489292
-0.024031525301182022
-0.03968956433173036
0.006565034287193874
-0.04510603079272326
-0.006435847677762511
-0.025091369632719733
0.000751982018287147
0.03769855384430824
0.018209319896899608
-0.03291239172952067
0.0009558594479258439
-0.031123466825240358
-0.04200092543104428
0.04024417470962033
-0.004425599886776804
0.020953293707461275
0.014430612385608551
0.04857699404617226
0.01347194607131964
0.08436145466861035
0.04561906350715669
0.002984495245495161
-0.028961333641699123
0.014273029147132068
0.049908358777643554
0.03237223348824893
-0.0038199574693298516
-0.04736752898356471
-0.05126594833511726
-0.03498768504887869
0.04084577830436591
-0.024700416443727384
0.01770303932270069
-0.011136135324919387
-0.031189099243881135
-0.015417646577507943
-0.006295137002890361
-0.03170920064889522
0.009544515617883026
0.008936095214737462
-0.05791579433499985
0.01609465600723991
-0.014854116098931218
0.010085578622766019
0.05347721079551513
0.043088278399969614
0.05495926936721356
