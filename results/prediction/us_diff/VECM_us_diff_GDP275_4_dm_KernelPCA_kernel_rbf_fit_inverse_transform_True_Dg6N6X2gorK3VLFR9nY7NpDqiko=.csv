# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP275_4
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=3, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.00837028822962863
0.007045341376051384
0.0069491528936942385
0.005882884047019027
0.00743424093653036
0.0033767327150921525
0.008105319114209364
0.0065257918732831936
0.005794011300150141
0.0070102785069922164
0.008788214581223681
0.0036640687437059947
0.007546873991548424
0.0056467165805810906
0.007179472094822356
0.010990904690414948
0.0054718701610881205
0.005163524770651319
0.009421931500013471
0.009484568767865806
0.007693377962267143
0.009512654902106005
0.011721283479657072
0.010530078644973514
0.008909273045820156
0.00918565158808612
0.010717086549086737
0.013237995623402967
0.008043246507312479
0.008980418319152722
0.012972508020371608
0.013143787948313657
0.005627243978011639
0.010275035770653895
0.00955197234335077
0.009139256159894991
0.007170264250003604
0.0030024876043224648
0.008257009143278255
0.005639043323774676
-0.005736246957566176
0.0014011984538735572
0.0016785061560547323
0.0008231456516491419
0.004021171008267195
0.0033502253715735008
0.002728472037005478
0.002632416300885334
0.005152154420539483
0.003929865682809538
0.004063679148856738
0.004820149683976558
0.0018038554861122033
0.002121868289945267
0.0022059022939149137
0.0045251488753792965
-0.0009856555490877139
0.002069535545153569
0.007585650492697139
0.004336088677648452
0.0058627957826416725
0.010432600254097067
0.01913511992198566
0.006972655442814418
0.01074943229305095
0.011766666818812135
0.0033069296947549325
0.011202649647235545
0.006572679089122346
0.0049934861818249745
0.00917883097089236
0.008255342932052464
0.008589495362261045
0.007242065329484828
0.0047014381694950496
0.00857808424654639
0.0050553389600350405
0.0008326826855486673
0.0018605887993466237
0.0007073002710270433
0.0016042352502569327
-0.0029952844827885496
0.00382901474552387
0.004148890931632291
-0.00014915669265777197
0.005176667803366281
0.004069042642216004
0.0031016467764520125
0.00505746570483674
0.005771661867498858
0.005800104183562273
0.006128792958481967
0.004922027398143943
0.003189412732879089
0.0050275936599280535
0.002331696269173059
0.0027377559640061446
0.005399023549950939
0.006356764870516327
0.004668324529209967
