# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP288A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=11, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.005834865793226914
0.004429748804667874
0.006638453030904577
0.003886667081966845
0.004964953928600482
0.004077384533378007
0.006846547488134763
0.005758240182221371
0.003109496361451735
0.003891460997192625
0.0021244747774867294
0.00020670948582769298
0.003657538334585511
0.007024291366140475
0.0067417914223673395
0.005421890653665932
0.004731122150147798
0.004523933154370008
0.0037893855212357114
0.0048840409685780364
0.0026418334442733313
0.005444401009306983
0.004564342001137777
0.006322460342069045
0.003122676506813025
0.006649115574081928
0.006758863031504529
0.005653479716459178
0.007030990191679421
0.007230947629316016
0.0046623910318782805
0.005106813423111664
0.005769311261786254
0.0014813281696967745
7.071609232222362e-05
0.004018004262458424
0.003540013095375846
0.003576301308721309
0.007527574515832767
0.00208492598792434
0.0037049965642049357
0.0015427709982801133
0.005496346375766495
0.003043271393811558
0.006195501908724566
0.004257928423108638
0.00520820949459919
0.005737263567428281
0.004909751867928626
0.001858295564365272
0.004694931213770102
0.0015174283506460082
0.004600401985180464
0.005431403327057016
0.002143561974724629
0.003967618939102196
0.002905635401892246
0.0031089432216965555
0.0007914170319729187
0.003336498919456551
0.0028196732734030753
0.005431185382154957
0.0035100072113214693
0.004920094367912519
0.006349969946363869
0.008688392146243803
0.009927872067296001
0.007773039218536693
0.008340456133735652
0.007659737131880876
0.006086547625803376
0.006841394652041537
0.00556352270734563
0.0022244907457960343
0.0030835648779258826
0.005204663206287962
0.006532164161681915
0.007047422047746906
0.01007933205729422
0.007295773960641891
0.008884336041308963
0.009605905276360583
0.0038631026452533765
0.008985032139284779
0.011425720131528755
0.01359406288579723
0.010537472941116593
0.013998316036580355
0.016715156634466603
0.016512294431200173
0.014129574552549408
0.015797015037156064
0.008256241606974968
0.00922428063878988
0.013287176966400343
0.009640722487319463
0.014762549833593725
0.016723123435966308
0.014891366213801865
0.01893682748524964
