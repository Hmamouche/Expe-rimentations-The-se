# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CPILFESL
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=5, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0070014946312127405
0.00708192053617084
0.009527662745868732
0.00850796211428003
0.005690026281517774
0.005776979699146822
0.00667936823686047
0.00474772684278006
0.005427221352206549
0.0064543565156444434
0.006049416513256801
0.005357086079315529
0.005392152304256405
0.006548301367015759
0.005588033221879006
0.006180282509881392
0.006959929664185376
0.007154709778229366
0.007311683418036258
0.008874486599036642
0.007343970002998407
0.009267061338578766
0.008085784126211271
0.006738693733810341
0.006165490964323093
0.007685548257167129
0.008141964596200923
0.008911291832323922
0.009596758937069657
0.008568751800086271
0.009929402719971532
0.00782835785019104
0.008061761738905604
0.0075830762525515355
0.007770196593425958
0.005778276484906307
0.005290530192090262
0.009523085732352015
0.007170877895121058
0.006094421822431545
0.00647997632620513
0.00444759004554286
0.005952881721957378
0.007143409581324691
0.006189805713923672
0.006698961442254648
0.0062331466906189095
0.007070838900617514
0.007174454495583257
0.00461186511469361
0.005033417004225282
0.0061506925373292975
0.004605326766739307
0.006411926151560079
0.006307173932578214
0.005421008432157019
0.00453952279278391
0.0049623222297238475
0.005275141074011706
0.005256267722851584
0.004769682762442669
0.004745947068267289
0.005701831261184848
0.003597733896550997
0.004823422533914809
0.006569893423187097
0.005739277002539068
0.006232857351254758
0.006934113206629126
0.006112460514352915
0.004512575355368804
0.005552222814252427
0.0060793580054954895
0.005889387670662387
0.008965436865872735
0.004296304229690759
0.005450654750546128
0.005702166719598453
0.003603812372365807
0.0016946947343978063
0.003810889419328653
0.003194182334726546
0.004967261204288912
0.006314409905233375
0.005553563101707591
0.005844755843574861
0.006957850097659113
0.005716808675000867
0.00413886027148544
0.005561251070468819
0.0066718806563107564
0.008855610331195135
0.008343819707935395
0.006902121200677708
0.005587355016965611
0.005507475513619912
0.005332202461326764
0.0065178537410237
0.006387535971199262
0.00617103698032582
