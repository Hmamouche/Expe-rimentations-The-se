# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP257
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=1, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.02073074061321217
0.015172605050935348
0.013672660944537025
0.014221446821613443
0.009921094416502838
0.007218982559667573
0.005552146677504926
0.006462797894928557
0.004564480167886395
0.005149445981852064
0.0073437390461738
-0.0015503478386016739
0.0017231755764871045
0.0019321483673016158
0.002170613491051835
0.0008913210443334191
0.011970374631088973
-0.001975632052213045
0.001252911002529828
0.008945767676226764
0.0015044182716038722
0.005182146782039998
0.003782159226385676
-0.0014331782472424043
-9.407536424063258e-05
0.00073493873628769
0.0030940738538792366
0.004183272278581653
-0.009363922625117068
-0.007240933980924446
-0.0156192075327516
-0.0030093399854927596
0.0003379263317216325
-0.005228405102545693
0.0028467922301611067
0.006480726051503847
0.008275595825095853
0.009032335653194326
0.012040227155740437
0.006150585317175229
0.012200951115257699
0.013247693545109846
0.017283687770559334
0.013580655064873366
0.0143230220662689
0.012729088628134655
0.009879193407357987
0.0015504926250528633
0.0055285223045492635
0.008396765570438357
0.011497283782405398
0.01918494894754896
0.01725697203908282
0.017836790075980404
0.014461939241973788
0.016978970080944976
0.020557668181183392
0.017391691917152913
0.012967595797777441
0.02511833196865668
0.014960333291223801
0.02023928658178691
0.025011488720193157
0.01846528040533686
0.023018172234187784
0.015727321074418828
0.014502034746208871
0.01877064985803893
0.011108842389780462
0.006914100050739213
0.0025061106691366512
-0.006842856464428328
-0.011968154578344943
-0.018502590558547034
-0.01213231041147396
-0.01337676665973227
-0.009081492331243578
-0.007666484760788783
-0.0034244612881405767
0.008046019270012644
0.023051765666965658
0.024196490508505593
0.011803179313555852
0.01778806827144762
0.016607402557257525
0.01708967049270752
0.02063387751778627
0.016236957158871586
0.01874477239266443
0.012330697076765144
0.01727720953990513
0.0055635713464968675
-0.0037392245867923744
-0.010449930078718191
-0.013531804090125535
-0.0024733681081834996
-0.007217956957240995
-0.010237941822521445
-0.012310952026152145
-0.006958900984678079
