# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; LBLCPU
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=14, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.0017177212152733176
0.02408218278565384
0.010092106680510842
0.009258172979278109
0.012183028510581092
0.0028202084180546623
0.002179842997910817
0.006303678928357821
0.005885663535543733
-0.006379301462534473
-0.0023854433689385955
-0.007709488897534015
0.000806819323031206
0.023105017336746306
0.013869385020073153
0.006291825721732626
0.005767005287309544
0.003508418535272618
0.012581337485813408
0.0016193843122244813
0.006016988656803905
0.006103513695211969
0.004497046778056235
0.004100126548645693
0.007206317998194337
0.003748941527129638
0.007356710908480867
0.007125605769242634
0.014714893381559655
0.011594165221690565
-0.0014904762306235844
0.0116827087323267
0.011496762156917887
-0.000956823469686695
-0.0006440753892477964
0.006950192982598864
0.008764025028507809
-0.0065763343821405255
0.00027834777471380957
0.014611038658105289
0.0007208305085994456
-0.0003549740822309915
0.002199408685405003
0.008501775270131488
0.0019018240250925126
-0.0014003227803401944
0.00013626178652453164
0.0017564054501322962
0.003026464881481345
0.007888819956030121
0.0020575117708827176
0.002613563669738416
0.0040814268584707875
0.007229598615173888
-0.002172063529373792
0.005496786647866564
0.001735621980605275
0.003590215123060757
0.002219308206657778
0.012378271707002802
0.0031709590735100237
0.009620427227304752
0.008080312125309505
0.006325225245437437
0.0045675258932300735
0.006304230301093953
0.00946201237585256
0.01097221635007644
0.004289637196192481
0.02457614192018012
-0.002336993921826208
0.014576558386705709
-0.0016324898675532102
0.00973491884203972
-0.008663699619667847
-0.00917974577227396
0.003851780131594192
0.005655912629805844
-0.002722961371904531
-0.007319158414564451
0.0034359393664520083
-0.0006808814351946827
0.0033416451031191333
0.005425639569907189
0.007519413687760235
0.002791982865710333
0.004113437714285326
0.0029039581483133103
0.005891667528996357
0.008002641935087445
0.00855752383968612
0.01573286839385448
0.003806448268326509
0.013535275403315557
0.010128858720571026
0.011468276353951904
0.018504044871070532
0.017777603320283587
-0.0024489465307718913
-0.0044815667555401385
