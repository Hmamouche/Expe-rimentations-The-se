# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP252
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=2, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.008068438008670801
0.00683057807163689
0.005281175618874748
0.005299205654829114
0.004239288990988142
0.0068912042804124135
0.009070421831356246
0.008562157663061303
0.009100863740984547
0.007358693918435024
0.0051294908700146155
0.0060985366014684825
0.00638616767732547
0.0064573245162186
0.004054601295486369
0.0058705889438390325
0.0064022920580639785
0.0035684426597523246
0.005286599878071286
0.0056537959546973495
0.005704416656721563
0.007178657022365692
0.0051075459911106
0.004335568299362331
0.004828907126799749
0.005286155787532058
0.006292852391427546
0.004876157644687629
0.003282501226696149
8.285482034570817e-05
-0.0007877613716054875
0.0022487388016840483
0.0025148516594505634
0.0021749654558706082
0.004228980792303975
0.002988662696109176
0.006358840515833818
0.00644581160842186
0.004931393209145899
0.005444645025826099
0.0052019316995667916
0.007770627613921263
0.009252406195158177
0.007397108627339637
0.005615873742939075
0.00519224470787713
0.003332555047614531
0.004289125881718103
0.005388668543992581
0.007019775118647656
0.008348690898977315
0.00808909694934851
0.007580408367253353
0.006948069804068948
0.006079285074181818
0.006912883913679378
0.008167977843647745
0.008286447109117414
0.010291585430463206
0.010354309727589363
0.011347780291688491
0.012794496982711418
0.01190268225517683
0.012281642923898599
0.01165397230353497
0.011449802465194007
0.011410707556431187
0.010925227592830095
0.009743926227576565
0.007898595024643485
0.00924247682754283
0.008562534471257042
0.005237796980722122
0.007575955930583582
0.008593564562892186
0.009611524950168019
0.004255122261712752
0.0035894228448231256
0.0032395310708971878
0.0066507974574536435
0.01020989954249957
0.011591563427922226
0.01092718689440185
0.008125635672040665
0.0074265510446502505
0.00819389552813462
0.008914946382116169
0.00859871881870251
0.00880559971855132
0.00897717425784088
0.009084574789315835
0.0069092539921046005
0.008261601572708176
0.007865077018335075
0.009762550475806854
0.011168655096728217
0.009268818263608643
0.005541257121975571
0.003908235317974107
0.004160974836384332
