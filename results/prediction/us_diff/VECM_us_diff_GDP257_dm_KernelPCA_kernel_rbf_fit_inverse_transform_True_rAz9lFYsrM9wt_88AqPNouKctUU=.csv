# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP257
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=5, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.021090367997274793
0.004092736871656658
0.02309737927661969
0.013418813816230387
0.007747792462461995
0.011342306392038657
0.02132602801746976
0.011442258822186992
-0.002874834243018723
0.0011652730160219386
0.010790201296629926
-0.0011859534754420158
-0.00439541041196332
-0.007699522858892888
-0.004027989633980558
-0.006399141058034101
0.005282531804429844
0.00016828255531162585
0.008055799730571855
0.007094185904208865
0.005091404774356647
0.008169862173153271
0.004760282909734365
-0.0020088886527794073
0.003116134978843263
0.004828525165613704
0.0030961385733035978
-0.0053577415932732336
-0.020667834952224007
-0.012116311459596437
-0.014076681798632066
-0.0043904648557585736
0.00459827444603444
7.976144821903852e-06
0.004532087586766836
0.003928706155965525
0.006620095314804619
0.014578116790887457
0.014823359141667212
0.005942660160349784
0.013375096678532202
0.02001208438287743
0.01901179465122636
0.011426449366013045
0.01917703927519655
0.009984963870637893
0.008081641061723056
0.009817414516337825
0.012202188286586584
0.012153870812232574
0.008971285158592964
0.015005229966886921
0.017402316100578553
0.01988512492756024
0.018747412264379423
0.020299918510824144
0.0237663277763015
0.021880506410982083
0.017478817595733467
0.023454892921119876
0.012522614252452132
0.018559333935032944
0.026711879772038902
0.011786691296211429
0.02035455053478388
0.02293114533536045
0.01611443911277321
0.015582020631721118
0.013209256696412564
0.011333107231309016
0.0069016010300219244
-0.002833337762871281
-0.01943428435666569
-0.025007762949985093
-0.012576133694333762
-0.012403023827819605
-0.017443131744237166
-0.0015388343851589835
-0.00541021276625675
0.00497025595934843
0.02495688982699196
0.030622363150554624
0.013302717017229734
0.01350068437911391
0.015718042919803794
0.019860977704834446
0.02090802215181572
0.01580876803038894
0.01941729498462169
0.0090136211770805
0.01939419043339194
0.001885449318902944
-0.004037529525092702
-0.007237545137723133
-0.013457951384988088
-9.553864375678125e-05
-0.0068235997846675615
-0.01664386358412287
-0.013344687935007798
-0.006130498362921764
