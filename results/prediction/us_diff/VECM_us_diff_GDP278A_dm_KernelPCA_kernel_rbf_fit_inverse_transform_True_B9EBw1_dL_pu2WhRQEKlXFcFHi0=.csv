# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP278A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=10, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0010230697502930965
0.005755430068755233
0.002986306504658618
0.0030223553943964985
0.005934282855847517
0.00120824719236179
0.00032839962155051575
0.0033231788438833456
0.0015739921193503202
0.0015505572248458934
0.003831376160825782
0.005957193025277458
0.008582391787840076
0.006020901352936434
0.004559374594200642
0.001933473515269879
0.0013393472645422322
0.011170775544462408
0.011136345481885747
0.008230116186571748
0.006487669961952067
0.012808794803715183
0.0070795200366793815
0.003751037999350402
0.003631832455166016
0.003287302546549369
0.0030998447020647284
0.005613245813300698
0.00313524403022948
0.003748578570688653
0.006172412553694877
0.005380409288978585
0.0010433284560477812
-0.0009334383865237546
-0.0039881797843859595
-0.0010998548921366924
0.0019382909831231038
-0.0003517919412772254
0.005254788951031562
0.0035963704772162606
0.0007321898001489803
0.002467674106389257
0.0051040695103503324
0.0054669075313841424
0.006817463090752483
0.0026478642291338983
0.005647515337037478
0.005995223416306929
0.0011653561795095875
0.0002903110114817778
-0.004508112244151367
-0.005899801199281399
0.002866991275621696
-0.0005173800165307925
-0.001078035756584387
0.0006243236719961722
0.000693601040529635
-0.001395061945279513
-0.0044313811601737795
-0.003993980691490191
-0.001016137626996862
-0.0018930649674207456
-0.0007603310422228278
0.0012242525915060571
0.0001466210207144591
0.0017579414899185522
0.006099566295042323
0.0044521413729823505
0.004626953217761959
0.0032704605459260433
8.536239903521943e-05
0.0045717555533228045
0.005980136663178153
-0.0019208771562572897
-0.0035770818955026297
0.001783432362206171
0.0021849075573287134
0.00807013956364115
0.007494159001591598
-0.0005264255739919388
0.0018770707095949392
0.008220392933210906
0.006325050428631495
0.014600385090260177
0.015093502085880778
0.011998993363542137
0.010540002185523952
0.013748796814711674
0.01380868709661236
0.015713119118586985
0.015472551696959219
0.012330379304938494
0.007645348238709725
0.009047909128147135
0.005740683488707211
0.002026977500188378
0.0035552079929249748
0.00024894403963690256
-0.0017384591720435965
0.0032990883122600407
