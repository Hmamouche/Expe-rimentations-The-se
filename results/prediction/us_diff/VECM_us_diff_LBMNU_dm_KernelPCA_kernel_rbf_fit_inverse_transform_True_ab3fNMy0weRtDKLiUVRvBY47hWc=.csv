# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; LBMNU
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=9, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.011747533534902193
0.023105082841713233
0.01742364788146705
-0.0019417622094486577
0.0037190622078781587
0.0014691199561295395
0.032943645962803345
0.006755520350277948
0.012735964390950665
0.010499828242932847
0.011027045485963687
-0.0012975280025057348
-0.003332975748087132
0.00784647131941243
0.010156931983293765
0.016662656937142535
0.016190680366116185
0.013665546438128387
0.01081160328138752
0.008030879180761934
0.009405666088947013
0.020495431893164558
0.006270279393809937
0.005250989090835249
0.00029278050738200606
0.011183258743396674
0.007187388447716988
-0.004263954920893082
-0.008517676743709653
-0.02577403208284874
-0.014872370508718986
-0.007710736661028338
0.010426097592285995
9.114506947435113e-05
-0.014264492694455861
0.00027919856313906623
-0.0007147088284371412
0.011360110278771696
0.014547626532520693
0.0037559185400616556
0.01789400869492072
0.013545867883676958
0.015409719244818357
0.01236378767630074
0.027645648118429195
0.01220612820289976
0.016010430656295267
0.0034275129424837037
0.0020380113605718096
-0.0002885497018385087
0.0001907206990327502
0.017580845098100092
0.01869288221898452
0.0231373827043561
0.025654240977979345
0.005637952813711894
0.018686138633175055
0.012305006853988592
0.003392533764552954
0.013335183548203892
-0.003812300799398424
0.00997334249636555
0.021273968385962426
0.009620554574246118
0.025034099465298332
0.014497375603029609
0.00353224596941327
-0.005778280306000342
-0.0012638049106675005
-0.0029819425046585103
-0.01370197894041977
-0.00807558790302808
-0.022318002725355945
-0.022434891894140618
0.009231381996091671
0.0007693332843757557
-0.005248069368128048
-0.009441839395444481
-0.010826235820736751
-0.009271309252361776
0.002831641663950144
0.010059156468928136
0.011618764409819673
0.0011261962351928017
-0.0012461817064470426
0.00010245463921429443
-0.00033273100345447646
0.005756269258143964
0.014477732999182574
0.0060364541986265095
0.018811965368226182
0.0022103733564698552
0.003464800590149683
0.011964887563919982
0.018230716725042288
0.0009242372186536825
-0.007204664692109724
-0.00978968457824103
-0.011680507337473011
-0.00769389962011313
