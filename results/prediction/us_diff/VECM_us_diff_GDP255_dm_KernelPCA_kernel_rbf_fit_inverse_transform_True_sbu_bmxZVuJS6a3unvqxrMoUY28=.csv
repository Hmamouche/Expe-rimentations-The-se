# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP255
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=1, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.008939901540669544
0.006709343102276064
0.0054918861068843665
0.0050291542407233745
0.00585579820325879
0.007565966333648353
0.009433992131483486
0.008533078990403075
0.009326042935337306
0.007264358527533284
0.004955506505195401
0.003544943799314251
0.003940613751152355
0.005402892170604688
0.007548905074525346
0.006443424051275826
0.0069957785890251605
0.005840223841755036
0.008317765358928255
0.00597183715798597
0.006733035833930085
0.007354498736724937
0.0053186803143714465
0.00506644273958294
0.004865989334032467
0.005786865511073865
0.003950026627027602
0.0062983315700871675
0.0068556911056839144
0.004366779422961834
0.0016784346160959793
0.00438335841162659
0.002010338833932331
0.004128214481126731
0.005909940613961169
0.005384956723176715
0.00820721955438329
0.00655052684271265
0.005002503207238501
0.004835911959691309
0.006329679171167498
0.005010981147618772
0.00699770318912573
0.005487160979789712
0.004898915750144745
0.004790947700843055
0.004494801899524848
0.00696026773360505
0.0055504984433984265
0.005594594821205757
0.007986975148003145
0.00505134486415088
0.005784696819029327
0.0058446332714807234
0.005826039763766968
0.007004435664977312
0.00830465961437263
0.008672807946794446
0.00985076438267817
0.01015557935641039
0.010348991636089358
0.007269312491924744
0.008855250510172412
0.0090137267594293
0.010255053832855077
0.009013040090124828
0.011796158156680718
0.011209018400180194
0.010830107357723143
0.01082132959189072
0.007999831288192422
0.006176596901879713
0.004014473757986463
0.005426811403063329
0.004429553434960562
0.004522019121958048
0.006173857431240727
0.00407304093440049
0.004120778046551214
0.004929298041662781
0.005555776005642488
0.0061669278122175155
0.008576852216109428
0.008696923744620853
0.007917391713663062
0.008997359630494145
0.007068560122348419
0.005990687853386202
0.008024177713402497
0.006907569681672419
0.0067979106373367544
0.006963587465979391
0.006272822860101277
0.008393431817187488
0.008823995013291433
0.007011717934670211
0.007017503487787646
0.0062639206544145305
0.00585573139433409
0.004717082039661993
