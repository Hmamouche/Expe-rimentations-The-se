# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; EXRCAN
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=3, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.003088059500808652
0.00622581836740943
0.028761834808463276
0.04555655486609064
0.03162638600442804
0.03184563101447398
0.028345803290057897
0.023180609560841687
0.013195291137874769
0.00986985564828607
0.030806662414484275
-0.01025990158081029
0.0009842953284550627
-0.005832259374551865
-0.02535640149675233
-0.0255057678883892
-0.027544016781358073
0.013350143623465354
-0.046166905214795294
-0.034348668114162456
-0.04422345331543672
-0.02438292207951394
-0.03543522431857332
-0.01805820320678799
-0.016689197252005142
-0.016541750304087444
-0.0022426013031198225
-0.02649843035420271
-0.007608338958206596
-0.008231986385842832
-0.01462482721373701
0.005477904986407084
-0.01666608908175067
-0.014016479524076619
0.04565322384220907
-0.005931559846592573
0.03488368723892775
0.053320983135949254
0.0056988579228019285
0.05052046743357225
0.011281630209543153
0.04131024055606396
0.035770995917280744
0.04894314776189135
0.019487215507495364
0.04002348991162471
0.013558254577351807
-0.0049732148984119595
0.017727138094107784
-0.05856092037827151
0.01843970093865118
-0.010522112070048474
0.007775596664382827
-0.006518102261603419
0.010584199115517721
0.0007569495069977205
0.020129753297799407
0.033368434259600066
0.012098000240127992
0.032651447314516094
0.056490193965341995
0.04174821451766842
0.03326716093890991
-0.026606023244344364
0.016778808825489582
-0.022599251002733068
-0.004555174330684622
0.002414237374381645
-0.00698003806594397
0.04693477448318483
-0.016293433323973795
0.041546131927948184
-0.00021244673035800826
0.039552750708161576
0.018017996529263662
-0.011975022499194259
0.01710349257790311
-0.020209865789212623
-0.029445168729253304
-0.08305176457243746
-0.04632091837462086
-0.12563623426608603
-0.01825358555949387
-0.0289707150982782
-0.024111423595441987
-0.0477470377702165
-0.03667611824765902
-0.04746914988312574
-0.040804017680754937
-0.03009279198233563
-0.03246898000551372
-0.041570984437521885
-0.02898448316806561
-0.021709544019877056
0.010029843297950659
-0.04354932349897897
0.001213144873391454
-0.08343771813832382
-0.015500018231427454
-0.07065760200741199
