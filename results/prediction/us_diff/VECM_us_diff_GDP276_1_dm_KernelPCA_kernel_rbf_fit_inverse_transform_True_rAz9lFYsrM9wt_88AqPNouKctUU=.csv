# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP276_1
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=5, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.005771715237342647
0.004177602239415171
0.006685397204719915
0.007397514741215444
0.00618698634564422
0.008103008064948583
0.007503985797447253
0.008373103774575927
0.0077159648022401845
0.008109179018841655
0.008465174306202642
0.008466659604212688
0.0056803705127295955
0.007553963465223478
0.007139805050547274
0.004805417523633473
0.005433561065612924
0.008522177115111676
0.007879552400517182
0.0058420040851367115
0.006574728780524649
0.007423764346595122
0.005348421808713824
0.006520084540065813
0.007695026907897311
0.007558811038221111
0.006311811312434391
0.007625656894297182
0.010795643797936266
0.005453042683372723
0.006789765885977745
0.005552174822628739
0.0029183786397865754
0.0060408223840913025
0.004479703120426049
0.004368073113987091
0.004752846525195528
0.005357379639290375
0.004901410428987828
0.006257206816675292
0.00463386620582457
0.004290926090256103
0.00496891016887947
0.005896986821827952
0.0052594825066681694
0.005325324178495146
0.005577625120544516
0.006432327864786435
0.006520374993031048
0.007002906616010806
0.005648357606371821
0.005710539034280999
0.005889702793816242
0.005246673945687433
0.005604138559159844
0.006429190105777789
0.005658291072361638
0.006637945309675301
0.006598813979792519
0.006855420166743208
0.006826612385054179
0.007785790908185054
0.004746889943468986
0.00601246631474938
0.0058693744967296775
0.005745236733925914
0.007002710057487352
0.006840862916410015
0.007709672182639847
0.008346098884342948
0.008120104023954274
0.008426289623664615
0.008829030376622814
0.00960381184403869
0.010335552167238924
0.00865093482521472
0.0079085116921984
0.008020195169832803
0.006212036798374134
0.0050772880199555165
0.0061811622114937405
0.006206839915011312
0.005097395942602833
0.007259454387241126
0.006772161197797231
0.006389194265890206
0.0074817296924483846
0.006401533553426007
0.005888150200050129
0.007050569926446921
0.007557835534582717
0.011176966795476242
0.010983685008993424
0.012644169852622188
0.010598335111070075
0.00954454451180035
0.00856395200571609
0.008220960524381406
0.00820054049397747
0.006271049544259757
