# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; IPS25
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=5, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.014102737058006961
0.007438128463802538
0.01664771613299261
0.007852311200403554
0.009022245711566441
0.0037571634299785996
0.010956795200218989
0.003060240490874131
-0.0009106087951031649
-3.548195751325699e-06
0.0009149681220429109
-0.003428232135314645
-0.0042312899287230785
-0.002967999134778498
0.007332226313299873
0.008534067399348632
0.011025887865899165
0.01569723009330488
0.01413372957000553
0.011546736233480407
0.011137966601819385
0.0074501399075118215
0.0037047670275492097
-0.0012674757096480351
2.7925619943237385e-05
0.0013301559224425956
0.00979084204655273
0.006964639329421566
0.0023909168504514518
-0.007534132961152476
-0.0036692262668359854
0.002605492316348755
0.006258488786918966
-0.0009355393214842635
0.004233232585861962
0.010715508624144535
0.002230305536227907
0.008655656129846966
0.007975301486263476
0.002397172120385704
0.002240545152342557
0.014469489133468736
0.006647206148027149
0.005708150603987574
0.012675989637630482
0.012948953181728569
0.008153625891389592
0.007081373078509819
0.014494662054152166
0.010641173874347378
0.011456215969610188
0.018928137404418687
0.018964531925890104
0.019668525364411237
0.024808372142894768
0.028965447366675088
0.030835309034048686
0.03022579647731141
0.02695859508156931
0.017851728077000657
0.014904161513657584
0.013157226961479054
0.01669915841393406
0.010148230108051166
0.015118850022361725
0.014333091187491284
0.019049781941878313
0.01792829410036592
0.015242269736009008
0.007593089594015779
-0.0070295534111719845
-0.029478838967738567
-0.03886131901289603
-0.0402317341742419
0.0008367582556097304
-0.009144147730190004
-0.00928865629466544
-0.007260823518022005
-0.008804536834249678
0.0004958788911010974
0.010414133602290508
0.01818754358214002
0.014586895762764814
0.006920325291215647
0.01337533680001664
0.008223087566687869
0.01675380426546877
0.014818801321984982
0.0029816407724328887
0.0300022552879073
0.031445946820254866
0.01900787928178733
0.02327162516410315
0.014228159872321936
-0.0033660486805952433
0.004889669514320695
0.017694707090976362
0.0073748974516720505
0.008869117401239303
-0.012305386467558002
