# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; IPS38
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=14, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.014388616312392475
0.02933458442598892
0.03650379977338498
-0.034611637048079125
0.007929975211763897
-0.012742200497900784
0.00894816066409708
-0.002596641098815836
0.023019754631016305
0.00781793195775976
0.021287419515541535
-0.012101831456142045
-0.0018447725060873905
0.010705049854475212
0.011402457081677659
0.04296941522022074
0.020885021419847726
-0.021367971376799688
-0.0011943807128504211
-0.013084936827688597
0.027527558980638415
0.014780354950291393
0.0045038822417391875
-0.009070392427188443
0.013311906997833023
0.004620650094877941
0.0055062565363450545
0.007188301181976314
-0.008466111109909984
-0.012447283648267464
0.016955956883953585
0.024933410384253445
-0.0027265888195840363
0.002091024921938145
-0.002549044568739476
0.014128110947643742
0.004242251582146526
0.005136694482472849
-0.0066278511588786036
-0.013243318686691525
0.027633889880349788
0.006799923572752577
0.01767085066538597
0.0008892369375277306
-0.004011915664096866
0.0005908479801357796
0.022248024090231355
-0.010111626440375896
-0.004262744480440366
-0.01012425244209598
-0.011746460821891935
0.01956513571904163
0.009947560092598158
0.02179898518202452
0.00613771686641392
-0.0018812832302353669
0.023880319344070974
8.808313999402254e-05
0.017793695454742884
-0.010259478313776348
-0.009653487804570855
-0.008223019426188305
0.021128741137336662
0.011136175723516245
0.014322881081913843
0.009247592477086591
0.0029522867734762745
-0.00944459717689705
-0.027938079078167515
-0.008170788140616569
-0.030796479127395013
-0.0016408299268509102
-0.022160955092517545
-0.003179586463291206
0.014861472766779394
0.006190018339957332
0.0035266425254332472
-0.03214018676572419
-0.016243286296885675
0.024654530388659383
0.014401455944858556
0.017685205193479013
0.007564541179625723
-0.004884170642661953
-0.005818342729887875
0.012414810153578374
-0.008639334201256158
-0.004938454079620952
-0.014971277761525688
-0.001414152885711735
0.05108014558911448
0.017298062018884865
-0.013575199900618687
-0.008185469270217023
0.028703911371349512
-0.007197787898383497
0.017559988424804125
-0.0048326094389884
-0.007760206734660978
-0.0054123771378594785
