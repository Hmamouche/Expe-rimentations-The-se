# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP267
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=15, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0017541461556200124
0.024789934932649412
-0.02503717501984507
0.0018519024604744072
0.0011239211235405428
0.005254446192677806
0.018839745357113552
0.0011016249444423
0.008731914903568063
0.017647963625660207
0.024287399452062784
0.013056071885652913
0.0030595883003990405
0.0051949421388806415
0.00015303997262762319
0.004898565459068492
0.01120617430839604
0.021939458145251632
0.01189765023682434
-0.006667415408014257
0.003998516197287806
0.009059715164397764
0.008351999767304857
0.014354372671232973
0.0041498719577057
0.013770602739992109
0.01380583990193685
-0.0006400686483103231
0.00827288360248689
0.009065706887063686
0.01778132033859617
0.010923670117824334
-0.002226145821604939
0.0035951635737868828
0.005477527484781138
0.00014820113164017807
0.0022407165092238873
0.008837679472085629
0.012273985791308603
-0.009906731975087735
0.007512346424513567
0.005899489933171572
0.0023399773171872747
0.009617078322935409
0.0072182880700191465
-0.005694456312403506
0.01981622699734562
0.006394559667018332
0.004548120187764447
0.009913047023808477
-0.0028446210615423956
0.009222007492803238
0.004253119195066886
0.003986067037005557
0.016284828979522853
0.00727690813908742
0.006151378224023812
0.008213193886172204
0.007378882691236349
0.006789202358111517
0.016253020812917733
0.01365131695644468
0.007157353388469671
0.010401874779419335
0.018006415337771323
0.01050250261417959
0.013725899837960201
0.0076958950805788955
0.008206603380009789
0.006017796435800431
0.005891530255407246
0.010997866602495014
0.009599091925686334
0.008299246617093322
0.01293729659107826
0.010483670510990965
0.006067913175258275
0.011784730675416886
0.004388264412992091
-0.006932215411945617
0.013705288256733318
-0.005645821201977649
0.0018102016718889494
0.009867222773171553
-0.007227608322212059
-0.004846619477819633
0.0026607443195429525
-0.0006035249683373147
0.00026905958895913394
0.0025975605535323186
0.003917978207703949
-0.0009125010371428851
0.0031002061562283357
0.00843135523040692
0.005435352197475893
0.005395348750683239
0.00860671680758627
0.0031923035699845037
0.0030677276983573573
0.009271960390145361
