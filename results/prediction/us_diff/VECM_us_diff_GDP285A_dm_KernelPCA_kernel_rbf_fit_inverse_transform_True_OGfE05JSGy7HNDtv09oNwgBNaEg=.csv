# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP285A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=7, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.008015260580796744
-0.012851121683349391
0.01197538822935889
0.015088020335917858
-0.020671069779891617
-0.00477320893934991
-0.015045681293511335
-0.004051150906292255
-0.0009481887764751342
0.017095959009505224
0.01657359259698154
-0.030325385887244857
0.007646003815899583
0.0016553678124548732
0.0150916856725851
0.023646204176537185
0.0011014280754786374
0.018462102684719837
0.01584319727788305
0.014299668110236384
-0.0023564794694370737
-0.0013517109227856245
0.012704337600561806
0.010588315927442606
-0.017142221987343543
0.008174263743625107
0.009623511411410553
-0.016787770328257023
0.02147645973577014
0.03983704487650553
-0.0065596426553140835
0.005048474264967542
-0.023999459401987767
0.005130640090275852
-0.019706250641953707
0.01236702831472046
0.010005886185100264
-0.009919523672007744
-0.0016936445809460873
-0.0011595223278595104
-0.01313250192303332
0.005607762948599151
-0.0027755719434325093
0.0085321069264084
0.010013635421608765
0.006837411002247552
0.008627360860074821
0.010678685992505668
-0.01019863987423385
0.003325672937850947
-0.006453941251666708
-0.004345078927060544
-0.005016068651759992
-0.0013425373258562398
-0.0064851278816574105
-0.009317571738176203
-0.0033178375973433516
-0.010386493672277237
-0.019570030406497952
-0.00993036911189502
-0.015357357249666677
-0.00749248019406187
-0.0032021936581679566
0.007948822111667739
0.008115741067384167
0.01581207902731397
0.012254927171288435
0.000994991933691429
0.007196134576364733
0.00017106039203947034
0.00047317324313737603
-0.00876256996945709
-0.005701106326990299
-0.02253500690293169
-0.006804902900163759
0.009288987983932597
0.0010483338810637426
0.00683168653088601
0.012787604274547894
-0.006266823607587508
0.011372683275309731
0.0051942260920549614
0.018155736753681283
0.012871091400914365
0.008415493735180687
0.01590218339958356
0.001842086178599914
0.018347454302948207
0.01504817251426619
0.01800035350244927
0.014346397270146524
0.014787028308429201
0.01303645057606513
-0.011903332446796606
0.010688477769759884
0.0041855220963283235
0.012003368184476483
0.02650038726686673
0.0269083687844868
0.05626551570695437
