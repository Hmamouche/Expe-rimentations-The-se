# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; PMNV
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=10, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.21058155546594384
0.06982665770163175
-0.07983075933938405
-0.28073447380763034
-0.2786059468090659
0.06191697908506754
-0.030405162416704712
0.05103723404490914
0.07409473247391345
0.04557097917483423
0.0482005416347935
0.008338665780267568
0.02159268075061144
-0.041406081372909714
0.09829662823811922
0.01789165643838979
0.13312134421537766
-0.03599299304012069
-0.1284230985410126
0.13259866232018763
-0.12588940350257652
0.05653236244379556
-0.11067852985499053
-0.05893761432729315
-0.05081788325768144
-0.057515735269288826
0.009302164339534924
0.10935870256859459
0.06720815775748575
-0.12630227917660583
-0.025910273634016982
-0.115325314074856
0.04414677625744237
0.17420752502336254
0.08171743255005234
-0.044680146318662906
0.053094564253843665
-0.0730308630899065
0.030123289167364252
-0.04166634779999121
0.04351164073589177
0.016067283451465637
0.056031580065077725
0.07993468313252033
0.05351847843500862
-0.017275177098345
-0.04914898076449474
-0.026026502926979462
-0.13723164512410618
-0.10481997370512748
-0.04518407246424265
-0.004496153781404069
0.009094728244279968
0.06961676475457823
0.05810571130609896
0.003064075190595539
0.022857479287372112
-0.007049328731975377
-0.03624560087665232
-0.06642499969362285
-0.07804229835190327
-0.10004055488109123
0.10703616818509415
0.010346759972705871
0.11004050406506609
0.09813380714703576
-0.05037574772254346
-0.007985387653020579
-0.08315314881485655
-0.041477940086913495
0.001119460676230876
-0.12679775192401938
0.017714158634645143
-0.07207490838373416
0.1525638995412822
0.09100317024766245
-0.012598687036741656
0.03858989772789301
-0.08808568576933003
0.05913354231223537
-0.017915654435605034
0.043246584163363355
0.12003403983010733
-0.002219730512827256
-0.011841605101584541
-0.09206118260547225
-0.05529512136408152
-0.08749099575075237
0.008790862787450324
0.045326578687375566
0.08652410092054813
-0.08168781076634161
-0.04484762341461081
-0.05500160382247832
0.003970879242186108
0.013772419881082909
0.04946624522064605
0.0022157247993647294
-0.050315217989957
0.08893234075952272
