# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; LBLCPU
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=7, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0070133994430153414
0.0024118444035302663
0.00984267330627359
0.006611979180818637
0.00864629888829562
-0.0005658695468597989
0.0012126793166394854
0.00421718188743568
0.0025692966829152057
0.0031416156949724836
0.006058382919862557
0.0024083610808830346
0.0011071039043003513
0.009759635749490894
0.008947493766075738
0.009538528404900899
0.010713235532233334
0.008246857235343805
0.004133194410018452
0.005210990944200984
0.004925567135909923
0.0031083618255686955
0.00629651246799545
0.005420186527147961
0.0030484760578740524
0.0011970503645211874
0.006989756556012758
0.010363383757522987
0.012737928812309927
0.012767738616206909
0.007743364204191331
0.007334277881155006
0.008697799083495217
0.0022148358797187562
0.004927237081043664
0.003779664155457688
0.006645033057193409
-0.00027110648329413964
0.0020835863844797685
0.00791980869751769
0.001326675200325429
-0.00010822146718726848
0.00339059728358911
0.006642886854383312
0.002597325334276066
0.0035193546268286477
1.9356644842229197e-05
0.0017593150263690524
0.0014864263111656704
0.0025798846492001586
0.004277984352180497
0.0018418420697077454
0.004643851193952288
0.003939103218958225
0.0039915322240008655
0.0027894650939805712
0.0007575179350553811
0.0041579136405545175
0.004567609589657317
0.011443867688603171
0.008075562977736732
0.006338254204744933
0.004210424851265889
0.010208781080647333
0.004853439752713432
0.0032510344484629854
0.012732912386657809
0.014047091893578409
0.007408190012728419
0.024329240133056637
-0.004195277141865086
0.01167132912875265
0.0001791300951099015
0.009617119288476927
-0.005631686649797446
-0.004337865101012752
0.0013029118647172604
-0.00035418994108696224
0.002661726338781447
-0.004795976817755154
0.007078329981880436
-0.004602450502344297
0.007435663442649641
-6.207300055636328e-05
0.007053165401767567
0.0028875272562813256
0.006581339024249277
0.0072613549290318
0.006948226914891729
0.0017265562767624597
0.0074302165808449085
0.016565319955565105
0.005705001409093688
0.006869130004947875
0.006505723094075682
0.015210636074146026
0.01667297450402434
0.01134420398081519
-0.002679499429584017
-0.002351140209785928
