# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; HSBR
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=3, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.08501746313831621
-0.04099777763678383
-0.0005777129426870822
-0.0038069791913842854
-0.014955339532483763
0.035615751976304066
0.09246261012546347
0.05615730124441556
-0.010823007027815353
0.026753365170978486
0.057267363466302346
0.04526861038152262
-0.01562712211780036
-0.06383720185970881
-0.04569690130557216
-0.07206610935014322
-0.05183409881776411
-0.05201352162331284
-0.032160476893244624
-0.061838006979474114
0.024471014047190875
-0.005432287390770762
-0.0006504994235223948
0.0031685606367553524
0.02406832057499537
0.026033429657107324
0.0013567397126829977
-0.02057479051340258
-0.06987351486908709
-0.06161097298538057
0.015147988461079839
-0.007440476668042623
0.02681012719401824
0.020515053601092327
0.011498446587264968
-0.01808425682930347
-0.007286535566108393
-0.011997062565330386
-0.029208977908240452
-0.02220634448232061
-0.011555453816011698
0.07053475898404593
0.03185473138078275
-0.030879896706602163
0.027700189805897613
-0.04210878026382864
-0.009517983263069253
0.043791220555069746
0.042820882215623975
0.05736397136444701
0.02883605967392409
-0.00037255709271355464
0.01816002632153107
-0.014799289265720343
-0.00565705669248553
-0.011547511928821735
0.011932653205254223
0.006980445336261968
0.04277619755886705
0.0034650266442193805
0.0428665928219617
0.04311971310447621
0.02670663355985011
-0.007506525889184138
-0.016351805512913545
-0.021760868689610163
-0.012051177224922664
-0.005720243262652374
-0.0071673567133865666
0.016625800764217883
0.06178977962958345
0.05801254958096374
0.06697900725300904
0.043439471869994056
-0.02881545403484327
0.001309393638785003
-0.06958610190361907
0.02608265566727994
-0.02898685132781892
0.03519303640377875
0.046958150961512825
0.032839516624113135
-0.00750920015655753
-0.03197623869791603
0.01375465712090037
0.00428333718248242
0.016833113650151173
0.030316159541338285
0.004490981238268465
-0.001030089398196602
0.030301539417694714
-0.053892219626127634
-0.05547437194767094
-0.04403606875893056
-0.06833473540307095
-0.04219747579328752
-0.03541449322570518
-0.10093631073630846
-0.030703372632594338
-0.07839465849366446
