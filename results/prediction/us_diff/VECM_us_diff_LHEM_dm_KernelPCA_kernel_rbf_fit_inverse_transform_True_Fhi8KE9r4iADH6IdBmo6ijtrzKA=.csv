# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; LHEM
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=12, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.005714941131071046
0.015160241708932981
0.006760036302567976
0.003140028396587937
-0.002153235778353855
0.002853979532352132
0.018918677880020218
0.001968393121824951
0.006843260003712021
0.013659906433729377
0.014364499179274638
0.0031382529982371893
3.1252043531569576e-05
0.008935134832307614
0.01033774987053389
0.015066514856503949
0.00988552110624666
0.005640554872853634
0.0070868224992719706
0.011850944466706993
0.010401425126398849
0.00910678554212605
0.005039523373943558
0.0025679085997326887
0.002215479870030353
0.007181640045102361
0.007112138243687311
0.006725252876946935
-5.627337940529824e-05
-0.004157969348720052
-0.00148060013780773
-0.0004384253123362455
0.004183380990220906
0.0020493877485977118
-0.005225549105007278
0.0009050633688867926
0.00483998134699901
0.006577210386390165
0.008036022389851127
0.0013825701177048583
0.014980632908567673
0.008607914055751967
0.008219461402991906
0.002897901552615332
0.009970097439692441
0.011106319153549711
0.008798698114579801
0.004522591629655998
0.006875974520321469
0.00023614630355771717
-0.0029817859936585676
0.0036000968378027483
0.0105838109757605
0.011366070603930044
0.010771330116351906
0.008857578028537615
0.009480152101404161
0.008850654265697346
0.005114125626609493
0.004617096485409075
0.0007418015203850567
0.0033174950699357713
0.009380107303484165
0.002988388400573208
0.007580000918227016
0.010484121089232204
0.010593360935900246
0.00334429959649574
0.00442379340906887
0.011201789654762113
0.005060151932452934
-0.0026089511026046886
-0.0034416347014488732
-0.00487947884266416
0.008426493223188591
0.001910706472107671
0.001931761875054418
0.0042031847203515185
-0.0019280401569729804
0.0059071376176367
0.004988088481287661
0.011681823003002228
0.003671654253539329
-0.002791636035326776
0.004613114766092278
0.00425132339522552
-0.0013039382961327738
0.008517435429670797
0.008662790087146233
0.008374908646709762
0.009734413295347041
0.005639067726869187
0.003227899364805926
0.009840028147245236
0.01022305026188107
0.003817196252652321
0.005965021032625805
-0.007781425871408235
-0.003722400335257447
-0.0027999875590319374
