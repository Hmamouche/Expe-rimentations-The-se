# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; LBMNU
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=2, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.021015288025436323
0.017000213322042265
0.014420378718120378
0.01424043075557023
0.007869226533555448
0.008310939493884702
0.01393377065751165
0.009849700680096631
0.008052134217395316
0.01375465216010734
0.009972433413087841
0.005275105488424824
0.003878775292558522
0.00028875816740542005
0.008525748357635848
0.010812889927325195
0.01800574296857991
0.015778593945802163
0.004085510585609148
0.012702113133716893
0.008559948546156606
0.014635651390357276
0.012570937772248159
0.004515341565142141
0.0017724572618740032
0.006947211508098624
0.010475517270318773
0.0038281179735310538
-0.006845038622094677
-0.012339306271516727
-0.017005263160713165
-0.005956554587533582
0.0035610355779172047
-0.005881975713502171
-0.006791532984517025
-0.000412175511918455
-0.003602710856234836
0.0027123654452704486
0.007373571000298821
0.009102414185596375
0.010970936247087691
0.01610241984930649
0.01766184934109931
0.024111922659626434
0.017110188997054333
0.015542373464164073
0.009433486010838064
0.0024485959986363997
0.009898719721321074
0.007009254618599622
0.0029127895058103257
0.015025124519994116
0.01524236106694448
0.01312225302619261
0.013117861753534209
0.015395454517333429
0.01673245264738167
0.015105510143561846
0.010339376159448358
0.0068432817544414
0.0032626607260753462
0.010661911647691653
0.01397768393732929
0.011008561704264456
0.016055514048154626
0.017019130249517105
0.0066774986259292715
0.004177152140530596
-0.0007028288074994084
-0.007171845806975674
-0.0077905249007767345
-0.007347123620589221
-0.011592789381868732
-0.01973012123689539
-0.006199836103438524
-0.008341635064857146
-0.009428633306342925
-0.012881265852724751
-0.008682560599922414
-0.0046093203317233425
0.003974879490595747
0.013202633037411288
0.007167349855214283
0.002480610925027971
0.004374444169887488
0.005949617869737756
0.005677217890493969
0.004508346473248811
0.010216640691059514
0.011817528408248446
0.013348296144267663
0.007934259346662698
0.0027255550326357736
0.005985811974951674
0.006228099284409802
0.005794391228916736
0.0005258781386505672
-0.0016484893597840259
-0.009742125154152936
-0.0070339422448346175
