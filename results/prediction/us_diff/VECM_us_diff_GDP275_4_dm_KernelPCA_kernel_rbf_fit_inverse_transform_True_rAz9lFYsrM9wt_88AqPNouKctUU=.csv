# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP275_4
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=5, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.009075037257327164
0.006099441803240239
0.008841300565140129
0.0056206672246513455
0.0072478204216747015
0.0023358576188490373
0.008748580592331353
0.006854403221090236
0.005362566342420629
0.006949314141186631
0.009258734605950785
0.0033775731512014277
0.006602203579230782
0.006219689724202662
0.007971634205471733
0.011270612420529732
0.005062860625715637
0.005124749839331051
0.009658552957864613
0.009880233390449772
0.007673608891205394
0.009634722184142923
0.011974631573940343
0.010992261364584878
0.00838945492628995
0.009541889643210908
0.010323701521997707
0.013307980515111143
0.007844740566019097
0.009043708625973325
0.012522205252994537
0.012588376955996418
0.005909249191976343
0.010633661641378163
0.009485622216662404
0.008677339820711253
0.006708262570835542
0.0033499747431932477
0.008394919034347137
0.006370029769525481
-0.004749528859117154
-0.0009455118937850262
0.0006785036259593425
0.0013651471950697567
0.004925561919018128
0.0026429003459946298
0.002177134667310832
0.003322002534159772
0.005519467386489769
0.004328917362845128
0.0032792449343300623
0.004445520964441258
0.0017765807093004916
0.0023490658691192714
0.00216965672440195
0.005015219260918966
-0.0008719515140703511
0.00122190077214565
0.008087169762787465
0.004285209897231264
0.005116649477122657
0.010475158074259255
0.019070486929949105
0.007130903702692017
0.009697491000325666
0.013370604426811858
0.0024886137303335924
0.011146179354656742
0.006743456811931288
0.005702382202252329
0.009376740677719087
0.007787994694030052
0.008301211154525562
0.0067134195847289475
0.0053942046865145315
0.009208150598881196
0.004726035298140087
0.001785255146869349
0.0013764627869239543
-0.0003763614687355031
0.00310095762651491
-0.003627133484801861
0.004193249708281454
0.0036285657815292942
-1.1408729758133937e-05
0.00531132844935065
0.00378829563078858
0.003499124007265719
0.005063358085595926
0.005544635931728751
0.005885469509538586
0.006137833776105851
0.00498343140178457
0.003427845483748409
0.005327354674369396
0.0027211720345406355
0.002789320422064793
0.0047672896220069426
0.006703106229324389
0.00541126445108016
