# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; LHEM
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=3, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0018197149832910086
0.010175550615827289
0.014578407171459236
0.013719022052683234
0.004203843941660193
0.006768488213720938
0.012639791929064356
0.003630459027058746
0.004291471679197425
0.008943319768465078
0.009318172677073626
0.008162674019135544
0.005465820899833105
0.003618549156271248
0.010327462971572408
0.011119265318774316
0.009656936570707278
0.008715455285141411
0.009551264089943279
0.007118173630816505
0.00864870265557907
0.008092581900785748
0.008591367338839041
0.0038804902219693937
0.0038624667224716773
0.005010837081672273
0.00914813424801413
0.0035726397805615467
0.0021676190074610977
-0.0028243560273351633
-0.006180580347677236
-0.0003802594025384022
0.0027918110672591635
-0.001174221394715833
-0.00029367687883767785
0.002153966508756328
0.002540538298294429
0.0029353993208349003
0.005416074153388684
0.003396039526566843
0.007080482187403264
0.00939237813102287
0.011229961145698979
0.007883283899144989
0.007221405553277583
0.012746672756458372
0.0078023925729503625
0.0032090386736208488
0.005147196599510506
0.0013719463155690177
0.00105162253710563
0.005805145590865838
0.008663638457157598
0.009604613537084536
0.01009675903332307
0.009514702447568774
0.009710801206127521
0.009592845455713313
0.005749108659838814
0.0034570892533260997
0.002382822402922609
0.006168298796590555
0.008219698446761375
0.005535715656016476
0.006442859200185284
0.008435878014825336
0.01595559967474546
0.005405452229094241
0.007432426592426257
0.007057563016582651
0.0022475509189856034
-0.0027632735622905727
0.0004927582918784286
-0.00513615344550041
0.0006196691900108243
0.0007093380106790883
0.0017380807225871563
-0.001769652115894918
0.002803500495493572
0.0015754778849219637
0.006022150825621212
0.010265331337245527
0.0038111640917709464
0.004614009597725583
0.003090712738956641
0.0055082302099095475
0.005869913787701627
0.006402805075085829
0.007967485084685508
0.00943143541974502
0.010232470809318247
0.005760515008477341
0.004693612367156348
0.007238442349084716
0.008122103835393194
0.00631613211236732
0.00292501471392803
0.0004253581010725219
-0.0015562436222569783
-0.0005392427093012914
