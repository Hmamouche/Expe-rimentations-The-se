# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; IPS306
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=3, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0011732307346226673
0.04225132603048352
-0.004606804300018471
0.024340023031111532
-0.00935622780699493
-0.018173261531826305
0.015191015694113654
-0.01917917417136646
-0.009730980439270025
0.009143569086133611
-0.014024748438387042
-0.006487502714943692
-0.012178430941001506
-0.00898559940254713
0.0031592751166516784
0.018803723086025556
0.02443834787843373
0.033728047579211516
0.02461889413035647
0.02404268414323579
0.009835549092953878
-0.012307214306222483
0.00500746383967767
-0.023739326885663072
-0.015275190322471937
-0.0027729887534518934
0.0007424657595934622
-0.012670738557300217
-0.013266498697494055
-0.009097539394179316
-0.015757821093312523
0.01128435163488917
0.0399278053186404
-0.013846747640479452
-0.005944756585246314
0.007634465725081606
-0.01752015423721318
-0.009140167230109608
0.008777761255335964
-0.01069834942217047
-0.010833272545150143
0.01802687248345581
0.026078514545709457
0.00803412347608487
0.013281154409870261
0.013468751880493932
0.006303924629148627
-0.005923261569247945
0.002507603150165664
0.0001478792971562979
-0.00652585243814777
0.024046310284230606
0.015419450622781458
0.005420429608031985
0.0199403382301249
0.0064053151852681255
0.017001618732203197
0.006297184793726591
-0.013745353620469256
-0.02195052969295261
-0.016758131817688367
-0.00341020412264877
0.011230498215893
0.029477862550108085
0.026457072488216424
0.026231467634730627
0.015762412916176163
-0.008408579582236387
-0.0010038119678808769
0.0028831412680861116
-0.014484919744607853
-0.0020683636930160622
0.018910312170560006
0.0025560915963461135
0.019765452819654913
0.027786994980526163
-0.0047966698396493136
-0.013775236266489823
-0.00854482785371348
-0.022550589604624766
0.0011978421829746
0.012501012697284895
0.02416229546412836
0.015899776787642997
0.02652777658462896
0.029731033002200074
0.038284924745371214
0.028882490662665582
0.012968177345477292
-0.0015363059270142778
-0.009984449529029398
0.008911575546584092
-0.004287192597981854
0.013789379423159638
0.002991925305010578
-0.0027623745079217274
0.006286485322907417
-0.00593244174568406
0.013260665170546566
0.009213290473691892
