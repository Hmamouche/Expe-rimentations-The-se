# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; LHU5
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=3, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.030414165445770754
0.013922444454127499
-0.00604013697421848
0.023606288612208724
0.013646920857624558
-0.05546344287420165
0.0076222185239145585
-0.01872388374961283
0.01598333702997612
-0.009554669452279252
-0.026088272667754472
-0.01036673107302467
0.0080978599922647
0.02800601619623796
-0.003574977610322531
-0.020054400966033815
-0.030491350651411654
0.004074419961197927
-0.048769079290989316
0.004948362861532527
-0.01534697440402789
-0.03559093518143603
0.017476274065865823
0.007781267352033841
0.003955435537155394
0.00940930125605718
-0.007890538964824575
0.004575137121480011
0.009957188890399695
0.02657655500733459
0.026569846713814904
-0.011915705586323166
-0.014697437482985196
-0.009276816385609548
-0.0074207146696859076
0.03229670926628888
-0.01569502815348243
-0.008369564301457641
0.023451569357755546
-0.021893146794696672
-0.009752228574734456
-0.006407057746057138
-0.0721194631322987
-0.0046273828152754905
-0.0648597706228862
-0.04823860214165854
-0.017499162175240918
-0.03850359167466
0.014636672677617686
-0.0057574204532990034
-0.0021545000235988067
-0.00959261614291223
-0.026716274759454116
-0.01581900991796013
-0.0029963937143495786
0.01193745458353061
-0.027855553587587904
-0.011676948924533357
-5.964551566762155e-05
0.014708634011215428
0.026668736436110757
-0.004924922245996112
-0.012858203359231005
0.016056115050516337
-0.031124562281523042
0.021646745113766113
0.004680424734655972
0.0044137232207762025
0.02022924081307066
-0.015012810274853112
0.013144491165006357
-0.01950367715154823
0.012534919746182253
0.03288117868570688
0.008466113192404732
0.04819794971760135
-0.017618743672224935
0.012806451383194719
0.02555223993431717
-0.01564347741756187
-0.0428695957318136
-0.024171237534065818
-0.03598429807490907
0.024853956905786692
-0.0026355655593989485
0.0330269485335104
-0.007215026959841249
0.016827451556547614
-0.027093068610627352
0.016164110843711145
-0.0401040856540092
0.03822884568075696
0.00619906027909527
0.0013793114509333716
-0.026278459156414608
-0.02561619925068496
-0.018344686928117065
0.0010155221086617476
0.02976466763804806
0.02074444713487872
