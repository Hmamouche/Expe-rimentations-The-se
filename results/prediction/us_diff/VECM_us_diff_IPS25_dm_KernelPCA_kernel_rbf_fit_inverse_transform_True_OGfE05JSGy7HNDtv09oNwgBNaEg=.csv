# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; IPS25
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=7, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.01406597143304602
0.01038928160485465
0.016919008187139845
0.005012448727365557
0.008340647849685433
0.0019655127089847095
0.009533213650908144
0.0018046669326417146
-0.0005035270216626831
0.00010835310374952985
0.0022584263890710905
-0.0045620544836413555
-0.004827054497827837
-0.0017864392572779749
0.008583394785761167
0.011460526703597486
0.013056971853987737
0.015491391936053811
0.011607910271879096
0.010246330564864573
0.010513950202966974
0.010589457440851123
0.0011015029034112077
-0.002438872497351872
-0.0025575779170819383
0.0033395735410479506
0.012024150435674098
0.009064825842465572
0.0030582188498764346
-0.012626021443332518
-0.005590101939674566
0.0006734699625513243
0.006926476845264295
0.0030897082377025643
0.0018740022135526856
0.011501289710892091
0.0017746464519321939
0.007116717088427579
0.009371087513585149
0.00047636904237181795
0.005239578698960966
0.015579431906645692
0.006437461017760516
0.004790425855484006
0.011343374413137595
0.012653922303654586
0.011348307253251857
0.004401804781998481
0.01554781945598503
0.011247907419468102
0.010373026165301093
0.01902860691257735
0.019095402805083143
0.017479135676615826
0.026259120129193892
0.029974449292272165
0.031840833743676564
0.029268431023876985
0.026868711095560712
0.017287173010890413
0.014845169805262246
0.01254079477369051
0.015781022018751124
0.009934110484579154
0.015741987766865913
0.016095646992319492
0.019287130886211482
0.018367190271282512
0.014368279623483216
0.006836752905242798
-0.00679654499888571
-0.033688947364984734
-0.04037812650542934
-0.042995105554429106
0.008045949691657507
-0.008148570178204518
-0.011862953381215272
-0.006863974443357987
-0.008477116047628738
0.0007371769521747097
0.010022736307416236
0.017429853928661653
0.015422660800423349
0.007167809001027517
0.012394828214475245
0.00985116775920063
0.01638719804886983
0.01380160060415634
0.003723127578016584
0.028776977739311562
0.03151556369975826
0.019610504078751315
0.02221215990255002
0.010314262879358903
0.003816437623153991
0.0015070272857250681
0.016529071306267705
0.008535954599924104
0.008245530031673342
-0.012417633175333079
