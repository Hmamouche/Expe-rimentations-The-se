# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP276_1
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=7, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.005319459124167838
0.004122590771132215
0.006736332444080635
0.0070442116538154955
0.006270600000129558
0.008169728486824712
0.007266694886979629
0.008224948908086659
0.008011942826006785
0.007936337726597815
0.00870861371025383
0.008518709465816149
0.005702944851741436
0.00745298686529656
0.006948776064134438
0.005042218463196189
0.005416939418661726
0.008507833251967068
0.00797422926962335
0.0058894535017023925
0.006674815881753479
0.007656097170469283
0.005120897370652267
0.006419186401366074
0.0076327748510129495
0.007546629486553308
0.006174764226382233
0.007703349962947903
0.011027585641126152
0.005225985593446015
0.007754405843387558
0.0053908424671915
0.0026053214778660396
0.006161683153866104
0.00436766195667158
0.004355687164535612
0.004766587760444196
0.0056797692606058246
0.004778340378048607
0.006331257906400061
0.004945992080194993
0.0041635757931087055
0.005005706911969776
0.006018716940885126
0.00491158525600412
0.005293133009019385
0.005634081576460114
0.006195451695516047
0.006942889537969809
0.007045540386104217
0.005599788137292011
0.005824498323636932
0.005910631609737666
0.004767439180664037
0.00567226061455729
0.0066056981390117675
0.0055712280013879125
0.006671641696326
0.006575996471219165
0.006884677595061285
0.006825430873421724
0.007991465983284927
0.0045951415324314545
0.0057531115884193
0.00599258049827385
0.0057394969234708815
0.006888916712469792
0.007010196150215308
0.007532378353930169
0.008277163981960338
0.008294591097173117
0.008595289163440597
0.008788347610116098
0.009396572097045407
0.010395769351320291
0.00895783790872945
0.00793613264177945
0.007944947783513305
0.006022797686531637
0.005464409363899329
0.006167614074508611
0.006001761850513148
0.0052572166664591555
0.007041446357795445
0.007038080390912534
0.0062351276362821745
0.0073057761349238194
0.006593270210054912
0.005589735947667088
0.00687442685514283
0.007556119060738798
0.011058213801737613
0.010756243152638593
0.013146765387463693
0.01053748901706022
0.009389323378208326
0.009204292601152537
0.00806069598857681
0.007841483788671054
0.006262602760801496
