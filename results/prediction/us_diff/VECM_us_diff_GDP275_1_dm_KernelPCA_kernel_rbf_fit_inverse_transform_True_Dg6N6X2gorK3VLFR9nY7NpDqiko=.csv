# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP275_1
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=3, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.0005869462567597546
0.007589497563693394
0.00948297824873968
0.004420269265945446
0.008154374137381471
6.494659129218245e-05
0.0043808914352231835
0.000725213606871978
0.0031122612575680293
0.0031924627517595453
0.0020530802878843285
0.004485928885425973
0.007871884473453517
0.004595643803735374
0.007533317292421088
0.005667384888783411
0.005239591874549278
0.005240912783640084
0.003750444490536241
0.005234874871256225
0.007845643870504427
0.005823464375525968
0.01030444275326686
0.00827436431827844
0.008040492164412138
0.00824972169685547
0.010916157808911359
0.005496616715082674
0.010916614551493908
0.005630462623505852
0.007665581264072173
0.007356624971243206
0.004132941341161686
0.0027246555328219444
0.002648144328223582
0.0020182599742972034
0.0030296443657013366
0.002940774284607334
0.0028204340717774617
0.002811564845428785
0.0026355214474681732
0.0038954130855047365
0.0023401994147320116
0.0047574988434926965
0.004513060910068894
0.004133419707075859
0.004476830927282366
0.0038953390466347506
0.004165661988112607
0.003915064933650784
0.004363254920319
0.006763173197933477
0.006148116208693912
0.008209606865898085
0.005728493696333863
0.004495800508523383
0.00355105522381646
0.003563416488596799
0.003713826956638426
0.004152212849712211
0.003920351489737179
0.0041110316801440715
0.004684874643611791
0.004208619051996794
0.004163342205692481
0.005052965080874561
0.004543450565382698
0.0054100473626068814
0.006721939236724974
0.004699079332907194
0.006582514003219918
0.006374292823468909
0.007843654494023291
0.006365962718281878
0.0070090872103660195
0.0028771864800401113
0.0029853659764082336
0.003548496590597582
0.004158635356668469
0.004073829620563467
0.005419245492307337
0.007094271848871658
0.007166691175803397
0.010143140172551815
0.007341819045813155
0.007615708023479408
0.0042342010309837684
0.006450717010448026
0.004605246530230663
0.006750232000340658
0.00499229884815818
0.0066206479366924835
0.00692787738600224
0.005200135027361108
0.0096587888219444
0.00972600557339033
0.01214912331369813
0.01254939024909841
0.012492662587957028
0.014924413439795288
