# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP275A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=11, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.00020778861457776453
0.002200640292885501
0.003369801849878537
0.005870961902778858
0.0028199768823458267
0.00488457130328878
0.005473980370515023
0.005226143265970635
0.003195255725120176
0.0067294140868746615
0.002979874551967822
-0.016552360687654526
-0.0023236225910145004
-0.007204064871396012
0.003859592041870483
0.008437876201963315
0.010218093218099453
0.005009763906419416
0.004112433204361513
0.0059621018640621595
0.007630543258819093
0.006127244042039513
0.007697535199225166
0.01570591002626674
0.008624950150481793
0.006402249180016114
0.008888734490506384
0.00976655818431287
0.013647871649657388
0.012222217227372703
0.0077066578678250475
0.006981254577793088
0.0031647925407881725
0.009731608392078414
-0.006107465892610335
0.006600148646630109
0.0059033268573987835
0.001257186257378362
0.007614139308463584
-0.000436646335657984
-0.0013158384365629936
0.00019129115049530882
0.0014671868628424287
0.004777534259858462
0.0008195023687804759
0.0035492747392527257
0.0049258892224089
-0.002037412922881168
0.003346415078217012
0.002744048977436957
0.0016466151469080217
0.006514288267955009
0.005935762856210266
0.00463972002894123
0.0038632132121268845
0.004652441489481724
0.0006917245725041862
0.0015878306877907004
-0.0029280982134616148
-0.0003072399867886347
-0.0010470528169906615
0.0034241742617243725
0.004962996138676023
0.006036838873032238
0.007821159692499885
0.010369315208009992
0.00797424254360109
0.008956159651478545
0.00896857184860137
0.006649200422514929
0.0034262266595592363
0.005205376252113666
0.005756508449186654
-0.0016789918254181456
-0.0010642776475446461
0.00576228025864952
0.0019560678947308915
0.00549741369641446
0.004700938794685871
0.0011398229783451182
0.009416556269274155
-0.002328772972946475
0.011459951795653714
0.006183551770293469
0.006895095912598312
0.009181919192121177
0.0041036607137004775
0.010804529688346096
0.011705327292968238
0.01040054319447594
0.01868867332136213
0.004361982222240623
0.009476772610668944
0.005980442734775534
0.009896274482917794
-0.007700838433785448
0.011560115398511926
0.01892877415657672
0.012275293691939507
0.020848777394759828
