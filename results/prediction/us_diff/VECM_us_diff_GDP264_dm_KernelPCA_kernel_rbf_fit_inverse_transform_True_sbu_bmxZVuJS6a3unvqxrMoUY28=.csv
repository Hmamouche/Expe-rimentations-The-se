# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP264
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=1, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.005187323024768564
0.006866579604906256
0.003957390950735119
0.00643670263097987
0.005466009940163858
0.003784353119436801
0.007207392857222358
0.0017155414130760889
0.0031221177354983434
0.0051132225894574106
0.0040369013342019654
0.001976985989046129
0.001589086692145502
0.0058814342161052045
0.009656379310537309
0.007198562522888866
0.00406816615116545
0.003317293269038791
0.002258595233292273
0.0066080331542939874
0.002067745635519671
-0.0008519086593881517
0.0027222604937071713
-0.0008493201504158818
0.00028586829506348243
0.0011868406230673904
0.0024250128586274537
0.0039731894894345695
0.0021557436630465637
0.0016736352048511433
-0.002265352355370992
-0.0018631003537525265
0.0013392548339993544
-0.0014138259072569211
0.004776041341087596
0.007350778906788414
0.0021979376567435125
0.004635895697697736
0.0060621777703842765
0.003542162884533573
0.006292896380760111
0.009489301489039922
0.009580636645927438
0.010779125067558591
0.010474279798834125
0.011895269396583984
0.009202852307603107
0.004373290562222533
0.007883191490239524
0.005930064464049316
0.0036557756420127372
0.01033394667007672
0.0098395095624608
0.012141459963363766
0.013943995034497472
0.012649444099779174
0.016232870490572628
0.01799576527071005
0.01714345871652855
0.015296694473582556
0.014676692451864358
0.014288705806708966
0.017573432183564094
0.016801630421620355
0.01803251024504038
0.02261376700626657
0.019968932094406474
0.01808953600466609
0.020153098608337583
0.022749999789952333
0.018082538309154912
-0.0013080794169304747
-0.014809569033137533
-0.015594164427066695
0.007041940533961696
0.011844434061793061
0.0019279401680447348
0.015130905789028213
0.004495091929415656
0.005395647108872739
0.011349159836935432
0.023662506314398844
0.020180775773610625
0.02212182439608957
0.01721918962996051
0.02174352808992709
0.021306051334074674
0.006089641971023204
0.008036014142329635
0.023167505252286575
0.021668138755580376
0.00440047449699813
0.009460138452942534
0.011873192172678779
0.012220661284508995
0.004850351948659123
0.0003671021923768393
0.0038805920469356207
-0.004348932383565088
-0.008381387239365292
