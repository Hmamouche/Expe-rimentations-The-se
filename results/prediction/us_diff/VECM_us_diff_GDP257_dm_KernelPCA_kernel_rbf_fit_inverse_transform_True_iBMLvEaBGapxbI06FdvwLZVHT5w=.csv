# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP257
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=15, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.01750404517798077
0.03454432162751021
7.7176968685767e-05
-0.017302130440528352
0.01023969919704111
0.009227606333780097
0.01723156539519377
0.011834239960463747
0.004609806754269016
0.005388265870459496
0.030229050148492826
0.0036450875615649334
-0.00856010081804749
-0.0026458636412707856
-0.0030923455702575485
0.006227028950175607
0.011379844860531223
0.00986992086798466
0.011410782426860451
0.01451066547297781
-0.006376392711931941
0.02141006610512793
-0.0033429556478070206
-0.0069072385986427565
0.0009911546832715484
0.004237741323084253
0.01423566270288346
-0.010806102677980827
-0.015177216848272224
-0.011746367328039914
-0.007508367503253404
-0.002813492606461401
-0.0030590133784195632
-0.012259918076710181
0.002915410836684137
0.015576629196252877
-0.0010454230286680304
0.01813383881074709
0.010633885199184847
-0.0017041392434608317
0.021069261709903208
0.015912434415712513
0.023562109065672854
0.006739812862022207
0.018310081597957835
0.01530899355306588
0.00929993559315975
0.009343903052576787
0.013516179336778336
0.0008566412624170603
0.009507936462574333
0.019561218476681044
0.015930109280105336
0.012144242177725936
0.024626776176849868
0.011783017565790463
0.02348220291043512
0.027218553809421057
0.015884233279640794
0.020608326212149836
0.015170961226423814
0.014388962640554349
0.024138349742079943
0.018938321166456166
0.019171426183765973
0.017109345895949236
0.0014612576046278678
0.025065564911072244
0.011256751948363066
0.016949953667320963
0.0023630640152432487
0.0009820277544671059
-0.03444719408164513
-0.03018072295895705
-0.00507842393382702
0.000976286615564343
-0.0190817368009727
-0.006533679034813039
-0.0036152747211459363
0.00996753372051643
0.024376768309364957
0.02826619481263684
0.014568843025450083
0.008240068200183425
0.016684516045887377
0.02731989264005165
0.021195968865270587
0.00943676414440411
0.017664428587282108
0.009491656158902828
0.01569652351382548
0.0025882991183847712
-0.0008910049042630706
-0.0065385513779918185
-0.019781345782745964
-0.0040899986752245395
-0.003594127321857742
-0.02732297226979839
-0.018095560053079378
-0.002211008900554612
