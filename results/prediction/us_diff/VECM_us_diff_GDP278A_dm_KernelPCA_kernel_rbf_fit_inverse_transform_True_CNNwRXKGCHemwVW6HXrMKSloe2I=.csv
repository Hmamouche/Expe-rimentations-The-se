# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP278A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=8, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.0005923889462738508
0.0067218640455591555
0.0022201061554087756
0.004663226704184261
0.005463851914505648
0.00045931902722678574
-0.0005469768581473967
0.0015624208158525356
0.002414907072660015
0.0036469189850900875
0.005576983379159125
0.005356603713642463
0.009974611671041068
0.00762538637654152
0.0021152299305104284
0.002065399162676838
0.002782517743839754
0.008970474786277719
0.009299130274037342
0.007637254603561386
0.005649350980385149
0.012594749721592118
0.008154617245971545
0.004358119623978066
0.003929583694438338
0.0037920724642400293
0.00414216481779947
0.003694796545266741
0.003951659460475351
0.005209668448864257
0.004489756606802754
0.0032577615305841544
0.0013144048233234987
-0.0005336942029573698
-0.002092880293912488
0.00014943702170352872
0.001701865417187747
-0.0006538051398905212
0.004970680930881943
0.0032692641483668384
0.000822527032827538
0.002366267872740608
0.005475004914645961
0.007509337903662091
0.0052887121310447194
0.0017629931320986647
0.004970436973903633
0.0039500520690235056
0.0007621846699506265
0.0006483359838729985
-0.004220995717844434
-0.004390203962406786
0.003924618813259068
-0.0002745797913267414
-0.0014007463140709362
-7.11969052130962e-05
0.0006613497559949675
-0.001041654254889418
-0.004320756853949582
-0.003835402893137169
-0.0012792731101013903
-0.0014309683567918117
0.0001297131546912425
0.0011508849241596993
0.00032539299941640654
0.0015551589732799677
0.005396365081956825
0.003911773313910385
0.0037176057010900247
0.003320230910341829
-0.0010024119015646915
0.003895905483510578
0.006450924766163547
-0.0010508750294080755
-0.001987393593945907
0.001215615470782622
0.0015795676834881407
0.005942510785265219
0.0070274649720656794
0.0004871796982372188
0.003685804617054664
0.007522217955618594
0.007222955175115936
0.015659727332557643
0.013187563601831088
0.011282150814098266
0.01158965361569698
0.013389703434156281
0.01363740687293942
0.016280150742447968
0.016408533583207676
0.01171563423121511
0.007732753612604911
0.00992094597179482
0.005677540012469917
0.001543749253721621
0.0033611694041025884
0.0012998600547148435
-0.0024561708876250712
0.0013216111134965699
