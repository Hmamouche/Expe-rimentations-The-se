# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; IPS10
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=6, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.011547161995794907
0.0034001617514458453
0.0195126507374324
0.00948963606380312
0.003352654462411283
0.007172650891459423
0.011574125449101181
-0.0005357887779892255
0.0036945467619997115
0.0011129585303205688
0.007089070465335985
0.0014319894025687056
-0.008742775440283472
-0.003968714663361487
0.00665374556930729
0.011592029179434218
0.01204695475435559
0.00824711267592083
0.013710461178500253
0.017857831237689414
0.01259339905407075
0.01392674987647155
-0.0027706474994809312
-0.002331585737082434
-0.003639795927311346
-0.0036118025645822615
0.0041444122631711985
0.00276679663417069
-0.0032332764226638
-0.00845901875985794
0.004192733886779061
-0.0023687233875153584
0.008417902477181586
0.0014962047483091266
0.006898962544286307
0.003274542225936179
-0.0005569371166756173
0.012548643274003382
0.010364826951815674
0.0038440638698102646
0.004472987440221119
0.010337755080669954
0.013945095100309762
0.012097948184922535
0.011760324851231496
0.017171138661541227
0.0050444748757303235
0.003709506408998562
0.012939364308997345
0.007865313419493192
0.009205377953236213
0.013528557036912308
0.01489547393507908
0.019396976477588774
0.014522936182426824
0.017809490232279082
0.02235788993812054
0.020441547938281367
0.01829512964609572
0.01841159609268096
0.008048302290445631
0.00733559185476162
0.01662348064735767
0.009529731171840288
0.01766031181555355
0.01785428389050431
0.012318290173363899
0.008903272162225627
0.009245964153320423
0.0017433863207057644
-0.005345503927027762
-0.004963874464537417
-0.014625103292172016
-0.02021781847372728
0.00296790452455284
-0.0023113036297862798
0.002831468657658238
0.000310976697492576
0.0005870142094853842
0.005498637333372608
0.010139997677568296
0.018677462660737512
0.009047165372228404
0.005723267201917127
0.0021332530474181917
0.004834689597161556
0.005981863472796422
0.00599733608748405
0.011231089224285767
0.007994028716863734
0.014306007101470234
-0.003937558912574184
0.006109441262035835
0.009597093640224557
0.005492723076353084
0.0044715925687380574
0.006466897776892723
-0.000587974238229704
-0.0054705624148276445
-0.006901389416954987
