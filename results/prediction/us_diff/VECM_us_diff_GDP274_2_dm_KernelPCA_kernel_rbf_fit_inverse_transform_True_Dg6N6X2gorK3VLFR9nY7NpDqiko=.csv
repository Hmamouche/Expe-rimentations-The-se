# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP274_2
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=3, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.0005573521177101122
0.0033852049844613364
-0.0037870894814460627
0.0050889260678036955
-0.006019920247514588
-0.003990564962621266
0.003528363931567918
0.0023540236074399918
-0.020315965962987223
-0.007717491989154404
-0.0023169136773006386
-0.010548016556563367
0.004700893521242755
-0.003625464543607483
0.008366779461333526
0.0025541669506339583
-0.008734813499907753
-0.002673743253790911
0.0006588241144768214
0.005423164426946637
-0.001673531727116707
-0.0031971116295087696
-0.0017356535281603334
-0.008361391924686448
-0.0003095365869719278
0.0053573579787051274
-0.0033948626059995715
-0.005833019337577518
-0.0024066308528509096
-0.006261081738712242
-0.004469317986127924
-0.003294213285358087
-0.008228928828972564
-0.010165277316940585
-0.0013362555286220894
-0.0034084378455104397
-0.011701067379082705
-0.00800547779166359
-0.011511203626722036
-0.009047130959478369
-0.006378862727821571
-0.006356404168752521
-0.0007915479193939239
0.002736326220371655
-0.0005092740189793382
-0.014284708324758769
-0.013372203862747368
-0.00878479995436981
-0.017178743290358796
-0.01997836599862481
-0.015028693144355124
-0.021396095832289238
-0.018631587258433318
-0.018744913546391802
-0.024678337140806292
-0.024432919194579728
-0.0217099961595575
-0.02005979384210616
-0.019909899505173054
-0.017324498364141676
-0.024577344020007896
-0.029126039660249476
-0.020323210285900412
-0.01605647672439323
-0.020953689402520778
-0.02152615123648898
-0.014022053392428832
-0.010285642671440356
-0.015240325356208454
-0.017784349182090813
-0.01971426927642717
-0.020877216048713055
-0.015963866364324862
-0.01521558052867038
-0.020687770547157924
-0.016856372023314574
-0.01061646269897091
-0.020675264353445074
-0.014886394422954023
-0.018694662973323242
-0.02035413725748241
-0.014121668195876373
-0.005669489018671871
-0.008764553522599408
-0.013141638814200315
-0.009471169850121103
-0.007627988539565688
-0.008847692175661705
-0.01305292871507025
-0.01108583291252998
-0.009603157729345814
-0.008383795165900708
-0.01191498103677854
-0.011364308438859397
-0.009649875588399227
-0.0101134148923691
-0.010598709543654838
-0.011582176079012314
-0.007842777874782516
-0.008683791794208341
