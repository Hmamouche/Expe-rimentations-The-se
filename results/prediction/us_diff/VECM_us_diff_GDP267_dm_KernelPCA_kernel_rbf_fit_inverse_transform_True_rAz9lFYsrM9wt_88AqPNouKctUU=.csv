# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP267
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=5, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.003976400445195423
0.0014282083515645932
0.0018283370703349334
0.004442568998930505
0.008531757434560031
0.00674956728861612
0.009085264295683971
0.009181090823178471
0.011337650954746786
0.012931903064367563
0.011819069847339141
0.009492194657811537
0.010508692871270455
0.01534718370745115
0.010021288972823696
0.001921409753504052
0.0026138324458431046
0.0022925844461555516
0.0072767455722898
0.005619282680809312
0.008628796174871067
0.007235415123659545
0.008633752652774624
0.006758669565572434
0.007264928668536231
0.00899395105318485
0.00956989840532148
0.006351780873638427
0.006262675126884201
0.012623004276147144
0.005479508512544351
0.0024214620393429053
0.007031088543094816
0.004672235905925314
0.005912551451927225
0.003097493754562231
0.0027291956223853926
0.006496981794256817
0.0048472725705428245
0.002482056933480648
0.00543388928418361
0.0012188840570115248
0.0030743296040256097
0.008566916449763273
0.010817832632280002
0.0033989476539837476
0.007952105282567578
0.0070992161997910285
0.005758941220050646
0.0062037891119576735
0.0008500474221981049
0.008007235799743051
0.00819640585245872
0.005498264891571665
0.010661410812074399
0.009530985554356858
0.006890119176526473
0.007426487986970709
0.005580106138863051
0.007821475345552333
0.015179893282744404
0.00982336671508554
0.012568374694955906
0.01407534166181236
0.013025714225456463
0.013768994471595648
0.009991818694444269
0.00629583497906769
0.0062674382257237714
0.009344948373287419
0.006761909672329206
0.009961572489130953
0.005889054591359622
0.009154396363401889
0.017144571458649158
0.013549893561666037
0.002929638858293392
0.008911774269309353
0.004249408160918491
-0.0010209527888469284
0.004327475807869937
0.0021093058685725586
-0.003110518856585985
-0.0023429845306987955
0.0016596683137252467
-0.003222704857172176
0.0003408171041209587
0.001328866606071271
-0.0020179346801830174
0.0028659918808122808
0.00041727852349250443
0.0033816771653409038
0.00433272751282304
0.0068863202269266585
0.005517684700339516
0.00808348305641221
0.007703236774059146
0.004913825623819057
0.004335618525411869
0.004170237064832711
