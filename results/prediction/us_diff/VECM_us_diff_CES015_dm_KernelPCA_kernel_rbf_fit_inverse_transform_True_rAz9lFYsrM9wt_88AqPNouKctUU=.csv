# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CES015
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=5, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0406937935058875
0.03195576056330506
0.02952857222943434
0.0077956370350118
-0.03538086794625731
0.0009854130579739547
0.013188119611594431
-0.012584543924266639
-0.015000806126954007
-0.007675992950276177
0.004767747023903617
0.00371497476262409
-0.03082514889781906
-0.028275943763758686
0.011742687193021212
-0.00748055307885484
0.013564741304808822
0.012463579519590318
0.003371558561867544
0.013448744567726623
0.008880440284080473
0.02395549989996476
0.0078035733779641715
-0.020233660920005152
-0.02056610088945536
-0.002203345301240736
-0.0008057471709259144
-0.008640831896356194
-0.04148736310510316
-0.05210077437297547
-0.042146176781543775
-0.004324242923511035
0.032168341911273726
-0.013082658713817488
-0.014679824301126167
-0.017593137644883825
-0.015710424579551328
-0.0006265506500059905
0.0021068868851304152
-0.01767945918119824
0.00417689071345532
0.018146384022941272
0.018521685936162453
0.010700158531678147
0.010715031727933345
0.02417380864207691
-0.010605652702793981
-0.0079371106564032
0.005341340525883643
-0.011131873291479088
0.0041629562137725186
0.009973964679670252
0.000780915818706257
0.026023534253004004
0.0009637375343379557
0.011023756573976261
0.021764290756754748
0.013964575131019879
0.00994921664572749
-0.008942853833367482
-0.019666769409346953
-0.00765862031427376
0.01284447868172315
-0.022640322257183612
0.003049774572089157
0.007789245602980761
-0.0070628847884667105
-0.016780760283525105
-0.010479019945817606
-0.022274561804182
-0.03279009649618691
-0.03999618803374493
-0.06081042705551063
-0.0651438264124829
-0.01758140407600626
-0.037765933500640496
-0.027957687455264668
-0.043225010617918835
-0.046678784282702196
-0.029122451698429863
-0.012685049921172675
0.010577000003586063
-0.004691726961989637
-0.01736458495406424
-0.010989887062271405
-0.00546361643694589
-0.009313573105686306
-0.011988166852362998
0.0025391161390864257
-0.004112388970244824
0.009274263211979413
-0.009838959089609566
-0.021433234077635484
-0.01424054297977917
0.0021617049584382983
-0.004570601790270093
-0.02266352525033985
-0.020488617353204463
-0.030160640569316433
-0.018922493137351875
