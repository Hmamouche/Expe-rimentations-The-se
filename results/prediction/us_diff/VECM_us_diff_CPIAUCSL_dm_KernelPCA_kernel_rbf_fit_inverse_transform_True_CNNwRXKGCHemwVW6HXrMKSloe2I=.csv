# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CPIAUCSL
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=8, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0014289625655818016
0.00687689940312022
0.007267368667276577
0.007456344748215837
0.005918464941840202
0.00400069812695771
0.004972564530113211
0.00438690087774212
0.004918251509609821
0.005959525276516091
0.0032050582577173702
-0.002834110634152276
0.0025294825059273426
-0.0008599137911030521
0.009446528538216922
0.004350127403937477
0.008017677904808087
0.006015950122785924
0.005413675708691338
0.007531463722518134
0.0064647168181037025
0.008404621488307696
0.007690297067023414
0.00900049713644227
0.005521384521773436
0.00734422042615365
0.007760013071442954
0.008057074691999068
0.011171565208243849
0.008802010317939396
0.009522261482426115
0.005273930668740089
0.005986070976723605
0.0065443134649475964
0.004344596091259243
0.0053442697924561446
0.0061875367368526045
0.0077607534967246514
0.006301051905299018
0.005183697535784494
0.0035912538925639355
0.0051696548541611785
0.004744329005556621
0.00812520667896169
0.004641155748231976
0.005374661114885549
0.007191516714376643
0.0041497173539476765
0.005393173655474609
0.003836417267748397
0.004770345905560705
0.007919341291414656
0.005527192099115503
0.0064937975411847185
0.006120777281990711
0.004590608268112485
0.003084937767282244
0.003982179700372748
0.003015917061773227
0.0029338625228996777
0.0030405846827610107
0.003183049515471481
0.004749958315776759
0.0058934650580311065
0.00523071010793037
0.007987192611331727
0.007272692206530276
0.007378706863852155
0.00862568901337833
0.006555702289090536
0.0077545080354340275
0.0047101808205048615
0.006091918596510268
2.9298603271036075e-05
0.005011651345301756
0.0039260145951366485
0.004788700896076941
0.007331352698332219
0.006566806384766802
0.0024434372492457297
0.007855542034552456
0.000256564476051512
0.010032683336835367
0.006901700563812623
0.007044910548096648
0.008393421984719323
0.006998502250169222
0.008243269783563713
0.008771928634629037
0.010829585682667196
0.011246202243626404
0.008896945839389974
0.008718473583192327
0.003308734255313541
0.007431845760900997
0.0028864134987466672
0.008964456179651468
0.011538477607229435
0.008886758370188312
0.014153877455954164
