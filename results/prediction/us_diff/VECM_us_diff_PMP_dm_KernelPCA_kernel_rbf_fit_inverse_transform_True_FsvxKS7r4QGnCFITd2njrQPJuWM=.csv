# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; PMP
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=2, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.014358861590692724
-0.21515549095302824
0.03052524039039535
-0.07983511501061183
-0.09955829540782452
-0.05538373232758473
0.08085910503232249
0.09311253661088492
0.05858432877470127
-0.00958076990376694
0.023064749180373476
-0.00044745228932463726
-0.011156765964559195
-0.006188429200424713
0.02134279768783348
-0.025275119821162217
-0.04076398517539116
-0.09093767458210666
-0.004541762507984254
0.021831160978714355
-0.04561845373319227
0.025157599111106793
-0.08027106225119787
-0.027445200135101266
0.03396439958137075
0.024997718032459707
0.0507745276738016
-0.018285142205314686
0.03281576750813765
0.03468856029922621
0.08931919244098423
0.07881561325258962
-0.023045930354199107
0.023323595485702096
0.07215563419247498
0.011502007585406454
0.018409381354021943
0.01754749181955014
-0.02305900334011194
0.0589332503069314
0.015556982774294235
-0.021869346572154242
-0.04512191623764807
-0.027148967041475184
-0.10454129613147128
-0.01734856445012467
-0.11904887386409325
-0.010067286548567433
0.03522477985127202
0.05420782109764635
0.0759572912209283
0.0006856353653011751
-0.03115014493791646
-0.039548338722417135
-0.0641354471591605
0.03297693070291948
-0.04589930187768772
-0.0296079124559007
-0.006573346458825279
0.020790656729590865
-0.013610152043271123
0.02561611294503245
0.012501648377551982
-0.024288563517771915
0.02544976814330727
-0.020330097040962072
-0.03246871141851113
-0.059958218549121735
-0.020970236161725594
0.011728211254148716
0.10843163516561465
0.07091596004015455
-0.0019272418540046167
0.08492587878601014
0.1298731507427214
-0.0099979186417859
0.030641909476768106
-0.031086424354087084
-0.0003270104634485356
0.05714377822765543
0.0250661308819701
-0.01568701130137856
-0.06323381793843218
-0.03778992561134027
-0.04973217481939905
-0.01799229037618789
-0.010084022490020468
-0.019107397179350092
0.018660056900631217
-0.053209182879342
0.02148586165427558
-0.06398205737746715
-0.056799144934655904
-0.01940132463791739
0.01337788901255743
0.018757526450881076
0.0021301199820909986
0.03771286341389246
-0.06712273380170014
0.10216480230344956
