# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; IPS306
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=8, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.01049725588744306
0.023786745754242646
0.0140972774622572
-0.0023075138053161408
-0.011785348107050035
-0.03372468965494032
0.05977427965777987
-0.0376194412552106
0.029621025452299724
-0.02505964625463677
0.01622025051798518
-0.05562716209032122
0.01764768972382579
0.01768507193246647
0.004656268352415088
0.01991436797930477
0.008075623352419901
0.027978539556612014
0.04015656283070126
0.01830579282689751
-0.021287720835768964
-0.01151428896139962
-0.020369503416169374
-0.013368304251909047
-0.006792151676555948
0.0012544509107912296
0.002229967805310125
-0.015293204118609273
0.011095170214854264
-0.016947334864440288
0.03298491709380507
-0.012937794898395704
0.008726214697897187
-0.020045955955817894
0.012217083949848192
0.012244186231265905
-0.025460492056675672
0.02044154354533402
0.019066831565410485
-0.027294417737770044
0.00131800901675167
0.020376244736237156
0.007580117319070493
0.01769783136574727
0.004332306015286257
0.026312475100907454
0.037750798182493536
-0.011208105569101056
-0.0002771458614019154
-0.018251414333006095
-0.03439828691286733
0.03554699849680207
0.021665271121167687
-0.012449260125490233
0.03978459719561671
0.0066402377334703585
0.008027762884024101
0.002113537771480185
-0.012076032970570909
-0.02842927528494063
-0.033082618098673806
3.69345185378681e-05
0.01073155938484946
0.03210955050414675
0.03188317332906888
0.033265958861651325
0.012578520714383597
-0.004601041816786392
-0.006698329712218319
0.009296191669344648
-0.015962981486263843
0.0006469093005130825
0.01221671502483327
-0.02472732116957297
0.03904335494157049
0.02612918135378349
0.01296583212130668
-0.011102097694780261
-0.012435603745372226
-0.006131347783406381
-0.005948993913372251
-0.002350392268192552
0.029113985148879196
0.03455488504060409
0.024163779794922798
0.012254758935732345
0.04596487604448596
0.029964196725682127
-0.004135368823839268
-0.007000163295588242
0.02970780906022554
-0.011691803809040977
0.0034999264026333117
0.03747856595377146
-0.028782863133619864
0.002854367306854402
0.0303781200786511
-0.02413008294721767
0.017753008949495195
0.030055498694418266
