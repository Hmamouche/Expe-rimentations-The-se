# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; HSSOU
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=13, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.09830654369510711
-0.187889972325539
0.025219392580380265
-0.18829250764491656
-0.0878679021746537
0.030749445206805642
-0.0557816743419538
0.047349539567880135
-0.02197437068459751
0.029771137718021784
0.08486689277999099
0.13549294500384307
-0.13764723655887057
0.020605815845118114
-0.16016575337158362
-0.16281209457403323
0.09185154900934553
-0.028305458796215446
0.07303098337277691
-0.14085363469957074
-0.04122111350158243
0.014350156719296393
-0.032469958554934855
-0.003034622200069552
-0.05318642749831428
0.07429070699626909
0.0005370987851150318
-0.08153217231334464
0.033456022703456365
-0.026377979159626516
-0.053517815206425234
0.1292399486637805
-0.02353990581435392
0.010845345368331358
0.029327947392050864
0.045267247201981886
0.00684796401719248
-0.0799382046679031
0.060630398729301045
-0.09343618676819118
0.11466917907921663
0.05783068812421539
0.0005482736887916159
-0.067919101642758
0.09498904816462209
-0.09191782502365735
-0.02320696224834933
-0.02601718869112247
0.04885380873208693
0.0011770774972927715
0.018356889287317116
-0.00961843409797139
0.07273902161831845
-0.08096103575853326
0.06539257035648859
-0.04477454106920614
0.04696595445031978
0.011057527100781941
0.002454462735391773
-0.03287979050700454
0.08310322597550888
0.04161826870701531
0.024339399043492756
-0.00862598786816857
-0.033450339573029744
-0.04251036154820766
-0.046666953833610324
0.060736184063099385
-0.02452182156503968
0.05358018110147081
0.035835588547102414
-0.022075450535976822
0.04439973278768717
0.032825323252419755
0.07472339092593679
0.0877019943561077
-0.012213613865118919
-0.017573170118297926
-0.03473613848064394
-0.05868104502093471
0.12946372771251013
-0.04525202928572621
0.0018868276803525423
-0.012406266791574742
0.013145356668010894
-0.0032989177268312984
-0.006189483659913009
-0.008990957337270837
0.03907997366693697
-0.007966400625882011
0.025714544752543575
-0.0064851364502352855
-0.052228874848948975
-0.07014872984241254
0.015351060986294567
-0.060025705971918766
-0.12203145401795013
-0.18900042227924346
-0.03503945019185862
-0.09166006401215392
