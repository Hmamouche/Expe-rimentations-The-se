# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP267
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=1, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.0004913636872511273
0.0028836991273392598
0.0016835769178148827
0.005586504965861945
0.007825555813922074
0.00603885262497843
0.009871657782884485
0.01078938619089503
0.010902602182996626
0.010184174052395596
0.013223134906964994
0.012925803048947778
0.011468451935759596
0.010313407317763286
0.007416182847154046
0.004237944330458933
0.001391050891683003
0.004577921271669277
0.0052202519878642075
0.006971946089457695
0.007696248755414402
0.006783322253961334
0.008334415822463661
0.006352088074050471
0.007107974794481815
0.009456144308856773
0.010106466445170274
0.0062047147038911885
0.00628701387528104
0.010698270710624472
0.0062467444814643825
0.003947281027897512
0.006202690382570995
0.003283074681665364
0.005593841977939099
0.007019693877576392
0.002904380723647566
0.003540035705340389
0.005023190001342196
0.0026309496373088524
0.0026216075623381623
0.004899349445161404
0.004362847266802065
0.006068234729122974
0.008428878798011123
0.004919363293123143
0.007938913143313027
0.007848966238388141
0.005915783034599213
0.006266610053221364
0.001308557781112645
0.006466748803291121
0.007048199517537985
0.0064630261789634545
0.010358824869544984
0.00992459695710806
0.008157839133662147
0.008114795245976825
0.005825603051489328
0.009195917046190924
0.013079157972349865
0.010086869400219836
0.012920115950913169
0.014551192274692978
0.01151530174339992
0.012650297423008458
0.01190547587004389
0.005643203524478712
0.006706685230139854
0.008949955454461514
0.007715545168603589
0.011042672441418018
0.004938655232554583
0.00961078031045503
0.013742888650146957
0.013251726917390402
0.003138449462994233
0.010962264221403074
0.004524451004936378
0.00016717024109697833
0.002319022917763723
0.000468324431231537
-0.002539772655618191
-0.0008700926485690797
4.656912306617855e-05
-0.0010489191897170888
-0.001436485131858165
0.0001615975462265711
-0.0015205507966463872
0.0019337204926933534
0.0009234300815974488
0.003506266417422871
0.004601291899369171
0.00546919466021617
0.007072180089261976
0.008062646521461842
0.007356298787261388
0.005644192021874194
0.005964935322817799
0.005737085514647059
