# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; IPS10
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=13, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.00865375064335186
-0.004107707700691044
0.016402506326536725
-0.01979771476788928
-0.0010732100075144602
0.004508908713667745
0.01018503039123359
0.01218594218344082
0.012573197097454579
0.017932574261142066
0.021142233430268456
-0.009343944928293088
-0.010358702258148143
-0.004615996499139277
0.006073627661403208
0.015995609793131825
0.013300782810903746
0.0054742217485594475
0.007628454498036188
0.013774867534830627
0.011978749849742993
0.014164929517767745
-0.008265808385337196
-0.002620523851468209
-0.008275492763084353
-0.0025579239081925135
0.006369095276982518
0.009992735698492104
-0.0010508398705383441
-0.00508498271293698
-0.0036589151585575052
-0.0004360563208404651
0.008601236356580735
-0.0013894309146203513
-0.0014390200050726273
0.0059042953910495985
0.0018687267344279547
0.01788627002887539
0.012035071240317316
0.00463717245913954
0.00781955182000786
0.006472070770387482
0.01855792115687547
0.008071341528634002
0.012431505994087478
0.012813140017318534
0.00762662060467427
0.007654388845728651
0.0015360758693821934
0.0024833880009398463
0.004764794993362102
0.017622590012610784
0.017312532866877475
0.017499724126770123
0.015608434104113
0.015438229101378069
0.021260255487793263
0.017930906758663934
0.017567480975666544
0.015925641179113433
0.008674829002818912
0.0030224465645047284
0.017006981978040916
0.014393212991770552
0.018842219397605033
0.018277232588720927
0.0063493669129109165
0.013300248936888623
0.0032001292047102617
0.0035580129232227658
-0.004940169484245112
-0.007365659165568477
-0.0186570130484452
-0.02446418040942394
0.008350217369294744
0.012151464780230253
0.004737891205516195
-0.0033293271323115376
-0.0041776083763591055
0.017968406171712456
0.005229518432657578
0.017792126772571228
0.008914701811880239
0.003005444875551939
0.00431296921815768
0.004360350710815534
0.0038992865177139395
0.006638948778868866
0.007711216523002172
0.007990458396372793
0.013517127312872076
0.0048277493967313475
0.004694920877512389
0.008935675798336018
0.013382616114660503
0.0010843012766433438
0.006748937810179018
-0.00763034896742381
-0.006370736544936209
-0.0044409238538855285
