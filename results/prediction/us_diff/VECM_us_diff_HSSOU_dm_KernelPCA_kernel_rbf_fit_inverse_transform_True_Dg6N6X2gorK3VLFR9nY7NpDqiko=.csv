# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; HSSOU
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=3, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.07112084133754787
0.019256417221852798
0.023484219168368268
-0.08411348614356685
0.02754160698953803
0.015037039477063231
-0.01744414234781857
0.00447940670876331
-0.03207959779719964
-0.010415700037030108
0.050154423052031896
0.01902813917162717
-0.06463961767869153
-0.06581722504166648
-0.08266926869620904
-0.12776491888636596
0.0013115569757436727
-0.03673133960989507
-0.015395568700362888
-0.09242442885135975
0.021916683854856185
-0.014201142600431444
-0.024154976495388558
0.021971725158290868
0.0264192620110519
0.024208522231008167
-0.0016986352067441708
-0.03319506400551037
-0.02152661672625865
-0.036409422581453535
0.049947676021509624
0.050300456067446146
-0.012259031925120085
-0.021734824233312015
0.01928611087187277
-0.014441469247506554
0.011328159795467781
-0.010555427984318445
-0.01462526192557828
-0.0068994303305506864
0.01623285810314765
0.07772167035363939
0.012887030446987822
-0.037901048321638334
0.02372147611522799
-0.04516523735582859
-0.02290862725009991
0.016309560848556382
0.03510507223360106
0.06069845277905938
0.04481122963440687
0.010656251039013673
0.026570256842370354
-0.026252849301494845
-0.027560383847502493
-0.02053405385795731
0.024118150887537722
-0.011432034990684611
0.022444735550084527
-0.01372446687333951
0.06252044600273599
0.06929306078649707
0.029829302985441855
0.011343234662394343
-0.04730748603011475
-0.042373838870829364
-0.02106878785795833
-0.03810088874533066
0.008869507671782937
0.0035670606060621453
0.05510438113526758
0.06235349356785664
0.06866218397465819
0.0395223592157609
0.01047584909767552
0.013296758275425195
-0.08148450204274665
-0.0012119591701113402
-0.02674883401104186
0.0333062098427504
0.02934245026811694
0.03554554844184465
0.004499969697510178
-0.04172541326662954
0.024731696758045117
-0.002885187957177725
0.008003680359280467
0.030755949611057543
0.03567412751810095
-8.029375042189861e-05
0.06867436117132233
-0.05355452016080856
-0.03872751491698828
0.01291456629958889
-0.07872356873863318
-0.05904442828077225
-0.04414574313154152
-0.11743997723563432
-0.02184060336441987
-0.06303918281571398
