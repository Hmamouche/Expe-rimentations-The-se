# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; FYGM3
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=4, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.09821822331874006
-0.07606661426589402
0.08989948205711831
0.01100508414322323
-0.029393975314749708
-0.07540290995086374
0.07531889604416911
-0.05811358179014548
-0.03652337230094604
-0.07005514434136004
-0.028541998873876498
-0.007190233749801472
-0.05429686315258166
-0.041400015154947734
-0.014452311410816637
-0.019777678743858315
0.01128146224493633
-0.02037726691392331
0.06804304952992939
-0.007131851399929394
0.02791339677142371
0.011348276553122313
0.02827911453217002
0.0028895487518021366
0.009452125367879878
0.028484832302681076
0.0021406716786536613
-0.021152948469000035
-0.07856955231477772
-0.043457132720255164
-0.032755398772910456
-0.008674435715729118
0.019100888494251927
-0.023556870983536458
-0.003927618543021809
-0.04733070944160599
-0.04699137604621525
-0.01474480009258005
-0.0397489470183766
-0.021348874814395426
0.0034707081541543693
0.012020114933590403
0.024202326736970616
0.012150945789851146
0.01707387600846893
0.055720372845882604
0.0072314271212262915
0.018165834672910143
0.02358597806650345
0.005076183178370941
0.004406027068568243
-0.007434742684010081
-0.017192528981836656
0.038286286416383285
-0.009358640681998617
0.020367574990210156
0.03226769894357114
0.006493095249276725
0.010843108932698003
-0.028664716367673662
-0.0263752740103057
-0.029293726646343388
0.0407497531486821
-0.053544567418720365
0.014691977861882251
0.021157047621615174
0.027892897822089525
-0.00975858788096139
0.007366317115352333
-0.019486151304793954
-0.026952201873693543
-0.01418182350611836
-0.05940945818625637
-0.10092855829901554
0.015069289836421668
-0.0738051329559884
0.0010737711626228903
-0.04659776928377298
-0.03761783432434503
-0.001158481664291334
0.007912552588467339
0.042816815470525
0.030968128515844878
-0.0007513254520680502
-0.013254885846450426
0.012995409163458586
0.0016519935713459463
-0.0008198821975341465
0.04424802562161309
0.022234398908018472
0.052217131786675974
0.01345974218229272
0.016691706272007882
0.0007543363991751959
0.05064419471249684
0.007971714769881793
-0.0025350262532742368
-0.03536686899950654
-0.05499940135341572
-0.036722597351747086
