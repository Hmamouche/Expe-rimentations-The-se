# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; PMCP
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=14, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.05043835571524774
0.28309684883411507
0.015755453004292902
-0.06771675576783283
-0.07233512642539212
-0.13476116902547344
0.158033669915983
0.10565409468618558
-0.04818617229449818
-0.021088590337983895
0.21819591221916998
-0.09810533384874945
0.18621952841427145
0.1236793473054572
-0.09281261406633012
0.05587495823761242
0.1231323816036082
-0.1797065289927497
-0.10772603247327152
0.19009931517476739
0.05612129492934895
0.08588023371529055
-0.01676530708285199
-0.1635970327064715
-0.06298334284424455
-0.1351901930043216
0.0697772143549896
-0.08626674547255783
-0.004710399305946723
0.13885527477494858
-0.09818552603671543
0.15461777227707732
0.07417296272702488
0.08869566420178475
-0.13245167952538675
0.08718180033475553
-0.1837558274901236
0.011461983690423921
0.05276876426502767
0.004661925259890905
0.0589773786264544
0.05413524857852134
0.024850109878597107
0.13549114884513513
0.05603529349150112
-0.05674893797722636
0.05415143821736684
0.027762117300441813
-0.10091450359386975
-0.12448302709583747
-0.2158170068235044
0.19230345895231432
-0.07660980022310979
0.026694952256306546
0.08798521074107904
-0.0550710596248486
0.05051910308596828
-0.057351183125758445
-0.077533276308684
-0.007006883382525302
-0.1220420771162308
-0.09564780007329143
0.08648148212605578
0.07509024241387341
0.13749905970317375
0.15730709535968676
-0.024545759189108854
-0.09127621143949345
-0.026741359024897146
-0.08790092370428179
0.010919691327943556
0.05979930926047289
-0.0674806602715305
0.024735432577197326
0.18230908597593165
0.08511349105011956
-0.14225613584985747
-0.040403723351033066
0.047162242918009294
0.16052417765050409
0.0449197371533963
0.16876950821853112
0.049837968151947964
-0.010860460453660237
-0.09493697775088801
-0.023308430326754725
-0.11410284462625242
-0.0038075198691931017
-0.02692986710808217
0.05421189651154153
-0.011575546434819124
0.018406004942961875
-0.07843091956525956
-0.03694617279004758
0.08461448903001655
-0.05385515722836847
0.08063040337367831
-0.12695178262392778
0.049756407157719694
0.04344775912470771
