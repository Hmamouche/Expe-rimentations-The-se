# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; LBMNU
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=11, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.008400800636377981
0.024517188810589105
0.01969065332948286
-0.0018567825441509755
-0.001958403653481308
0.001954274590241348
0.03128087761281982
0.0063042546680785756
0.014408550085492126
0.012645947547109865
0.010551035122422892
-5.73255322255696e-05
-0.002660311318360265
0.0041340279048077124
0.0035643378142803392
0.021606559141352788
0.017986393821725243
0.012214836148816086
0.014460483975298937
0.010086955610145075
0.005855815040867547
0.021731337122320636
0.010886128295246017
0.005098623784560203
-0.0012715675966034528
0.011973625033798346
0.005506330920207183
-0.005549186306805533
-0.007417135081499747
-0.024221253799345525
-0.01676472682383582
-0.0067778234966636855
0.010001079614957548
-0.002291691676275496
-0.015615338136075518
0.0020947453537493864
0.002894076977525478
0.01265550662940931
0.019735863028871564
0.0020219246758296904
0.018771692677086955
0.016923589409610095
0.020512805109721928
0.01278462988998113
0.03304976967789432
0.015598950893368012
0.02015330780686312
0.007123044001578168
0.005365814478203134
0.000983222678316623
-0.0005291989171777962
0.008732907312626301
0.01863405929407033
0.024730790476869775
0.02374565802095902
0.0024993494442908165
0.023302444419005072
0.010627226628461042
0.004221931889406137
0.015435907456930947
-0.007079607291856228
0.011171516638508265
0.023121218478217492
0.00930135399176797
0.02030409220001205
0.013144349840899966
0.002193105898756157
-0.002971991919672242
-0.0010894151545663526
-0.0013975686253000306
-0.01507044150041024
-0.011155700146120986
-0.024818125577477715
-0.021406766620002553
0.008159741477333508
-0.0017107141128543685
-0.006185614224711642
-0.010946118614973563
-0.011919644593799534
-0.007265685811085606
0.007399942452661129
0.008712700263390431
0.010554793175336797
0.0064747165482807265
-0.0017224270201883958
0.0003673142755000825
0.002781863023976615
0.004845252889185773
0.017484838141033913
0.008786964015813917
0.017059643792478596
0.005065230020478781
-0.0007302005434915887
0.008991724819964537
0.015758921516157542
-0.0013899480008148157
-0.010476461403294892
-0.008715610635204376
-0.01446310949924034
-0.009749297642477499
