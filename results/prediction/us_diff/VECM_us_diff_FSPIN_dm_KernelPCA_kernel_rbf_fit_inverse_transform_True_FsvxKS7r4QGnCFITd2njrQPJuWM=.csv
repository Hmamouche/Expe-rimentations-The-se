# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; FSPIN
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=2, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.004637071871789728
-0.00300534837414855
-0.003501632613141765
-0.003964453231397386
0.00047586997342731257
0.003169083512423671
0.003854404780700724
0.005167092344115628
0.0031955241647072963
0.005198080721253353
0.009289625312373331
0.010894676935368237
0.0011975996959526017
0.005097256132381409
0.018352089382444235
0.004476895949714177
0.010316981519381069
0.009238620833517211
0.000516137503752916
0.041054084893856285
-0.0037470610393863773
-0.02544598932646879
0.0046388714988060565
0.007801086496267875
0.011369979583287913
0.010678497591815527
0.007602725594871017
0.011950016117715298
0.006591602858595235
-0.0015633436243003857
0.010867401412780343
0.007732454841383128
0.0005717605209891554
0.006462387125925849
0.01341093304388961
0.004096638963722872
0.004337384183501435
0.006731700957291226
0.005079800805080449
0.004141692416659311
0.0035977450256169654
0.005411111514637337
-0.0005039703640795974
-0.0060614786750269375
0.0021793742354240205
-0.00042821730705340294
0.0004746986557826197
0.014541683901738604
0.019482107373079795
0.019991554149326324
0.02529103060006609
0.021037701394979423
0.012234420160734354
0.02106006727952855
0.021963532710228773
0.024912828211011692
0.04452425508258902
0.035255849536256975
0.04377349235397259
0.035225156591945826
0.05160526749247852
0.03707071677243184
0.023040328982899327
0.03864295654461705
0.06264175874816241
0.048741709796917616
0.05057581754610074
0.026206757349252194
0.03873206825056293
-0.027052212654731574
-0.04610232965417754
-0.06045664519085755
-0.06487360389202097
-0.025317612657698295
-0.02668502875729282
-0.02896013459218115
-0.07752276637946694
-0.021883482669616715
-0.06340952964399525
0.017169803456889964
-0.005565971810693158
0.032404833219308794
0.037809040249836744
0.014875516084098666
0.006977288687056984
0.024876898389184915
0.01895101914633155
0.013871282832239113
0.017609894379307753
0.0011502982264783132
0.030581868502202205
-0.0030431222661772466
0.015102646219202799
0.03531074621250223
0.02624719294510798
0.04963463573645963
0.018059729846593344
0.041093463840888064
-0.03419465303001042
0.013679912413208097
