# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP275_1
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=8, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.0011739894725141969
0.009287763083748535
0.0065679283585010715
0.0031689276817013744
0.00690284024815473
-0.0006255812745177148
0.00424473870945347
0.0008237387948849105
0.0035249801972531145
0.0023628777423967107
0.0031690038316473934
0.005252173308221381
0.009530725427440944
0.0019329283738096742
0.007234210874546813
0.0054139454497031
0.007838263382174119
0.005095042115604858
0.0018974581726901923
0.0059469019883163455
0.00742929619413
0.00823917446217838
0.009707471215820359
0.007817629496612626
0.007286772950919976
0.008648913126902866
0.011662915215794637
0.00458293245149666
0.01263572721542989
0.004063749708948998
0.005497050104961058
0.0040922351140431365
0.0072035246322213545
0.00380937832298935
0.004050256594734804
0.0029401007780636263
0.0027860957281220806
-0.0011030222257339237
0.004121448079179289
0.0019993776917060163
0.003966264829851877
0.004054360298008773
0.0015588446894687145
0.004279436418903044
0.003660347282222709
0.006159376104698971
0.0031248741408983864
0.0033163309857092127
0.004708466707748586
0.004958434035888729
0.004995181605293811
0.007229981392293652
0.0061842879561455465
0.007369859106517559
0.005248496279529745
0.0039890456501451635
0.0034631794117040288
0.004264976920622091
0.0032600251893632804
0.004631816233548594
0.005494609827845719
0.005445759358303802
0.004548328505607564
0.004454500264338115
0.002668705555191756
0.006455022045236184
0.002050405278544587
0.005289073656696036
0.0055298743376273754
0.006507123846679326
0.008729792757672978
0.00512278185656473
0.00737433247430211
0.005456160072255981
0.008993851978109821
0.0036937413362990532
0.002304317296916136
0.0028098173037425503
0.004327662938422032
0.003638082460635533
0.0034678459041944235
0.008517047563019428
0.007762155393957646
0.007563043987382711
0.006374100340314563
0.007946736379887716
0.004154080752193198
0.007223006087500972
0.004078787943542809
0.008031350454988855
0.0042735267231571155
0.005611830578031812
0.00667305182877598
0.005193432021725074
0.008292080370782778
0.01066874390311521
0.013123637544420601
0.0122077147573056
0.011380553273863546
0.013603221553011986
