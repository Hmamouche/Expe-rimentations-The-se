# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CES046
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=11, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.008653016254843434
0.009840788096651681
0.007526560669860027
0.006859385662560847
0.007475855278580191
0.007829308467139284
0.009486914040927897
0.00946283935104847
0.009658089688447913
0.006529824057338841
0.006343148025325996
0.0049143692182175396
0.0058056186174678705
0.006920490817566036
0.008433400768384341
0.008766153219695446
0.0069135584560934
0.009165023012336078
0.009003872762865918
0.010025219668990554
0.008848137747074844
0.011683182701112425
0.007059139819569633
0.006764250134427656
0.004065497745862826
0.006067145975592484
0.007825648186695967
0.006084109467225936
0.00013886843004445328
-0.0022968424971714294
0.003297362781387009
-0.0001364077332200197
0.004200494288729203
-1.1492288542713964e-05
0.00142603590782704
0.0030178083892362993
0.0029597477003416427
0.006603996327953904
0.007584122068300758
0.006409316441779899
0.008957900573267423
0.007613090910032143
0.00795773585543237
0.009645262687577821
0.01044674928350143
0.009208692744282208
0.009057824317205136
0.007576306206997322
0.005727308667147601
0.005262654957990056
0.004505154469523198
0.008023860589516561
0.00776842348023463
0.00862829263856668
0.008867486720329646
0.007860707192928976
0.00812448269445939
0.008086568787159343
0.007620596528646132
0.008280157362044691
0.007614502912091766
0.008110069554381932
0.009473887431891178
0.00970558554869312
0.008953571373743493
0.00992427503127082
0.007921094326712761
0.00763227223743924
0.005035457936133093
0.002572806170636834
0.003074529139307248
0.0007789120484056829
-0.0020398180301056746
-0.0025769083555414987
0.0016848264862036428
0.001608541581482116
0.00048825997591233424
0.001565498033208075
0.0019830477195698993
-0.0011126882507692224
0.0028979886058689694
0.004623440910463404
0.002776277994873528
0.005990125944694417
0.0036702695408734887
0.005567769618320347
0.0052597307905887705
0.006042821959699967
0.009968468000879707
0.0049391922324207695
0.006598687242576108
0.005438628316105394
0.004635751536012763
0.007263154933259819
0.007640787479661194
0.005335286105616353
-6.486858780840075e-05
0.002931661842313157
0.0018763970069956971
-0.001655888395891994
