# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; LHELX
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=1, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.008866517364252358
0.029923516787302658
0.020187655957029406
0.026592547796002605
-0.002478079598344953
0.01630780164381146
0.010188723006721459
0.014982902907158747
0.017456796590199525
0.012696457958217944
-0.0007876159452268792
-0.007181109683791233
0.008461951161134643
0.011822438321755314
0.01818010782096636
0.03205076668505983
0.035987699490559424
0.019779429490204743
-0.0005403938069458904
0.018938639594244074
-0.005028150058843688
0.016767869853436083
0.00658695514016693
-0.014237698937067396
-0.02040282722404177
-0.008231042105953969
-0.007674840486251298
-0.020763956843153915
-0.04368626221367726
-0.07236814904123064
-0.058229855988043686
-0.021814454903919842
-0.00544428778763593
-0.011134540571333208
-0.004384384391411273
-0.017692944420035703
-0.01152744528969666
0.01612134169855865
0.011361019608939468
0.003059423482977381
0.023586243685372876
0.01996955004587586
0.015832430305780267
0.030060035472337557
0.01294371585286257
0.04013941080817531
-0.0014858516841199545
-0.02461564108516456
0.003310738227852936
0.011984800659447788
0.00971393871533707
0.004116638917299503
0.007033167318419824
0.008668290014934094
0.013400957268388294
1.2963669367009253e-05
0.018251730416115355
0.02435912882593609
0.014115482473900275
0.021544076839919366
-0.02163380465560127
0.004239092238122268
0.03309382649327211
-0.003956764119087058
-0.00992376569704823
0.0067236941095847515
0.018930785504587724
-0.01611347697133695
-0.038460566975664766
-0.011541030821590656
-0.05710332498806508
-0.05748710180931915
-0.06475127808068652
-0.06954458249455381
-0.003864979820125314
-0.022199385800705497
-0.006476855629672018
-0.021109291527068995
-0.011991327678608176
-0.022756823107723492
0.00842021272673415
0.004378192441340909
0.010600090427302616
-0.00391897039695448
-0.010177605890265604
-0.008293319952942505
0.01472668163561395
-0.0020709380409012555
0.0050749501083728246
0.0002620343002299422
0.00987334756273849
-0.017262703234477966
-0.01720345796077019
-0.0021591016453254112
-0.0005885873136681924
-0.005068192921129676
-0.02114983938964267
-0.011277131329578588
-0.010057041742911268
-0.019951434879248706
