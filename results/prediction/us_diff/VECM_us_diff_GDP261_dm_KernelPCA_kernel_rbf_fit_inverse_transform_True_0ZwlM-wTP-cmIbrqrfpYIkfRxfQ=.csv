# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP261
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=13, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.021169457645039674
0.00803092478627699
0.012499350754462176
-0.04913462320824867
-0.004782828636894922
-0.01441203087797499
0.030429338503019793
0.060912760363694106
-0.00928806618120303
0.023851178933361174
0.05587154975689031
0.02741092165881149
-0.011495294193403519
-0.005516349995416272
0.0029316527051159533
-0.012862038398480522
0.020989964166220097
-0.006528098875234889
0.0027409639205397754
-0.007957760438847359
0.026143533059020653
0.04831282178096086
-0.028836504063168768
-0.01707556315708858
-0.0027787472614741494
-0.015453151252905448
0.020652571116247995
-0.03199136366880672
-0.04214215389872848
-0.03734450562142823
0.0105656079424641
0.004784891310282429
-0.022307086202559733
-0.004913105813064275
0.017327633775103476
0.029352970165805365
0.020961153872203674
0.012725991944609069
-0.001160375626047993
-0.004762433069024045
0.02983315631285759
0.03003137136653134
0.03373009425154388
-0.02451664872675556
0.030084444007921183
0.008152660414185846
-0.002744895678407447
0.0002765686851762053
0.0015018834582234174
0.006863332723330423
0.0125087680911752
-0.0018210266265994129
0.004586544853207622
-0.00024969972619543965
0.02365601165894437
0.004384988899496629
0.01929056971269503
0.009074369576744585
0.011598860128219847
0.009512957447866803
0.022408562176860512
0.012573609448684214
0.021403229856275945
-0.008436682558737378
0.002622659715450681
0.007927674938052348
0.015426252755191383
0.005394640755286466
-0.015555484280007893
0.014768580409352292
-0.00224722276985927
0.012964751542748256
-0.030170417687905942
-0.008125167289442865
0.05997754337008957
0.036216172418282934
-0.0007675992695617018
0.010586643148196583
0.006939430062895022
0.015630082237605963
0.03162586031607318
0.060487947517825005
0.02947551995112204
-0.012557307383903487
0.024939427675776858
0.014960988632106202
0.02726356766901852
0.023762738714483568
0.018969314394923754
-0.005357229272789768
0.008279302777871141
-0.0369405489684873
-0.05710796551428141
-0.03606929887772836
-0.05508312425041354
-0.03636184121467265
-0.06927578514979968
-0.09321587014910669
-0.04525329231002166
-0.0507281976864331
