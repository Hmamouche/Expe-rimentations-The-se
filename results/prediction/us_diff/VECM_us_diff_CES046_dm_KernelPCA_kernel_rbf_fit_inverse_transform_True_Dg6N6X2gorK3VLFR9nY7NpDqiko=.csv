# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; CES046
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=3, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.007027060569926931
0.008314580028415211
0.009231699433128425
0.008892600029981787
0.007571080000299025
0.009859723375107156
0.00853241193040326
0.009176515204996434
0.008517631760079377
0.008112615810328913
0.006001652456259883
0.005307761243469977
0.0064956190381278344
0.007376136353616301
0.007475009755006732
0.007890013671669546
0.007922056907221175
0.008751021222788058
0.008419615633075297
0.009745504812449254
0.008143200318257049
0.009875164881141077
0.008820673142344691
0.006108342471299646
0.0042293186453408824
0.006001227312644784
0.007921058850325813
0.0060148853653922765
0.0019829823234185752
-0.0006963517633942414
-0.000879723843934153
-0.0008035620925828028
0.0019546926068280783
0.001131663753471293
0.0027346949298275238
0.00345508096920468
0.003224757754542844
0.004990876873541778
0.006038995284923813
0.006323688237793829
0.0078358501617147
0.008525781411919842
0.009081230822803446
0.010436781661827968
0.009924223550286885
0.009902546172481052
0.008769593750909207
0.005567267669270603
0.006440248013038824
0.005652023879982793
0.005288137010605822
0.008341581717155723
0.007283714085698212
0.007877331767505193
0.007801929329123772
0.009132617714228696
0.007856350254085535
0.00933977460134416
0.007567353804358544
0.0075980259474529984
0.008150650586124398
0.008444493698788335
0.009421308655175877
0.009415564630438052
0.008944445392118996
0.010212354797275336
0.008557328050402145
0.008627745638082785
0.004435782253060794
0.002875762851395482
0.0032392220133528275
0.0011614724690388394
0.00040706043140619885
-0.00414196884030302
-0.0006610049371608539
0.0007170019238661472
0.00039978043509401423
0.0019620709244541467
0.0006329776168545059
-0.0002064361184836502
0.002038272885926443
0.004782362552628983
0.00431614433772314
0.0059340283654221474
0.00418639176176879
0.005266267664164378
0.005721215632083407
0.00593411007914716
0.008073165113168747
0.00582019198398832
0.006553266204965811
0.0052269243172760075
0.004487541090114935
0.006055534654165034
0.0068959196078568884
0.005772267005662069
0.0020618129078675777
0.004538569099547509
0.0025898717103181976
-0.00025855564199342895
