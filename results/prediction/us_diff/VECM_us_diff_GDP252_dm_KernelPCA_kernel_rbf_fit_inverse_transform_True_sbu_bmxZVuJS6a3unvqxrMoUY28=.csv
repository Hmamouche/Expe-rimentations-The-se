# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP252
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=1, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.010225999548483774
0.007033292666027348
0.007749601897470502
0.006985972319552035
0.005857706944386483
0.007471004635042017
0.00869685284195316
0.009001178107145038
0.010278367607061927
0.008077668177765174
0.005649182317949302
0.005976115948113472
0.006607278738463335
0.0070347338465355826
0.005146497247980267
0.006176283486498159
0.006281725301087934
0.0030903990106188545
0.006298859250951187
0.006518188552274903
0.005861423193556843
0.007800569433326104
0.005508122993781976
0.004866522955044631
0.004916683950650638
0.004885647736390238
0.005904549486869191
0.004812824463432965
0.003809509512346616
0.0008887058840275188
-0.000589727719016977
0.0009764506035612189
0.0011355191810238118
0.001311214448577716
0.00393183106628861
0.003103663162052125
0.007053311504839952
0.007069397095718487
0.006182300067138787
0.006578919198843484
0.005932166143032979
0.006655402178526889
0.008034734346487021
0.007226319922755932
0.006029015691048463
0.006514561599411074
0.004323788099045062
0.005277378727902849
0.0051144604076447135
0.006635504152135701
0.007794353503752644
0.007507704585329965
0.007175426530224609
0.007477101721454515
0.006250993008851703
0.0068434365972995575
0.008379618947667932
0.008281966011036328
0.010422091608204752
0.010731459256227325
0.011747805955621938
0.013161219892147802
0.01218837689529523
0.01230130456068133
0.01161041067049909
0.011802956933478033
0.011680822165260505
0.011556990947937242
0.011162718115885815
0.008995347746910555
0.009071091173509665
0.007109408226517544
0.004839830371067744
0.0074928992759309525
0.008954237671927896
0.009799347961449375
0.006680483738074071
0.004916115738507848
0.00473684522163471
0.006388351431112366
0.008948178843467554
0.00981090716906264
0.010703401785632788
0.007965544439922322
0.008492839866232286
0.008915557265546686
0.009487352353384541
0.009112510968818328
0.009030328192168579
0.008877212811511003
0.008932223790093887
0.007313393986148995
0.009042398942565309
0.008348550843199402
0.009850623988821193
0.010391792837398441
0.008702987146028034
0.006347632163939212
0.004770346977706671
0.0043349804972748415
