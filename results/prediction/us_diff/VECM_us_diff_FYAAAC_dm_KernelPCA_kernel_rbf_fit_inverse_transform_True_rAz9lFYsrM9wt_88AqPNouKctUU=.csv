# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; FYAAAC
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=5, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.008633256890571248
0.00939943687771936
0.0909464264692095
0.013190068900958352
-0.0019490254393278277
-0.019807810737836266
0.005570399720847245
-0.02913655205439772
-0.048664262227846054
-0.06322353917991592
-0.05278616669275675
-0.01630962424522954
-0.076463095652096
-0.013120789965565406
-0.0516555333239018
-0.011046662740184511
0.05038930341661806
0.04439081876138009
0.061619875055663985
-0.02354203837712294
0.011133298580852793
0.028197970353177827
0.0062758175767496545
-0.0344821794172577
-0.01592936294779158
-0.020045530931937817
-0.021379484295474177
0.01664914606661317
-0.026028994103531045
-0.03304616478495464
-1.2641321592012436e-05
-0.007251708348230357
0.0005455555742215901
-0.003904876888143397
-0.005550189136428754
-0.008424402452165296
-0.03115682295089212
-0.004048016320811173
-0.0031229141711545433
-0.05744870987405333
-0.01961801400749025
-0.010990330735016906
0.016488668405095438
0.04338481660239742
0.026095012864839947
0.058181590816063486
-0.0013947168910989436
-0.022057005391366583
-0.026728929145481105
-0.027709905619487368
-0.01584082484634651
-0.005721287646492106
0.029152090621195958
0.0063149760676931965
-0.00033038795482839573
0.01954708912613333
0.023864511894451407
-0.015550560353201116
-0.010675305085399892
-0.029158723074458485
-0.019491391313505777
-0.044157795057458
0.029182074859920918
0.007017737618305764
0.008506037184095885
0.0525309337850653
0.030329878019985445
0.0018924096284128542
-0.003968914364371794
-0.020344168902628832
-0.04070489069557451
-0.00011781786763976438
-0.004367108387624289
-0.04646519206726822
-0.00559395115286185
-0.011472042068427595
-0.04201460129246437
-7.656999409463155e-05
-0.04438094329622874
-0.023468304519731295
0.012740560479949117
0.0045684784116059515
0.042554723169401794
-0.006396182307733089
-0.025771436439321886
0.005135378905179219
-0.02967434175638895
-0.023146094786773222
-0.016769823941062717
0.00556900736226788
0.023427618387351246
0.010019983609570519
0.006778901853128431
0.007431318449618581
-0.0037367267073762107
0.013454895697125636
0.023575721090004588
-0.02509985839394227
-0.027890005080851685
-0.013095921389732843
