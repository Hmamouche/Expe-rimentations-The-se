# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; IPS34
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=8, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.004844115918935146
0.010060571782623873
0.01574514758145558
-0.0038163120697516846
-0.0005961976730919942
-0.0011227174244721222
0.008482221777182226
0.0036055891505515866
0.006079641292721591
-0.0014938982497075255
0.006285603260215917
-0.0011716355573724172
-0.006243500046961829
-0.00515815953906749
0.00080388970309163
0.011773189515129328
0.009845093098038351
0.004733010102909564
0.010789822485179686
0.00856464784142839
0.009731598867019593
0.015569408427019238
-0.0022227549497839207
-0.005186179307880605
-0.008393719314789817
-0.0014119362963425164
-0.0023530676574846504
0.001020352261982486
0.0036760185724419754
-0.013248180495585137
-0.0046344299489590145
0.005296911525253224
0.0007444159661464363
0.0030429569016389105
0.006534032332128747
0.007914415880441786
0.001379364779331515
0.011393553271916802
0.007726444832645106
-0.0008405734611032889
0.011465796722032982
0.014284301254590072
0.015293049072108173
0.011655512188931743
0.014379610957340687
0.010996707746819698
0.01142018691027486
0.0067568478825743485
0.005791539704813417
0.006823463047463764
0.010013902294181268
0.021785705457048905
0.01976232455479013
0.023731595500104223
0.022785340100380743
0.017078906933583167
0.028334897448684993
0.02234020529877459
0.021899269739688816
0.020632041179979615
0.011480774331625898
0.014224096841165408
0.02076938069296619
0.018949949410807947
0.029113386372822937
0.032755301354911545
0.027823610984604126
0.01505266110818653
0.018635516064000948
0.00578680982373209
-0.00882116662038334
-0.0012393285181805363
-0.019914317388263353
-0.026220531823593678
0.012449652620871828
0.015990289618277524
0.0077524995720296315
0.0058972348654708065
-0.0027307171536853784
0.005442885206646205
0.01965662248120373
0.018101842640568487
0.013502181372900535
0.01353598558873782
0.00478841972655227
0.012096666397041217
0.003592227624694151
0.006629354748414399
0.018738110409364357
0.016751002717593794
0.01764282863206836
0.0057514814276656175
-0.003196283537060854
-0.0023796139446295933
0.021456807119901333
-0.0015164689781230257
0.01590769573489608
-0.0026872001160628293
-0.007129177556034725
-0.000818619339453988
