# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; LBOUT
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=12, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.00048075633343415414
-0.008975598864164219
0.016589585890819512
-0.0008717559281142171
-0.0038153223346204367
-0.0018409571504081276
0.0015207721912432201
-0.0023740488765008104
0.018327243239210894
0.011269623686953304
0.017452886223595816
0.008033915920374298
0.002345931157420016
-0.0063429379436366964
0.014184054676738066
0.005280852114938609
-0.0034717734908385253
0.004301286526655557
-0.003982450744209574
0.0022688473590846713
0.0029444548902904303
0.015068639035725317
0.007482556546303407
-0.004762403108482386
0.0006368318176188971
0.0020199374372345882
0.0010911709524457753
0.007095442182474948
0.007000018022086387
0.004042919035022201
0.007964101998459946
0.00917122128783528
0.00038533535943810926
0.006046574785461374
0.007928736577041875
0.00703258011421562
0.005254491193905151
0.013565748559081943
0.01040879303589576
0.0002526681823235128
0.011651227440429448
0.002046195149574623
0.0041980980024430145
-0.004175317618456032
-0.0013720279605450498
0.006384621578433305
0.00046630221516649577
-0.0028348518773170356
0.00521652079530533
0.005901530645407044
0.004128978771836251
0.007332975525206038
0.0026011725209008534
-0.0008979741340917661
0.006964688787767323
0.005372259174850267
0.008908822458446571
0.005493663327066179
0.011524299122576302
0.004947864758294366
0.012703552623250505
0.00983473278789434
0.004543532877353846
0.00516579578489304
0.0012081692823056917
0.010623956243379782
0.012356475705085922
0.004639456297416449
0.010624562048824199
0.009378773512745818
0.010183112968366246
0.01357819764923798
0.006823187431068582
0.006016130945858201
0.01598926013638841
0.017655893500165224
0.00846815888156741
0.005225828065765634
0.011674645720788603
0.015318468888445574
0.013481365437731534
0.01623532454946244
0.023083497503713694
0.001339831384879809
0.00539386738815737
0.01507545231414993
0.012277074579998985
0.007746168836682003
0.0067623258587306105
0.003905089944488969
0.0034313922931513085
-0.0010840369432180358
0.0008400778571134187
-0.0025574893569674166
-0.00013149145708220072
0.004203020467561296
0.006971623835017376
0.00010406413790270408
0.009744825434868081
0.019509629456291103
