# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; IPS25
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=13, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.01226472806575005
0.0005887363307810131
0.024556539826208434
-0.012446168074042217
0.005767053440906497
0.0013067494301713155
0.009652227164409758
0.005084321606499427
0.0032281982918698896
0.011501209381388749
0.007589105199115426
-0.005203003410363151
-0.0010146932872457837
-0.003914725890421329
0.003617579163914266
0.01490335952000122
0.014020347683610828
0.012070431884205797
0.013871905137679927
0.014447440916585633
0.00479072523712948
0.008477002501620222
0.0001005543525197032
-0.003243039431281277
-0.00447843506655356
0.004204066829963812
0.01432511795715883
0.008884623445697706
0.007961839534642192
-0.008031756629496949
-0.013065187170707183
0.0032291305329094746
0.006743402886750129
0.0013966169588673482
0.0008605575713045723
0.011909593269912219
0.000175801193142919
0.014849866443373055
0.0059107630967589146
-0.003497110769858111
0.009408522455881287
0.012728567866386882
0.006549906579787308
0.004022658405197088
0.0134780487058463
0.013488904661786502
0.010556616712257128
0.007220548391909484
0.01281592971145465
0.001922945263801299
0.009394457135763815
0.017825506578831696
0.02115691174229616
0.019710789826260983
0.0272193058774733
0.028091327844432138
0.029292868759330484
0.028415316726120653
0.02447343232673247
0.013419402104844528
0.013059651326501737
0.011172291239248688
0.015332888039227057
0.013623831874487435
0.017119971634006165
0.01825089831204651
0.017149792005326757
0.021662395045179642
0.01024718196099596
0.005989213949320926
-0.009853686380306984
-0.037727415651657534
-0.044348691578795015
-0.03244678174050946
0.012081924959134745
-0.003353031354971674
-0.006963293973893314
-0.01092385288707205
-0.01739767645778154
0.007476175218257474
0.00890320478679035
0.013288662851065895
0.01873618036717636
0.008772725034558638
0.014334534161313786
0.007981927164281664
0.015198029505561293
0.011760077387920655
-0.0005786524589454982
0.0354456910678416
0.029820499057733693
0.025478346073013317
0.02411597796912456
0.010034273792876209
0.010604618087876931
0.0004954382942711864
0.016303729753868908
0.0087772506420872
0.0027940804031906397
-0.013196277205909782
