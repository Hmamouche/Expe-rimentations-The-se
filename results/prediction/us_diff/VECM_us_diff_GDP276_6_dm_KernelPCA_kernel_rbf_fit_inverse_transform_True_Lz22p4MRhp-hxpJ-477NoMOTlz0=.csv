# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP276_6
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=11, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.008013363657725672
0.006611088227023095
0.009387637983774875
0.007856293611468305
0.0055526858874508115
0.00537300860355892
0.004378050799012137
0.005410727709647605
0.004083326071951656
0.004775892574943169
0.004068932214033809
0.0040468243264325824
0.0035050208436139033
0.004785037025504749
0.0022576468369271043
0.005751508708342637
0.007522666190573306
0.006469931422372314
0.008000905844524892
0.00972484323943123
0.00975505484559442
0.01186836763957799
0.012154975272568307
0.008254917254164213
0.010872465384930639
0.009555327503285633
0.010199714263742582
0.010811528888141634
0.009412107569114843
0.010004285694985944
0.008115494438561164
0.009316036780219337
0.00864591421856039
0.008263041918466335
0.0071309756903640146
0.008589050398440623
0.008300732682525342
0.007694504788008818
0.008454342426475555
0.007519070484682376
0.007244114095902959
0.0068351002172627314
0.00790696801048303
0.006932936196133764
0.00685047299528777
0.007773682957376419
0.006825948386654837
0.005661678359479569
0.004658878186270082
0.006106432400374047
0.0028598644856408046
0.006858826479242033
0.004322158881226193
0.005864339140337382
0.0035328822553464907
0.005541129998684955
0.004243760345534177
0.0034976700981985756
0.004409494859950433
0.005375108324941068
0.00520993411619983
0.004224765839123752
0.004648177020012594
0.004412742931149638
0.004946789478791628
0.006604724388848903
0.005089993827316825
0.005985500429489003
0.006575078841850035
0.005945009675889642
0.009173764444320182
0.0073067741893141115
0.007913462778371714
0.005023892257949408
0.005020741945557477
0.00563933915341295
0.004975110892985491
0.006233105418251872
0.007936890471757947
0.009824248088017446
0.009423842995120111
0.011053913966552432
0.010865544387898593
0.008795551021515474
0.009065347216481093
0.007131604451277129
0.009868177530067457
0.007425527371986143
0.007974003778413027
0.008182423928354799
0.005463301054736935
0.007762649978466536
0.007661494930221979
0.008306872999367235
0.011348638585406306
0.008375268033347266
0.010280413102121848
0.004003842863077597
0.006305941883471661
0.005299321753272758
