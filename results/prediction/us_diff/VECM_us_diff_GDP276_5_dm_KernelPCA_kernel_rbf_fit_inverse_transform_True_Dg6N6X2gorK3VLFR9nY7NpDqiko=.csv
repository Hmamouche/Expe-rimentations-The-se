# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP276_5
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=3, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
-0.006991072572610535
0.01166263713450855
-0.012676101369245785
-0.0033322672370858517
0.027235611244452063
-0.0035991492644356937
0.027037679537401327
-0.0027408949211318893
0.0029984340560361778
0.005051688103072864
-0.0037924520050056742
-0.0023163638894875375
-0.002615854156931113
0.004625117573134748
0.008238393700635923
0.001062417710368588
0.010557926462885028
-0.000964574642647608
0.017127164664089443
0.001955253117796438
0.013620199949456013
0.0067875069336059525
0.006751447859182193
0.011832308538039528
0.00974860101222503
0.008673248855916407
0.004704649238079171
0.0016658146668450963
0.004164954769382511
0.0072564802804649005
0.01052668945283575
0.008962891805114412
0.005649492674134069
0.0015149362639446163
0.004413306855791932
0.009304545068836356
0.009741328523024034
0.0027503029580793568
0.007070623753296895
0.009154183248738193
0.011538731805466808
0.01108007621361864
0.00817263733808306
0.0025540813708673426
0.005766701164859767
0.003972630190865245
0.004197106366669556
0.0035653707243220646
0.007638621009778556
0.01052438705512685
0.005317828557077714
0.0025773725164768622
0.001707558481138832
0.0012937253205245712
0.007074721542614836
0.006134509908906176
0.005667627549849131
0.0018414536974177152
0.005588053327259991
0.0028647693523654602
0.007041711451440589
0.005389579397637116
0.004066353769589045
0.0016830726711877175
0.004450253383016639
0.0037930073860149537
0.006706258346796251
0.004831144377092166
0.005783593051316922
0.00819841311692521
0.00651727013272736
0.0039050585188848005
0.006941862775852288
8.72478618594145e-05
0.004036420273789847
-0.0005994270077461939
0.0021179945129748954
-0.0027805302947732525
0.008227292618149898
0.00268584673905774
0.008457338046141636
0.009100599634364713
0.007786519270199697
0.005131900271687619
0.00728755425396365
0.003996923117592341
0.009511333996180519
0.0049261505356566196
0.00922502981714901
0.011187107099172403
0.012356458144623871
0.005432680002404852
0.010086206165936732
0.008940683553994362
0.005497883418326009
0.005350834809738645
0.0046848060291873606
0.004011068994358671
0.011773708990420052
0.01092061612025403
