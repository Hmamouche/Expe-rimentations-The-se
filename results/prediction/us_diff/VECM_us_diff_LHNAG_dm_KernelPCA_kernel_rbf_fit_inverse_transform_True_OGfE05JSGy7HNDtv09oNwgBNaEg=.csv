# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; LHNAG
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=7, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.005420346432616439
0.011132058009576975
0.014781475634717031
0.01130634073940295
0.006090307626836666
0.0009471940651911365
0.014182516783489828
0.002657898160714483
0.005165566594299233
0.00793842538594068
0.010940685635796248
0.005320042709173255
0.0012518883354462578
0.005589462086259728
0.012611074178049658
0.01071941999410607
0.009038568868063014
0.0065076249110162295
0.007914346188881535
0.011255406759534795
0.01021775618997284
0.011522866772815256
0.002965085476519201
0.00399838326222266
0.002376339340180906
0.005710529806255121
0.00860172295060436
0.0023773194813451705
-5.9736446636732385e-05
-0.005066130898616557
8.468355399011323e-05
-0.001830029101328551
0.004521875674870002
0.002615620435304543
-0.00271224937100519
0.0006268870269968258
0.0008104054756529439
0.005492390433961483
0.008181442051524797
0.005215728907767616
0.011547155009160391
0.008090182406169072
0.006784139450409136
0.005000863148112778
0.0061855870985119046
0.010632062134477708
0.007130640806449942
0.002170322000034681
0.007316263440631025
0.0020517945157691713
-0.0005399231027218498
0.00418926619575663
0.007444661080134662
0.007671748434127388
0.011379478411073857
0.011024373776390444
0.008824261425847581
0.007989460669638234
0.00687094653858427
0.003695782009239641
0.0008691175318505434
0.004753873714814707
0.0073313622205586956
0.002645325635029306
0.009387557068407838
0.009489216869002653
0.01459846002701457
0.006707749907853637
0.008122249027916272
0.01603705764223973
0.007556963901597939
-0.005455624984104485
-0.003421936902825701
-0.006615426227675101
0.00742281498813829
0.0016204857812898098
-0.0012902678210786175
0.001159663408955134
0.0024112190214241273
0.004233013665017861
0.006236211665263924
0.008808377604624152
0.00618308185939383
0.000346829381600895
0.006057933600641993
0.005697179154986812
0.005089983135075469
0.007291761518844456
0.007489485437298188
0.00629080966768535
0.01119810898723965
0.0025579341197684347
0.003237135555928029
0.010176042270446831
0.008024672689357077
0.007354328830595193
0.0053938063412240535
-0.006312929819840938
-0.001746901641506374
0.0019748045386151314
