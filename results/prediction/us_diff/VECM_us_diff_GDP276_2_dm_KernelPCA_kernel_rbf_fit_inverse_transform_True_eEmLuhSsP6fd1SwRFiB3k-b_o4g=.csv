# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP276_2
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=4, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.013440672254095447
0.004565665220474298
0.008964763859740528
0.005268144106580496
0.01133860067616808
0.007981743626310782
0.004532941421815712
0.006304881609969136
0.005099318797496703
0.0034372904318147224
0.005246738710838176
0.0025128563291287563
0.002161726768852268
-0.0029836857464977085
-0.0013204258074411104
0.0014146112922037754
0.000778421781329476
0.00040393451468925297
-0.001636890455709594
0.0035774939169343984
0.0035858386545783594
0.004748939342899193
0.004089837813295517
0.004601726459186961
0.004393602120849203
0.003162208894744212
0.005033811506269043
0.004065079860394813
0.0004610689990000731
0.005358295940071091
0.012113836682593113
0.001454040935956847
0.006024707802943303
0.0077263689384330335
0.002639937651636825
0.004500969637239483
0.0033895295026455676
0.006161767956360467
0.004893593294665623
0.007124637445466598
0.007701868254997944
0.004342754780863183
0.0036583357292433614
0.0023716886562890876
0.0037590054250827526
0.001686340032541576
0.003829641652310615
0.0007797099436760095
0.0015127378408443365
0.003080636574506004
0.001766082708909821
0.00532519217432593
0.0060330947377739965
0.0037936696817191798
0.006285141355116582
0.0029842253513100445
0.0012128995231043315
0.0008698523204556962
-0.003622414816297032
-0.0007484593660970915
-0.0024566004565472685
-0.0004922385623024396
-0.000839641942060226
-0.0013310260100012584
0.0004754738126779088
0.0027496160395473544
0.0018559297883650318
0.0022299862492040218
0.004816305638676286
0.008508424354244488
0.02218004871510386
0.013782350729079379
0.006600565813411648
-0.0005962741908609767
0.003960905337212835
0.0004357605915920248
0.002448229529758153
0.0025923290803115994
0.011741581709969452
0.010736522466868108
0.00401925286964793
0.0005508741461200087
0.007335960423499067
0.005787176583202388
0.007709056119842948
0.006565380662697215
0.00765659521734007
0.013212599613882173
0.013697620539874875
0.03013271691009327
0.023054072961728882
0.00330310032662069
0.01466399999887099
0.013979237543346675
0.008998176032874216
0.005380933422722777
0.003862355802150634
0.006331660665503167
0.012019650597560796
0.026642041149350728
