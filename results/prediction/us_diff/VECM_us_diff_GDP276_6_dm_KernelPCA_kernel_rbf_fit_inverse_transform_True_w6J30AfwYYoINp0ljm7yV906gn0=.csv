# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP276_6
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=14, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.009680006553348908
0.009684744478816603
0.01187232214759918
0.006043235268686977
0.006007229037463471
0.0060077117465084555
0.003503479040545171
0.005041501588823646
0.005127634718484798
0.003191078691513938
0.0024609383942068978
0.002530530762871419
0.0032635265037890496
0.006223879128480619
0.0036918983653498588
0.006526733133048352
0.008134650460230923
0.006316391126176692
0.007834772659913558
0.007785912067716918
0.008917456724988383
0.012967297785984648
0.011790479164338393
0.007733572677723307
0.011219180666000406
0.010018049207953642
0.010692663456977482
0.009980517891192258
0.01025639484593816
0.009597633314861905
0.007218040594481391
0.008347591532421112
0.009990859992808422
0.008622324402624271
0.00675343381826964
0.008283401960285472
0.008855031147428935
0.006934703571233874
0.008886987156747456
0.006735100180955111
0.006595200950738923
0.007193104720924813
0.008699018081100681
0.00735224832396949
0.006828660858261547
0.007835886740710854
0.007090195573614333
0.0055723554171063835
0.0043544516456346626
0.005798691838329937
0.0027954005226316784
0.0075305835059664315
0.004458150209906674
0.0065694178392191795
0.0037717116349823545
0.005078424041804618
0.004441995845471078
0.0034612745920378795
0.004082122842156984
0.004690010585672599
0.005023223446216417
0.004906800628524104
0.004294790974858585
0.004716529166159877
0.005676957488882361
0.00671492140790604
0.004934199015921212
0.005641382202543102
0.006309415953936928
0.005223215485288367
0.009359692501631293
0.006508764325035604
0.008124346487521335
0.004664489108949291
0.005201293396862114
0.005855964826181372
0.005386150970815187
0.006797882481497509
0.007108029990042593
0.009359223229126851
0.008231201087425616
0.010764321007019295
0.01136328189962487
0.009021195630489004
0.009470918291310665
0.007029467207540108
0.009992741551977064
0.006791411022439213
0.00807333079156066
0.008703238134894148
0.005747425297620003
0.007403979243468144
0.007789170919654139
0.008174879189639633
0.010676836989381357
0.008800400489929536
0.010392136903802574
0.004606428148567017
0.006607102824295944
0.0052057984465787716
