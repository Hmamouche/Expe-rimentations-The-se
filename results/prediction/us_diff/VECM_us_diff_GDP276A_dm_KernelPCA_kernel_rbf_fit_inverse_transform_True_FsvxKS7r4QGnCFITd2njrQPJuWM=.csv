# name_prefix; us_data_stock_watson_2012;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# description; Stock and Watson 2012: US indicators;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# lag_parameter; 4;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# predict; GDP276A
# number_predictions; 100;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# horizon; 1;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# prediction_type; rolling;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# max_attributes; 15;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
# method; dm_KernelPCA_kernel_rbf_fit_inverse_transform_True(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto', fit_inverse_transform=True, gamma=None, kernel='rbf', kernel_params=None, max_iter=None, n_components=2, n_jobs=None, random_state=None, remove_zero_eig=False, tol=0)
# predict_model; VECM
Predictions
0.007046725634046833
0.00546941437782042
0.0058206836135928615
0.0076950548013922085
0.0069871628751823145
0.006034879044330886
0.006758033253209308
0.004468507426650726
0.0055088513624377625
0.0053440837319398745
0.005552945803627718
0.006765554361682805
0.006428577007700247
0.006089839793717827
0.004366914312251793
0.004337900105282408
0.004695599586937198
0.00542840886209636
0.0075240475982897
0.007816190082147923
0.008368171186081647
0.007411467101856377
0.007256191637028167
0.007008768458767875
0.00654998448382842
0.006563044650617056
0.0070095433613444995
0.0085027569764185
0.008377317351874351
0.007880854453953132
0.007928997450577908
0.006811801372808641
0.006812005253187132
0.0061508829258512514
0.007554217823715195
0.00792626360435301
0.0064999264265411414
0.006155600827706935
0.00559334422006923
0.0063608196602630155
0.005720943126488878
0.005444756675553246
0.005166874083360072
0.004433625661319494
0.006059037202988958
0.005855278656662646
0.005698348684430675
0.005433355558013573
0.005752834733826363
0.005882365097316778
0.004851234324403195
0.0056567849837584035
0.0059762835419445515
0.005873532805820197
0.005922467305820802
0.005637559298994589
0.004894933869409134
0.004594910886491235
0.004541013708461324
0.004150158302574174
0.00407344600154282
0.004709065981452718
0.004418711722048737
0.004731862838285172
0.004451089481156258
0.005160348683789376
0.006941207221359196
0.005807269683780047
0.005021081593066699
0.004991642898327777
0.007824950496232651
0.007518074758084741
0.006400107693829047
0.007539667054756298
0.006475456619151403
0.00634380067724178
0.005956816734688928
0.0061665130968848215
0.007753696765383835
0.007312820746857576
0.007441619712374395
0.00724102211525275
0.007676290936327372
0.007754902277758137
0.008083045507128328
0.007627991763608288
0.008233736274456416
0.008251833876151972
0.008081551754604942
0.009938946995605703
0.008729221543651628
0.008967363971899327
0.008903258313354366
0.008820022289048133
0.00864264175946884
0.008707856642602933
0.008656797142026666
0.008576843581005068
0.008844648873999009
0.00996664916984538
